<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>columnar-file-formats</title>
      <link href="/2025/11/16/column-format-compare/"/>
      <url>/2025/11/16/column-format-compare/</url>
      
        <content type="html"><![CDATA[<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>在分析场景下列存相对行存有非常大的优势，可以极大减少 IO 的开销。在 Data Page Layouts for Relational Databases on Deep Memory Hierarchies[1] 一文中，引出了 PAX 格式并与行存进行了对比。</p><p>以下表数据为例</p><div class="table-container"><table><thead><tr><th>column_a</th><th>column_b</th><th>column_c</th></tr></thead><tbody><tr><td>1</td><td>abcd</td><td>3.2</td></tr><tr><td>2</td><td>efdf</td><td>4.7</td></tr></tbody></table></div><p>分别使用行存和列存写到磁盘后的格式大致如下</p><blockquote><p>为了较好展示，以 <code>,</code> 为分隔符，且省略了各种 header/footer</p></blockquote><div class="table-container"><table><thead><tr><th>存储格式</th><th>内容</th></tr></thead><tbody><tr><td>行存</td><td>1,abcd,3.2,2,efdf,4.7</td></tr><tr><td>列存</td><td>1,2,abcd,efdf,3.2,4.7</td></tr></tbody></table></div><p>在分析场景中，读取某一列所有的数据是常见操作，但是对于行存来说读取某一列数据，需要在文件中进行多次 IO 定位，然后读取值，而对于列存来说可以直接顺序的读取某列整体的值。比如上述示例中读取 <code>column_c</code> 的值</p><p>在行存中需要</p><ul><li>定位到 3.2 的位置</li><li>读取 3.2 的值</li><li>定位到 4.7 的位置</li><li>读取 4.7 的值</li></ul><p>在列存中需要</p><ul><li>定位到 3.2 的位置</li><li>连续读取 3.2 和 4.7 的值</li></ul><p>连续读取的开销比随机读取少，也就是第二种的开销更小，因此列存在分析场景中开销更小。</p><p>文献[1] 中描述列存格式可以比行存减少由于 cache miss 导致的停顿延时 75%；range selection 的查询可以快 17-25%，TPC-H 中 I/O  更重的 query 要快 11-48%。</p><span id="more"></span><h1 id="Apache-Parquet"><a href="#Apache-Parquet" class="headerlink" title="Apache Parquet"></a>Apache Parquet</h1><p>现在工业界中的列存格式大部分场景都会使用 Apache Parquet[2] 或者 Apache ORC[3]。由于数据湖格式的兴起，Apache Iceberg/Delta 等均以 Apache Parquet[2] 为主要格式，其他一些分析型 DB 重点支持 Apache Parquet，Apache Parquet 基本成为工业界列存的事实标准。</p><p>Apache Parquet 定义了一套语言无关的规范，不同语言基于同一套规范进行开发。定义大致如下</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202511200846927.png" alt=""></p><p>Parquet 的读写流程大致如下</p><ul><li>写入<ul><li>将数据写入内存并记录相应的 stat</li><li>待数据足够大（满足一个 row group 大小）后写出到磁盘，并重复该步骤</li><li>整个文件写完（主动或触发条件）写入可选信息（ColumnIndex/OffsetIndex/BloomFilter 等）</li><li>写出整个 footer 完成文件的写出</li></ul></li><li>读取<ul><li>读取 footer 信息<ul><li>解析 footer 信息中的 column metadata（使用 Thrift 所以需要进行全部读取和解析）</li><li>使用 column metadata 中的 stat 对数据进行过滤 (如果有 ColumnIndex/OffsetIndex 可以读取并进行更精细的过滤)<ul><li>column 级别的信息是 row group 中 column 级别的信息</li><li>columnIndex/offsetIndex 则是 column 中 page 级别的信息（如果没有 columnIndex 则需要读取 PageHeader 才能对 Page 进行过滤，PageHeader 保存在 Page 内部）</li></ul></li></ul></li><li>定位到对应的 offset 读取实际的 page<ul><li>读取并反序列化 page 的内容</li><li>对内容进行过滤</li></ul></li></ul></li></ul><p>从读写流程可知</p><ul><li>写入<ul><li>需要 buffer 整个 row group 然后整体写出, 因此：1）写入端需要较多内存；2）列的大小差异较大会导致部分列存储的数据量少，从而影响读取时的 IO (多次小 IO)。</li></ul></li><li>读取<ul><li>对于列非常多的情况下，读取和反序列化 columnChunkMetadata 可能开销较大（部分列实际不需要，但必须要读取），在没有 ColumnIndex 的情况下，stat 信息过滤的粒度太粗，且需要读取 page header 才能对 page 进行过滤（page header 和 page data 存放在一起）</li><li>对于嵌套列（Map/List）读取不太友好（比如读取 Map 中某个 key）</li></ul></li></ul><p>由于现在 AI 场景中对于宽表（列比较多）和宽列（以及嵌套列）比较多，因此问题会更突出。现在工业界和学术界都有想办法进行改进和优化。</p><h1 id="Another-FileFormat-or-Better-Parquet"><a href="#Another-FileFormat-or-Better-Parquet" class="headerlink" title="Another FileFormat or Better Parquet"></a>Another FileFormat or Better Parquet</h1><p>对于解决 Parquet 的劣势场景，主要有两个方向：1）是造一个新的 file format；2）在 Parquet 的基础上进行迭代优化。</p><p>其中前者出现了 Nimble/Lance/Vortex 等一系列 format; 后者包括 Parquet Variant[4], 优化 footer 的读写[5][6]，以及在 Parquet 之上增加纯内存的 format 作为 cache 等；</p><h2 id="Another-FileFormat"><a href="#Another-FileFormat" class="headerlink" title="Another FileFormat"></a>Another FileFormat</h2><p>从零开始构造一个新的 file format 满足更多的场景以及硬件是一个很直观的想法，大公司和初创公司出现较多，Google/Meta 等有自己的列存格式，Goolge 的没有开源，Meta 的 Nimble[7] 已经开源；初创公司现在有 Lance[8]/Vortex[9] 是两个新兴的 file format。Lance 由于字节在推动知名度更高一些。Lance 和 Vortex 在 IcebergSummit 2025 上也有一个相关的 talk[10]。</p><h3 id="Lance"><a href="#Lance" class="headerlink" title="Lance"></a>Lance</h3><p>从 Lance 官网[11] 可知，Lance 的结构大致如下</p><p><img src="https://lancedb.com/assets/blog/lance-v2/wide-columns-grouping.png" alt=""></p><p>Lance 以一种更扁平的方式存储文件，没有 Parquet 中的 row group 的概念，数据会包括多个 page，每列的 page 写满后即可落盘，每个 page 会包括多个 buffer。ColumnMetadata 中会记录每个 buffer 的信息，然后也会记录 Global 的 Buffer 信息（全局的信息），最终的 Footer 会记录 ColumnMetadata 的相关信息（offset/size 等）以及一些其他类似版本，校验字等信息。</p><p>从格式可以知道</p><ul><li>写入的时候不需要 buffer 整个 <code>RowGroup</code> 信息，因此内存消耗会小一些</li><li>随机读取的时候因为有更细粒度的 stat 和索引，所以查询会更快一点（对于定长的数据，甚至可以直接通过计算定位到具体的 row）</li></ul><p>另外 Lance table format 有一个很有意思的点, 提供了 fragement: 一个 fragement 可以包括多个文件，这些文件的数据可以属于不同的列。这样可以在不重写数据的情况下支持动态增加列，并给存量数据的新列加上值。这在需要频繁加列的情况下会很友好，不过这个属于 table format 的层面，也就是说其他像 Iceberg/Delta 等也可以支持。</p><h3 id="Vortex"><a href="#Vortex" class="headerlink" title="Vortex"></a>Vortex</h3><p>Vortex 的结构大致如下</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20251118160924.png" alt=""></p><ul><li>DataPages 记录了具体的数据</li><li>Zone Map 记录某一列多行（逻辑 row group）的 stat，比如 min/max/nullcount 等</li><li>Filestatistics 记录文件级别的列 zonemap</li><li>Dtype 则是文件的逻辑数据类型（类似业务视角的数据类型），也就是 schema</li><li>Layout 是文件的存储格式，比如文中可以理解为和 Parquet 类似的一个存储</li><li>Footer 记录一些可以用来做过滤的信息</li><li><p>Postscript 记录了 schema/layout/filestatistics 以及 footer 信息，每个信息都是一个 segment(包括 offset, length, alignment exponent, compression spec, encryption spec 等) </p></li><li><p>写入</p><ul><li>Vortex 内 row group 更多的是一个逻辑概念，写入不需要 buffer 整个 row group 的内容，因此内存消耗比 Parquet 也会更小。</li></ul></li><li>读取<ul><li>Vortex 首先读取 footer 创建 reader，然后可以通过 zonemap 中的信息进行过滤，然后从剩下的 segment 中进行读取（可以通过 segmentId 直接定位到文件中的 offset 继续读取），然后反序列化后进行更细的过滤。</li><li>对于嵌套类型（Struct），可以使用不同的 Layout 将内部数据拆开，比如上图中的 Struct 两列 Column_A 和 Column_B 可以分开存储，这样读取的时候，仅需要读取某一列，而不是整个 Struct。</li></ul></li></ul><p>由于 Vortex 将逻辑数据和物理存储拆开，因此可以同样的逻辑数据使用不同的物理存储，这样也可以支持在压缩数据上进行一定的计算与过滤。Vortex 中数据类型有 Owned 和 Viewed 两种，Owned 表示内存上的数据，Viewed 则表示磁盘上数据的视图，这样可以按需加载。</p><h2 id="Better-Parquet"><a href="#Better-Parquet" class="headerlink" title="Better Parquet"></a>Better Parquet</h2><p>Parquet 拥有一个不错的生态，在生产环境中要从一个成熟的生态中迁移是一件较难的事情，因此在 Parquet 基础上进行迭代改进也是一个方向，包括 Variant 以及 footer 读取的优化等。</p><h3 id="Variant"><a href="#Variant" class="headerlink" title="Variant"></a>Variant</h3><p>Paruqet 的 Dremel 类型对存储量更优化，但是对于 CPU 计算和内存向量化（读取吞吐）等则不那么友好</p><p>比如在 paruqet 中读取 nested data 的时候, 需要</p><ul><li>根据 repetition level 和 definition level 重构整个数据</li><li>Filter 支持不好，因为 Parquet 的 stat 经常是 RowGroup 或者 Page 级别的，无法对 inner data 进行过滤</li><li>SchemaEvolution 支持不好</li><li>不太好支持 SIMD</li></ul><p>现在 Parquet variant 的出现则希望解决这一问题: Variant 默认将所有数据存储到一个二进制数组中，且包括一个 metadata，这样形成自解释的数据结构，同时可以将部分数据从二进制数组中抽出来单独存储成一个物理列，这样可以更好的进行计算和过滤。</p><p>Variant 大致如下所示，其中 metadata 用于解释当前 variant，value 包括了所有非进行 shred 的二进制数据，typed_value 则存储了实际被抽出来的子列。更具体的可以参考 VariantShredding[12]<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- metadata</span><br><span class="line">- value</span><br><span class="line">- typed_value</span><br><span class="line">  - [value]</span><br><span class="line">  - [typed_value]</span><br></pre></td></tr></table></figure></p><p>这样操作之后</p><ul><li>可以很好的支持 SchemaEvolution</li><li>数据访问的时候，可以使用 stat 进行过滤（因为单独抽出来一列，有 stat 信息）；可以使用 SIMD 操作（因为单独一列存放在一起）</li></ul><h3 id="Cache-amp-MemoryFormat"><a href="#Cache-amp-MemoryFormat" class="headerlink" title="Cache &amp; MemoryFormat"></a>Cache &amp; MemoryFormat</h3><p>Parquet 是一个非常成熟，拥有良好生态的 format，所以改动会相对缓慢，因此有人提出在 Parquet 之上搭建一套纯内存的 file format, 这个 file format 相比 Parquet 更适合使用在 cache 场景，这就是 LiquidCache[13] 的想法, Cache 中存储的是“逻辑数据”，而不是原始的 Paruqet 文件，主要考虑是：纯内存的 file format 可以比 Parquet 更适合 cache，且更自由的进行更新迭代（升级成本低）；可以复用现有 Parquet 的整体生态。</p><p>直接 cache Parquet 格式本身，然后进行 filter pushdown 可能无法提升速度，反而会导致速度下降，主要原因在于 Parquet 的主要开销是 decode 和 decompress（超过 90%），而 Parquet 本身也不好针对 filter pushdown 做优化。文中描述了将物理结构与逻辑结构进行解耦，这样 LiquidCache 可以将 Parquet 转换成 liquid format。Liquid format 结合了 selective decoding，late filter materialization 以及 endocing-aware predicate evaluation，可以比 Parquet 更好的支持 filter pushdown。Parquet 转换为 liquid format 则是异步进行的，可以不 block 正常的处理流程。</p><p>LiquidFormat 相对 Paruqet 的优势可以从下面两种图中可以查看</p><p>下图中 LiquidFormat 可以比 Paruqet 少 decode 数据（只需要 decode 实际命中的数据）<br><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191105278.png" alt=""></p><p>下图中则是 liquid format 在多 filter 场景下，可以应用 late materialization，在前面 filter 处理后的数据上进行 decode，这样可以减少第一个 filter 中被过滤掉数据的 decode。<br><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119110635.png" alt=""></p><p>文中有给一些结论，整体来说 liquidcache 拥有不错的性能，更详细的数据可以参考原文以及 Github 仓库</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119111018.png" alt=""><br><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119111040.png" alt=""></p><h1 id="Column-File-Format-in-Academic"><a href="#Column-File-Format-in-Academic" class="headerlink" title="Column File Format in Academic"></a>Column File Format in Academic</h1><p>学术界也有关于列存的研究[14][15]. 其中文献[14] 对列存进行了对比，文献[15] 则提出了一种新的列存 F3，并和已有的列存进行了对比，虽然学术界到工业界落地可能需要一段时间，但是其思路是可以参考的。</p><h2 id="Compare-between-column-file-formats"><a href="#Compare-between-column-file-formats" class="headerlink" title="Compare between column file formats"></a>Compare between column file formats</h2><p>本文[14] 设计了一个 benchmark 并以 Parquet 和 ORC 为例进行了对比。</p><p>Benchmark 中引入了数据分布的几个维度: NDV, NullRatio, ValueRange, Sorteness, SkewPattern 用来表示数据的不同维度。</p><p>论文中从 Public BI Benchmark/Clickhouse/UCI-ML/Yelp/LOG/Geonames/IMBD 多个数据集中进行分析得到如下分布情况</p><ul><li>超过 80% 的 Integer，超过 60% 的 String NDV 小于 0.01, 超过 60% 的 float NDV 小于 0.1<ul><li>也就是说 Dictionary Encoding 是有用处的</li></ul></li><li>Null 的数据比较多</li><li>大部分数据分布式不均匀，小于 5% 的数据是 Uniform，60-70% 的在 Gentle Zipf 分布<ul><li>file format 需要能同时处理热点数据和长尾数据</li></ul></li><li>数据要么是完全排序的，要么就是无序的<ul><li>对于有序的编码部分情况有用的</li></ul></li><li>数据范围比想象中的要小<ul><li>数值型的大小绝大部分在 1e4 以内（80%）</li><li>String 80% 的长度小于 25, 60% 的长度小于 10, 90%+ 的长度小于 50</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20251120111333.png" alt=""></p><p>将相关数据分类后总结成如下表格</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201122186.png" alt=""></p><p>在不同场景下 Parquet 和 ORC 的对比如下（绝大部分场景相差不是很大）更详细的数据可以参考论文(从这里也能看出 Decode 比 IO 耗时更多)。</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201123543.png" alt=""></p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201124790.png" alt=""></p><h2 id="F3"><a href="#F3" class="headerlink" title="F3"></a>F3</h2><p>本文认为已有的 format 诞生时的假设已经不成立</p><ul><li>1 relative hardware performance</li><li>2 workload access pattern</li></ul><p>主要原因在于</p><ul><li>最近 10 年存储和网络性能有很大的提升，但是 CPU 的性能没有成比例的增长</li><li>数据湖的出现也让更多的数据存储在高吞吐高延迟的云存储中，也让整体瓶颈从 IO 转移到 CPU</li><li>数据的结构也发生了很大的变化（数据越来越”宽” — 表的列很多，以及列里面的数据可能很大 — 比如 blob)，ML 场景下存储几千列的特征，以及高维向量、图片等 blob 数据已经变成越来越常见，同时应用也希望能够进行随机读取甚至对已有数据进行更新。</li></ul><p>另外文中认为 Nimble/Lance/TSFile/Bullion/BtrBlocks 这些新的 format 也和之前的 format 有一样的问题: 对硬件和数据模式有一定的假设，就算取代了之前的 format, 在未来也会被新的 format 所取代。</p><p>F3 则是为了解决这些问题而诞生的，F3 的全称是 Future-proof File Format, 号称是下一代开源的 file format，拥有 interoperability，extensibility 以及 efficiency 等特性。</p><blockquote><p>Eache self-describing F3 file includes both the data and meta-data, as well as WebAssembly(Wasm) binaries to decode the data. </p></blockquote><p>F3 的整体架构如下所示</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191116416.png" alt=""></p><p>文件包括 Data 和 Metadata 两部分，其中 Data 保存数据，Metadata 保存元数据</p><p>Data 中的结构和 Parquet 类似，F3 的 RowGroup 是逻辑的，因为写入的时候不需要 buffer 整个 row group, 可以单独写某一个 IOUnit（对应 Parquet 中的 page)，因此没有列大小不一样导致 IO 不是最优的情况。IOUnit 包括多个 EncUnit，EncUnit 是编解码的最小单元。EncUnit is essentially an opaque byte buffer that can be interpreted by the corresponding decoding implementation.</p><p>File Metadata 的结构如下所示</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191125566.png" alt=""></p><p>Metadata 包括 OptData/ColMetadata/Footer 以及 Postscript, 整体使用 flatbuffer 存储。其中</p><ul><li>OptData 是一个 keyvalue 的数据结构，现在用于存储 wasm binary （可以携带编解码逻辑），后续可以用来存储 index 和 filter 等</li><li>ColMetadata 保存了每个 RG 中每个 column 的元数据（包括 offset/size, 以及 dictionarytype, size encoding method 等）这里也记录了类似 Parquet 中 page header 的信息，这样可以直接从 Metadata 中对数据进行过滤。</li><li>Footer 记录 schema 以及 optData/ColMetadata/SharedDict 等的地址</li><li>Postscript 记录 ColMetadata/Footer/checksum 等</li></ul><p>在 F3 中 dictionary encoding 不像 Parquet 一样固定是 row group 级别，而是可以三类：None/Local/Shared。其中 None 表示没有 dictionary encoding，local 表示在当前 IOUnit 中，Shared 则表示可以和其他 IOUnit 共享（甚至跨 Column），这样可以有更好的灵活性。</p><p>对于 NestedData 的处理则使用 L&amp;P 的格式(有 buffer 记录是否存在，然后其他的 buffer 记录具体的位置），右下角的形式</p><p>最后 F3 最后给出的一些不同 FileFormat 上的测试数据</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191551919.png" alt=""></p><p>上图展示了随着列的增加，(所有 format）元数据的 overhead 基本是线性增长。因为不管 metadata 是否支持随机访问，在 footer 中均有与列大小正相关（比如 schema）的信息。Nimble 最快是因为存的信息最少；其他使用 FlatBuffer 但比 Nimble 慢的有一部分原因在于正确性校验; F3 比其他使用 FlatBuffer 的格式更好的原因在于支持跳过特定列的 I/O; Lance 需要读取和反序列化所有的 metadata，这也是导致它是所有使用 FlatBuffer 中最慢的；Vortext 可以跳过无关 metadata 的反序列化，但是无法跳过 IO。</p><p>文中的一些其他测试数据可以参考，更详细的可以参考原文</p><p>下图比较了不同 FileFormat 中压缩比、读吞吐、随机读延迟的情况。可以看出</p><ul><li>F3/Vortex 在所有的情况下都有不错的性能</li><li>Parquet 拥有不错的压缩比，读取吞吐也不错，但是随机读性能差</li><li>Orc 的压缩率不错，吞吐一般，随机读取的性能比较弱</li><li>Lance 压缩率很差，读吞吐一般，随机读的能力很强</li><li>Nimble 压缩率, 读吞吐和随机读大部分情况下都属于中等水平，少数情况下优秀</li></ul><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191656466.png" alt=""></p><p>下图中上面的曲线表示不同的 row group size 情况下消耗的内存大小（左右是两个不同的场景）. 其中 Parquet 对内存的消耗比其他的都要大; Lance 和 F3 都是以 IOUnit 为最小单位刷盘，因此消耗内存较小；Nimble 和 ORC 则控制了单个 row group 的物理大小, 但是这样会导致 row group 存储数据量较少；Vortex 则由 writer 控制 buffer 大小。</p><p>表格则表示不同的 FileFormat 的平均 ColumnChunk 大小，可以看到 ORC/Nimble 会有比较小的 ColumnChunk，Parquet 会有比较大的 Chunk，Lance 和 F3 的则会相对平均。</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119170350.png" alt=""></p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>随着数据湖以及分析场景的广泛使用，列存的关注度也越来越高，如何在新场景，新硬件下拥有更好的性能，本文做了一些调研，总的来说 Parquet 在随机读取、SIMD 等方面较弱，其他的相对不错，这些可以有不同的优化方向；新的 FileFormat 则从不同的角度希望解决不同的问题。这些可以让我们在后续进行决策的时候提供一定的基础。</p><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><p>[1] Data Page Layouts for Relational Databases on Deep Memory Hierarchies<br>[2] <a href="https://parquet.apache.org">https://parquet.apache.org</a><br>[3] <a href="https://orc.apache.org/">https://orc.apache.org/</a><br>[4] <a href="https://github.com/apache/parquet-format/blob/master/VariantEncoding.md">https://github.com/apache/parquet-format/blob/master/VariantEncoding.md</a><br>[5] <a href="https://lists.apache.org/thread/j9qv5vyg0r4jk6tbm6sqthltly4oztd3">https://lists.apache.org/thread/j9qv5vyg0r4jk6tbm6sqthltly4oztd3</a><br>[6] <a href="https://arrow.apache.org/blog/2025/10/23/rust-parquet-metadata/">https://arrow.apache.org/blog/2025/10/23/rust-parquet-metadata/</a><br>[7] <a href="https://github.com/facebookincubator/nimble">https://github.com/facebookincubator/nimble</a><br>[8] <a href="https://github.com/lance-format/lance">https://github.com/lance-format/lance</a><br>[9] <a href="https://github.com/vortex-data/vortex/">https://github.com/vortex-data/vortex/</a><br>[10] <a href="https://www.youtube.com/watch?v=p6ZKY8JViCA">https://www.youtube.com/watch?v=p6ZKY8JViCA</a><br>[11] <a href="https://lancedb.com/blog/lance-v2/">https://lancedb.com/blog/lance-v2/</a><br>[12] <a href="https://github.com/apache/parquet-format/blob/master/VariantShredding.md">https://github.com/apache/parquet-format/blob/master/VariantShredding.md</a><br>[13] <a href="https://github.com/XiangpengHao/liquid-cache/blob/main/dev/doc/liquid-cache-vldb.pdf">https://github.com/XiangpengHao/liquid-cache/blob/main/dev/doc/liquid-cache-vldb.pdf</a><br>[14] <a href="https://www.vldb.org/pvldb/vol17/p148-zeng.pdf">https://www.vldb.org/pvldb/vol17/p148-zeng.pdf</a><br>[15] <a href="https://db.cs.cmu.edu/papers/2025/zeng-sigmod2025.pdf">https://db.cs.cmu.edu/papers/2025/zeng-sigmod2025.pdf</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> parquet </tag>
            
            <tag> file-format </tag>
            
            <tag> column-fiel-format </tag>
            
            <tag> lance </tag>
            
            <tag> vortex </tag>
            
            <tag> nimble </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>价值投资是一种思维模式</title>
      <link href="/2025/10/07/a-perspective-of-investment/"/>
      <url>/2025/10/07/a-perspective-of-investment/</url>
      
        <content type="html"><![CDATA[<blockquote><p>交易市场往往在大幅波动（大涨/大跌）的时候会比较活跃，最近市场行情不错，整体活跃度增长，这里记录下自己当前关于价值投资的一些看法。值投资价值投资的好处：比较大概率能赚钱（逻辑通顺），主要依赖自己下的功夫，不需要一直盯盘（投入时间不一定少，但是不那么急迫），最近 2972 天的复合年化 22.03% ，基本没有盯盘，整体效果还不错。</p></blockquote><p>所有的投资都是一种 <a href="https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q">套利</a>，价值投资则是在有价值的资产上以较低价格买入，然后等升值后卖出赚钱。因为在投资之前就已经进行了重复的计算，因此投资过程相对简单，但是简单并不表示容易：1）什么是有价值的资产：2）什么时候是（较）低价：3）如何能做到不受波动影响。每一步都不容易，但是做到一次之后就会越来越容易，而且这个会有复利</p><span id="more"></span><h1 id="投资是一种资产配置"><a href="#投资是一种资产配置" class="headerlink" title="投资是一种资产配置"></a>投资是一种资产配置</h1><p>如果把投资看成一种<a href="https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q">资产配置</a>，所有人每时每刻都在进行资产配置，因为钱终归是以某种标的形式而存在。投资中有又会有不同的类型，包括固定收益和非固定收益，而非固定收益中常常以股票、基金等形式而存在，在股票中一个很常见的投资手段就是价值投资。根据个人经验而言：价值投资是挺不错的一种投资手段，能够大概率依靠自己赚钱，且不需要一直盯盘（投入时间少，不会有非常大的压力），个人最近 2972 天的复合年化 22.03% 也是一个很好的收益率。另外关于价值投资是否适合所有人，可以参考《The Superinvestors of Graham-and-Doddsville》[3]。</p><h1 id="价值投资"><a href="#价值投资" class="headerlink" title="价值投资"></a>价值投资</h1><p>投资实际是一种 <a href="https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q">资产配置</a> 希望能够从配置的过程中进行 <a href="https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q">套利</a>，我们希望现在的资产配置，在未来能够“更值钱”。<br>具体到单个投资标的中，则可以简单到两个动作：买入和卖出。那么就是以“低价”买入，“高价”卖出，从而赚取中间差价赚钱（当然可能不需要卖出也能赚钱）。</p><p>价值投资假定投资标的的价格围绕真实价值波动。因此在“买入”和“卖出” 的时候，将价格与价值进行比较，如果被低估则进行买入，被严重高估的时候进行卖出。对于价值的估算则需要对投资标的进行详细的研究，具体可以用未来现金流折现进行计算。</p><p>因此整个过程会分为</p><ul><li>买入之前  -&gt; 做研究</li><li>买入      -&gt; 根据研究结果以及价格进行买入</li><li>卖出      -&gt; 研究结论有变，或者过分高估</li></ul><p>实际在买入之前已经做了重复的研究，公司所在的行业是否足够有差异化（如果没有差异化，那么公司会获得相对比较累，赚辛苦钱），公司是否有足够的竞争力，产品是否有差异化（可以参考波特五力） — 换句话说：用户是否愿意同等价格（甚至高价）购买自己的产品。行业的事情也可以参考头部公司的阐述以及专业公司的描述。公司的竞争力是否能够持续（也就是通常说的护城河是否够宽），在持续演化过程中，<a href="https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw">文化</a>是一个很重要的因素，文化不仅仅是墙上的话语，还要看实际怎么做的。另外对于文化/价值观来说，也需要区分开 “做错的事” 和 “把对的事做错” 两者，前者是要避免的，而后者则是不能避免的 — 任何人都会出错，都需要从错误过程中学习。</p><p>在做了充分的研究之后，如果价格相对较低，则可以进行买入，买入实际是一个很简单的动作，因为相对于未来的价格来说，当前的价格是很便宜的，也就是说未来可以赚钱。当然部分足够好的投资标的不一定能够持续足够低的价格，因此可以在合适（不一定低估）的价格也可以买入 — 相对高的价格买入好的投资标的，比低价买入差的投资标的，在长远来看更赚钱。另外任何人都可能出错，因此要视自己研究的程度给买入价格留有一定的 buffer，就算自己看错了，也不会亏太多。这一点也可以看出越好的投资标的对投资人越友好，因为买贵只是少赚一点而已，但是不好的投资标的则可能亏钱。</p><p>公司的价值可以使用未来现金流折现进行 _估算_ — 之所以是估算，因为折现率每个人可能设置的都不一样，这个和自己的机会成本有关。在投资来说，也就是自己能找到的无风险投资的最高收益率。这也很多地方说的未来现金流折现是一种思想方式，而不是用来具体进行计算的公式。</p><p>买入结束之后，就剩卖出了。卖出的逻辑也相对简单</p><ol><li>如果买入逻辑已经不成立，则考虑卖出。这里分为两种情况。第一种是之前的研究有误，那么这种情况下应该立即卖出，因为知道错误之后，立即改正的代价永远是最小的。第二种则是公司的基本情况发生变化导致之前的买入逻辑不再成立，那么这种情况也需要卖出。</li><li>如果价格严重超出了预估的价值，也可以卖出。价格围绕价值波动，如果觉得严重超出了价值，那么也必然会下降下来，或者等后续价值再涨上去。但是“严重超出”需要自己定义，尤其是好的投资标的，可能卖出后短期无法再以同样的价格进行买入，另外卖出/买入也有交易成本，这些也会减少自己的收益。</li></ol><p>这几个过程中，研究公司往往比较枯燥，但是这个确实真正决定能否赚钱的根本。研究的越清楚，才能够下更大的注，才能有更大的定力赚的更多。研究清楚之后，往往能否赚钱、能赚多少在买入的时候已经基本决定（假设投入的钱可以长期使用，不会中间被迫卖出），卖出只是在兑现之前赚取的收益。研究公司情况是贯穿整个阶段的，因为对于单个投资标的来说，需要持续跟进基本情况是否有发生变化，同时需要不断的扩展自己对其他公司的了解。研究公司的过程也能加深自己对真实世界的了解。</p><p>在整套系统串起来之后，就可以把压力分摊到平时，也不需要进行那么精确的择时，不再需要时刻进行盯盘，大大减轻自己所面临的压力。</p><h1 id="投资是一项技能"><a href="#投资是一项技能" class="headerlink" title="投资是一项技能"></a>投资是一项技能</h1><blockquote><p>纸上得来终觉浅，绝知此事要躬行。</p></blockquote><p>投资是一项技能，有再多的理论知识，最终还是需要在实际操作过程中不断优化迭代，因此投资越早开始越好，既能够不断提升自己的投资能力，也可以享受<a href="https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A">复利</a>所带来的收益。</p><p>投资也是一项少有的个人可以胜过专业机构的活动。不需要依赖别人，纯靠自己本事，可以获得非常不错的回报。同时在这个过程中也可以对商业世界的运行有更好的理解。当然对现实实际有更好的了解，那么大概率是可以在投资市场有不错的回报。比如之前有人看到新东方开始带货之后的一些直播数据，通过自己的经验进行估算，觉得股价过于低估，因此就大幅买入，赚了不少钱, 这里面的“直播数据”为啥这么值钱就是自己的理解。</p><p>当自己对投资了解越深，同时在实际投资过程中被验证或者证伪后，整个视角都会发生变化，最直接的变化就是如何看待价格的短期变化</p><div class="table-container"><table><thead><tr><th></th><th>之前</th><th>之后</th></tr></thead><tbody><tr><td>1</td><td>价格是否还会上涨/下跌</td><td>价格小范围的波动已经不再关注</td></tr><tr><td>2</td><td>价格涨了高兴，跌了伤心</td><td>短期价格涨了可能难过，短期下降反而会高兴</td></tr><tr><td>3</td><td>更关心公司的股价波动</td><td>更关心公司的基本面情况</td></tr><tr><td>4</td><td>我需要投资成功很多次才行</td><td>只需要在自己足够了解的标的上赚几次钱就足够</td></tr><tr><td>5</td><td>价值投资只对大资金有用</td><td>价值投资使用所有资金</td></tr><tr><td>6</td><td>被价格波动所影响</td><td>价格的波动为我所用</td></tr></tbody></table></div><p>对上面几点进行部分补充</p><ul><li>关于第二点中的“价格涨了难受，下降反而高兴”，可以从股本位的视角理解，价格更高的话，相同法币能兑换更少的股数，反之则能获得更多的股数。</li><li>关于第四点，首先现在 A 股（算上沪港通）有足够多优秀的公司能够容纳足够的资金，而且获得不错的收益。<ul><li>关于足够优秀的公司容纳足够的资金，可以以一个小目标为例，单股价格按照 300 进行计算，也就是 34W 股，现在头部公司的总股数是亿级别（单价公司），我们只需要选择几家公司即可，这也大大降低我们的工作量。</li><li>关于获得不错的收益，大家可以自行查看 A 股（沪港通）头部公司的回报率（可以算上分红再投入），ROE 以及 PE 值。</li></ul></li><li>关于第五点：投资关注的是收益率，与本金大小无关。</li></ul><p>那么价值投资到底要多久才能见效呢？这个和大环境､行业的周期，以及大家对公司价格预期的周期有关系，在三者的共同影响下得到一个当前的价格，价格的高低在当下是不太好实际感受到绝对值的，但是可以有一个相对值。我们希望的是能在整个周期中价格相对低点的时候进行买入，然后持有到较高点（再视情况而定是否卖出）。正因为如此，价值投资的周期也相对较长（至少以年为单位）— 这也要求投资的钱是闲钱，这样才能够放置足够长时间，享受价格上涨带来的利润。实际经历过一个完整的周期后，也会对具体的信号、噪音等更有体感。如果暂时没有实际投资，也可以尝试进行模拟，把相关的情况记录下来，供后续复盘迭代优化使用。</p><blockquote><p>价格是大家预期 — 交易撮合 —的结果，反应的是市场中更多人出的价格，也就是群体的共识，群体的共识不是理性的，所以短期价格的波动也是不理性的。也正是因为如此，投资不要加杠杆，因为我们无法预测市场的走向，也无法预测回归正常需要的时间，加杠杆的风险在于可能在低点被强制平仓，导致永久性的损失。</p></blockquote><p>如果是在不想研究单一投资标的，则可以投资指数/基金，指数会有一揽子投资标的进行均衡，可以减少波动的方差。</p><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>投资是一项技能需要不断的学习，最简单的可以选择部分指数/基金；投资有复利，因此越早开始越好。投资是少有的个人可以比机构做的更好的活动，同时投资有风险，入市需谨慎，价值投资是一个相对靠谱的投资手段。</p><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><p>[1] 投资、创业与创新 <a href="https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q">https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q</a><br>[2] 股市是不是一个好的投资渠道 <a href="https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q">https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q</a><br>[3] The Superinvestors of Graham-and-Doddsville <a href="https://business.columbia.edu/insights/chazen-global-insights/superinvestors-graham-and-doddsville">https://business.columbia.edu/insights/chazen-global-insights/superinvestors-graham-and-doddsville</a><br>[4] 差异化和公司文化 <a href="https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw">https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw</a><br>[5] 复利比较与机会成本  <a href="https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A">https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> investment </tag>
            
            <tag> pattern </tag>
            
            <tag> theory </tag>
            
            <tag> arbitrage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>投资、创业与创新</title>
      <link href="/2025/09/19/investment-startup-innovation/"/>
      <url>/2025/09/19/investment-startup-innovation/</url>
      
        <content type="html"><![CDATA[<blockquote><p>尝试记录一个思想快照，供后续 review 使用。</p></blockquote><h1 id="套利"><a href="#套利" class="headerlink" title="套利"></a>套利</h1><blockquote><p>Arbitrage is the practice of taking advantage of a difference in prices in two or more markets – striking a combination of matching deals to capitalize on the difference, the profit being the difference between the market prices at which the unit is traded. Arbitrage has the effect of causing prices of the same or very similar assets in different markets to converge.</p></blockquote><p>套利(Arbitrage)： 是一种利用资产在不同市场/不同形态进行交易获取价差来获利的行为。这里的描述中更多的是空间上的，而没有描述时间上的。加上时间维度，就变成了二维空间（时间和空间），套利行为则是在二维空间中某两个（或多个）点之间赚取利差。前面的套利则是时间（基本）一致的情况下。</p><span id="more"></span><p>简单的图形如下所示，上图是仅空间维度上套利；下图是时间和空间维度一起进行套利。</p><div style="text-align: center;"><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202509111518153.png" alt="仅空间维度" width="400" inline-block/><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202509111518647.png" alt="时间和空间维度一起" width="400" inline-block/></div><p>套利系统中的利润通常是金钱，也可以不是金钱, 广义上来说，可以是任何自己想要获得的东西。我们在时空二维范围内某个点进行 <em>投入</em>，然后在另外一个点上获得更好的回报，从而获得套利。这个回报可以是金钱，可以产品能力，可以是影响力，可以是其他任何自己想要的东西。</p><h1 id="投资"><a href="#投资" class="headerlink" title="投资"></a>投资</h1><p>这里的投资是 <em>价值投资</em> 的简称，认为资产的价格会锚定到资产本身的价值上。</p><p>如<a href="https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ">股市是不是一个好的投资渠道</a> 一文所描述，投资是在多个资产之间进行比较，选取一个未来获益可能更大的标的，这也可以归一成一种套利 - 时间维度的套利。对于同一个标的，<em>现在</em> 与 <em>未来</em> 的价值不一样，通过现在的价格买入，在未来价格更高的时候获利。这里未来的价值涉及到估算，比如通过现金流折现，某公司在未来能赚多少钱。首先需要知道未来该公司能赚多少钱，这一步需要对公司以及公司所在的行业有一定的认识，然后需要对钱在不同时间点的价值有一定的了解 — 也就是“折现”。二十年前的 1 万元，和现在的 1 万元是完全不同的，10 年后的 10W 和现在 8W 谁更值钱呢？这就提现“折现率”的地方，通常的折现率选择自己能找到的稳定收益中利率最高的一个，或者可以直接锚定到十年期的国债。</p><p>本文中的 <em>未来</em> 是一个泛指，可以是 1 年，3 年或者更久，在这里是一个代指。在实际投资中需要考虑资金的可使用周期，如果资金仅能使用 1 年，也就是说 1 年内会强制兑现，那么需要更多时间才能盈利的标的就不太合适，就算该标的在之后的时间涨了很多，也和自己无关，对自己来说也是一次失败的投资。但是由于市场的不可预测性，因此建议投资的金钱是“闲置金钱” — 也就是可以无限期不使用的，这样能够穿过市场的情绪周期，直到投资标的的价值被反馈到价格上。</p><h1 id="创业"><a href="#创业" class="headerlink" title="创业"></a>创业</h1><p>创业是希望提供一套能够解决某些用户需求的产品，获取更好利益的行为，是一种商业行为，本质上和小卖部等生意类似，不同的公司复杂度不一样，难度不一样，获利也会不一样。</p><p>由于创业是通过产品来获利，那么就需要对目标市场/用户需求有足够了解，能够更好解决用户需求的产品，往往能够获得更多的用户，从而获得更好的回报。由于金钱会流向更赚钱的地方，因此创业不仅仅需要有解决用户需求的产品，也需要有一套系统/方法能够保证自己处于领先地位，或者较长时间处于领先地位（或者至少能够让公司存活下来），需要有自己的竞争性优势/差异化，而且需要能够持续的进行迭代演进，否则现在的竞争性优势在未来会被其他公司追赶上，并反超。</p><p>了解到创业的有如下两种：1）面向 VC 的创业；2）面向客户的创业。第一类创业通过融资，以及后续的退出来赚钱，产品可能可以盈利，也可能无法盈利。第二类则主要通过客户用金钱投票来使公司活下去。这两种也可能有重合，也就是说拿 VC 钱的也可能能够产品盈利很多；通过客户盈利的在后来也可能进行融资。</p><h1 id="创新"><a href="#创新" class="headerlink" title="创新"></a>创新</h1><p>创新往往和创业联系在一起，说起创业都会说创新，需要做一个新的东西来创业。但实际上创新和创业是两个维度的事情，创业是做生意，创新更像是一项开创性的工作，希望突破某个边界。创新在短期来看往往是投入比回报更多的，需要在看到结果之前能够持续的投入。因此如果相对较大的创新，如果是作为创业的核心因素，则要么能够有 VC 持续的投入，要么公司能够盈利持续投入，否则可能在看到结果之前无法持续。</p><p>创新成功后如果有足够的壁垒，可以给公司未来一段时间内带来竞争性优势，带来或者保证收益。如果公司有不错的盈利能力，进行一些长期创新性的投资是合理，而且是有必要的，因为客户需求随着时间发展往往会发生改变，但是拥有足够盈利能力后，往往会由于各种各样的因素导致跟不上新的形式，从而错过一些大趋势。保持一些创新（可能不是很大），则是希望能够保持一些更多的可能性，也能够在整个环境发生变化的时候，能够较快的适应和转变。</p><h1 id="综合"><a href="#综合" class="headerlink" title="综合"></a>综合</h1><p>投资、创业、创新都是时间空间维度上进行套利，如果按照价值投资的角度，则投资和创业基本能统一起来，要找一个市场大的（基数大，可能性更高），然后在里面找自己想比较别人有优势的（差异化），而且要确认这个差异化是用户愿意付钱的。这里面每一步都不容易，但是在这几步分析完成之后，往后的路更好走。比如在投资前详细分析了公司，那么投资出去之后，不会因为一些股价的涨跌而导致自己内心的波动。换句话说，在投资出去的那一刻，你的收益已经基本决定了 — 长远来看涨跌是相对靠谱的，但是短期来看涨跌不定，而且浮动不定。创业和投资的差异在于创业需要自己动手去做，能获取到更多的一手信息；而投资仅投钱，由公司的人进行操盘。创新则是更长时间维度的套利，创新的大小会影响需要的时间以及资金投入。</p><p>另外，不管是投资还是创业，需要弄清楚，哪些是资产，哪些是成本，哪些是负债，哪些会创造现金流。随着时间的演进，能够加强企业竞争力，增加护城河的，是资产，其他的则是成本。对于资产来说，只有买便宜和买贵的差异，最差的情况是买贵了，也就是少赚一点。对于成本则不一样，浪费了就浪费了，甚至会有负作用（比如受沉默成本等影响）。不管是投资还是创业，如果能很好的分清楚资产和成本，也能够比其他人看得更远一些，更深刻一些，长期来看也可以更坚定一些，赚大钱的概率也更大一些，如果能将成本通过某些方式转化成资产，则是更好的方式。</p>]]></content>
      
      
      
        <tags>
            
            <tag> investment </tag>
            
            <tag> startup </tag>
            
            <tag> innovation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Arrow 中一次代码性能优化的记录</title>
      <link href="/2025/07/29/arrow_variant_optimize/"/>
      <url>/2025/07/29/arrow_variant_optimize/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文记录 Arrow-RS 中一次性能优化的情况。</p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近尝试在 Arrow-rs 中做一些贡献来更好的学习了解下 Arrow 和 Rust。本文的事情则是在为 Arrow-rs 支持 parquet variant 中的一个修改。当前实现的过程中，Object 和 List 会创建临时 buffer，然后在最终 copy，这样会有一定的性能损失（主要在于临时 buffer 的创建以及拷贝），希望有一种方案能够直接写入到目标的 buffer 而不需要进行拷贝，也就是 <a href="https://github.com/apache/arrow-rs/issues/7977">ARROW-RS-7977</a> 所记录的事情。</p><span id="more"></span><h1 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h1><p>由于之前在 ARROW-RS#7899 中做过一个 Object 相关的，这个是类似的，因此觉得应该会是一个相对比较容易的事情。不过整个过程还是可以记录下</p><p>首先我给了一个最初的版本，这个版本中我写了四份代码，分别是</p><ol><li>使用 <code>PackedU32Iterator</code> 的<a href="https://github.com/apache/arrow-rs/pull/7987/commits/e4603c1d9b885c2f15871eddc87d1de45beb998e">方案</a></li><li>纯粹使用 Iterator 的<a href="https://github.com/klion26/arrow-rs/blob/1d594b3b4a461a44ad72ecac730cbdfc537767d4/parquet-variant/src/builder.rs#L1220-L1240">方案</a></li><li><a href="https://github.com/klion26/arrow-rs/blob/7179a56258429d8431273d525ced836dd706e3e4/parquet-variant/src/builder.rs#L1220-L1241">该方案</a>在 2 的方式下，进行一次 iterator 的 collect，然后进行 splice</li><li><a href="https://github.com/klion26/arrow-rs/blob/9cc1b04a007c54274db81059d317747b2512e169/parquet-variant/src/builder.rs#L1265-L1285">该方案</a>直接生成一个临时的 buffer，然后逐步填充 header 后进行 splice</li></ol><p>记录下 scovich 给的一些反馈<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; 2. Splice with Iterator</span><br><span class="line">This one will perform poorly because the chained iterator doesn&#x27;t infer an accurate lower bound, so `Vec::splice` has to shift bytes twice (once to fit the lower bound, and again to fix the remainder).</span><br><span class="line">&gt; 3. Collect the header with iterator before splice</span><br><span class="line">一定比 2 差，因为多一次 collect</span><br><span class="line">&gt; Splice with actual header bytes</span><br><span class="line">This is still iterator-based like 1, but with all the unsafety of indexing into a pre-allocated temp buffer(and the overhead of allocating said temp buffer).</span><br></pre></td></tr></table></figure><br>针对这几个方案，给出了两外两个建议</p><p>第 5 种方案<br><code>A fifth approach would be to use the packed u32 iterator from 1/, and splice in a pre-populated temp buffer like 5/, but to populate the temp buffer by push+extend calls instead of chain+collect:</code></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">bytes_to_splice</span> = <span class="built_in">vec!</span>[header];</span><br><span class="line">  ...</span><br><span class="line">bytes_to_splice.<span class="title function_ invoke__">extend</span>(num_elements_bytes);</span><br><span class="line">  ...</span><br><span class="line">bytes_to_splice.<span class="title function_ invoke__">extend</span>(offsets);</span><br><span class="line">  ...</span><br><span class="line">bytes_to_splice.<span class="title function_ invoke__">extend</span>(data_size_bytes);</span><br><span class="line">buffer</span><br><span class="line">    .<span class="title function_ invoke__">inner_mut</span>()</span><br><span class="line">    .<span class="title function_ invoke__">splice</span>(starting_offset..starting_offset, bytes_to_splice);</span><br></pre></td></tr></table></figure><p>以及第六种，主要是优化了原来的 <code>PackedU32Iterator</code><br><code>A sixth approach would also use a pre-populated temp buffer, but ditch the packed u32 iterator from 1/ and just directly append the bytes:</code></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">append_packed_u32</span>(dest: &amp;<span class="keyword">mut</span> <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;, value: <span class="type">u32</span>, value_bytes: <span class="type">usize</span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">n</span> = dest.<span class="title function_ invoke__">len</span>() + value_bytes;</span><br><span class="line">    dest.<span class="title function_ invoke__">extend</span>(value.<span class="title function_ invoke__">to_le_bytes</span>());</span><br><span class="line">    dest.<span class="title function_ invoke__">truncate</span>(n);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Calculated header size becomes a hint; being wrong only risks extra allocations.</span></span><br><span class="line"><span class="comment">// Make sure to reserve enough capacity to handle the extra bytes we&#x27;ll truncate.</span></span><br><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">bytes_to_splice</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">with_capacity</span>(header_size + <span class="number">3</span>);</span><br><span class="line">bytes_to_splice.<span class="title function_ invoke__">push</span>(header);</span><br><span class="line"></span><br><span class="line"><span class="title function_ invoke__">append_packed_u32</span>(&amp;<span class="keyword">mut</span> bytes_to_splice, num_elements, <span class="keyword">if</span> is_large &#123; <span class="number">4</span> &#125; <span class="keyword">else</span> &#123; <span class="number">1</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="variable">offset</span> <span class="keyword">in</span> std::mem::<span class="title function_ invoke__">take</span>(<span class="keyword">self</span>.offsets) &#123;</span><br><span class="line">    <span class="title function_ invoke__">append_packed_u32</span>(&amp;<span class="keyword">mut</span> bytes_to_splice, offset <span class="keyword">as</span> <span class="type">u32</span>, offset_size <span class="keyword">as</span> <span class="type">usize</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_ invoke__">append_packed_u32</span>(&amp;<span class="keyword">mut</span> bytes_to_splice, data_size <span class="keyword">as</span> <span class="type">u32</span>, offset_size <span class="keyword">as</span> <span class="type">usize</span>);</span><br><span class="line"></span><br><span class="line">buffer</span><br><span class="line">    .<span class="title function_ invoke__">inner_mut</span>()</span><br><span class="line">    .<span class="title function_ invoke__">splice</span>(starting_offset..starting_offset, bytes_to_splice);</span><br></pre></td></tr></table></figure><p>然后进行了 benchmark 的测试，发现第六种在所有的方案中会更好</p><p>这里有一些性能的点</p><ul><li><code>Vec::splice</code> 需要 <code>Iterator</code> 的 lower-bound 来进行预测，不然可能会耗时更多，可以通过自定义的 Iterator 来提供</li><li>使用 extend 这些可能会性能更好（？）</li><li>可以通过对 U32 进行处理，直接完成 PackedU32 相关的事情，其中 U32 可以当成是 4 个 U8 然后 <code>to_le_bytes()</code> 就是按照顺序来排列的，这样的话，可以使用 <code>truncate</code>来轻量级的处理只需要 U32 部分 byte 的情况</li><li>另外在 Rust 中 <code>into_iter()</code> 和 <code>iter()</code> 这些还需要继续学习了解下。</li></ul><p>整体看 Rust 中是可以获得更好的性能，这些需要对相对更低层的知识有更好的了解（或者这里更多的是对 API 有更好的了解），这些如果仅仅通过学习是比较难了解到的，通过实际的项目则可以更好/直观的看到不同实现的差异。</p>]]></content>
      
      
      
        <tags>
            
            <tag> arrow </tag>
            
            <tag> variant </tag>
            
            <tag> parquet </tag>
            
            <tag> rust </tag>
            
            <tag> optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>maotai-price-deprese</title>
      <link href="/2025/07/05/maotai-price-decreasing/"/>
      <url>/2025/07/05/maotai-price-decreasing/</url>
      
        <content type="html"><![CDATA[<blockquote><p>茅台股价和批价齐跌，作为股民我该怎么办？</p></blockquote><p>最近（一年）茅台股价下跌，加上现在批价下行，作为茅台股民我该怎么办呢？</p><p>这个时候作为股民应该感到高兴，理由有几：1）股价下跌，导致入场成本低；2）批价下跌，会影响股价向下，转到第一点；3）股价/批价不影响茅台公司的盈利能力。</p><span id="more"></span><h1 id="投资投什么"><a href="#投资投什么" class="headerlink" title="投资投什么"></a>投资投什么</h1><p>投资是一项希望赚钱的游戏，本质属于套利，换句话说也就是低买高买（需要算上时间的价值）。那么对于同一个标的来说，肯定是买入价价格越低越好，这样可以在未来赚取更多的钱；未来的价格希望越高越好 — 但是未来的价格是一种预期/估算。</p><p>从 <a href="https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ">投资是投什么</a> 我们知道，投资标的可以和无风险利率 — 长期国债 — 进行对比（或者自己能找到利率最高的“无风险”标的），按照十年期国债 3% 左右的利率算，也就是需要 33 年回本，PE 毛估 33 倍。那么如果一个投资标的盈利能力没有水分的情况下，PE 长期来看一定不会一直低于 33。原因在于如果投资标的 A 盈利能力稳定，PE 低于 33 倍，那么无需 33 年就能回本，也就是说比长期国债更好，市场上的金钱自然就会流向 A，流入金钱多导致供不欲求，从而推高价格和市值，间接的推高 PE — 买入价格变高了，回本所需要的时间也变长。这一过程最终会在投资标的的 PE 与长期国债的 PE 基本持平后稳定下来。</p><p>当然上面是一个理想和简化过的模型，但是实际来看，市场长期会偏理性，短期会受情绪影响，因此长期来看市值与公司的盈利能力是正相关的。由于短期会受市场上情绪的影响（比如茅台股价和批价齐跌），因此也需要尽可能持有久一点，另一方面我们可以利用市场情绪来拉低自己的入场成本，间接增加自己的收益。</p><h1 id="茅台的情况"><a href="#茅台的情况" class="headerlink" title="茅台的情况"></a>茅台的情况</h1><p>上面的描述中有一个假设 — 茅台公司的盈利能力没有变差。 这个是需要每个投资者需要确认的，同时这个这是一项需要平时做的工作，而不仅仅是在股价/批价波动时需要做的事情。下文会结合两个最近听到较多的声音一起分享下自己的看法：</p><ul><li>批价下行会导致茅台赚不到钱</li><li>禁酒令或者年轻人已经不喝酒了</li></ul><h2 id="批价和茅台公司的关系"><a href="#批价和茅台公司的关系" class="headerlink" title="批价和茅台公司的关系"></a>批价和茅台公司的关系</h2><p>在 <a href="https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA">赚钱机器茅台</a> 中有写，茅台酒的销售有几个渠道：经销商，自营，商超等。其中大家看到的批价是经销商的卖价，和茅台公司的营收无关，影响的是经销商的利润。出厂价是 1169 的前提下，如果批价 2300 那么经销商转 2300 - 1169 = 1131 每瓶，如果是 2000 的批价，则每瓶赚 831。所以批价下行影响的是茅台经销商的利润，不影响茅台公司的利润。但是如果经销商没有利润则会影响茅台的销售，可能间接影响茅台公司的收入。</p><p>那么是否会由于批价下跌导致影响经销商不再采购茅台呢，有可能。这个我们看下预收款的变化，这部分是经销商提前打款，预订茅台产品的钱。</p><p>首先我们简单看下公司财报中的部分数据</p><div class="table-container"><table><thead><tr><th>时间</th><th>营业收入</th><th>利润</th><th>净利润</th><th>合同负债（预收款）</th></tr></thead><tbody><tr><td>23 年年报</td><td>1500亿</td><td>1030 亿</td><td>650亿</td><td>141 亿</td></tr><tr><td>24 年年报</td><td>1740亿</td><td>1190 亿</td><td>890亿</td><td>95 亿</td></tr><tr><td>24 年一季度报</td><td>460亿</td><td>330 亿</td><td>240亿</td><td>95 亿</td></tr><tr><td>25 年一季度报</td><td>510亿</td><td>370 亿</td><td>270亿</td><td>87 亿</td></tr></tbody></table></div><p>从上面看有一些信息</p><ul><li>25 年第一季度比 24 年第一季度的营收有增长</li><li>25 年第一季度的合同负债比 24 年第一季度要少，也就是收到的预售款比兑现的少; 24 年年报中的合同负债和 24 年第一季度的基本持平，表示 24 年后三季度收到的预售款和兑现的基本持平。</li><li>不管哪一阶段，都有较多的合同负债。24 年底占营收的 5% 左右。</li><li>24 年经销商已经在控制预收款的投入了，25 年第一季度还在持续, 可以看 25 年年中报再确认</li><li>25 年第一季度茅台公司的营收以及利润较 24 年第一季度是增长的。</li></ul><h2 id="禁酒令和年轻人不再喝酒"><a href="#禁酒令和年轻人不再喝酒" class="headerlink" title="禁酒令和年轻人不再喝酒"></a>禁酒令和年轻人不再喝酒</h2><p>首先酒肯定是对身体不好的，现在的酒桌文化也在慢慢的变化。但是整体白酒的营收是在逐年增加的（具体参考前文<a href="https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA">赚钱机器茅台</a>)，然后茅台酒和茅台系列酒的收入占整体白酒的收入也是在逐年增长的。也就是说茅台酒和茅台系列酒的增长是高于整体白酒的涨幅的。</p><p>然后禁酒令是否会影响白酒或者茅台酒的销售，这个短期应该还是会有影响的，但是对公消费现在占比已经不高，另外茅台酒整体供不欲求，所以不一定会影响到茅台公司的营收（酒品质保持不变的情况下）。</p><p>年轻人是否喜欢喝茅台酒不是决定性的因素，但是如果想求人办事，或者送礼，那么茅台还是一个很不错的选择，这是文化的一种体现，文化是一种共识，共识的建立和转变都需要足够长的时间。短期来看只要有迎来送往等情况，那么就有茅台酒的市场。</p><h1 id="茅台的买入价"><a href="#茅台的买入价" class="headerlink" title="茅台的买入价"></a>茅台的买入价</h1><p>如果说茅台是一个不错的投资标的，那么是否什么价格都可以买呢？其实也不是，因为买入价格太高会导致自己没有利润（如前所示），那么什么价格是一个比较合理的价格呢？</p><p>这里分享两种方法</p><p>1 按照自己估算的盈利，如果复合年化可以超过 X — 这个自己设定，进行打折保留安全空间<br>2 如果公司有回购的话，那么在回购价一下购买基本算不错的 — 回购价是公司对市值的一个预测</p><p>其中第一个可以根据公司的净利润以及本文前面与长期国债比较的方式进行估算，然后可以根据自己对公司的了解情况做一些打折，比如公司净利润 800 亿，那么按照 33 倍 PE 也就是市值值 2.6万亿。然后如果打 7 折就是 1.82 万亿，现在总股数 12.56亿，1.82万亿 / 12.56亿 ~ 1450。也就是说 1450 一下是 ok 的。当然这只是进行股价的一个粗略估算，里面的具体数值（尤其是折数）需要自己替换。</p><p>另外茅台现在每年会有分红，这部分利润（可能）无法反应在市值上，比如 25 年 6 月按照 10 股分红 276.73 计算（假设以后都不低于这个值），那么按照股价 1500 计算的话，一年两次分红总共是 276.73 <em> 10 </em> 2 = 5534.6，5534.6/(1500 * 100) = 3.68%。也就是说把茅台当定存的话也有 3.6 % 左右的年化，这个回报已经高于长期国债了。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>整体来说，市值的降低，以及整条销售链路上的价格波动，不一定会影响公司的盈利能力，可能是一个更好的入场机会，我们需要分析公司的情况，然后等待市值下降之后入场，从而获得更好的利润。</p>]]></content>
      
      
      
        <tags>
            
            <tag> stock </tag>
            
            <tag> maotai </tag>
            
            <tag> wine </tag>
            
            <tag> price </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>iceberg summit 2025 notes</title>
      <link href="/2025/05/20/iceberg-summit-2025/"/>
      <url>/2025/05/20/iceberg-summit-2025/</url>
      
        <content type="html"><![CDATA[<p>本次 Iceberg Summit 2025[0] 上行业内众多公司做了分享，包括 Iceberg 核心技术、使用案例，优化方案，未来走向等等。其中国内的腾讯（两个 talk），小米，小红书均有分享，整体内容不错，这里做一个总结，更详细的请参考原视频。</p><span id="more"></span><h1 id="Beyound-Iceberg’s-ongoing-evolution"><a href="#Beyound-Iceberg’s-ongoing-evolution" class="headerlink" title="Beyound Iceberg’s ongoing evolution"></a>Beyound Iceberg’s ongoing evolution</h1><p>首先是 Iceberg 的 PMC member Ryan Blue 的 talk[1], 这个 talk 整体介绍了 Iceberg 的过去，现在以及将来的一些事情。Iceberg 现在已经成为湖仓的事实标准，在各大公司被官方使用，在湖仓一体/流批一体等方案中作为共享存储存在，提供了 ACID，time travel，branch，tag 等各种功能，支持了众多查询引擎，整体生态非常繁荣。</p><p>最近一年已经完成或者正在进行的一些重大特性包括</p><ul><li>Geo type 的支持，更好的支持地图数据</li><li>Variant type 的支持，可以支持半结构化数据（这个另外一个 talk 单独有讲）</li><li>全表加密（data 和 metadata）</li><li>deletion vector  — 更好的 position deletes（有另外一个 talk 单独讲），在性能、文件数量以及维护成本做了一个均衡</li><li>row lineage，主要方便增量消费以及数据的校验等</li></ul><p>在 Iceberg 中增加新的数据类型可以带来：1）有标准，各引擎更方便交互；2）能够借用 Iceberg 的 Metadata/Index 等做查询优化。</p><p>另外在广泛使用过程中，大家也有提出来一些有关 metadata 的痛点，比如</p><ul><li>manifest 相关<ul><li>文件可能会比较多：先生成 manifest 然后是 manifest list；manifest 会重写最后删除</li><li>现在对小表不太友好（实际中有很多小表）：scan 需要走 manifest list 然后顺序的访问每个 manifest 文件</li><li>manifest 文件太多：导致 metadata 需要周期性合并</li></ul></li><li>故障恢复比较困难: file replication  不够恢复整张表；metadata 需要重写（主要是绝对路径）</li><li>列信息是二进制的：对扩展类型不优化（比如 geo/variant 等)</li><li>plan 性能可以更好: 需要读取所有列信息（不在 filter 中的列信息也需要读取）</li><li>Metadata skipping 需要分区信息：数据倾斜处理不好；无法和 geo 数据很好的结合；容易过度分区</li></ul><p>针对这些问题，也有一些相应的规划，整体思路是 metadata 往 adaptive tree structure方向走，adaptive tree structure 加上 RestCatalog, 再加上 servcie 就更像 DB 了。</p><p>adaptive tree structure 大致如下<br><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20250512145432.png" alt=""></p><p>另外 Iceberg 也在如下一下方面有考虑</p><ul><li>Relative paths：主要是为了容灾、故障恢复考虑</li><li>Columnar metadata: 更方便跳过不需要的 column stat；typed lower/upper bounds/alternative sort orders</li><li>Adaptive metadata &amp; Unified manifests: 更好的 manifest 结构，主要适配多模态数据，优化小表，manifest 的维护性等。</li></ul><p>后文中会从如下几方面展开描述</p><ul><li>Manifest/Index：表元数据相关</li><li>Catalog: Catalog 相关</li><li>Compute&amp;Management(Optimiztion&amp;Service): 表查询和管理相关</li><li>File format: file format 相关</li><li>Streaming: 流式入湖</li><li>Ecosystem(&amp;usecase&amp;migration): 生态以及迁移到 Iceberg</li></ul><h1 id="Matadata-manifest-Index"><a href="#Matadata-manifest-Index" class="headerlink" title="Matadata(manifest/Index)"></a>Matadata(manifest/Index)</h1><p>Iceberg 的 metadata 是核心组件，包括了支持各种功能以及查询优化所必需的信息，这里介绍一些和 metadata 相关的演讲内容。更详细的可以查看原视频（下同）。</p><p>本次 Summit 中有介绍 Iceberg （正在）支持多种类型：geo 类型[2]，variant 类型[3]，支持了 deletion vector[4] — 更好的 position delete。</p><p>也有尝试将 Iceberg 的 metadata 暴露成常规的 Iceberg 表方便分析的[5]，演讲中有介绍使用 PG 来承载 metadata 的分析，发现量大之后会遇到性能瓶颈，因此希望 Iceberg 原生支持将 metadata 暴露为标准表。</p><p>其中增加新类型主要是定义标准以及优化查询，geo 主要是地图相关的数据（点、线，区域等），而 variant 则主要是支持半结构化的数据 — 比如 json。variant 在 log/event 等数据类型中大量使用，IoT/Telemetry 数据非常多，variant 的支持还有一个就是增加 shredding 过程，用于进一步加速。</p><p>在 position delete 的基础上演化出了 delete vector，出要出发点在于不管是 partition-level 还是 file-level 的 position delete 文件都有局限。因此演化成现在的 delete vector 方式，这样磁盘和内存中的数据结构统一，每条数据仅会被删除一次，文件数也大大减少。</p><p>也有一些分享提了类似[29] first-row/last-row 的 merge option 等需求。</p><h1 id="Catalog"><a href="#Catalog" class="headerlink" title="Catalog"></a>Catalog</h1><p>Catalog 主要负责表层面的元数据，包括最新的元数据，事物控制协调等。现在 Iceberg 提供了多种类型的 Catalog 供用户选择。</p><p>本次 Summit 中有用户介绍使用 Catalog 的具体情况[6]，也有介绍 RestCatalog 的相关事情[7][8][9]。</p><p>其中 Bloomberg 对不同的 catalog 有一些总结如下</p><ul><li>Hive<ul><li>Easiest to utilize, as we were already using the ApacheHive Metastore</li><li>Scale and performance challenges</li></ul></li><li>AWS Glue<ul><li>managed service</li><li>vendor lock-in</li><li>access control limited through AWS primitives</li></ul></li><li>JDBC<ul><li>Easy and familiar to manage and connect to a database</li><li>access control limited through AWS or DB primitives</li></ul></li><li>Rest<ul><li>Gave use the most flexibility to support the Iceberg Spec and additional custom features</li><li>Flexible integration with different query engines</li><li>Backed by a PostgreSQL database</li><li>Provided the most flexibility on access control and multi-tenancy</li></ul></li></ul><p>[7][8]分享了 RestCatalog 的由来。RestCatalog 从最初解决 HiveCatalog 的问题出发（锁粒度，以及事物控制等），分析了一个 Catalog 需要满足的条件：可靠性，低延迟提交；事物/冲突管理；客户端的兼容性；数据的权限等。Iceberg 的 RestCatalog 将部分客户端的职责移到 server 端，这样客户端更轻量级；更好的事物控制（DML/DDL 的协调，合并和实时写入的协调），多表事物控制；客户端更好实现（更轻量级，更方便多语言实现）。以及 Apache Polaris 的一些实际使用情况。</p><p>[9] 分享了 Pinterest 使用 Gravtino 解决 Iceberg 过程中的一些实际问题，包括：partition list 很慢；性能分析；已经引擎相关的性能问题等。</p><h1 id="Compute-amp-Management"><a href="#Compute-amp-Management" class="headerlink" title="Compute&amp;Management"></a>Compute&amp;Management</h1><p>数据存储后会被查询使用，为了查询效率高也需要对数据进行管理优化。</p><p>[10] 主要分享了不同参数下 Iceberg 表的性能情况。主要在 file format 层面的调优，包括 <code>write.target-file-size-bytes</code> 和 <code>write.parquet.row-group-size-bytes</code> 的调优实践。一些具体的测试数据如下：</p><div class="table-container"><table><thead><tr><th>metric</th><th>2mb row-group size(unsorted)</th><th>128mb row group size(unsorted)</th><th>2m row group size(sorted)</th><th>128mb row group size(sorted)</th></tr></thead><tbody><tr><td>num_columns</td><td>21</td><td>21</td><td>21</td><td>21</td></tr><tr><td>num_rows</td><td>391844</td><td>391844</td><td>1794155</td><td>656682</td></tr><tr><td>num_row_groups</td><td>33</td><td>1</td><td>150</td><td>1</td></tr><tr><td>serialized_size</td><td>94736</td><td>4824</td><td>424318</td><td>4799</td></tr></tbody></table></div><p>并测试了不同引擎下的查询效率</p><ul><li>unsorted 情况下 2MB vs 128MB row group size 性能可以提升 15%</li><li>sorted 的情况下 2MB vs 128MB row group size 性能可以提升 177%</li></ul><p>[11] 分享了 Impala 优化 Iceberg MOR 的流程，主要思路是避免无限重复读取 delete 文件，单独一个算子读取 delete 文件，然后使用 broadcast join 来进行数据的删除。</p><p>[12] 分享了如果给 Iceberg 查询做 I/O 优化进行加速，主要思路是尽可能的进行 filter pushdown — <code>filter pushdown is the gold standard of I/O optimizations</code></p><p>由于不是所有的 filter 都能够 pushdown，可以可能需要 rewrite SQL。现在 Iceberg 中 filter pushdown 会有如下约束</p><ul><li>Filters are only useful if they eliminate entire partitions or data files</li><li>Limited set of statistics to evaluate with<ul><li>Lower and upper bounds</li><li>Null, NAN, Value Counts</li><li>Partition Values</li><li>Not as useful for non-numberic cols</li></ul></li><li>Complex filters contain compute functions<ul><li>Iceberg transforms are only a subset</li></ul></li></ul><p>然后给出了一些 rewrite 的具体例子</p><div class="table-container"><table><thead><tr><th>Before</th><th>After(completely pushable)</th></tr></thead><tbody><tr><td>coalese(date, TODAY) &lt;= TODAY</td><td>date is null or date &lt;= TODAY</td></tr><tr><td>zip_code in (12345, 54321, 31524)</td><td>zip_code = 12345 or zip_code = 54321 or zip_code = 31524</td></tr><tr><td>size / 2.0 &gt; PARAM</td><td>size &gt; PARAM * 2.0</td></tr><tr><td>username LIKE ‘bill%’</td><td>STARTSWITH(username, ‘bill’);</td></tr><tr><td>tag ILIKE ‘A’</td><td>tag = ‘A’ or tag = ‘a’</td></tr></tbody></table></div><p>对于无法全部下推的，可以考虑部分下推，如下所示</p><div class="table-container"><table><thead><tr><th>original</th><th>runtime filter</th><th>file-level filter</th></tr></thead><tbody><tr><td>url like ‘<a href="http://%.com%">http://%.com%</a></td><td>startswith(url, ‘http://‘) and contains(url, ‘.com’)</td><td>startswith(url, ‘http://‘)</td></tr><tr><td>lower(name) = ‘adam’ (name ilike ‘adam’)</td><td>lower(name) = ‘adam’)</td><td>name = ‘ADAM’ and name =’adam’</td></tr><tr><td>qyt INT &gt; 100</td><td>qty INT &gt; 100</td><td>qty is NOT null</td></tr></tbody></table></div><p>在最后对 Iceberg Metadata 提出一些需求，希望未来有更多可用于 file pruning 的 metadata 信息。</p><p>[13] 分享了 partition stats 的背景，当前情况等。主要是为了更好优化查询(CBO 过程)。</p><p>现在 Iceberg 有 FileLevel/Manifest Level/Snapshot Level 的指标，希望有 partition level 的指标。由于实际场景中大部分是分区表，因此 partition level 指标在现实世界中有很多使用场景。</p><ul><li>避免读取所有的 manifest（有些表的 manifest 非常多）</li><li>在 plan 的时候可以 autoscaling（根据 partition level 指标动态调整并发）</li><li>动态调整 query plan（join reordering，IO operator）</li><li>仅在最新 snapshot 中 partition 会影响查询时进行合并</li><li>根据 partition 指标刷新数据写入链路（Two sigma 无法 expire snapshot 的例子）</li></ul><p>[14] 分享了 Iceberg 的跨集群复制以及灾难恢复，主要思路是基于 snapshot 的增量复制。</p><p>[15] 腾讯(TEG) 分享了处理超宽表的一些线上生产经验，主要在 ML/DL 等场景下，会有上千列的情况。主要问题有：</p><ul><li>表太宽，单表上 P<ul><li>单表上千万的文件数量，上千数量的 manifest 文件</li><li>plan 性能瓶颈</li><li>batch 写入消耗内存多，容易导致 OOM</li></ul></li><li>列管理困难<ul><li>不是所有列的价值都一样</li><li>列的频繁增删</li></ul></li></ul><p>整体的思路包括：减少不必要的元数据（比如指标）；通过 column stats 知道列的使用频率，然后进行调整；将 datafile 合并到 manifest file 中，减少文件数量；另外在合并的时候通过直接操作 parquet 来加速等一系列优化方案。更详细的可以查看对应视频。</p><p>[16][17][18] 有讲表管理、优化相关的事情（和 Amoro 定位类似，Linkdin 开源了他们的  OpenHouse），这里面有比较多实际生产经验可以借鉴，包括合并策略、资源优化、扩展性、观测性（用户侧，服务侧）、告警等</p><p>[22] 分享了腾讯云基于 Amoro 做的流批一体的湖仓系统，包括 MixedIceberg 承接实时数据，以及支持 partial update 等需求。</p><h1 id="File-format"><a href="#File-format" class="headerlink" title="File format"></a>File format</h1><p>为了满足不同的场景（尤其是 ML&amp;AI），有不同的 file format 出来(lance, vertox 等)，如何在 Iceberg 中结合新型 file format 的能力是一个社区正在做的事情。</p><p>[19]分享了 fileformat 出现的一些原因，以及 Iceberg 正在做的事情 — 抽象 FileReader/Writer 的接口等。</p><ul><li>ML workload 的特点<ul><li>wide columns</li><li>both scan &amp; search</li><li>grow horizontally(wide schema)</li></ul></li><li>新硬件的特点<ul><li>not just(or even primarily) run on CPUS</li><li>Accelerators like GPU &amp; FPGA are embarrassingly parallel</li><li>Common bottlenecks: CPU, Copying to device memory</li><li>IDEA: Load compressed data, decompress on-device</li></ul></li></ul><p>新的 file-format 要求和特点如下所示</p><ul><li>要求<ul><li>Decompression via GPU SIMT</li><li>Decompression via CPU SIMD</li><li>Random access on compressed data</li></ul></li><li>特点<ul><li>workload diversity</li><li>flexibility &amp; interop</li><li>accelerated computing</li></ul></li></ul><p>[15] 中腾讯的分享是在 parquet 中做的一些工作。</p><h1 id="Streaming"><a href="#Streaming" class="headerlink" title="Streaming"></a>Streaming</h1><p>随着大家对实时入湖的需求，以及 Iceberg 在实时入湖上的现状，大家在寻找时效性，湖仓治理的一个平衡点。</p><p>不同公司也在尝试实时入湖的事情，如何做到时效性、管理成本等的平衡是一个难点。</p><p>[20] 分享了 Snowflake 在 Iceberg 上做增量计算的一些事情，这个分享包括了增量计算的定义，以及在 snowflake 中实现的一些思路，思路大概是通过 row_id 来记录数据的演进（row_id 也可以当成 watermark），然后通过代数变换讲 join 等算子变换为增量计算的算子减少计算量。比较麻烦的是多表事物的处理 — 需要有一个全局的时间。</p><p>[21] 分享了实时入湖效率，以及后续湖仓内数据治理的一些实测数据，希望达到一个全局的最优，主要思路是在不影响 compaction 的情况下增大入湖效率（增大写入并发），然后通过类似 RestCatalog 的角色来协调 commit。另外会对一些错误配置等提前预判并通知。</p><p>[26] 分享了如何实时入湖相关的事情，并给出了从 Snowflake 迁移到 Iceberg 的一些情况，并且基于实际情况提出了 Flink Dynamic Schama 的需求，在最新的 Sink 中有相关的工作正在进行中。</p><h1 id="Ecosystem-amp-usecase-amp-migration"><a href="#Ecosystem-amp-usecase-amp-migration" class="headerlink" title="Ecosystem(&amp;usecase &amp;migration)"></a>Ecosystem(&amp;usecase &amp;migration)</h1><p>[6] 有分享迁移到 Iceberg 前后的收益</p><div class="table-container"><table><thead><tr><th>Before Iceberg</th><th>After Iceberg</th></tr></thead><tbody><tr><td>Full daily restatements of 7TB+</td><td>Incremental daily revision between 5~10 GB(&lt;1% of total table)</td></tr><tr><td>High ingestion overhead</td><td>Streamlined ingestion and processing</td></tr><tr><td>Slow processing and costly storage</td><td>Efficiency gains in storage and compute</td></tr><tr><td>Hard to diagnose and debug data quality</td><td>Easier to diagnose and debug data quality</td></tr></tbody></table></div><p>[17][25][27]分享了 Hive 迁移到 Iceberg 的一些事情，描述了 Hive 的一些限制：partition 支持不好；ACID 支持不好，性能，扩展性，多引擎支持等等，以及从 Hive 迁移到 Iceberg 的详细流程和 checklist，包括前期分析，迁移计划，具体执行，以及最后验证等，对于 Hive 迁移 Iceberg 的可以参考下。从 Hive 迁移到 Iceberg 后，整体减少了 70% 的资源，查询峰值时间降低了 95%，对于 streaming 入湖也更简单了。</p><p>[9] 使用 Iceberg 做流批一体存储，链路大致如下 [upstream] -&gt; kafka -&gt; flink -&gt; Iceberg -&gt; [Flink/Spark]，使用了两张表来承接实时数据：其中一张表保留全量数据，一张表保留增量数据，增量数据周期性写入全量表（Amoro 中的 mixed-iceberg 思路类似）。</p><p>[23] 分享了使用 Trino 做可扩展的湖仓，主要解决如下问题：扩展性；管理难度；查询性能慢；vendor lock-in 等。</p><p>在扩展性方面遇到：metadata 增长；不同的 workload；查询性能的稳定；数据倾斜的处理以及限速等。</p><p>基于生产经验总结了一些最佳实践：</p><ul><li>读方面：使用 NDV Status，filter pushdown， metadata/data cache，materialized view(trino），合适的线程池大小等</li><li>写方面（主要是 trino 相关）：限制写入并发；数据合理分区，专用 plan/delete 的线程池等</li></ul><p>[23] 分享了使用 Iceberg 做统一存储后，避免在各系统之间进行数据的传输，计算等，减少了整体的计算和存储量。</p><p>[24] 分享了构建基于 Iceberg(+StarRocks/BigQuery) 的大规模分析系统，并且在生产中实现了 blue/green 的常规流程。 使用 Iceberg 前后的对比如下所示（之前是 PG 和 BigQuery）</p><div class="table-container"><table><thead><tr><th>Before</th><th>After</th></tr></thead><tbody><tr><td>大查询经常超时</td><td>查询耗时大规模减少  P95 2.976s  Avg 1.65s</td></tr><tr><td>increasing SSD costs to store ever increasing volumes of data</td><td>数据可以 offload 到 object storage</td></tr><tr><td>存算一体（耦合）</td><td>存算分离（可以单独扩展）</td></tr><tr><td>Hourly and daily data loads frequently resulted in SLO misses</td><td>存储只需要在一个地方就行</td></tr><tr><td>无法很容易的换计算引擎</td><td>可以使用多引擎查询</td></tr><tr><td>数据太大需要从 PG 切到 BigQuery，无法在 on-premise 环境</td><td>可以在 on-premise 环境使用</td></tr></tbody></table></div><p>[28] 则分享了 PG 支持 Iceberg 外表的一些情况，这样可以结合 PG 和 Iceberg 的能力。</p><p>[30] 分享了 Redpanda 的 iceberg table，听起来和Automq 的 iceberg table 以及 fluss 有相似之处，可以将 MQ 的数据直接 compaction 到 datalake 中，这块或许一个完整的是，有轻量级 MQ + service 能力负责 offload 和 compaction，以及现在的 datalake。</p><p>[31] 则分享了生产中实际情况，比如使用 storage partitioned join 来避免大量 shuffle 的场景。</p><p>另外类似 Trino/StarRocks/BigQuery 等引擎均在大会上分享介绍如何结合 Iceberg 的，在语言方面，除了 Java 之外，现在 Python/Rust/C++ 等语言也在积极推动中。</p><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><p>[0] <a href="https://www.icebergsummit2025.com/agenda/">https://www.icebergsummit2025.com/agenda/</a><br>[1] V3 and Beyond Iceberg’s ongoing evolution<br>[2] Decoupling Metadata: Leveraging Queryable Iceberg Tables for Scalable, Cross-Engine Innovation<br>[3] Understanding Deletion Vectors in Apache Iceberg<br>[4] Iceberg Geo Type: Transforming Geospatial Data Management at Scale<br>[5] Decoupling Metadata: Leveraging Queryable Iceberg Tables for Scalable, Cross-Engine Innovation<br>[6] Building Bloomberg’s First Incremental Alternative Data Product Using Apache Iceberg<br>[7] Pioneering the Next Frontier: The REST Revolution in Apache Iceberg Metadata<br>[8] Scalable Lakehouse Architecture with Iceberg &amp; Polaris: A Battle-tested Playbook<br>[9] Scaling Iceberg Adoption at Pinterest with Gravtino<br>[10] Deep Dive into Iceberg Optimizations and Best Practices for a Scalable and Performant Lakehouse<br>[11] Extending the One Trillion Row Challenge to Iceberg V2 Tables<br>[12] Iceberg I/O Optimizations in Compute Engines<br>[13] Supercharging Apache Iceberg Strategies for Harnessing Partition Stats<br>[14] Iceberg Resilience: Building a DR Strategy for the Data Lake<br>[15] Efficiently Managing Table With Thousands of Columns Using Iceberg In Tencent<br>[16] Learning from running large-scale Apache Iceberg Table Management Service<br>[17] Airbnb Icehouse: The Journey to Iceberg<br>[18] Optimizing Iceberg Table Layouts at Scale: A Multi-Objective Approach<br>[19] Turbocharge Queries on Iceberg with Next-Gen File Formats<br>[20] CDC Implementations on Apache Iceberg and where are we headed<br>[21] Unleashing the power of Iceberg ingestion 100GB/s and beyond<br>[22] Building a Batch-Stream-Unified Lakehouse on Apache Iceberg in Tencent Cloud<br>[23] Eliminating redundancies in ETL with Iceberg tables on Snowflake<br>[24] From zero to one: Building a petabyte-scale data analytics platform with Apache Iceberg<br>[25] Hive Tables to Apache Iceberg: A Step by step Migration Blueprint<br>[26] Iceberg with Flink at DoorDash<br>[27] Implement Iceberg for Improved Data Management at Autodesk<br>[28] Postgres meets Iceberg<br>[29] Supercharging wise data lake with apache iceberg<br>[30] The ‘Streamhouse’: Extending Redpanda into a fully managed, Iceberg-backed realtime data lakehouse<br>[31] Adopting Apache Iceberg at Slack: Challenges, Lessons, and Best Practices</p>]]></content>
      
      
      
        <tags>
            
            <tag> iceberg-summit </tag>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>差异化和公司文化</title>
      <link href="/2025/04/26/differentiation/"/>
      <url>/2025/04/26/differentiation/</url>
      
        <content type="html"><![CDATA[<p>在商业世界中，公司靠持续提供有差异化的产品保持竞争力，公司的文化则在更长时间范围内保证可以提供差异化的产品。</p><blockquote><p>本文受《雪球特别版-段永平投资问答录》启发</p></blockquote><span id="more"></span><h1 id="差异化"><a href="#差异化" class="headerlink" title="差异化"></a>差异化</h1><p>公司的提供某产品，是因为客户有需求，同一个需求可以有不同的满足方式，因此不同的公司会提供不同的产品。在市场上所有产品中，那些有差异化的产品能够更受客户欢迎。</p><p>差异化可以理解为：客户想要但还未满足的需求。</p><p>差异化并不是一个高高在上的概念，但是却需要非常实际了解客户的需求，了解那些实际需要但还未得到满足的需求，满足这些需求就提供价值，就有了差异化的竞争力。比如 hao123 的导航栏，比如苹果的产品，比如小商店的地理位置等都是差异化的一种体现。功能，性能，体验等</p><h2 id="hao123-的故事"><a href="#hao123-的故事" class="headerlink" title="hao123 的故事"></a>hao123 的故事</h2><p>hao123 是一个很好的体现差异化需求的事情。hao123 站长在网吧当网管期间，一个人设计和维护了 hao123 网帐。在最初的时候，由于上网的人比较难记住经常要访问的网址 — 有一个导航的需求，而网吧是按时收费的，如果找不到地址则钱就白白浪费了。hao123 就在这种情况下诞生了，从解决客户的实际需求（需要能记录常用网站）开始，然后不断的维护网址导航。后来 2004 年 hao123 以 1190 万加 4 万股的价格卖给百度，可见其价值。</p><p>hao123 从技术角度上看，没有太大的难度（后期量大之后还是有难度的），但是能够实实在在解决用户的需求 — 网站导航。或者说成为当时互联网的入口。这是用户可观存在的需求，解决了用户的需求之后就能够获得对应的流量。</p><h2 id="苹果产品"><a href="#苹果产品" class="headerlink" title="苹果产品"></a>苹果产品</h2><p>苹果从 iPhone4 出来之后，产品卖的非常好，产品拥有不错的差异化。这里以用户视角描述下苹果产品的差异化。</p><p>苹果不仅提供了硬件，还包括了软件，服务等。其中 iPhone 提供了非常流畅的体验，iCloud 提供了一套帐号，云存储服务，整体体验不错。对于要求不是特别高的情况下，苹果自带的产品就能够满足基本的要求。</p><p>比如 iNote 可以解决日常笔记问题，能够随手进行记录，可以自动同步到云存储，有基本的格式、分类功能; iBook 能够阅读 pdf/epub 等各种格式的书籍，在不同设备（iPhone/Mac/iPad) 上进行同步，还能够进行听书，算是看书的一种补充；「提醒事项」可以在特定时间点提醒自己，释放自己的记忆压力。换设备的体验也很好，登录 iCloud 帐号之后，所有的能够自动进行同步，基本感受不到设备的切换。而如果有更高的要求，也可以在 AppStore 上进行相关软件下载。</p><p>不过苹果最近的品控感觉不如以前，最近遇到好几次问题，最后在客服人员的帮助下，进行解决。比较好的是，有专门的客服协助解决（售后），但是品控比起之前确实感受有下降。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>差异化不仅仅是功能，性能，也可能是地理位置，体验，感受等。比如小区的商店就比 3 公里外的商店更能满足自己的需求，喜欢咖啡/酒的人，习惯喝的饮品就是能满足自己体验，感受的；游戏也是类似。这些有差异化的产品，往往不会因为（部分）提价客户就进行转换，从公司角度这就是竞争力，就有一定的护城河。</p><h1 id="文化"><a href="#文化" class="headerlink" title="文化"></a>文化</h1><p>差异化是用户需要但还未被满足的需求，那用户需求被满足后，就会有新的需求，因此需要能够持续的提供差异化的产品，而保证能够持续的提供差异化的产品，就需要一套系统，或者说公司的文化。</p><p>文化包括公司墙上宣传的，也包括大家内心认可的。也就是说分为明面上的规则，和潜规则。潜规则的影响往往也会很大。</p><p>另外文化在没有经过验证之前，是不太靠谱的。只有面临真正的考验的时候，才能说是自己公司的文化，这也会影响后面非常多的情况。</p><p>比如阿里 2011 年 B2B 事件[1]，这种会很大影响公司外对公司的看法和判断，同时也会影响公司内的后续决策上的取舍。当然好文化也需要持续保持，不然也会被稀释，或者变差。</p><blockquote><p>2011年2月21日下午消息，阿里巴巴B2B公司宣布，为维护公司“客户第一”的价值观及诚信原则，2010年公司清理了约0.8%逾千名涉嫌欺诈的“中国供应商”客户，公司CEO卫哲、COO李旭晖因此引咎辞职，原淘宝网CEO陆兆禧接任。阿里巴巴表示，公司绝不能仅仅变成一家赚钱的机器，让天下没有难做的生意才是其使命所在。</p></blockquote><p>另「外某电商平台自营」实际并不一定是自己经营的产品，这种如果出问题也无法找到该平台，这里的「自营」和平常的理解有差异，但是这种会一定程度降低客户的信任度。</p><p>如果某些规章制度明显不合理，那么能否修改规章制度，还是随机执行，也能体现文化。比如公司园区内有很多地，车位不多，发现大家乱停车的时候，到底是宣传说不能乱停车，然后罚款，还是调研后增加车位，这些选择会影响公司的文化。</p><p>文化也是一件件选择塑造的，每一次选择可能可以对公司的文化往更好的方向发展，不变，往更差的方向发展，我们应该选择那些长期来看往更好方向发展的。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>公司的产品是需要有差异化才能保证更好的卖给客户，更好的赚钱，这也就是生意模式。但是生意模式也许要有系统/文化来保持，从而持久的产生有差异化的产品。文化不仅仅是公司墙上的规章制度，也包括平时的选择。但是需要区分这两点：1）是做了错的事情；2）做对的事情过程中犯了错。其中第一点就会导致文化变差，但是第二点是无法避免的（所有人都可能会犯错）。</p><p>另外对于个人来说，可以思考自己提供的什么产品/服务，自己的客户是谁，怎么提供差异化的产品/服务，然后怎么保持持续提供差异化的产品/服务，这样更能够将焦点聚焦在自己身上，而不是围绕工作转。</p><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><p>[1] <a href="https://baike.baidu.com/item/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ceo%E5%8D%AB%E5%93%B2%E5%BC%95%E5%92%8E%E8%BE%9E%E8%81%8C%E4%BA%8B%E4%BB%B6/6317687">https://baike.baidu.com/item/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ceo%E5%8D%AB%E5%93%B2%E5%BC%95%E5%92%8E%E8%BE%9E%E8%81%8C%E4%BA%8B%E4%BB%B6/6317687</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> differentiation </tag>
            
            <tag> strategy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>比较，机会成本以及迭代速度</title>
      <link href="/2025/04/17/compare-opportunity-cost-and-ratio/"/>
      <url>/2025/04/17/compare-opportunity-cost-and-ratio/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文希望能够通过对一些例子，梳理一些基本/常用的事项。</p></blockquote><p>在 <a href="https://mp.weixin.qq.com/s/7T22TF60g_FQV10xfzZBZw">分红及投资复利-以茅台为例</a> 一文中主要阐述了投资中复利的力量，从相关数据可以看出，复利能够让我们的得到更好的结果，复利中结果和利率也会相关。</p><p>本文尝试对利率(本文中的迭代速度)，比较以及机会成本进行相关阐述，希望能对这些有一个更深的认识。部分想法受《雪球特别版-段永平投资问答录》启发。 </p><span id="more"></span><h1 id="迭代速度"><a href="#迭代速度" class="headerlink" title="迭代速度"></a>迭代速度</h1><p>复利中有两个因为比较重要：时间，和增长率。时间我们在之前的文章中有大致描述。增长率/迭代速度 会在这里进行描述。</p><p>迭代速度大致分为三类：负数，零 和正数。其中负数表示往反方向发展，零表示不发展，正数表示往正方向发展。</p><p>下面的图形中展示了不同情况下 20 年后的总收益</p><ul><li>迭代速度分别是 2%，5%，8%，10%，15%，20%，30%，-2%，-5%，-8%，-10% 的总收益</li><li>迭代速度是 8%，15% 的情况下，每过两年会有 -2% 的增长的情况</li></ul><blockquote><p>这些数字的选择，大概是，每年 CPI 涨幅 2% 左右，GDP 涨幅 5% 左右，CPI + GDP 大概 8%，具体可以参考 <a href="https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ">股市是一个好的投资渠道吗</a><br>时间跨度选择的是 20 年</p><p>下图中通过点击标题，可以展示/隐藏不同情况下的曲线</p></blockquote><div id="echarts4680" style="width: 85%;height:400px;margin: 0 auto"></div><script src="https://unpkg.com/echarts@5.6.0/dist/echarts.min.js" ></script><script >  if (window.eChartecharts4680ResizeHandler) {    window.removeEventListener("resize", eChartecharts4680ResizeHandler);  }  var optionecharts4680 = {  legend: {    data: ['2', '5', '8', '8(-2)', '10', '15', '15(-2)', '20', '25', '-2', '-5', '-8', '-10']  },  tooltip: {    trigger: 'axis'  },  xAxis: {    type: 'category',    data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]  },  yAxis: [    {      name: 'total-value',      type: 'value'    },  ],  series: [    {      name: '2',      data: [1, 1.02, 1.0404, 1.061208, 1.08243216, 1.1040808032, 1.126162419264, 1.14868566764928, 1.1716593810022657, 1.195092568622311, 1.2189944199947573, 1.2433743083946525, 1.2682417945625455, 1.2936066304537963, 1.3194787630628724, 1.3458683383241299, 1.3727857050906125, 1.4002414191924248, 1.4282462475762734, 1.4568111725277988, 1.485947395978355],      type: 'line',      yAxisIndex: 0    },    {      name: '5',      data: [1, 1.05, 1.1025, 1.1576250000000001, 1.2155062500000002, 1.2762815625000004, 1.3400956406250004, 1.4071004226562505, 1.477455443789063, 1.5513282159785162, 1.628894626777442, 1.7103393581163142, 1.79585632602213, 1.8856491423232367, 1.9799315994393987, 2.0789281794113688, 2.1828745883819374, 2.2920183178010345, 2.406619233691086, 2.5269501953756404, 2.6532977051444226],      type: 'line',      yAxisIndex: 0    },    {      name: '8',      data: [1, 1.08, 1.1664, 1.2597120000000002, 1.3604889600000003, 1.4693280768000003, 1.5868743229440005, 1.7138242687795207, 1.8509302102818825, 1.9990046271044333, 2.158924997272788, 2.331638997054611, 2.5181701168189803, 2.719623726164499, 2.937193624257659, 3.172169114198272, 3.425942643334134, 3.7000180548008648, 3.9960194991849343, 4.315701059119729, 4.660957143849308],      type: 'line',      yAxisIndex: 0    },    {      name: '8(-2)',      data: [1, 1.08, 1.1664, 1.143072, 1.2345177600000001, 1.3332791808000002, 1.306613597184, 1.41114268495872, 1.5240340997554178, 1.4935534177603094, 1.6130376911811342, 1.742080706475625, 1.7072390923461125, 1.8438182197338016, 1.9913236773125058, 1.9514972037662557, 2.107616980067556, 2.2762263384729606, 2.2307018117035016, 2.409157956639782, 2.601890593170965],      type: 'line',      yAxisIndex: 0    },    {      name: '10',      data: [1, 1.1, 1.2100000000000002, 1.3310000000000004, 1.4641000000000006, 1.6105100000000008, 1.771561000000001, 1.9487171000000014, 2.1435888100000016, 2.357947691000002, 2.5937424601000023, 2.853116706110003, 3.1384283767210035, 3.4522712143931042, 3.797498335832415, 4.177248169415656, 4.594972986357222, 5.054470284992944, 5.559917313492239, 6.115909044841463, 6.72749994932561],      type: 'line',      yAxisIndex: 0    },    {      name: '15',      data: [1, 1.15, 1.3224999999999998, 1.5208749999999995, 1.7490062499999994, 2.0113571874999994, 2.313060765624999, 2.6600198804687487, 3.0590228625390607, 3.5178762919199196, 4.0455577357079076, 4.652391396064093, 5.350250105473707, 6.152787621294762, 7.075705764488976, 8.137061629162321, 9.35762087353667, 10.761264004567169, 12.375453605252243, 14.231771646040078, 16.36653739294609],      type: 'line',      yAxisIndex: 0    },    {      name: '15(-2)',      data: [1, 1.15, 1.3224999999999998, 1.2960499999999997, 1.4904574999999995, 1.7140261249999993, 1.6797456024999993, 1.931707442874999, 2.221463559306249, 2.1770342881201237, 2.503589431338142, 2.879127846038863, 2.8215452891180854, 3.244777082485798, 3.7314936448586677, 3.6568637719614943, 4.205393337755718, 4.836202338419076, 4.739478291650695, 5.450400035398299, 6.267960040708043],      type: 'line',      yAxisIndex: 0    },    {      name: '20',      data: [1, 1.2, 1.44, 1.728, 2.0736, 2.48832, 2.9859839999999997, 3.5831807999999996, 4.299816959999999, 5.159780351999999, 6.191736422399999, 7.430083706879999, 8.916100448255998, 10.699320537907196, 12.839184645488634, 15.407021574586361, 18.48842588950363, 22.186111067404358, 26.62333328088523, 31.947999937062274, 38.33759992447473],      type: 'line',      yAxisIndex: 0    },    {      name: '25',      data: [1, 1.25, 1.5625, 1.953125, 2.44140625, 3.0517578125, 3.814697265625, 4.76837158203125, 5.9604644775390625, 7.450580596923828, 9.313225746154785, 11.641532182693481, 14.551915228366852, 18.189894035458565, 22.737367544323206, 28.421709430404007, 35.52713678800501, 44.40892098500626, 55.51115123125783, 69.38893903907228, 86.73617379884035],      type: 'line',      yAxisIndex: 0    },    {      name: '-2',      data: [1, 0.98, 0.9603999999999999, 0.9411919999999999, 0.9223681599999999, 0.9039207967999998, 0.8858423808639998, 0.8681255332467198, 0.8507630225817854, 0.8337477621301497, 0.8170728068875467, 0.8007313507497957, 0.7847167237347998, 0.7690223892601038, 0.7536419414749017, 0.7385691026454037, 0.7237977205924956, 0.7093217661806457, 0.6951353308570327, 0.6812326242398921, 0.6676079717550942],      type: 'line',      yAxisIndex: 0    },    {      name: '-5',      data: [1, 0.95, 0.9025, 0.8573749999999999, 0.8145062499999999, 0.7737809374999999, 0.7350918906249998, 0.6983372960937497, 0.6634204312890623, 0.6302494097246091, 0.5987369392383786, 0.5688000922764596, 0.5403600876626365, 0.5133420832795047, 0.48767497911552943, 0.46329123015975293, 0.44012666865176525, 0.41812033521917696, 0.3972143184582181, 0.37735360253530714, 0.35848592240854177],      type: 'line',      yAxisIndex: 0    },    {      name: '-8',      data: [1, 0.92, 0.8464, 0.778688, 0.7163929600000001, 0.6590815232000001, 0.6063550013440001, 0.5578466012364801, 0.5132188731375618, 0.47216136328655683, 0.4343884542236323, 0.3996373778857418, 0.36766638765488246, 0.3382530766424919, 0.31119283051109253, 0.28629740407020515, 0.26339361174458875, 0.24232212280502166, 0.22293635298061995, 0.20510144474217037, 0.18869332916279674],      type: 'line',      yAxisIndex: 0    },    {      name: '-10',      data: [1, 0.9, 0.81, 0.7290000000000001, 0.6561000000000001, 0.5904900000000002, 0.5314410000000002, 0.47829690000000014, 0.43046721000000016, 0.38742048900000015, 0.34867844010000015, 0.31381059609000017, 0.28242953648100017, 0.25418658283290013, 0.22876792454961012, 0.2058911320946491, 0.1853020188851842, 0.16677181699666577, 0.1500946352969992, 0.13508517176729928, 0.12157665459056936],      type: 'line',      yAxisIndex: 0    }  ]};  if (window.echarts !== undefined) {    var eChartecharts4680 = echarts.init(document.getElementById('echarts4680'));    eChartecharts4680.setOption(optionecharts4680);    var eChartecharts4680ResizeHandler = function() {      eChartecharts4680.resize();    };    window.addEventListener("resize", eChartecharts4680ResizeHandler);  }</script><p>我们可以大致对比几组上面的情况：</p><ul><li>不同迭代速度下 10/20 年后的情况</li><li>同一迭代速度前 10 年和后 10 年的情况</li><li>同一利率下有回撤与无回撤的情况对比</li><li>负利率情况下的情况</li></ul><p>我们可以看到 5%，10%，15%，20% 迭代速度下</p><ul><li>10 年后，分别的总收益是 1.62, 2.59，4.04, 6.19, 可以看出不同迭代速度下，总收益差距还是不少的，但是好像也并没有那么大（从 5% 增长到 10%，增长了没有 1 倍，从 10% 增长到 20% 的情况下，总收益增长了 1 倍多一点）；</li><li>20 年后，分别的总收益是 2.65, 6.72, 16.36, 38.33. 拉长时间后，如果迭代速度增加越大，整体收益会越高，而且迭代速度每增长 5%，整体收益增长 2-3 倍的样子。</li></ul><p>在不同迭代速度下（5%，10%，15%，20%），前 10 年和后 10 年的增长分别如下</p><div class="table-container"><table><thead><tr><th>迭代速度</th><th>10 年收益</th><th>20 年总收益</th></tr></thead><tbody><tr><td>5%</td><td>1.62</td><td>2.65</td></tr><tr><td>10%</td><td>2.59</td><td>6.72</td></tr><tr><td>15%</td><td>4.04</td><td>16.36</td></tr><tr><td>20%</td><td>6.19</td><td>38.33</td></tr></tbody></table></div><p>可以看出如果迭代速度越大，那么 20 年和 10 年总收益差距越大（但是前 10 年的增长率和后十年的增长率实际是一样的，因为都是 (1 + r) ^ 10), 整体差距来自于基数的差异，由于迭代速度越大，第 10 年的时候整体收益越大，因此第 20 年的时候总收益会越好（基于第 10 年的总收益）</p><p>接下来对比下，每两年有 2% 回撤的增长情况：增长率分别为 8% 和 15%，然后另外在当前迭代速度下，每 3 年有 2% 的回撤</p><ul><li>在第 10 年的时候，8%，8% + 每 3 年回撤 2%，15%， 15% + 每 3年回撤 2% 的总收益分别是：2.15，1.61, 4.04, 2.5 ，可以看到每 3 年回撤 2% 对整体收益影响就挺大：总收益将近少了一半。</li><li>第 20 年的时候，8%，8% + 每 3 年回撤 2%，15%， 15% + 每 3年回撤 2% 的总收益分&gt;别是：4.6, 2.6, 16.3, 6.2。可以看出年限越长，有回撤的和无回撤的差距更大。</li></ul><p>接下来再看看负迭代速度的情况，-2%，-5%，-8%，-10% 迭代速度的情况下<br>10 年的情况下，总收益分别为 0.81, 0.59, 0.43, 0.34， 在 20 年的时候总收益分别为 0.66, 0.35, 0.18, 0.12。不管负迭代速度是多少，时间久了之后，整体收益会比较明显，如果迭代速度达到 -10% 的情况下，10 年就已经不剩一半了，20 年就只剩 1 成了。</p><p>另外由于股市是非固定收益，因此不卖出的情况下，可以不算回撤（但是股价能否涨上去是另外一回事），股市更好的计算比例需要看长期的复合年化收益。如果自己不好计算，可以找一个 App 帮助计算。</p><h1 id="比较和机会成本"><a href="#比较和机会成本" class="headerlink" title="比较和机会成本"></a>比较和机会成本</h1><p>投资中决策是非常重要的一点，决策会涉及到比较，在日常生活中也会经常有比较, 这里主要阐述一些常见的比较情况。</p><p>有两个假设前提<br>1 同一时刻只能做一件事情<br>2 时间是不可逆的，过去了就没有了</p><p>比较的时候可能会涉及多个维度，或者对比的维度不统一，而在做决策的时候更好的是能够对一个或多个选项进行同样维度的比较。比如下面的一些比较问题：</p><ul><li>投资中，某个投资标的数据发生变化，那么是否实际影响投资决策（比如茅台的预收账款变少）</li><li>低价促销的东西，到底要不要买，不买感觉亏了，买好像又不是特别需要</li><li>某类投资方式能大概率变富，但是时间比较长，比如 20 年，这种要不要投呢</li></ul><p>下面尝试对每一个问题进行详细的阐述</p><h2 id="投资数据变化的影响"><a href="#投资数据变化的影响" class="headerlink" title="投资数据变化的影响"></a>投资数据变化的影响</h2><p>之前文章中我们说过，买股票就是买公司，那么公司的指标就会影响公司的情况，到底哪些指标的变化，变化成啥样会影响公司呢</p><p>这里以一个预收款减少的情况作为例子，比如某公司某年的预售款比之前少了，可能不少人会觉得，这是公司变差的一个信号，甚至说已经不是一个可以继续投资的信号了。</p><p>回到投资的本质来说，我们希望将钱放到某些投资标的中，从而获取更好的收益，就像 <a href="https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ">股市是一个好的投资渠道吗</a> 描述的那样。那么我们应该比较的是：1）当前公司因为预收款等实际影响公司的营收；2）其他公司的情况怎么样 — 因为如果我们不投资到当前公司，就需要投资到其他地方。</p><p>然后我们可能发现，大部分公司实际上是没有预收款的，反而是有不少应收账款。那么预收款减少也就是说还有，还有就表示相对下游还有定价权（比较抢手，下游希望通过提前交钱来预订）。那么就要看这个预收款减少是否有影响公司未来的盈利能力。</p><h2 id="促销商品购买"><a href="#促销商品购买" class="headerlink" title="促销商品购买"></a>促销商品购买</h2><p>商品经常会使用类似降价的方式来进行促销，比如原价 A 售卖的，现在通过降价 30% 售卖，而且降价只有最后 3 天。</p><p>那么这种情况下我们的购买策略应该比较的是：[购买] VS [不购买] 是否影响自己的生活情况。而不是 [原价] 和 [降价了 30%] 进行对比。将是否需要和价格情况进行组合将得到如下的情况</p><div class="table-container"><table><thead><tr><th></th><th>需要</th><th>不需要</th></tr></thead><tbody><tr><td>原价</td><td>(1)</td><td>(2)</td></tr><tr><td>降价</td><td>(3)</td><td>(4)</td></tr></tbody></table></div><p>也就是对应的优先级应该是 (3) &gt; (1) &gt;&gt; (4) &gt; (2)。也就是说在我们应该在需要的情况下再考虑价格，如果不需要的情况下，就算降价购买，那也是一种浪费。</p><h2 id="长期和短期"><a href="#长期和短期" class="headerlink" title="长期和短期"></a>长期和短期</h2><p>在价值投资中，往往需要比较长时间才能有好的结果，比如 10 年 5 倍，20 年 15 倍（复合年化 15% 已经很不错了），但是可能有人看到后会说，自己希望是短期就能变富，10 年 20 年太久了，另外看上去 10 年 20 年后这个收益好像也不是很高。</p><p>这个可以这样比较：[选择这种投资方式，复合年化 15%] VS [其他投资渠道]。然后比较两种投资渠道哪个更能满足自己的需求</p><ul><li>投资时间的情况（短期还是长期）</li><li>变富</li></ul><p>其中短期和长期来说，不同的投资市场会影响投资决策，如果是短期投资，不一定适合投资非固定收益的标的（比如股市），因为股市短期的涨跌太难预测，但是长期来说，股价围绕公司价值波动，那么股价就更好预测一些。</p><p>另外变富是人人都想要的，但是具体到投资来说，就会有复合年化收益来衡量。对于不同收益率在不同年限中的总收益情况可以参考前文的情况。然后我们应该考虑的是 [选择该方式] 和 [选择其他方式] 哪个更能够让自己变的更富有，而不是单纯的觉得某个收益率太高或者太低。</p><h2 id="机会成本"><a href="#机会成本" class="headerlink" title="机会成本"></a>机会成本</h2><p>比较会进一步促进决策（不行动也是一种决策），由于没法同时做两件事，因此部分只能进行假设的比较，因此选择的成本实际是我们选择了 A 之后，剩下的所有选项中最好结果来决定的，这也就是我们的机会成本 — 因为当前决策导致我们丧失了一次机会。</p><p>投资是一个称重游戏，那么我们需要做的是，在较长的时间内，比较多个投资标的，哪个会增长的更多，所有投资的机会成本是自己能获得的稳定收益的最高值，这个对大部分人来说是长期无风险国债，具体的利率可以参考 <a href="https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ">股市是一个好的投资渠道吗</a>。然后对于未来现金流折线来说，折现率我们也可以使用机会成本来进行计算。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文尝试描述迭代速度/增长比率，比较以及机会成本，这些不仅仅在投资中重要，在平时生活中也有不小影响，有复利的情况下都能套用迭代速度，然后比较和机会成本也会影响我们的每次决策，从而影响我们的生活。</p><p>但是需要注意的一点是 决策的质量 和 决策后的结果好坏并不完全相关，它们会有如下四种情况</p><div class="table-container"><table><thead><tr><th></th><th>好决策</th><th>差决策</th></tr></thead><tbody><tr><td>好结果</td><td>1</td><td>2</td></tr><tr><td>坏结果</td><td>3</td><td>4</td></tr></tbody></table></div><p>其中 1 和 4 是我们很容易了解并接受的，但是实际生活中还会有 2 和 3 的存在，如果在对过去决策进行复盘的时候，我们需要考虑到这些情况的存在，另外每次决策的时候也应该记录更多的上下文信息，这样在后续复盘的时候能够知道当时的决策是否好，而不仅仅是通过结果来进行判断。</p>]]></content>
      
      
      
        <tags>
            
            <tag> compare </tag>
            
            <tag> opportunity-cost </tag>
            
            <tag> iterative velocity </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分红以及投资复利-以茅台为例</title>
      <link href="/2025/04/09/invest-compond/"/>
      <url>/2025/04/09/invest-compond/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文尝试对上市公司分红以及投资复利进行一些分析，希望能够更好的了解投资的选择标准，以及操作标准。</p></blockquote><p>在 <a href="https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA">赚钱机器茅台</a> 一文中，我们有提到分红相关的事情，这里我们仍旧以茅台为例分析下分红相关的内容。</p><span id="more"></span><h1 id="股本位"><a href="#股本位" class="headerlink" title="股本位"></a>股本位</h1><p>现在的生活中大家会以拥有 <em>本币本位/纸币本位</em> 的视角，也就是所有的价值/价格体系等都会锚定到本国法币的价值，同时也有一个 <em>金本位</em>，表示所有的价值都体现在包含多少黄金。</p><p>那么对于股市投资是不是可以有一种“股本位”的视角，那么所有的目的都是以 <em>股数</em> 作为衡量，我们的目的也将变成获取更多的 <em>股数</em>。</p><h1 id="分红以及投资收益"><a href="#分红以及投资收益" class="headerlink" title="分红以及投资收益"></a>分红以及投资收益</h1><p>接下来我们以茅台上市后股东收益来阐述分红，复利，收益等。</p><h2 id="分析情况说明"><a href="#分析情况说明" class="headerlink" title="分析情况说明"></a>分析情况说明</h2><p>首先描述下本文会使用到的一些情况</p><ol><li>本文假设股票可以零散买入，也就是没有最低股数要求，甚至可以买入小于 1 股（比如 0.01 股）</li><li>对于茅台整个上市历史的收益，起点为上市是购入 1 元茅台股（为了计算方便，不影响整体收益比例）</li><li>对于比较中最近十年的收益情况，起点为 2015 年选择一个市值高点，以市价买入 1 元茅台股票</li></ol><p>原始数据整理如下，数据来源[1]，股数计算公式参考图片中左上角的公式，市值是 股数 * 股价。</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121251913.png" alt=""></p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121253102.png" alt=""></p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121254827.png" alt=""></p><h2 id="收益和股数"><a href="#收益和股数" class="headerlink" title="收益和股数"></a>收益和股数</h2><p>通过整体茅台的数据，绘制如下几张图，下图中展示了不同纬度情况下茅台股票的收益（总市值和总股数），其中</p><ul><li>ValueFromInit 表示从上市开始投入 1 元，然后分股继续持有，分红再买入后的总市值</li><li>CountFromInit 表示从上市开始投入 1 元，然后分股继续持有，分红再买入后的总股数</li><li>ValueFrom2015 表示从 20150526 开始投入 1 元，然后分股继续持有，分红再买入后的总市值</li><li>CountFrom2015 表示从 20150526 开始投入 1 元，然后分股继续持有，分红再买入后的总股数</li></ul><blockquote><p>选择 20150526 是因为当天市值是当年一个高值<br>下图中的每条线可以点击标题控制是否显示</p></blockquote><div id="echarts7404" style="width: 85%;height:400px;margin: 0 auto"></div><script src="https://unpkg.com/echarts@5.6.0/dist/echarts.min.js" ></script><script >  if (window.eChartecharts7404ResizeHandler) {    window.removeEventListener("resize", eChartecharts7404ResizeHandler);  }  var optionecharts7404 = {  legend: {    data: ['ValueFromInit', 'CountFromInit', 'ValueFrom2015', 'CountFrom2015']  },  tooltip: {    trigger: 'axis'  },  xAxis: {    type: 'category',    data: ['20020725', '20030714', '20040701', '20050804', '20060519', '20060524', '20070713', '20080613', '20090701', '20100705', '20110701', '20120705', '20130607', '20140625', '20150717', '20160701', '20170707', '20180615', '20190628', '20200624', '20210625', '20220628', '20221226', '20230629', '20231219', '20240618', '20241219']  },  yAxis: [    {      name: 'total-value',      type: 'value'    },    {      name: 'stock-count',      type: 'value'    }  ],  series: [    {      name: 'ValueFromInit',      data: [1.15, 0.93, 1.38, 3.47, 4.97, 5.05, 14.69, 19.29, 18.94, 16.52, 27.98, 37.33, 30.06, 24.64, 44.26, 56.68, 89.67, 157.71, 203.64, 305.67, 442.03, 433.51, 376.70, 376.17, 371.87, 344.64, 356.74],      type: 'line',      yAxisIndex: 0    },    {      name: 'ValueFrom2015',      data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.88, 1.12, 1.78, 3.13, 4.05, 6.08, 8.79, 8.62, 7.49, 7.48, 7.40, 6.86, 7.10],      type: 'line',      yAxisIndex: 0    },    {      name: 'CountFromInit',      data: [0.0356, 0.0394, 0.0517, 0.0626, 0.1257, 0.1275, 0.1283, 0.1290, 0.1301, 0.1313, 0.1460, 0.1483, 0.1532, 0.1732, 0.1938, 0.1980, 0.2010, 0.2039, 0.2069, 0.2093, 0.2112, 0.2135, 0.2162, 0.2190, 0.2220, 0.2265, 0.23],      type: 'line',      yAxisIndex: 1    },    {      name: 'CountFrom2015',      data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.00344, 0.00385, 0.00394, 0.0040, 0.00405, 0.00411, 0.00416, 0.0042, 0.00425, 0.0043, 0.00436, 0.00441, 0.0045, 0.00457],      type: 'line',      yAxisIndex: 1    }  ]};  if (window.echarts !== undefined) {    var eChartecharts7404 = echarts.init(document.getElementById('echarts7404'));    eChartecharts7404.setOption(optionecharts7404);    var eChartecharts7404ResizeHandler = function() {      eChartecharts7404.resize();    };    window.addEventListener("resize", eChartecharts7404ResizeHandler);  }</script><p>下面的图中，20140625 之前的表示从上市开始投入 1 元后，总市值和总股数的情况，20140625 以及以后的情况则表示在 20140625 买入 1 元后的总市值和总股数情况，其中</p><ul><li>Value 表示对应时间的总市值</li><li>Count 表示对应时间的总股数</li></ul><blockquote><p>下图中的每条线可以点击标题控制是否显示</p></blockquote><div id="echarts9375" style="width: 85%;height:400px;margin: 0 auto"></div><script src="https://unpkg.com/echarts@5.6.0/dist/echarts.min.js" ></script><script >  if (window.eChartecharts9375ResizeHandler) {    window.removeEventListener("resize", eChartecharts9375ResizeHandler);  }  var optionecharts9375 = {  legend: {    data: ['Value', 'Count']  },  tooltip: {    trigger: 'axis'  },  xAxis: {    type: 'category',    data: ['20020725', '20030714', '20040701', '20050804', '20060519', '20060524', '20070713', '20080613', '20090701', '20100705', '20110701', '20120705', '20130607', '20140625', '20150717', '20160701', '20170707', '20180615', '20190628', '20200624', '20210625', '20220628', '20221226', '20230629', '20231219', '20240618', '20241219']  },  yAxis: [    {      name: 'total-value',      type: 'value'    },    {      name: 'stock-count',      type: 'value'    }  ],  series: [    {      name: 'Value',      data: [1.15, 0.93, 1.38, 3.47, 4.97, 5.05, 14.69, 19.29, 18.94, 16.52, 27.98, 37.33, 30.06, 1, 0.88, 1.12, 1.78, 3.13, 4.05, 6.08, 8.79, 8.62, 7.49, 7.48, 7.40, 6.86, 7.10],      type: 'line',      yAxisIndex: 0    },    {      name: 'Count',      data: [0.0356, 0.0394, 0.0517, 0.0626, 0.1257, 0.1275, 0.1283, 0.1290, 0.1301, 0.1313, 0.1460, 0.1483, 0.1532, 0.00344, 0.00385, 0.00394, 0.0040, 0.00405, 0.00411, 0.00416, 0.0042, 0.00425, 0.0043, 0.00436, 0.00441, 0.0045, 0.00457],      type: 'line',      yAxisIndex: 1    },  ]};  if (window.echarts !== undefined) {    var eChartecharts9375 = echarts.init(document.getElementById('echarts9375'));    eChartecharts9375.setOption(optionecharts9375);    var eChartecharts9375ResizeHandler = function() {      eChartecharts9375.resize();    };    window.addEventListener("resize", eChartecharts9375ResizeHandler);  }</script><h2 id="简单分析"><a href="#简单分析" class="headerlink" title="简单分析"></a>简单分析</h2><p>上面的信息可以分为如下几组的对比</p><ul><li>不同阶段十年的对比：2001 年到 2010 年这十年，与 2015 年到 2024 年这十年对比</li><li>十年和二十多年的对比：2001 年到 2012 年这 11 年，与 2001 年到 2014 年这 23 年对比</li><li>二十多年前后段和后半段的对比：2001 年到 2012 年，与 2012 年到 2024 年进行对比</li><li>对比分红再买入和分红不再买入的情况</li></ul><p>其中第一组可以发现 2001 年到 2010 年这十年总市值变为 <strong>16.56</strong>, 总股数是 <strong>0.1313</strong> 。也就是总市值变成了原来的 <strong>16</strong> 倍，股数变为原来的 <strong>3.6</strong> 倍左右；2015 年到 2024 年这十年总价值变成了 <strong>7.1</strong>，总股数变成了 <strong>0.00457</strong>, 总价值变成了原来的 <strong>7</strong> 倍左右，股数变成了原来的 <strong>1.3</strong> 倍。通过对比可以看出</p><ol><li>后面这十年总收益比前面十年少</li><li>后面这十年总股数增加的不如前十年多</li><li>总股数前十年比后十年多更多。这里可能有多个原因：1）前十年有过送股；2）前十年股价更低，同样分红的钱能买更多的股数</li></ol><p>第二组可以看出来，总共 24 年总市值变为 <strong>356.74</strong>，总股数变为 <strong>0.23</strong>，总市值是原来的 <strong>356</strong> 倍，总股数是原来的 <strong>6.4</strong> 倍；前 11 年总市值变为 <strong>37.33</strong>，总股数变为 <strong>0.1483</strong>, 总市值变为原来的 <strong>37</strong> 倍，总股数变为原来的 <strong>4</strong> 倍。这里可以看出来，时间长一倍，总市值不仅仅是多一倍，二十将近 <strong>10</strong> 倍，从原来的 <strong>37</strong> 倍变成了 <strong>356</strong> 倍。总股数由于后面股价上涨了，则增长不多。</p><p>第三组可以看出来，前面十二年总价值从 1 涨到 <strong>37.33</strong>，总股数从 <strong>0.0356</strong> 变为 <strong>0.1483</strong>；后面十二年，价值从 <strong>37.33</strong> 涨到 <strong>356.74</strong>,总股数从 <strong>0.1483</strong> 涨到 <strong>0.23</strong>。可以看出来</p><ol><li>前面十二年总价值涨了 <strong>37</strong> 倍，后面十二年总价值涨了将近 <strong>10</strong> 倍</li><li>前面十二年总股数涨到原来 <strong>4</strong> 倍，后面十二年总股数涨到 <strong>1.6</strong> 倍<br>可以大致认为，股数越多，总收益越多；股价更低的时候，股东总收益反而会更好。</li></ol><p>第四组 分红不再买入的情况下，总市值变为 <strong>248.27</strong>, 总股数变为 <strong>0.16</strong>。分红再买入的情况下，总市值变为 <strong>356.74</strong>，总股数变为 <strong>0.23</strong>。分红再投入的总收益会更高。从总收益来看差异还挺大，分红不再买入的情况下是 <strong>248</strong> 倍，分红再买入的情况下是 <strong>356</strong> 倍。</p><h2 id="整体结论"><a href="#整体结论" class="headerlink" title="整体结论"></a>整体结论</h2><ol><li>投资是有复利的，所以越早开始投资越好，投资的时间越长越好</li><li>对于好公司（上面的茅台），不管是否分红再投入，都能有不错的收益</li><li>对于好公司，分红应该再投入，收益会更多<br>3.1  分红可以理解为公司部分收益的处置权交给所有股东（而不是只有大股东），股东收到分红后至少有两个选择：1）继续买入；2）不买入该投资标的。那么这两种选择也会有不同的收益，如果不买入该投资标的的收益无法比过当前投资标的，则收益会变少 — 当然如果有正当使用需要则另说。<br>3.2  另外可以从股本位的视角来考虑，分红再买入是再增加整体股数，长远来看收益也会更好。</li><li>市值 = 股数 * 单价。股数和股票单价上涨均能导致市值上涨。<br>4.1. 市值短期受市场影响（市场内参与该股票交易所有人的预期），长期受公司内在价值影响。也就是说从长期来看公司股价会围绕公司价值波动。<br>4.2. 不管股价是否增长，股数增长均会提高整体市值，但是股价增长，会导致同样资金能够买到的股数变少。<br>4.3. 因此股价大幅增长对股东来说反而不是一个好事情:1）股价是否涨高，并不会影响公司的营业情况 — 也就是盈利、分红等；2）股价涨高导致能买的股数变少（实际情况下甚至由于股价过高，分红没法购买 1 手）。</li></ol><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ol><li>上面的所有分析，有一个前提：公司是一个好公司。</li><li>不是所有公司的收益率都如茅台，因此上述数据仅作参考。</li><li>我们可以多一个维度分析公司的收益情况。如果公司是好公司的情况下，整体收益可以由 &lt;股数 * 股价&gt; 决定，那么我们在用数据进行筛选公司的时候，可以考虑分红再买入后的情况。</li><li>既然上面说的分红再买入会更好，那是不是可以让公司不分红（变相的相当于再买入），分红的意义是啥呢？<br>4.1. 分红会从利润中出，公司分红表示有利润，同时如果公式有分红比例的话，会变相的约束公司不虚报利润（只可能隐藏利润） — 表明公司利润只会比表现出来的更好。也可以一定情看下监督公司一年经营情况<br>4.2. 分红后的钱股东有自由取决权，可以再买入，可以用于其他途径（生活，或者投资其他地方）</li><li>分红的情况是将当年的收益分配给股东的一种形式，可以有三种：现价分红；派发新股；转增股本[2]，这里说的分红主要是是现价分红。</li></ol><p>另外建议结合 <a href="https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ">股市是一个好的投资渠道吗</a> 一起阅读（注意：里面茅台相关总收益/总股数计算有误，以本文为准），里面对不同投资标的进行一个分析</p><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><p>[1] <a href="https://vip.stock.finance.sina.com.cn/corp/go.php/vISSUE_ShareBonus/stockid/600519.phtml">https://vip.stock.finance.sina.com.cn/corp/go.php/vISSUE_ShareBonus/stockid/600519.phtml</a><br>[2] <a href="https://www.morganstanleysecurities.com.cn/investor/education-dividendpolicy.html">https://www.morganstanleysecurities.com.cn/investor/education-dividendpolicy.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> stock </tag>
            
            <tag> investment </tag>
            
            <tag> 分红 </tag>
            
            <tag> compond </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>maotai-input-output</title>
      <link href="/2025/03/16/maotai-input-output/"/>
      <url>/2025/03/16/maotai-input-output/</url>
      
        <content type="html"><![CDATA[<p>本文尝试更详细的分析茅台以及所在行业的一些指标信息，希望对茅台是否赚钱，以及赚钱后是否能够归属小股东等有一个大体的认识，也希望能够更好的了解应该关注公司哪些指标以及信息。</p><span id="more"></span><p>对于股东来说，主要关注一个公司两点</p><ol><li>公司业务是否赚钱</li><li>公司业务赚钱之后，是否都归属于股份有限公司（股东所有)</li></ol><h1 id="茅台的业务"><a href="#茅台的业务" class="headerlink" title="茅台的业务"></a>茅台的业务</h1><p>茅台的业务主要是卖酒，在茅台酒的整条链路中，大致如下所示</p><p>[原材料提供商] —原材料—&gt; [茅台股份有限公司]  —酒—&gt; [直销/经销商] (—酒—&gt; [终端销售]) —酒—&gt; [终端客户]</p><p>其中 [终端销售] 这一环节可能没有，比如在直销或者电商等渠道</p><p>国信证券梳理[2]的销售渠道以及相关价格如下所示（2023 年出厂价涨价前）</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231410651.png" alt=""></p><p>涨价后，大致修改如下所示</p><ul><li>原材料提供商<ul><li>茅台股份有限公司<ul><li>[直销] i茅台/数字营销平台  &lt;— 零售指导价 1499</li><li>茅台销售公司<ul><li>[经销] 一级经销商  &lt;— 拿酒成本是 出厂价 1199<ul><li>终端销售  &lt;— 一批价 按照[2] 大概 2300<ul><li>客户    &lt;— 实际购买价  散装大概 2600[3]，会持续有变动</li></ul></li></ul></li></ul></li><li>商超  &lt;—  1399 参考国信证券数据[2]</li><li>电商  &lt;—  1399 参考国信证券数据[2]</li><li>团购  &lt;— 零售指导价 1499</li></ul></li></ul></li></ul><p>其中出厂价是固定的(1199)，零售指导价是固定的(1499)，批价和终端价会随着市场需求的变动而变化。如果终端需求多，终端价会增加，从而会提高批价，反之则会导致终端价和批价下降。</p><p>其中出厂价/建议零售价/商超/电商/团购的 基本固定（变动周期较长），经销商相关的的销售链路，其中 [终端价] 和 [批价] 的差异为终端销售的利润，[批价] 和 [出厂价] 的差异则是经销商的利润。如果这两个利润过低甚至变负，则会影响整条链路上的整体酒销售。</p><p>下图展示了经销商在过去几年中的利润空间变化（其中灰色的区域是渠道利润，红色是出厂价，蓝色是批价）[2]</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202504021431926.png" alt=""></p><h1 id="茅台是否赚钱"><a href="#茅台是否赚钱" class="headerlink" title="茅台是否赚钱"></a>茅台是否赚钱</h1><p>茅台的整体业务比较简单，主要是卖酒，然后还有部分金融业务。</p><p>首先看下最近几年的营收和成本，如下图所示<br><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231446109.png" alt=""></p><p>上图中可以看出几点</p><ul><li>利润主要来自于营业收入 — 也就是卖酒。</li><li>营业收入最近几年逐年增加</li><li>营业成本的增长率和营业收入的增长率差不多</li></ul><p>其中营业收入拆开来看的情况如下图所示<br><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231417076.png" alt=""></p><p>从图中可以看到</p><ul><li>最多的成本是税及附加 — 由于税率固定，这部分是卖的越多，税越多</li><li>营业成本逐年增加，但是增加的没有税多</li><li>管理费用/销售费用 逐年增加，但是增加不是很多，整体占比也不是很多</li></ul><p>另外从不同角度查看营业收入的情况。</p><p>茅台酒和系列酒的情况（单位：百万）</p><div class="table-container"><table><thead><tr><th>年份</th><th>茅台酒(占比/较上年涨幅)</th><th>系列酒(占比/较上年涨幅)</th></tr></thead><tbody><tr><td>2023</td><td>126589(85.9%/17.6%)</td><td>20629(14.1%/29.4%)</td></tr><tr><td>2022</td><td>107833(87.1%/15.3%)</td><td>15938(12.9%/26.5%)</td></tr><tr><td>2021</td><td>93464(88.1%/10.1%)</td><td>12594(11.9%/26%)</td></tr><tr><td>2020</td><td>84830(89.4%/11.9%)</td><td>9991(10.6%/4.7%)</td></tr><tr><td>2019</td><td>75802(88.8%/15.7%)</td><td>9542(11.2%/18.2%)</td></tr></tbody></table></div><p>经销和直销的收入情况（单位：百万）</p><div class="table-container"><table><thead><tr><th>年份</th><th>经销（占比/较上年涨幅)</th><th>直销（占比/较上年涨幅）</th></tr></thead><tbody><tr><td>2023</td><td>7998611.94(54.33%/7.5%)</td><td>6723287.69(45.67%/36.15%)</td></tr><tr><td>2022</td><td>7439359.47(60.10%/-9.4%)</td><td>4937873.77(39.9%/105%)</td></tr><tr><td>2021</td><td>8202992(77.34%/0.5%)</td><td>2402936(22.66%/81.48%)</td></tr><tr><td>2020</td><td>8158164.26(86.03%/377%)</td><td>1324035.65(13.97%/82.6%)</td></tr><tr><td>2019</td><td>7809590.86(91.5%/-)</td><td>724865.97(8.5%/-)</td></tr></tbody></table></div><p>经销和直销的酒量情况（单位：吨）</p><div class="table-container"><table><thead><tr><th>年份</th><th>经销（占比/较上年涨幅)</th><th>直销（占比/较上年涨幅）</th></tr></thead><tbody><tr><td>2023</td><td>57639.09(78.66%/1.1%)</td><td>15634.95(21.34%/39.76%)</td></tr><tr><td>2022</td><td>56989.75(83.59%/-6.1%)</td><td>11186.57(16.41%/95.04%)</td></tr><tr><td>2021</td><td>60702.99(91.36%/0.9%)</td><td>5735.70(8.64%/45.85%)</td></tr><tr><td>2020</td><td>60123.8(93.86%/-3.01%)</td><td>3932.08(6.14%/48.32%)</td></tr><tr><td>2019</td><td>61993.46(95.89%/-)</td><td>2651.84(4.11%/-)</td></tr></tbody></table></div><p>从上面的数据可以看到，经销的量基本没有太大变化，总收入稍微有些增长；直销的量和收入均有比较大的增长。</p><p>国内和国外销售情况（单位：百万），暂时国内销售占主要比例</p><div class="table-container"><table><thead><tr><th>年份</th><th>国内（占比/较上年涨幅)</th><th>国外（占比/较上年涨幅）</th></tr></thead><tbody><tr><td>2023</td><td>142868(97%/19.5%)</td><td>4350(3%/2.6%)</td></tr><tr><td>2022</td><td>119532(96.5%/15.5%)</td><td>4239(3.5%/61.9%)</td></tr><tr><td>2021</td><td>103440(97.5%/11.9%)</td><td>2618(2.5%/7.6%)</td></tr><tr><td>2020</td><td>92389(97.4%/12%)</td><td>2432(2.6%/-16.8%)</td></tr><tr><td>2019</td><td>82424(96.5%/16.6%)</td><td>2920(3.5%/0.9%)</td></tr></tbody></table></div><p>接下来查看预收账款（单位：百万）相关的情况 — 经销售需要预打款才能买到货（这个也变相的说明茅台不愁销量 — 这里的销量和终端销售公司的销量不完全是一个概念），可以每年有百亿级别的预收账款</p><div class="table-container"><table><thead><tr><th>年份</th><th>预售款（增长）</th></tr></thead><tbody><tr><td>2023</td><td>14,125(-8.7%)</td></tr><tr><td>2022</td><td>15,471(21.64%)</td></tr><tr><td>2021</td><td>12,718(4.5%)</td></tr><tr><td>2020</td><td>13,321(-3.0%</td></tr><tr><td>2019</td><td>13,740(-)</td></tr></tbody></table></div><p>然后再看下不同类型酒的销售额（单位：十亿），以及涨幅如下。从数据可以看出来，白酒持续在增长，但是其他类型酒的销售额则有不同类型的波动。</p><div class="table-container"><table><thead><tr><th>年份</th><th>白酒（涨幅)</th><th>啤酒（涨幅）</th><th>葡萄酒（涨幅）</th><th>黄酒（涨幅）</th></tr></thead><tbody><tr><td>2023</td><td>756(19.5%)</td><td>186.3(8.6%)</td><td>9(4.8%)</td><td>21(2.1%)</td></tr><tr><td>2022</td><td>662(9.64%)</td><td>175.1(10.1%)</td><td>9.1(-2.91%)</td><td>1.2(-24.3%)</td></tr><tr><td>2021</td><td>603(18.6%)</td><td>158.4(7.91%)</td><td>9(-9.79%)</td><td>12.7(-5.24%)</td></tr><tr><td>2020</td><td>583(4.61%)</td><td>146.8(-6.12%)</td><td>10(-29.82%)</td><td>13.4(-20.18%)</td></tr><tr><td>2019</td><td>561(8.2%)</td><td>158(4.8%)</td><td>14.5(17.5%)</td><td>17.3(2.7%)</td></tr></tbody></table></div><p>然后查看茅台酒和系列酒占整个白酒的销售收入情况如下（单位十亿），可以看出茅台酒和系列酒的收入在缓慢上升。</p><div class="table-container"><table><thead><tr><th>年份</th><th>白酒（较上年涨幅)</th><th>茅台酒（占比）</th><th>系列酒（占比）</th></tr></thead><tbody><tr><td>2023</td><td>756(19.5%)</td><td>126.5(16.7%)</td><td>20.6(2.7%)</td></tr><tr><td>2022</td><td>662(9.64%)</td><td>107.8(16.2%)</td><td>15.9(2.4%)</td></tr><tr><td>2021</td><td>603(18.6%)</td><td>93.4(15.4%)</td><td>12.5(2.0%)</td></tr><tr><td>2020</td><td>583(4.61%)</td><td>84.8(14.5%)</td><td>9.9(1.6%)</td></tr><tr><td>2019</td><td>561(8.2%)</td><td>75.8(13.5%)</td><td>9.5(1.6%)</td></tr></tbody></table></div><p>另外由中酒协披露 2023 年酒业数据[4] 可知，白酒销量在减少，但整体实现营收不断上升，白酒整体逐步迈向高端化。</p><h1 id="收益归属"><a href="#收益归属" class="headerlink" title="收益归属"></a>收益归属</h1><p>接下来查看相关归属情况</p><p>我们看下以茅台股份有限公司为中心视角的一些公司情况</p><ul><li>中国贵州茅台酒厂（集团）有限责任公司  54.07%</li><li>香港中央结算有限公司  6.45%</li><li>贵州国有资本运营有限责任公司  4.64%</li><li>贵州茅台酒厂（集团）技术开发有限公司 2.22%</li><li>中国工商银行-上证50交易型开放式指数证券投资基金 1.01%</li><li>中国工商银行股份有限公司-华泰柏瑞沪深300交易型开放式指数证券投资基金 0.91%</li><li>中央汇金资产管理有限公司 0.83%</li><li>中国证券金融股份有限责任公司 0.64%</li><li>中国建设银行股份有限公司-易方达沪深300交易型开放式指数发起式证券投资基金 0.61%</li><li>中国人寿保险股份有限公司-传统-普通保险产品-005L-CT001沪 0.44%<ul><li>贵州茅台酒股份有限公司<ul><li>贵州茅台酱香酒营销有限公司 100%</li><li>贵州茅台酒销售有限公司 95%</li><li>北京友谊使者商贸有限公司 70%</li><li>国酒茅台定制营销（贵州）有限公司 70%</li><li>贵州茅台酒进出口有限责任公司 70%</li><li>贵州茅台集团财务有限公司 51%</li><li>贵州赖茅酒业有限公司 43%</li><li>贵州金石（贵州）产业发展基金合伙企业（有限公司）</li><li>茅台招华（贵州）产业发展基金合伙企业（有限合伙）</li></ul></li></ul></li></ul><p>其中「茅台股份有限责任公司」的收益是所有股东共享的，也就是说该公司的利润普通股东是有份的。</p><p>如果有部分利益从「贵州茅台酒股份有限公司」移到其他地方，则会有损小股东的权益，比如 2009 年成立的 茅台销售公司成立是大家所担心的那样 —  后来茅台股份公司回应统一按照出厂价较会议，不影响股份有限公司的收。</p><p>那么另外有一个问题，这部分归属于小股东的权益，怎么保证实实在在会给到小股东呢？是否有可能造成大股东替小股东决策，然后导致大股东占小股东便宜的事情呢，这个在后续加上分红相关的一起描述。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>从本文我们可以看出，作为茅台股份有限公司的股东来说，主要关心的一些点</p><ul><li>茅台酒的利润情况：这个和酒的质量、销量、价格等有关</li><li>茅台酒的利润归属：是否有相关收益从股份公司移到了其他公司，归属在茅台股份公司的利益是否都分给所有股东了 — 主要是小股东</li></ul><p>第一点来说主要有公司的商业模式决定，茅台酒（白酒）的商业模式好，不愁卖（有很多预收款），对上下游均有定价权，且进入门槛/口味等拥有一定的差异化，因此在可预见的未来。在之前的文章 [茅台是一个好的投资标的吗] 以及[茅台的成本分析] 中也有一些相关分析。</p><p>第二点主要从历史以及公司的透明度等情况来进行分析，另外后面会尝试从分红等角度来进行一些分析。</p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>Q: 茅台的销量能持续吗？未来很多年轻人可能不喝白酒了？酒是有害物品<br>A: 关于这个问题，大致思考是这样的：整体白酒的销量不太确定，但是茅台的销量暂时看不太会受影响</p><ol><li>人不仅仅是为了健康（比如吸烟），还会考虑快乐 </li><li>通过和一些常喝酒的人沟通，酒会有用户粘性（至少到类似香型），不会因为稍微涨价而喝其他的。另外茅台在整体白酒中占比也还较低</li><li>茅台有一定的送礼/面子 属性在里面，这属于文化的一种，只要相关文化不变，就需要一种载体，茅台现在充当这个载体，载体是一个群体共识，共识的改变会比较难。</li></ol><p>[1] <a href="https://echarts.apache.org/examples/en/editor.html?c=bar-negative">https://echarts.apache.org/examples/en/editor.html?c=bar-negative</a><br>[2] <a href="https://pdf.dfcfw.com/pdf/H3_AP202407301638468976_1.pdf">https://pdf.dfcfw.com/pdf/H3_AP202407301638468976_1.pdf</a><br>[3] <a href="https://m.cls.cn/detail/712100">https://m.cls.cn/detail/712100</a><br>[4] <a href="https://jljcscyxs.mofcom.gov.cn/efile/html/yjbg/2024/3/1711437584739419.html">https://jljcscyxs.mofcom.gov.cn/efile/html/yjbg/2024/3/1711437584739419.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> stock </tag>
            
            <tag> maotai </tag>
            
            <tag> profit </tag>
            
            <tag> cost </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>maotai-basic</title>
      <link href="/2025/02/22/maotai-basic-2025-02-08/"/>
      <url>/2025/02/22/maotai-basic-2025-02-08/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文尝试记录一些茅台公司的基本情况，便于对公司的深入了解。</p></blockquote><p>茅台的香型有三种典型体 — 酱香，窖底香，醇香。茅台酒命名为酱香型。[1]</p><ul><li>酱香体：具有酱香味，且味感优雅细腻</li><li>窖底香：用窖底酒醅酿烤、放香好，但酒味冲辣者定位窖底香。</li><li>醇甜体：含有大量多种香气成分，味醇甜者定为醇甜体。</li></ul><span id="more"></span><p>茅台酒有多个独特的作法：</p><ul><li>茅台酒生产从投料到丢糟直至结束，需要一年时间，也正好是一年一个生产周期</li><li>茅台酒全年生产用料—高粱，要在两个月内两次投完。</li><li>茅台酒的陈酿的时间，最短也要四年以上。这就是茅台酒显得优雅细腻的重要原因之一。</li><li>茅台酒制曲需要经过数十天的高温发酵，时间之长，温度之高，在白酒生产中可以说是首屈一指。五月端午前后开始踩曲，曲香特别浓郁，用曲量大，是形成茅台酒酱香突出的重要原因。</li><li>成熟了的曲药要经过 6 个月以上的贮存才能使用。</li><li>茅台酒对同一种原料药反复 7 次取酒，由于每一轮酒醅的基础不一样，气候条件不一样，所以每一轮次酒都有其特点，再经勾兑，相互取长补短，酒体显得协调，丰满。</li><li>同一批原料要经过 8 次摊凉，8 次加曲，8次堆积，8次入窖发酵，每一次入窖前都要喷洒一次“尾酒”，这种回沙技术是非常独特和科学的。</li><li>生产季节性强，九月重阳投料，这个季节性生产的特点，是和气候密切相关联的。</li></ul><p>茅台酒的独特酿造工艺：高温制曲、高温堆积、高温流酒、两次投料、七次蒸馏、八次发酵、九次蒸煮、长期陈酿，精心勾兑。由于茅台酒生产受产地的地质、水源、气候、温度、湿度、风向等自然条件影响，形成了有利于茅台酒的微生物群，使茅台酒酱香突出，风格独异，他处难于仿制。</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/202502081749302.png" alt=""></p><p>因为刚酿烤出来的酒，具有爆辣、冲鼻，刺激性大的缺点。经过一定的陈酿期后，新酒变成陈酒，新酒具备的缺点就基本消失了。这个过程，经过氧化还原等一系列化学变化和物理变化，有效地排除了酒的低沸点物质，如醇类、硫化物等。除去了新酒的不愉快气味，乙醇缩合，辛辣味减少，增加了酒的芳香。随着酒的贮存时间的延长，增加爱了水分子和酒精分子的结合，减少了刺激，增加了香味。</p><p>陈酿的工艺：新酒入库以后，经检验品尝鉴定定香型后，装入容量为几百公斤的大酒坛内，酒坛上贴标签，注明该坛酒的生产时间，哪一班，哪一轮次酿制，属哪一类香型。存放一年后，将此酒“盘勾”。盘勾两年后，共经过三年的陈酿期，酒已基本老熟，进入了小型勾兑和大型勾兑的“精心勾兑”阶段。精心勾兑后的茅台酒，还要在酒库里继续陈酿。一年以后，通过检查，如果符合或超过茅台酒的质量标准，即可送包装车间包装出厂。</p><p>茅台是固态发酵，和洋酒的液态发酵不一样，液态发酵需要将原料经过粉碎后，在水溶液里添加酵母进行发酵。酵母相对比较单一，发酵力非常强，发酵速度一般比较快，比较充分，耗粮率比较低。但它带来的结果就是，里边的大分子物质比较多，香味成分少。大分子多的结果就是喝多了会上头。而我们国内的这些名白酒很细腻，喝太多不会上头，这是非常大的一个差别。</p><p>堆积发酵是茅台酒独特的操作工艺，既网罗、筛选繁殖了微生物，又弥补了大曲微生物品种和数量的不足，同时生成 大量的香味物质和香味的前驱物质，在茅台酒传统的工艺中，占用重要的位置。</p><p>茅台酒生产所需的原料是红高粱和小麦。每公斤酒用粮 5 公斤左右，红高粱和小麦大体上各占一半。据 1956 年的历史资料记载，有 4 个红高粱品种最适合于酿造茅台酒：矮子高粱、中心高粱、麻鸡婆高粱和红缨子高粱。</p><p>制曲是酿酒的第一套工序，由于曲中有益微生物数量和品种较多，香味物质也较多，因此，它是关系到酒的质量高低的一个重要环节。茅台酒采用优质小麦制造高温大曲，与其他酒的大曲相比，有三个独特之处：</p><ul><li>生产季节性强，要求“伏天踩曲”，每年端午节前后开始踩曲，重阳节结束。这段时间内气温高、湿度大，空气中微生物的种类和数量多，且活跃。</li><li>制曲需要优质小麦，不加任何辅料。小麦粘着力强，营养丰富，适宜于菌种的生长，也符合前人总结酿酒经验中之处的“得自然之曲，乃称第一品”的要求。</li><li>制曲温度高在 60 摄氏度以上，俗称高温大曲。<br>在踩曲过程中，高度、湿度、水分比例，母曲投放比例等均有独特的要求和严密的工艺。</li></ul><p>白酒中的主要成分包括醇类物质，酸、酯、醛、酮，酚等。酒中包含的物质含量、比例等不一样均会影响最终的口感，茅台酒通过不同香型、不同轮次，不同酒度，不同年龄的茅台酒相互勾兑，形成最终用户拿到的茅台酒。</p><p>茅台酒的勾兑工序如下：茅台酒陈酿期满三年后，先勾兑基础酒，再调香，调味，先是小型勾兑，再大型勾兑。小型勾兑后，将样品摇匀，放置一个月，与标准酒样对照，如质量没有发生变化，即按照小型勾兑的比例进行大型勾兑。然后将大型勾兑后的酒密封贮存，一年后，将此酒样送厂评委检验，如果此酒达到或超过出厂酒的标准，即可包装出厂。</p><p>制酒工艺的整体流程可以如下所示，假设第 X 年开始制曲和酿酒，那么在第 X + 5 年开始可以售卖成酒。<br><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20250218203542.png" alt=""></p><ul><li>第一年开始制曲和酿酒（假设是第 X 年），这个流程完成之后，会有基酒（此处是第 X + 1年）</li><li>由于基酒不好喝，因此需要陈酿。<ul><li>基酒首先存放一年，然后继续盘勾（这是第 X + 2 年）</li><li>盘勾两年后，酒基本老熟，可以进行进行勾兑（这个过程完成是在第 X + 4 年）</li></ul></li><li>精心勾兑是在第 X + 4 年完成，然后精心勾兑的酒需要再存放一年（这个过程完成是在第 X + 5 年），然后酒品达标酒装车包装出厂。</li></ul><p>茅台酒有两道工序需要冷却：一是蒸馏取酒，二是蒸馏后酒糟的摊凉。现在使用锡制水冷却器，天锅改用甑盖，蒸汽通过甑盖，顶部 2 米长的天桥管道，进入冷却器冷却，聚成酒接入酒坛，取酒手段大大进步，酒甑体积增大，增加了容量。</p><p>茅台公司认为的核心竞争力如下：环境、工法、品质、品牌，文化，并拥有独一无二的原产地保护，不可复制的微生物菌落群、传承千年的独特酿造工艺，长期贮存的基酒资源组成的“四个核心势能”。</p><p>系列酒</p><ul><li>2014 年 12 月，茅台酱香酒营销有限公司正式成立，系列酒开始独立运行，不再作为茅台的附属品存在。</li><li>2015 年，推出赖茅、王茅、华茅和贵州大曲四个新平台。王茅和华茅很快就失败了，相继停产，到 2018 年又重新启动。</li><li>系列酒包括：1935、一曲、三茅、四酱，以及大单品 1935</li></ul><p>公司的经营模式：采购原料 — 生产产品— 销售产品。<br>原料采购模式为：茅台酒用高粱采取“公司+地方政府+供应商+合作社或农户”的模式；小麦采取“公司+供应商+合作社或农场”的模式，其他原辅料及包装材料采购主要根据公司生产和销售计划，通过集中采购方式向市场采购；<br>产品生产工艺流程为：制曲 — 制酒 — 贮存 — 勾兑 — 包装<br>销售模式为：公司产品通过直销和批发代理渠道进行销售。直销渠道指自营和“i 茅台”等数字营销平台渠道，批发代理渠道指社会经销商、商超、电商等渠道。</p><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><p>[1] <a href="https://www.rh.gov.cn/yxrh/rhjj/mswh/202405/t20240508_84599090.html">https://www.rh.gov.cn/yxrh/rhjj/mswh/202405/t20240508_84599090.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> stock </tag>
            
            <tag> maotai </tag>
            
            <tag> company-analysis </tag>
            
            <tag> wine </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lsm-tree</title>
      <link href="/2023/04/24/lsm-tree-1-2023-05-17/"/>
      <url>/2023/04/24/lsm-tree-1-2023-05-17/</url>
      
        <content type="html"><![CDATA[<blockquote><p>文章内容基于原论文，结合自己的理解和思考，发现有错漏的地方，欢迎反馈探讨，感谢。</p></blockquote><p>LSM-Tree 拥有优异的性能出现在各种存储引擎中，本文希望对 LSM-Tree 进行一个最小全局认识，对其有个骨架结构认识，从 LSM-Tree 的原始论文开始，到现在的进展以及 LSM-Tree 中各种影响的因素。</p><span id="more"></span><h1 id="起始"><a href="#起始" class="headerlink" title="起始"></a>起始</h1><h2 id="1-LSM-Tree-的缘起"><a href="#1-LSM-Tree-的缘起" class="headerlink" title="1 LSM-Tree 的缘起"></a>1 LSM-Tree 的缘起</h2><p>LSM-Tree 从论文[1] 中出生，在该论文中谈及了 LSM-Tree 诞生的原因，主要流程，优缺点，适合场景，以及决定性能的相关参数等。首先接下来重点介绍这篇 LSM-Tree 的原始论文。</p><p>在论文[1] 之前的年代中，存储引擎主要使用 B-Tree 系列的数据结构，这种数据结构并不是 I/O 友好型的，随机 I/O 所带来的成本会比较高，尤其是写多读少的情况下，更新叶子节点会有两次随机 I/O（读+写），会有性能瓶颈。LSM-Tree 则以两个 batch 操作来优化 I/O 成本：1）首先写入 memory，然后 memory 的数据以 batch 形式写入磁盘；2）磁盘顺序读写，减少 seek 的成本（次数减少），均摊后单次成本更低。</p><p>由论文[2] 中的结论可知，在一定范围内使用内存换 I/O 能减少整体成本。随着硬件的更新换代，内存和磁盘的成本关系也在变化，可根据具体使用的硬件进行对比。</p><h2 id="2-LSM-Tree-的结构，以及主要流程"><a href="#2-LSM-Tree-的结构，以及主要流程" class="headerlink" title="2 LSM-Tree 的结构，以及主要流程"></a>2 LSM-Tree 的结构，以及主要流程</h2><p>LSM-Tree 是一个多层的数据结构，其中第一层（最上层）保持在内存中，除第一层外的其他层均在磁盘（部分频繁访问的数据会 cache 在内存）。最简单的 LSM-Tree 拥有两层：内存中一层，磁盘中一层。接下来首先以两层 LSM-Tree 介绍相关功能，后续在定量分析过程中，会详细介绍多层 LSM-Tree 结构。</p><p>两层 LSM-Tree 的结构如下所示：</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516141825.png" alt="tow-component-lsm"></p><p>上图中 L0 与 L1 均是 tree-like 的数据结构，由于 L0 不需要特别考虑 tree high（都在内存，无 I/O），因此 B-Tree、AVL-Tree 以及 2-3-tree 等各种 tree like 数据结构读可以。 L1 保存在磁盘，需要考虑 tree high，使用 B-Tree。</p><p>对 LSM-Tree 数据结构，首先看一下基本操作的流程(为了描述方便，L0 中的结构也以 B-Tree 为例）:</p><ul><li>insert：数据直接写入内存 L0 中。在 L0 大小达到一定阈值后，会进行 rolling merge 操作（后面详述），将数据从 L0 转移到 L1。</li><li>get：读取数据的时候，首先从 L0 中进行查找，找到后直接返回（不管是否带 delete meta 信息的 key/value），否则继续从 L1 进行查找。</li><li>delete：如果 L0 中没有 key/value 对，则在 L0 中增加一个 key/value 对，且 value 包括 delete 相关的 meta 信息；如果 L0 中有对应的 key/value，则将 value 更改为包括 delete meta 信息的值。rolling merge 的时候将带有 delete meta 信息的 key/value 从 L_i 写入到 L_(i+1) 删除 L_i &amp; L_(i + 1) 中的 key/value 对，然后在 L_(i+1) 插入一个带有 delete meta 信息的 key/value 对，当达到最底层的时候，将 key/value 对进行物理删除。同样 delete 的操作和 insert 一样，支持 batch 操作。</li><li>update：update 可以看作是 delete&amp;insert 的组合</li></ul><p>LSM-Tree 为了保证更上层有空间接受插入的新数据，维护一个 rolling merge 的后台流程，该流程会从相邻两层中分别读取数据，写入到下层中，在 rolling merge 的过程中也可以进行部分逻辑处理：比如 ttl 的数据可以直接删除等。下图是一个 rolling merge 的示意图： </p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516141924.png" alt="rolling-merge"></p><h2 id="3-LSM-Tree-相关的定量分析"><a href="#3-LSM-Tree-相关的定量分析" class="headerlink" title="3 LSM-Tree 相关的定量分析"></a>3 LSM-Tree 相关的定量分析</h2><p>上文介绍了 LSM-Tree 诞生的原因，以及基本的流程，下面着重进行性能相关的定量分析，包括双层 LSM-Tree 以及多层 LSM-Tree。</p><h3 id="双层-LSM-Tree-的-IO-定量分析"><a href="#双层-LSM-Tree-的-IO-定量分析" class="headerlink" title="双层 LSM-Tree 的 IO 定量分析"></a>双层 LSM-Tree 的 IO 定量分析</h3><p>本节介绍双层 LSM-Tree 的 I/O 定量分析，以及和 B-Tree 的相关对比情况。</p><p>以下对比内容基于 1995 年的硬件架构：</p><ul><li>1MByte 内存需要 100$</li><li>1MByte 磁盘的存储需要 1$</li><li>随机访问 I/O 成本是 25$</li><li>顺序访问的 I/O 成本是 2.5$</li></ul><p>同时为了后面描述方便，定义变量如下:</p><ul><li>$COST_d$ 表示磁盘存储 1MByte 所需要的成本</li><li>$COST_m $ 表示内存中存储 1MByte 所需要的成本</li><li>$ COST_P $ 表示提供 1 page 每秒所需要的磁盘成本（随机访问）</li><li>$ COST_\pi $ 表示提供 1 page 每秒所需要的磁盘成本（顺序访问）</li></ul><p>内存的成本由存储空间决定，而磁盘的成本则由存储空间和访问频率的更大者决定。</p><p>假设需要存储 S MByte 大小的数据，且每秒 H 的随机 I/O 访问（数据无缓存），则磁盘的开销是 $ COST_D = max(S <em> COST_d, H </em> COST_P $，其中 $ S<em>COST_d $ 表示存储所需成本，$ H </em> COST_P $ 则表示随机 I/O 访问的成本。</p><p>当使用内存来缓存部分数据后，使得磁盘的瓶颈变为存储量后，则对应总成本是 $ COST-B = S <em> COST_m + S</em>COST_d $ 其中， $ S<em>COST_M $ 表示内存的成本，$ S</em>COST_d $ 表示磁盘的存储所需成本。</p><p>综合上面两种情况可得，总共存储 S MByte 大小的数据，且每秒 H 随机访问的总成本公式如下所示：</p><p>$ COST-TOT = min(max(S<em>COST_d, H</em>COST_P), S<em>COST_m + S</em>COST_d) $</p><p>通过上述公式我们可以看到，整体的成本受总存储量，以及访问频率的影响，我们将 H/S（访问热度） 作为横轴，COST-TOT 作为纵轴画图得到如下曲线</p><Graph-of-cost-of-access-per-MByte-vs-Temperature.jpg> <p>通过上图可知，总成本会随着访问热度的增长而增长，当达到一定程度后不在增长。上图中两个拐点将数据分为三段：cold，warm，hot。其中第一段的成本主要来源磁盘存储量，第二段则随着访问频率的增加而变多，第三段主要是内存与磁盘容量的成本。其中两个拐点则用如下公式定义</p><ul><li>$ T_f = COST_d / COST_P = 1 / 25 = 0.04 $ 表示 cold 和 warm data 之间的拐点</li><li>$ T_b = COST_m / COST_P = 100 / 25 = 4 $ 表示 warm 和 hot data 之间的拐点</li></ul><blockquote><p>对于连续 I/O 访问来说，也有类似上图的分析，而其中 warm 和 hot 的划分则是对 “The Five Minute Rule”[2] 的概括。</p></blockquote><p>根据论文[3] 中的说法，访问热度与实际的磁盘访问有关，而不是逻辑插入速度，LSM 也是通过减少实际的磁盘访问量来提效，LSM-Tree 有两个减少磁盘访问的点：1）先写内存，然后 batch 写磁盘；2）顺序访问磁盘。接下来接下下顺序 I/O 的收益。</p><p>根据[4] 给的数据，随机读取一个磁盘页的耗时大概是 20ms（其中 10ms 用于磁道寻址，8.3ms 来源于旋转延迟，1.7ms 来源实际读取）。顺序读取 64 个磁盘页的耗时大概是 125ms（其中 10ms 来源于磁道寻址，8.3ms 来源于旋转延迟，106.9ms 来源于实际的数据读取），— 平均后大概只需要 2ms 读取一个磁盘页，是随机访问的 1/10。也就是 $ COST_{\pi} / COST_P = \frac{1}{10} $。通过前面计算也能直观感受到顺序 I/O 所带来的(均摊)具巨大性能收益。</p><p>我们使用[3] 中的给的结论来计算 “五分钟规则” 的参考区间 —  $ \tau $，规则指出“维持每秒 1 page 访问所需要的成本与保存它所需的内存成本一致”，我们得到如下公式</p><ul><li>$ \frac{1}{ \tau } <em> COST_P = pagesize </em> COST_m $  （I/O 速率 * 随机 I/O 的成本 = 内存存储的成本）</li></ul><p>那么 $ \tau = (\frac{1}{pagesize} <em> \frac{COST_P}{COST_m}) = \frac{1}{pagesize </em> T_b} $，如果每个 page 是 4k(0.004 Mb) 的话我们可以得到 <code>$\tau = 1/(0.004 * 4) = 62.5 seconds/IO</code>。换句话说在访问间隔小于 62.5 seconds/IO 的时候，用内存换磁盘是合理的（现在需要根据硬件成本进行具体计算）。</p><h3 id="B-Tree-和-LSM-Tree-的定量分析对比"><a href="#B-Tree-和-LSM-Tree-的定量分析对比" class="headerlink" title="B-Tree 和 LSM-Tree 的定量分析对比"></a>B-Tree 和 LSM-Tree 的定量分析对比</h3><p>在进行 B-Tree 和 LSM-Tree 的对比分析之前，先单独进行 B-Tree 和 LSM-Tree 的分析。主要对比 insert 的性能，同时忽略了 index 更新过程中所带来的微小 I/O 成本。</p><h4 id="B-Tree-的定量分析"><a href="#B-Tree-的定量分析" class="headerlink" title="B-Tree 的定量分析"></a>B-Tree 的定量分析</h4><blockquote><p>假设所有的 insert 是完全随机的，因此不会有叶子节点 buffer 在内存的情况。</p></blockquote><p>根据论文[5] 的结论，B-Tree 中的有效深度 - $D_e$ - 表示随机查找中，未在 buffer 中命中的平均 page 数目。在 B-Tree 的插入中，首先需要进行 $D_e$ 次 I/O 查找对应的叶子节点，更新改节点，然后将脏页写回（1 I/O），因此整个 I/O 的开销如下所示</p><p>$ COST_{B-ins} = COST_P * (D_e + 1) $</p><h4 id="LSM-的定量分析"><a href="#LSM-的定量分析" class="headerlink" title="LSM 的定量分析"></a>LSM 的定量分析</h4><p>由于 LSM 的单 entry insert 时直接写入内存，可能没有 I/O 开销，因此分析 LSM-Tree 的 insert I/O 开销时，使用均摊分析进行。</p><p>首先定义一些变量如下</p><ul><li>$ S_e $ 表示 entry（index entry） 的大小（byte 为单位）</li><li>$ S_p $ 表示 page size 的大小（byte 为单位）</li><li>$ S_0 $ 表示 C0 中叶子节点的大小（MByte 为单位）</li><li>$ S_1 $ 表示 C1 中叶子节点的大小（MByte 为单位）</li><li>M 表示 rolling merge 的过程中平均有多少个 entry 插入到 <strong>每个</strong> C1 的叶子节点 (a given LSM-tree as the average number of entries in the C0 tree inserted into <strong>each</strong> single page leaf node of the C1 tree during the rolling merge)</li></ul><p>每个 page 中的 entry 数目大致为 $ S_p / S_e $，整个 LSM-tree 中在 C0 中的数据比例是 $ S_0 / (S_0 + S_1) $ )，因此 rolling merge 过程中会平均插入到每个 C1 叶子节点的 entry 数 M 可以通过其他公式计算得到 $ M = (S_p/S_e) * (S_0/(S_0 + S_1)) $。</p><p>根据上述公式可以得到 LSM-Tree insert 的均摊开销为（将 C1 叶子节点读入和写出内存的开销均摊到 M 个 entry 上）</p><p>$ COST_{LSM-ins} = 2 * COST_{\pi} / M $ （读写一次 C1 的叶子节点，平均涉及到 M 个 entry）</p><h4 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h4><p>观察 B-Tree 和 LSM-Tree 的 insert I/O 开销我们可以得到如下的公式</p><p>$ COST_{LSM-ins} / COST_{B-ins} = K1 <em> (COST_{\pi}/COST_{P}) </em> (1 / M) $  </p><p>其中 $ K1 ~ 2/(D_e + 1) $ 是一个常数</p><p>上述公式对比展示出，LSM-Tree 比 B-Tree 的优势主要来自于两方面：1）$COST_{\pi}/COST_{P}$ 也就是磁盘的连续访问相比随机访问所带来的优势；2）M 也就是 rolling merge 时批量写入到 C1 中单个叶子节点的平均 entry 数目（注意 M 并不是一定会大于 1）。</p><p>在 B-Tree 作为索引的情况下，如果整体访问热度比较高的话，则可以使用上述公式进行粗略的估算，使用 LSM-Tree 之后大概会有多少收益。</p><h3 id="多-component-LSM-Tree-的分析"><a href="#多-component-LSM-Tree-的分析" class="headerlink" title="多 component LSM-Tree 的分析"></a>多 component LSM-Tree 的分析</h3><p>上面所有关于 LSM-Tree 的讨论均假设 LSM-Tree 是两层的，在实际的生成中，LSM-Tree 则可能会有多层，具体的层数，以及相邻层之间的大小比例等可以通过分析得出，本节介绍多层 LSM-Tree 相关的分析。</p><blockquote><p>为了方便讨论，下面的描述中，假设 LSM-Tree 中的 entry 在插入后，仅在最底层进行删除。</p></blockquote><p>上面几节中的分析可以得到从 C0 写入到 C1 每个叶子节点的平均 entry 数目 M 并不一定大于 1，如果 M &lt;= 1 的话，则 LSM-Tree 两个优势中的一个：“批量更新” 就失效了，因此如果分析得知 $ M &lt; K1 * COST_{\pi} / COSTP $ 的话则 B-Treee 比 LSM-Tree 会更好。另外一方面，为了更好的利用 LSM-Tree 的优势，则需要尽可能增大 M（也就是 C0 和 C1 的比值需要更大）；同时无限增大 C0  则会由于内存消耗更高造成成本过高，因此需要综合考虑计算一个总成本更小的参数值。</p><p>为了保持 LSM-Tree 中上层有空间持续接受新数据，因此 rolling merge 从上层读取并删除的速度与 C0 接受到插入速度需要保持一致。</p><p>在两层的 LSM-Tree 中，可以从 LSM-Tree 的总成本出发，寻找更合适的 C0 大小。首先从一个较大的 C0 开始，逐渐减小 C0 的大小（同时 I/O 开销会增加，I/O 的访问频率和存储成本会越来越小），直到达到一个平衡（此情况下再减少 C0 的大小会导致总成本增加）。另外的一个思路则是使用多层的 LSM-Tree 结构（这可以减少 C0 的大小，同时减少 I/O 的访问频率），同时没多一层会多部分 I/O 操作，因此需要综合考虑。</p><p>下图是一个多层 LSM-Tree 的结构</p><p><img src="https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516142001.png" alt="multi-component-lsm-tree"></p><p>对于 K+1 层的 LSM-Tree 来说，总共有 C0, C1, C2, … C_{K-1} 以及 C_K，并且每层的大小递增（C1 比 C0 大，C2 比 C1 大，依次类推，最小的层 C0 在内存，其他的所有均在磁盘），相邻层之间会有异步的 rolling merge 过程，将 C_{i - 1} 层的数据迁移到 C_i 层中。对于一个插入后从未删除的 entry 来说，会从最上层 C0 逐步迁移到最底层 C_K 中。</p><p>接下来会通过定量的分析来说明多层 LSM-Tree 中不同参数对总成本的影响，并且推导得出一个总成本更低的参数组合。</p><p>首先定义一些在定量分析中需要的参数与假设</p><ul><li>$ S(C_i) $ — 表示 LSM-Tree 第 i 层叶子层所有 entry 的总大小（单位是 byte）</li><li>$ S_i $ — 表示 LSM-Tree 中第 i 层所有 entry 的总大小（单位是 byte），也就是 $S(C_i) = S_i$</li><li>$ r_i = S_i / S_{i-1} $  — 表示相邻两层中的总大小比例</li><li>S — 表示所有层中叶子节点的总大小，也就是 $S = \sigma{1}{i} S_i$</li><li>R — C0 接受到的插入速度（假设速度相对稳定），单位 byte/s</li><li>每层的中数据量保持稳定，且接近该层的阈值</li><li>每个 entry 只从 C0 插入，从 C_K 删除，中间层不删除 entry</li><li>C_K 的大小保持相对恒定，删除与插入保持相对的平衡，C_K 层的删除，可以理解为不增加插入速度的情况下将 entry 从 C_0 删除</li></ul><p>假定 LSM-Tree 有 K + 1 层，其中 S_0 和 S_K 固定，S_0 接受到的插入速度 R 恒定<br>问题：求所有的 $ r_i $ 使得整个 LSM-Tree 的总 I/O  速度 H 最小。</p><p>证明过程如下：</p><ol><li>由于假设每条数据从 C_0 插入后，一直到最底层 C_{K} 才会被删除，则所有相邻层 (C_{i-1}, C_{i}) 的 I/O 速度和 C_0 接受到的 I/O 速度一致，均是 C_0 接受的插入速度 R。</li><li>如果 C_{i-1} 和 C_{i} 都在磁盘上，那么 C_{i-1} 层从磁盘上读取的 I/O 速度就是 $ R/S_P $（这部分数据会被移入到 $C_{i}$ 层，其中 $S_P$ 是单 page 的字节数大小，从 C_{i} 层会有 $r_i <em> R/S_P$ 的读取 I/O（一个 C_{i-1} 层平均对应 C_{i} 层 r_i 个 page），然后所有读取的数据会写入到 $C_i$ 层，其速度是 $ (r_i + 1) </em> R / S_p $ (从 C_{i-1] 与 C_{i} 读取的数据都会写入到 C_{i} 层中，不会中途删除)，因此整个 LSM-Tree 的总 I/O 速度 H 可以用公式计算如下： $ H = (R / S_P) <em> ((2 </em> r_1 + 1) + (2 <em> r_2 + 2) + … + (2</em>r_{K-1} + 2) + (2<em>r_K + 1)). 其中 $ (2 </em> r_i + k) $ 表示 rolling merge 过程中第 i 层的总 I/O 量，其中 $ r_i <em> R / S_p $ 表示从 C_{i-1} merge 到 C_{i} 中从第 i 层读取的 I/O 量，(r_i + 1)</em>R/S_P 表示从 C_{i-1} merge 到 C_{i』 层后写入到第 i 层的 I/O 量，R/S_P 表示从第 i 层 rolling merge 到第 i + 1 层时的读取 I/O （C_0 没有 I/O，C_K 不需要合并到更下一层，没有下一层对应的 I/O)</li><li>简化 H 后得到 $ H + (R / S_P) <em> ((2 </em> r_1 + 2) + (2 <em> r_2 + 2) + … + (2</em>r_{K-1} + 1) + (2 * r_K + 1))  = (2R/S_p) (\sigma{1}{K} r_i + K - \frac{1}{2}) $</li><li>需要在已知条件下求 H 的最小值，其中 S_K 和 S_0 恒定，可以换算为同等已知条件 $ \prod\limits_{1}^K r_i = (S_k / S_0) = C $</li><li>也就是希望在 $ \prod\limits_{1}^K r_i = (S_k / S_0) = C $ 的情况下求 $ \sigma{1}{K} r_i $ 的最小值。</li><li>通过求偏导，得到 $ 0 = 1 - \frac{1}{r_j} <em> C </em> \prod\limits_{1}^{K-1} r_j^{-1}.  然后求的每个 r_j 等于 $ C * \prod\limits_{1}^{K-1} r_j^{-1} $ 或者 $ C^{\frac{1}/{K}} $ 情况下求的最小值。</li><li>在 LSM-Tree 中，相邻层然后把条件放宽（也就是不固定最大层的大小），每一层是上一层的 r 倍，由于正常情况下 r 会比较大，因此最大层会占据所有数据的大头（S_K ~~ S），那么固定整体大小 S 和 固定 S_K 就近似（上面的推导过程）</li></ol><blockquote><p>其中通过求偏导得到最小值的过程，自己推导的结果与论文中有差异，如果有人知道，恳请告知，自己推导的结果是 $ 0 = -\frac{1}{r_j} <em> C </em> \prod\limits_{1}^{K-1} r_j^{-1} $ 不是论文中的 $ 0 = 1 - \frac{1}{r_j} <em> C </em> \prod\limits_{1}^{K-1} r_j^{-1} $。</p></blockquote><p>根据已知条件与上述证明可得</p><ul><li>$ S = S_0 + r <em> S_0 + r^2 </em> S_0 + … + r^K * S_0 $</li><li>$ H = (2R / S_p)<em>(K </em> (1 + r) - 1/ 2) — 其中 R 是插入速度，S_p 是页大小，K 是磁盘上的层数，r 是相邻层的比值大小</li></ul><p>也就是 R 和 S_K 均保持不变的情况下，H 于 S_0 负相关（内存大小），与 r （相邻层的大小比例）正相关。</p><p>可以使用两层 LSM-Tree 进行具体的推演<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">两层的 LSM-Tree 中</span><br><span class="line">- K = 1， r = S_1 / S_0</span><br><span class="line">- H  = \frac&#123;2R&#125;&#123;S_P&#125;(K*(1+r) - \frac&#123;1&#125;&#123;2&#125;)</span><br><span class="line">- COST_tot = COST_m * S_0 + max(COST_d * S_1, COST_\pi * H)</span><br><span class="line">- s = (COST_m * S_0) / (COST_d * S_1) -- cost of memory relative to storage cost for S_1 data</span><br><span class="line">- t = 2 ((R/S_p) / S_1) * (COST_\pi /COST_d) * (COST_m / COST_d)</span><br><span class="line">- C = COST_tot / (COST_d * S_1)</span><br><span class="line"></span><br><span class="line">当 S_0 / S1 比较小的时候， C ~ s + max(1, t/s) </span><br></pre></td></tr></table></figure></p><p>其中 C 是 t 和 s 的函数，其中 t 是应用的平均访问热度（the variable t is a kind of normalized temperature measuring the basic multi-page block I/O rate required by the application），s 表示使用的内存大小。</p><p>最简单的来说，可以让 s = t, 这样 C  = s + 1，这样磁盘得到充分利用（I/O 的存储和访问量都打满）。</p><blockquote><p>个人理解这里是假定总存储量（磁盘所需空间）已知，且访问热度已知，也就是说 C 的最小值就是总成本的最小值。</p></blockquote><p>对于 t &lt; 1 的情况，s = t 的成本是最小的，但是 t &gt; 1 的情况下，C 在 s = t^{1/2} 的时候取得最小值，也就是 C = 2s = 2 t^{1/2}. 这个情况下 COST_tot = 2[(COST_m<em>S_1) </em> (2<em>COST_\pi</em>R/S_p)]^{1/2}（通过 C = 2<em>t^{1/2} 以及 C = COST_tot / (COST_d </em> S_1) 然后换算得到），也就是说当 t &gt; 1 的时候（两层的 LSM-Tree 最小代价如前所是），整体代价来源于两方面：1）内存的开销；2）I/O 访问的开销（由于 t 足够高，因此 I/O 开销比 I/O 存储代价更大）</p><p>对于 t &lt;= 1 的情况来说，C = s + 1 = t + 1 &lt;= 2. 也就是说总在成本总是小于存储成本的两倍，因此通过存储需求来确定磁盘使用大小，然后利用所有的 I/O 能力来最小化内存使用。（尽可能打满对应存储所能提供的 I/O)</p><h3 id="具体例子计算-B-Tree-和-LSM-Tree-的成本分析"><a href="#具体例子计算-B-Tree-和-LSM-Tree-的成本分析" class="headerlink" title="具体例子计算 B-Tree 和 LSM-Tree 的成本分析"></a>具体例子计算 B-Tree 和 LSM-Tree 的成本分析</h3><p>上面对 LSM-Tree 和 B-Tree 做了定量分析，接下来使用具体例子计算 B-Tree 和 LSM-Tree 在具体场景下的成本对比。</p><p>1 给定如下场景，计算 B-Tree 以及两层 LSM-Tree 的成本</p><ul><li>R = 16000 byte（每个 entry 16 byte，也就是 1000 个 entry 每秒）</li><li>总共 576 million entries（总存储空间 9.2Gbyte），每个 entry 的 ttl 是 20 days</li></ul><p>如果使用 B-Tree 的话，成本如下</p><ul><li>由于 I/O 访问是瓶颈，因此需要更多的磁盘存储空间才能满足对应的 I/O 访问（H = 2 <em> 1000 = 2000 随机访问），COST_P = 25$，那么随机访问的成本是 2000 </em> 25$ = 50,000$</li><li>然后非叶子节点需要缓存，具体的缓存成本计算如下<ul><li>假设叶子节点 70% 满，也就是每个叶子节点有 0.7 * (4K / 16) = 180 个 entry，上层节点需要 576 million/180 = 3.2 million 数据，在加上部分前缀压缩的技术后，假设每个非叶子节点可以存储 200 条数据，也就是 3.2 million / 200 = 16000 个节点，每个 4KB，总共有 64MB 的内存存储空间</li><li>64MB 的存储空间总成本是 64MB * 100$/MB  = 6400 $</li><li>忽略其他一些细小的成本开销</li></ul></li><li>B-Tree 的总成本 = 50000$ + 6400$ = 56400 $</li></ul><p>两层 LSM-Tree 的话，成本如下</p><ul><li>首先 C1 需要的总存储空间是 9.2Gbyte，总成本是 .1$/Mbyte * 92000Mbyte = 9200$</li><li>根据 C1 的大小计算出打满情况下的 H  = 92000 / COST_\pi = 9200 / 2.5 ~ 3700 page/s</li><li>假设单 page 大小 4K 的情况下，根据 H 以及 H = (2<em>R/S_P)</em>(K*(1 + r) - 1/2) 计算得到 r ~ 460，可以得到 C_0 = C_1/460 = 9.2G / 460 = 20Mb</li><li>20Mbyte C_0 的成本是 20MB * 100$/MB = 2000$，另外增加 2MB 用于 rolling merge 时使用，也就是 2000$ + 200$ = 2200$</li><li>总成本是 9200 + 2200 = 11400$</li></ul><p>大致计算之后 LSM-Tree 比 B-Tree 的成本会低很多（11400 VS 56400)，相当于 B-Tree 的 1/5 左右</p><p>2 如果 R 增加 10 倍，也就是 160000 byte/s，再计算 B-Tree，两层 LSM-Tree 以及三层 LSM-Tree 的成本</p><ul><li>R = 160000 byte（单 entry 16 byte，也就是 10000 entry/s）</li><li>576 million entries（总存储量 9.2GByte），每个 entry 的 ttl 是 20 days</li></ul><p>B-Tree 的情况下</p><ul><li>需要使用更多的磁盘来满足相应需求（主要是为了满足 I/O 的读写） 随机访问的总成本是 (2 <em> (160000 / 16)) </em> 25$ = 500,000$（相当于 500G 的存储，实际只需要 9.2G，也就是有 491G 的存储浪费）</li><li>buffer 非叶子节点的成本不变，也就是 6400$</li><li>总成本 = 500,000$ + 6400$ = 506400$</li></ul><p>两层 LSM-Tree 的情况</p><ul><li>首先通过 t 的公式计算得到 t = 2<em>((R/S_p)/S_1)</em>(COST_\pi/COST_d)*(COST_m/COST_d) ~ 2.2 &gt; 1</li><li>通过公式得到最低成本 = 2[(COST_m<em>S_1) </em> (2<em>COST_\pi</em>R/S_p)]^{1/2} ~ 27129$，其中一半用于磁盘，一半用于内存开销，磁盘的总存储空间是 13.5G（27129/2/1 Mb），135M 的内存</li><li>额外增加 2M 的内存用于 merge，200$ </li><li>总成本 ~ 27329$</li></ul><p>对于三层 LSM-Tree 的情况</p><ul><li>C_2 需要 9.2G 存储，总成本 9.2<em>1000</em>1$/Mb =9200$, 能提供的 I/O 访问频率 H  = 9.2 * 1000 / 2.5 ~ 3700</li><li>根据 H  = (2R/S_p)*(K ( 1 + r) - 1/2) 计算得到 r ~ 23</li><li>C_0 = C_2 / r / r ~ 17MB，成本为 17 * 100$/Mb = 1700$</li><li>C_1 的成本是 C_2 的 1/r =  1/23 也就是 9200/23 * 1$/Mb = 400$ （由于是最大层成本的 1/23，因此在估算时也可以忽略）</li><li>另外增加 4MB 用于 rolling merge，也就是 400$</li><li>总成本 ~ 9200$ +  1700$ + 400$ + 400$ = 11700$</li></ul><p>对比可知 三层 LSM 的成本（11700$） &lt; 两层 LSM 的成本（27329$） &lt; B-Tree 的成本（506400$）</p><h2 id="4-未来可能的优化"><a href="#4-未来可能的优化" class="headerlink" title="4 未来可能的优化"></a>4 未来可能的优化</h2><ul><li>为了更好的平衡插入和查询性能，留取部分 I/O 供查询使用；另外在 rolling merge 的时候，可以适当保留部分上层数据（并不完全迁移）</li><li>插入/合并的时候，CPU 做隔离，使用单独的 CPU 做合并，以及 LSM-Tree 结构的维护，这样可以在基本不增加延迟的情况下完成查找。</li></ul><h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><p>[1] <a href="https://www.cs.umb.edu/~poneil/lsmtree.pdf">The Log-Structured Merge-Tree (LSM-Tree)</a><br>[2] <a href="https://www.hpl.hp.com/techreports/tandem/TR-86.1.pdf">The Five Minute Rule</a><br>[3] <a href="">Database Buffer and Disk Configuring and the Battle of the Bottlenecks</a><br>[4] <a href="">GPD Performance Evaluation Lab Database 2 Version 2 Utility Analysis, IBM Document Number GG09-1031-0, September 28, 1989</a>  </p>]]></content>
      
      
      
        <tags>
            
            <tag> lsm </tag>
            
            <tag> lsm-tree </tag>
            
            <tag> minimum-global-awareness </tag>
            
            <tag> paper </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
