{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"source/HTML/2010/12/09/hello-world-1/index.html","path":"HTML/2010/12/09/hello-world-1/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/12/usaco-4-1-4-cryptcowgraphy/index.html","path":"HTML/2010/12/12/usaco-4-1-4-cryptcowgraphy/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/15/xampp-apache-cant-work-80-port/index.html","path":"HTML/2010/12/15/xampp-apache-cant-work-80-port/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/15/vmware-redhat9-cant-mount/index.html","path":"HTML/2010/12/15/vmware-redhat9-cant-mount/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/14/red-hat9-command-messy-code/index.html","path":"HTML/2010/12/14/red-hat9-command-messy-code/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/22/linux-shell-problem/index.html","path":"HTML/2010/12/22/linux-shell-problem/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/16/wordpress-link-order/index.html","path":"HTML/2010/12/16/wordpress-link-order/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/14/linux-rename/index.html","path":"HTML/2010/12/14/linux-rename/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/30/linux-fork-test/index.html","path":"HTML/2010/12/30/linux-fork-test/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/31/linux-fork-2/index.html","path":"HTML/2010/12/31/linux-fork-2/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/30/wordpress-clickchar-plugin/index.html","path":"HTML/2010/12/30/wordpress-clickchar-plugin/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/23/linux-single-user-config/index.html","path":"HTML/2010/12/23/linux-single-user-config/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2010/12/23/linux-grub-encrypt/index.html","path":"HTML/2010/12/23/linux-grub-encrypt/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/02/10/usaco-4-1-2-fence-rails/index.html","path":"HTML/2011/02/10/usaco-4-1-2-fence-rails/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/02/11/usaco-4-2-2-the-perfect-stall-dinic/index.html","path":"HTML/2011/02/11/usaco-4-2-2-the-perfect-stall-dinic/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/02/10/networkflow-1-maximum-matching/index.html","path":"HTML/2011/02/10/networkflow-1-maximum-matching/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/02/21/usaco-4-2-4-cowcycle/index.html","path":"HTML/2011/02/21/usaco-4-2-4-cowcycle/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/02/10/usaco-4-2-1-drainage-ditches/index.html","path":"HTML/2011/02/10/usaco-4-2-1-drainage-ditches/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/02/26/usaco-4-3-1-buy-low-buy-lower/index.html","path":"HTML/2011/02/26/usaco-4-3-1-buy-low-buy-lower/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/02/12/usaco-4-2-3-job-processing/index.html","path":"HTML/2011/02/12/usaco-4-2-3-job-processing/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/02/27/networkflow-sap/index.html","path":"HTML/2011/02/27/networkflow-sap/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/07/usaco-4-3-3-street-race/index.html","path":"HTML/2011/03/07/usaco-4-3-3-street-race/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/06/usaco-4-3-2-the-primes/index.html","path":"HTML/2011/03/06/usaco-4-3-2-the-primes/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/14/usaco-4-3-4-letter-game/index.html","path":"HTML/2011/03/14/usaco-4-3-4-letter-game/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/03/networkflow-24-2-minimum-cut/index.html","path":"HTML/2011/03/03/networkflow-24-2-minimum-cut/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/18/usaco-4-4-1-shuttle-puzzle/index.html","path":"HTML/2011/03/18/usaco-4-4-1-shuttle-puzzle/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/17/poj-1704-game/index.html","path":"HTML/2011/03/17/poj-1704-game/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/18/another-ux-strong-password/index.html","path":"HTML/2011/03/18/another-ux-strong-password/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/22/usaco-4-4-3-frame-up/index.html","path":"HTML/2011/03/22/usaco-4-4-3-frame-up/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/22/c-cow-problem/index.html","path":"HTML/2011/03/22/c-cow-problem/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/16/usaco-4-4-2-pollutant-control/index.html","path":"HTML/2011/03/16/usaco-4-4-2-pollutant-control/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/15/hdu-1730-game/index.html","path":"HTML/2011/03/15/hdu-1730-game/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/19/networkflow-5-round-table/index.html","path":"HTML/2011/03/19/networkflow-5-round-table/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/24/hdu-3389/index.html","path":"HTML/2011/03/24/hdu-3389/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/28/usaco-5-1-3-musical-themes/index.html","path":"HTML/2011/03/28/usaco-5-1-3-musical-themes/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/29/pointers-on-c-8-array/index.html","path":"HTML/2011/03/29/pointers-on-c-8-array/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/29/segment-tree-my-templete/index.html","path":"HTML/2011/03/29/segment-tree-my-templete/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/19/networkflow-24-3-minimum-path-cover/index.html","path":"HTML/2011/03/19/networkflow-24-3-minimum-path-cover/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/27/usaco-5-1-2-starry-night/index.html","path":"HTML/2011/03/27/usaco-5-1-2-starry-night/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/30/c-string-point-two-dimension/index.html","path":"HTML/2011/03/30/c-string-point-two-dimension/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/30/pointers-on-c-10-struct-union/index.html","path":"HTML/2011/03/30/pointers-on-c-10-struct-union/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/30/pointers-on-c-9-string/index.html","path":"HTML/2011/03/30/pointers-on-c-9-string/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/25/usaco-5-1-1-fencing-the-cows/index.html","path":"HTML/2011/03/25/usaco-5-1-1-fencing-the-cows/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/31/poj-2478-eular-function/index.html","path":"HTML/2011/03/31/poj-2478-eular-function/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/04/permalink-change/index.html","path":"HTML/2011/05/04/permalink-change/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/30/usaco-5-2-1-snail-trails/index.html","path":"HTML/2011/03/30/usaco-5-2-1-snail-trails/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/05/computational-geometry-hdu-2857/index.html","path":"HTML/2011/05/05/computational-geometry-hdu-2857/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/02/ball-union-zoj-3350/index.html","path":"HTML/2011/05/02/ball-union-zoj-3350/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/03/25/undefined-reference-to-sqrt-c/index.html","path":"HTML/2011/03/25/undefined-reference-to-sqrt-c/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/08/gcj-2011-klion26/index.html","path":"HTML/2011/05/08/gcj-2011-klion26/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/12/recent-life/index.html","path":"HTML/2011/05/12/recent-life/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/13/factor-num-hdu-1299/index.html","path":"HTML/2011/05/13/factor-num-hdu-1299/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/16/sg-function-hdu-2873/index.html","path":"HTML/2011/05/16/sg-function-hdu-2873/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/07/09/fedora13-h3c/index.html","path":"HTML/2011/07/09/fedora13-h3c/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/30/south-central-china-invite-competition-by-klion26/index.html","path":"HTML/2011/05/30/south-central-china-invite-competition-by-klion26/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/12/number-theory-poj-3358/index.html","path":"HTML/2011/05/12/number-theory-poj-3358/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/18/number-theory-hdu-2879/index.html","path":"HTML/2011/05/18/number-theory-hdu-2879/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/07/19/cg-hdu-3834/index.html","path":"HTML/2011/07/19/cg-hdu-3834/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/07/03/hdu-3074-bit-inver/index.html","path":"HTML/2011/07/03/hdu-3074-bit-inver/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/07/25/half-plan-cross/index.html","path":"HTML/2011/07/25/half-plan-cross/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/05/23/mon-monsterkill-xiangtan-by-klion26/index.html","path":"HTML/2011/05/23/mon-monsterkill-xiangtan-by-klion26/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/02/pointers-on-c-11-dynamical-memory/index.html","path":"HTML/2011/04/02/pointers-on-c-11-dynamical-memory/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/06/pointers-on-c-link-list/index.html","path":"HTML/2011/04/06/pointers-on-c-link-list/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/07/usaco-5-2-2-electric-fences/index.html","path":"HTML/2011/04/07/usaco-5-2-2-electric-fences/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/09/pointers-on-c-advanced-point/index.html","path":"HTML/2011/04/09/pointers-on-c-advanced-point/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/08/why-am-i-cancer/index.html","path":"HTML/2011/04/08/why-am-i-cancer/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/10/usaco-5-2-3-wisconsin-squares/index.html","path":"HTML/2011/04/10/usaco-5-2-3-wisconsin-squares/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/10/usaco-5-3-4big-barn/index.html","path":"HTML/2011/04/10/usaco-5-3-4big-barn/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/18/poj-2480/index.html","path":"HTML/2011/04/18/poj-2480/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/11/drab-queue-poj-2823/index.html","path":"HTML/2011/04/11/drab-queue-poj-2823/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/12/pointers-on-c-preprocessor/index.html","path":"HTML/2011/04/12/pointers-on-c-preprocessor/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/15/eular-function-2/index.html","path":"HTML/2011/04/15/eular-function-2/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/20/math-education/index.html","path":"HTML/2011/04/20/math-education/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/19/eular-function-hdu-3307/index.html","path":"HTML/2011/04/19/eular-function-hdu-3307/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/08/03/csu-summer-training-team-1/index.html","path":"HTML/2011/08/03/csu-summer-training-team-1/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/08/20/reverse-poj-3761/index.html","path":"HTML/2011/08/20/reverse-poj-3761/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/23/5th-csu-acm-competition/index.html","path":"HTML/2011/04/23/5th-csu-acm-competition/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/08/29/usaco-5-4-5-5/index.html","path":"HTML/2011/08/29/usaco-5-4-5-5/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/11/27/fuzhou-a-hdu-4121/index.html","path":"HTML/2011/11/27/fuzhou-a-hdu-4121/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/06/22/xp-fedora-double-os/index.html","path":"HTML/2011/06/22/xp-fedora-double-os/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/12/13/windows-mpi/index.html","path":"HTML/2011/12/13/windows-mpi/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/03/26/replay-email/index.html","path":"HTML/2012/03/26/replay-email/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/12/22/fuck-csdn/index.html","path":"HTML/2011/12/22/fuck-csdn/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/03/29/game-theory-prove/index.html","path":"HTML/2012/03/29/game-theory-prove/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/03/29/github-create-project/index.html","path":"HTML/2012/03/29/github-create-project/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/03/29/user-chrome-cross-gfw/index.html","path":"HTML/2012/03/29/user-chrome-cross-gfw/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/03/29/github-port-22-error-bad-file-number/index.html","path":"HTML/2012/03/29/github-port-22-error-bad-file-number/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/03/02/e3-80-8a-e6-ad-a4-e7-94-9f-e6-9c-aa-e5-ae-8c-e6-88-90-e3-80-8b-e4-ba-8e-e5-a8-9f/index.html","path":"HTML/2012/03/02/e3-80-8a-e6-ad-a4-e7-94-9f-e6-9c-aa-e5-ae-8c-e6-88-90-e3-80-8b-e4-ba-8e-e5-a8-9f/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/04/19/vmware-ubuntu-fedora/index.html","path":"HTML/2012/04/19/vmware-ubuntu-fedora/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2011/04/30/primitive-root-poj-1284/index.html","path":"HTML/2011/04/30/primitive-root-poj-1284/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/10/08/scheme-and-the-little-scheme/index.html","path":"HTML/2012/10/08/scheme-and-the-little-scheme/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/10/17/structure-and-interpretation-of-computer-programs-1-2/index.html","path":"HTML/2012/10/17/structure-and-interpretation-of-computer-programs-1-2/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/10/16/structure-and-interpretation-of-computer-programs-1-1/index.html","path":"HTML/2012/10/16/structure-and-interpretation-of-computer-programs-1-1/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/02/12/2011-2012-plan/index.html","path":"HTML/2012/02/12/2011-2012-plan/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/02/12/xp-office-2010-error-1406/index.html","path":"HTML/2012/02/12/xp-office-2010-error-1406/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/10/23/structure-and-interpretation-of-computer-programs-1-3/index.html","path":"HTML/2012/10/23/structure-and-interpretation-of-computer-programs-1-3/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/09/21/wordpress-fatal-error/index.html","path":"HTML/2012/09/21/wordpress-fatal-error/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/10/23/google-adsense/index.html","path":"HTML/2012/10/23/google-adsense/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/09/27/concrete-mathematics-chapter-1-homework-exercises/index.html","path":"HTML/2012/09/27/concrete-mathematics-chapter-1-homework-exercises/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2015/02/18/everything-about-2014/index.html","path":"HTML/2015/02/18/everything-about-2014/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/09/26/concrete-mathmatics-chapter-1/index.html","path":"HTML/2012/09/26/concrete-mathmatics-chapter-1/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/11/06/chrome-https-connection/index.html","path":"HTML/2012/11/06/chrome-https-connection/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/11/13/fedora-13-opengl/index.html","path":"HTML/2012/11/13/fedora-13-opengl/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/11/08/vc-6-clistctr-add-image-and-cant-display/index.html","path":"HTML/2012/11/08/vc-6-clistctr-add-image-and-cant-display/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/11/21/apue-chapter-3-excise-3-2/index.html","path":"HTML/2012/11/21/apue-chapter-3-excise-3-2/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/11/26/fedora-13-movie-mkv-mp4-rmvb-rm-song/index.html","path":"HTML/2012/11/26/fedora-13-movie-mkv-mp4-rmvb-rm-song/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/12/03/first-linux-module-lvm/index.html","path":"HTML/2012/12/03/first-linux-module-lvm/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2015/03/08/github-blog-math-expression-support/index.html","path":"HTML/2015/03/08/github-blog-math-expression-support/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/12/12/fedora-13-texlive2012-install-chinese-configure/index.html","path":"HTML/2012/12/12/fedora-13-texlive2012-install-chinese-configure/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/12/10/implicit-declaration-of-function-class-device-create/index.html","path":"HTML/2012/12/10/implicit-declaration-of-function-class-device-create/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/12/27/too-many-levels-of-symbolic-links/index.html","path":"HTML/2012/12/27/too-many-levels-of-symbolic-links/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/12/28/vi-basic-command/index.html","path":"HTML/2012/12/28/vi-basic-command/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/11/15/advanced-programming-in-the-unix-environment-apue-h/index.html","path":"HTML/2012/11/15/advanced-programming-in-the-unix-environment-apue-h/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2015/07/16/a-brief-view-of-storm/index.html","path":"HTML/2015/07/16/a-brief-view-of-storm/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2015/07/17/experiment-of-storm-grouping/index.html","path":"HTML/2015/07/17/experiment-of-storm-grouping/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/12/26/fedora-13-update-to-fedora-15/index.html","path":"HTML/2012/12/26/fedora-13-update-to-fedora-15/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/11/05/display-views-count-without-plugin/index.html","path":"HTML/2012/11/05/display-views-count-without-plugin/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/06/21/linux-command-shell-scripts-3/index.html","path":"HTML/2013/06/21/linux-command-shell-scripts-3/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2015/01/03/algorithm-series/index.html","path":"HTML/2015/01/03/algorithm-series/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2015/01/17/recursion/index.html","path":"HTML/2015/01/17/recursion/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/03/26/some-easy-math-problems/index.html","path":"HTML/2013/03/26/some-easy-math-problems/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/01/02/fedora-15-install-opencv-2-4/index.html","path":"HTML/2013/01/02/fedora-15-install-opencv-2-4/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/03/07/matlab-2012-libsvm/index.html","path":"HTML/2013/03/07/matlab-2012-libsvm/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/01/21/github-pages-jekyll-blog-free/index.html","path":"HTML/2013/01/21/github-pages-jekyll-blog-free/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/01/03/fedora-15-yum-rpm-problem/index.html","path":"HTML/2013/01/03/fedora-15-yum-rpm-problem/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/05/25/linux-command-shell-script-2/index.html","path":"HTML/2013/05/25/linux-command-shell-script-2/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/05/24/linux-command-shell-script/index.html","path":"HTML/2013/05/24/linux-command-shell-script/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/09/11/algorithms-chapter-5/index.html","path":"HTML/2013/09/11/algorithms-chapter-5/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/11/23/nonviolent-communication/index.html","path":"HTML/2013/11/23/nonviolent-communication/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2015/07/26/redis-pqsort-c/index.html","path":"HTML/2015/07/26/redis-pqsort-c/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/11/28/use-vundle-to-manage-vim-plugin/index.html","path":"HTML/2013/11/28/use-vundle-to-manage-vim-plugin/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/10/16/algorithms-chapter-6-dynamic-programming/index.html","path":"HTML/2013/10/16/algorithms-chapter-6-dynamic-programming/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/07/20/algorithms-chapter-3-homework-sol/index.html","path":"HTML/2013/07/20/algorithms-chapter-3-homework-sol/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/12/22/spiral-matrix/index.html","path":"HTML/2013/12/22/spiral-matrix/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/07/28/algorithms-chapter-4-and-some-exercises/index.html","path":"HTML/2013/07/28/algorithms-chapter-4-and-some-exercises/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/12/20/level-order-of-a-tree/index.html","path":"HTML/2013/12/20/level-order-of-a-tree/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2015/01/05/dynamic-programming/index.html","path":"HTML/2015/01/05/dynamic-programming/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2013/12/25/string-to-integer-atoi/index.html","path":"HTML/2013/12/25/string-to-integer-atoi/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/01/04/reverse-linked-list/index.html","path":"HTML/2014/01/04/reverse-linked-list/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/05/17/srm-620-randomgraph/index.html","path":"HTML/2014/05/17/srm-620-randomgraph/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/05/02/linux-daemon/index.html","path":"HTML/2014/05/02/linux-daemon/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/05/09/linux-dbm/index.html","path":"HTML/2014/05/09/linux-dbm/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/07/08/select-and-poll/index.html","path":"HTML/2014/07/08/select-and-poll/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/05/27/using-gdb-to-debug-nginx/index.html","path":"HTML/2014/05/27/using-gdb-to-debug-nginx/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/06/16/nginx-advancd-data-struct-1/index.html","path":"HTML/2014/06/16/nginx-advancd-data-struct-1/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/08/25/the-hardwaresoftware-interface-csapp-lab2-bomb/index.html","path":"HTML/2014/08/25/the-hardwaresoftware-interface-csapp-lab2-bomb/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/10/01/2014-code-interview/index.html","path":"HTML/2014/10/01/2014-code-interview/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/11/02/least-recently-used-algorithm/index.html","path":"HTML/2014/11/02/least-recently-used-algorithm/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/12/29/show-me-the-code/index.html","path":"HTML/2014/12/29/show-me-the-code/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/01/15/spark-streaming-e5-be-80-hdfs-e8-bf-bd-e5-8a-a0-lzo-e6-96-87-e4-bb-b6/index.html","path":"HTML/2017/01/15/spark-streaming-e5-be-80-hdfs-e8-bf-bd-e5-8a-a0-lzo-e6-96-87-e4-bb-b6/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/02/16/spark-streaming-consume-kafka-at-00-second-of-every-minute/index.html","path":"HTML/2017/02/16/spark-streaming-consume-kafka-at-00-second-of-every-minute/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/06/01/如何在不重启-Spark-Streaming-作业的情况下，增加消费的-topic/index.html","path":"HTML/2017/06/01/如何在不重启-Spark-Streaming-作业的情况下，增加消费的-topic/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/01/07/binary-tree-traversal-without-recursive/index.html","path":"HTML/2014/01/07/binary-tree-traversal-without-recursive/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/06/20/风险不仅仅是事件发生的概率/index.html","path":"HTML/2017/06/20/风险不仅仅是事件发生的概率/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/executor.jpg","path":"HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/executor.jpg","modified":0,"renderable":0},{"_id":"source/HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/hang_job.jpg","path":"HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/hang_job.jpg","modified":0,"renderable":0},{"_id":"source/HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/index.html","path":"HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/04/15/从现在开始写作/index.html","path":"HTML/2017/04/15/从现在开始写作/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/BFS_DFS.jpeg","path":"HTML/2017/09/17/GC-标记-清除算法/BFS_DFS.jpeg","modified":0,"renderable":0},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/bibop.jpeg","path":"HTML/2017/09/17/GC-标记-清除算法/bibop.jpeg","modified":0,"renderable":0},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/bitmap.jpeg","path":"HTML/2017/09/17/GC-标记-清除算法/bitmap.jpeg","modified":0,"renderable":0},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/heap.png","path":"HTML/2017/09/17/GC-标记-清除算法/heap.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/index.html","path":"HTML/2017/09/17/GC-标记-清除算法/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/lazy-sweep.png","path":"HTML/2017/09/17/GC-标记-清除算法/lazy-sweep.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/multilink.jpeg","path":"HTML/2017/09/17/GC-标记-清除算法/multilink.jpeg","modified":0,"renderable":0},{"_id":"source/HTML/2014/02/28/how-to-think-like-a-computer-scientist/index.html","path":"HTML/2014/02/28/how-to-think-like-a-computer-scientist/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/11/09/django-configuration-in-action/index.html","path":"HTML/2017/11/09/django-configuration-in-action/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/07/14/tmux-简单使用指南/index.html","path":"HTML/2017/07/14/tmux-简单使用指南/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/07/14/tmux-简单使用指南/tmux_pic.png","path":"HTML/2017/07/14/tmux-简单使用指南/tmux_pic.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/11/20/git-inside/first_version.png","path":"HTML/2017/11/20/git-inside/first_version.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/11/20/git-inside/file_tree.png","path":"HTML/2017/11/20/git-inside/file_tree.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/11/20/git-inside/index.html","path":"HTML/2017/11/20/git-inside/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/11/20/git-inside/second_version.png","path":"HTML/2017/11/20/git-inside/second_version.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/11/20/git-inside/project.png","path":"HTML/2017/11/20/git-inside/project.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/11/20/git-inside/third_version.png","path":"HTML/2017/11/20/git-inside/third_version.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/11/27/TaskScheduler/index.html","path":"HTML/2017/11/27/TaskScheduler/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/10/16/spark-dagscheduler/procesure.jpg","path":"HTML/2017/10/16/spark-dagscheduler/procesure.jpg","modified":0,"renderable":0},{"_id":"source/HTML/2017/10/16/spark-dagscheduler/index.html","path":"HTML/2017/10/16/spark-dagscheduler/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/10/16/spark-dagscheduler/stage.jpg","path":"HTML/2017/10/16/spark-dagscheduler/stage.jpg","modified":0,"renderable":0},{"_id":"source/HTML/2017/05/10/Python-代码实践小结/index.html","path":"HTML/2017/05/10/Python-代码实践小结/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver.png","path":"HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver_ReceiverSupervisor.png","path":"HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver_ReceiverSupervisor.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver_sample.png","path":"HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver_sample.png","modified":0,"renderable":0},{"_id":"source/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/index.html","path":"HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/05/29/从源码级别分析-metric-core-的抽样算法/index.html","path":"HTML/2017/05/29/从源码级别分析-metric-core-的抽样算法/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/12/03/tasksetmanager/index.html","path":"HTML/2017/12/03/tasksetmanager/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2018/01/06/线程堆栈分析/dead_lock.png","path":"HTML/2018/01/06/线程堆栈分析/dead_lock.png","modified":0,"renderable":0},{"_id":"source/HTML/2018/01/06/线程堆栈分析/index.html","path":"HTML/2018/01/06/线程堆栈分析/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2018/01/06/线程堆栈分析/wait_sleep.png","path":"HTML/2018/01/06/线程堆栈分析/wait_sleep.png","modified":0,"renderable":0},{"_id":"source/HTML/2014/09/26/epoll-and-select/index.html","path":"HTML/2014/09/26/epoll-and-select/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/12/22/millwheel/figure11_checkpoint.jpg","path":"HTML/2017/12/22/millwheel/figure11_checkpoint.jpg","modified":0,"renderable":0},{"_id":"source/HTML/2017/12/22/millwheel/figure12_transaction.jpg","path":"HTML/2017/12/22/millwheel/figure12_transaction.jpg","modified":0,"renderable":0},{"_id":"source/HTML/2017/12/22/millwheel/figure14_latency_scalability.jpg","path":"HTML/2017/12/22/millwheel/figure14_latency_scalability.jpg","modified":0,"renderable":0},{"_id":"source/HTML/2017/12/22/millwheel/figure13_latency.jpg","path":"HTML/2017/12/22/millwheel/figure13_latency.jpg","modified":0,"renderable":0},{"_id":"source/HTML/2017/12/22/millwheel/figure15_lowwatermark.jpg","path":"HTML/2017/12/22/millwheel/figure15_lowwatermark.jpg","modified":0,"renderable":0},{"_id":"source/HTML/2017/12/22/millwheel/figure16_cache.jpg","path":"HTML/2017/12/22/millwheel/figure16_cache.jpg","modified":0,"renderable":0},{"_id":"source/HTML/2017/12/22/millwheel/index.html","path":"HTML/2017/12/22/millwheel/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image1.png","path":"HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image1.png","modified":0,"renderable":0},{"_id":"source/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image2.png","path":"HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image2.png","modified":0,"renderable":0},{"_id":"source/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image3.png","path":"HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image3.png","modified":0,"renderable":0},{"_id":"source/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/index.html","path":"HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2012/11/27/why-can-not-use-weixin-miliao/index.html","path":"HTML/2012/11/27/why-can-not-use-weixin-miliao/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2014/06/20/nginx-http-filter-module/index.html","path":"HTML/2014/06/20/nginx-http-filter-module/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/03/30/mit-6-824-lab-2-part-a/index.html","path":"HTML/2016/03/30/mit-6-824-lab-2-part-a/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2018/09/09/一次-InputStream-read-使用不当导致的问题/index.html","path":"HTML/2018/09/09/一次-InputStream-read-使用不当导致的问题/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/03/23/mit-6-824-2015-lab-1/index.html","path":"HTML/2016/03/23/mit-6-824-2015-lab-1/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2017/05/20/hello-world/index.html","path":"HTML/2017/05/20/hello-world/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/05/03/e6-88-91-e5-bf-83-e7-9b-ae-e4-b8-ad-e7-9a-84-e8-80-81-e5-b8-88/index.html","path":"HTML/2016/05/03/e6-88-91-e5-bf-83-e7-9b-ae-e4-b8-ad-e7-9a-84-e8-80-81-e5-b8-88/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/07/14/spark-streaming-save-offset-to-zookeeper/index.html","path":"HTML/2016/07/14/spark-streaming-save-offset-to-zookeeper/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/08/27/spark-streaming-kafka-read-binlog-to-json/index.html","path":"HTML/2016/08/27/spark-streaming-kafka-read-binlog-to-json/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/07/15/spark-streaming-saving-offset-in-zookeeper-2/index.html","path":"HTML/2016/07/15/spark-streaming-saving-offset-in-zookeeper-2/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/10/26/e8-a6-81-e5-a4-9a-e5-bf-ab-e6-89-8d-e8-83-bd-e8-b7-91-e5-ae-8c-e4-b8-80-e5-9c-ba-e9-a9-ac-e6-8b-89-e6-9d-be/index.html","path":"HTML/2016/10/26/e8-a6-81-e5-a4-9a-e5-bf-ab-e6-89-8d-e8-83-bd-e8-b7-91-e5-ae-8c-e4-b8-80-e5-9c-ba-e9-a9-ac-e6-8b-89-e6-9d-be/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/10/22/storm-e7-9a-84-e5-8f-af-e9-9d-a0-e6-80-a7-e4-bf-9d-e8-af-81-e6-b5-8b-e8-af-95/index.html","path":"HTML/2016/10/22/storm-e7-9a-84-e5-8f-af-e9-9d-a0-e6-80-a7-e4-bf-9d-e8-af-81-e6-b5-8b-e8-af-95/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/06/11/asking-the-right-questions/index.html","path":"HTML/2016/06/11/asking-the-right-questions/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/09/26/e4-b8-80-e7-a7-8d-e5-8f-af-e8-a1-8c-e7-9a-84-e8-8b-b1-e8-af-ad-e9-98-85-e8-af-bb-e5-ad-a6-e4-b9-a0-e6-96-b9-e6-b3-95/index.html","path":"HTML/2016/09/26/e4-b8-80-e7-a7-8d-e5-8f-af-e8-a1-8c-e7-9a-84-e8-8b-b1-e8-af-ad-e9-98-85-e8-af-bb-e5-ad-a6-e4-b9-a0-e6-96-b9-e6-b3-95/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/11/01/spark-streaming-topic-partition-change-auto-adaptive/index.html","path":"HTML/2016/11/01/spark-streaming-topic-partition-change-auto-adaptive/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/01/20/how-to-read-a-book/index.html","path":"HTML/2016/01/20/how-to-read-a-book/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/11/26/spark-streaming-e5-be-80-hdfs-e5-86-99-e6-96-87-e4-bb-b6-ef-bc-8c-e8-87-aa-e5-ae-9a-e4-b9-89-e6-96-87-e4-bb-b6-e5-90-8d/index.html","path":"HTML/2016/11/26/spark-streaming-e5-be-80-hdfs-e5-86-99-e6-96-87-e4-bb-b6-ef-bc-8c-e8-87-aa-e5-ae-9a-e4-b9-89-e6-96-87-e4-bb-b6-e5-90-8d/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/12/02/spark-streaming-consume-kafka-message-from-specify-timestamp/index.html","path":"HTML/2016/12/02/spark-streaming-consume-kafka-message-from-specify-timestamp/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2018/04/06/Flink-State/index.html","path":"HTML/2018/04/06/Flink-State/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2018/04/06/Flink-State/state-hierarchy.png","path":"HTML/2018/04/06/Flink-State/state-hierarchy.png","modified":0,"renderable":0},{"_id":"source/HTML/2018/04/06/Flink-State/state-rescale.png","path":"HTML/2018/04/06/Flink-State/state-rescale.png","modified":0,"renderable":0},{"_id":"source/HTML/2020/05/20/RocksDB-Single-CF-Result/list_state_result.html","path":"HTML/2020/05/20/RocksDB-Single-CF-Result/list_state_result.html","modified":0,"renderable":0},{"_id":"source/HTML/2020/05/20/RocksDB-Single-CF-Result/map_state_result.html","path":"HTML/2020/05/20/RocksDB-Single-CF-Result/map_state_result.html","modified":0,"renderable":0},{"_id":"source/HTML/2020/05/20/RocksDB-Single-CF-Result/value_state_result.html","path":"HTML/2020/05/20/RocksDB-Single-CF-Result/value_state_result.html","modified":0,"renderable":0},{"_id":"source/HTML/2016/12/16/spark-streaming-ran-out-of-messages-before-reaching-ending-offset/index.html","path":"HTML/2016/12/16/spark-streaming-ran-out-of-messages-before-reaching-ending-offset/index.html","modified":0,"renderable":0},{"_id":"source/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image1.png","path":"HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image1.png","modified":0,"renderable":0},{"_id":"source/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image2.png","path":"HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image2.png","modified":0,"renderable":0},{"_id":"source/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image3.png","path":"HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image3.png","modified":0,"renderable":0},{"_id":"source/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image4.png","path":"HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image4.png","modified":0,"renderable":0},{"_id":"source/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/index.html","path":"HTML/2018/03/14/Java-内存泄漏分析和对内存设置/index.html","modified":0,"renderable":0},{"_id":"source/HTML/index.html","path":"HTML/index.html","modified":0,"renderable":0},{"_id":"themes/freemind/source/css/comment.css","path":"css/comment.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/font-awesome.css","path":"css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/google-fonts.css","path":"css/google-fonts.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/highlight-default.min.css","path":"css/highlight-default.min.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/highlight.css","path":"css/highlight.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/responsive.css","path":"css/responsive.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/style.css","path":"css/style.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/bootstrap.min.js","path":"js/bootstrap.min.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/comment.js","path":"js/comment.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/gallery.js","path":"js/gallery.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/highlight.min.js","path":"js/highlight.min.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/jquery-2.0.3.min.js","path":"js/jquery-2.0.3.min.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/jquery.imagesloaded.min.js","path":"js/jquery.imagesloaded.min.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/marked.js","path":"js/marked.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/spin.min.js","path":"js/spin.min.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/js/timeago.min.js","path":"js/timeago.min.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/freemind/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/freemind/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/freemind/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/freemind/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/freemind/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/freemind/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/FontAwesome.otf","path":"fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/fontawesome-webfont.eot","path":"fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/fontawesome-webfont.svg","path":"fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/fontawesome-webfont.ttf","path":"fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/fontawesome-webfont.woff","path":"fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/freemind/source/img/github-sprite.png","path":"img/github-sprite.png","modified":0,"renderable":1},{"_id":"themes/freemind/source/img/glyphicons-halflings-white.png","path":"img/glyphicons-halflings-white.png","modified":0,"renderable":1},{"_id":"themes/freemind/source/img/glyphicons-halflings.png","path":"img/glyphicons-halflings.png","modified":0,"renderable":1},{"_id":"themes/freemind/source/img/grid-18px-masked.png","path":"img/grid-18px-masked.png","modified":0,"renderable":1},{"_id":"themes/freemind/source/img/grid-baseline-20px.png","path":"img/grid-baseline-20px.png","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/bootstrap.css","path":"css/themes/bootstrap.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/cerulean.css","path":"css/themes/cerulean.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/common.css","path":"css/themes/common.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/cosmo.css","path":"css/themes/cosmo.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/cyborg.css","path":"css/themes/cyborg.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/darkly.css","path":"css/themes/darkly.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/default.css","path":"css/themes/default.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/flatly.css","path":"css/themes/flatly.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/journal.css","path":"css/themes/journal.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/lumen.css","path":"css/themes/lumen.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/paper.css","path":"css/themes/paper.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/readable.css","path":"css/themes/readable.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/sandstone.css","path":"css/themes/sandstone.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/simplex.css","path":"css/themes/simplex.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/slate.css","path":"css/themes/slate.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/spacelab.css","path":"css/themes/spacelab.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/superhero.css","path":"css/themes/superhero.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/united.css","path":"css/themes/united.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/css/themes/yeti.css","path":"css/themes/yeti.css","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/google-fonts/0AKsP294HTD-nvJgucYTaIbN6UDyHWBl620a-IRfuBk.woff","path":"fonts/google-fonts/0AKsP294HTD-nvJgucYTaIbN6UDyHWBl620a-IRfuBk.woff","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/google-fonts/0XxGQsSc1g4rdRdjJKZrNBsxEYwM7FgeyaSgU71cLG0.woff","path":"fonts/google-fonts/0XxGQsSc1g4rdRdjJKZrNBsxEYwM7FgeyaSgU71cLG0.woff","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/google-fonts/2UX7WLTfW3W8TclTUvlFyQ.woff","path":"fonts/google-fonts/2UX7WLTfW3W8TclTUvlFyQ.woff","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/google-fonts/LKf8nhXsWg5ybwEGXk8UBQ.woff","path":"fonts/google-fonts/LKf8nhXsWg5ybwEGXk8UBQ.woff","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/google-fonts/PIPMHY90P7jtyjpXuZ2cLD8E0i7KZn-EPnyo3HZu7kw.woff","path":"fonts/google-fonts/PIPMHY90P7jtyjpXuZ2cLD8E0i7KZn-EPnyo3HZu7kw.woff","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/google-fonts/UyYrYy3ltEffJV9QueSi4RdbPw3QSf9R-kE0EsQUn2A.woff","path":"fonts/google-fonts/UyYrYy3ltEffJV9QueSi4RdbPw3QSf9R-kE0EsQUn2A.woff","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/google-fonts/cj2hUnSRBhwmSPr9kS5899kZXW4sYc4BjuAIFc1SXII.woff","path":"fonts/google-fonts/cj2hUnSRBhwmSPr9kS5899kZXW4sYc4BjuAIFc1SXII.woff","modified":0,"renderable":1},{"_id":"themes/freemind/source/fonts/google-fonts/lILlYDvubYemzYzN7GbLkHhCUOGz7vYGh680lGh-uXM.woff","path":"fonts/google-fonts/lILlYDvubYemzYzN7GbLkHhCUOGz7vYGh680lGh-uXM.woff","modified":0,"renderable":1},{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0}],"Cache":[{"_id":"themes/freemind/source/css/themes/common.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1684294058224},{"_id":"themes/freemind/.gitignore","hash":"7d65523f2a5afb69d76824dd1dfa62a34faa3197","modified":1714964121908},{"_id":"themes/freemind/_config.yml","hash":"25c6730dc22111606f9bcdedde01fcfa4473ac43","modified":1714965110025},{"_id":"themes/freemind/package.json","hash":"00357ef6f24eb049074da81809e98f973f528cca","modified":1714964121917},{"_id":"themes/freemind/README.md","hash":"9b80c245e49f602739c05038fea18186432d0ad9","modified":1714964121909},{"_id":"themes/freemind/layout/page.ejs","hash":"781887eec7ac7b9812c529baccb564a77061d687","modified":1714964121916},{"_id":"themes/freemind/layout/archive.ejs","hash":"c97be36b33bb44957778587f00c978f2d28016f8","modified":1684294058217},{"_id":"themes/freemind/LICENSE","hash":"a708d11fd1944ab4b94b39a8c83c75f362a170d7","modified":1714964121908},{"_id":"themes/freemind/layout/categories.ejs","hash":"9864e02b4c08678910d0be3f0f16cfcaa26232dc","modified":1714964121916},{"_id":"themes/freemind/layout/layout.ejs","hash":"6d1b7b626a2b2d994ff6fff4eaad60dd9fd42aeb","modified":1714964121916},{"_id":"themes/freemind/layout/index.ejs","hash":"2beec802d9dadb9369ffc7511304b1cc1feb96b0","modified":1714964121916},{"_id":"themes/freemind/languages/default.yml","hash":"6ea300b240139d3f363c66e105feed4113629c86","modified":1714964121909},{"_id":"themes/freemind/layout/post.ejs","hash":"06a110a121af15c00921b8cb4b99fe736d4e17c7","modified":1714964121916},{"_id":"themes/freemind/layout/tags.ejs","hash":"6f36ab68d9998177a92bb85b438dc7954e659356","modified":1714964121916},{"_id":"themes/freemind/languages/zh-CN.yml","hash":"9a5392c125c20d1b64f7fdc8c22e1d30b4a8fbe4","modified":1714964121909},{"_id":"themes/freemind/languages/pt-BR.yml","hash":"5909ce04246e958746c2d75a0dfd47076f8d0132","modified":1714964121909},{"_id":"themes/freemind/languages/zh-TW.yml","hash":"44f8887b925454e7144c8c1bb9c8ca194cec969c","modified":1714964121910},{"_id":"themes/freemind/layout/_partial/after_footer.ejs","hash":"464732987cb5d1e47e52559b7a278880083b3819","modified":1714964121910},{"_id":"themes/freemind/layout/_partial/archive.ejs","hash":"35e7ec42bda8d339cb2ed422835bec8996afc096","modified":1762938908492},{"_id":"themes/freemind/layout/_partial/article.ejs","hash":"21463a6393a1468778dbb49d0eb61c556bf4e869","modified":1714964121910},{"_id":"themes/freemind/layout/_partial/footer.ejs","hash":"b4b55c57c4172931af355565ba404dc7dd367c21","modified":1714964121911},{"_id":"themes/freemind/layout/_partial/navigation.ejs","hash":"5b690ac12661e296329c1371d3d87ee74a6f4239","modified":1714964121911},{"_id":"themes/freemind/layout/_partial/index.ejs","hash":"e20fe55bfb46e9e7e0191c6639268ef66583084a","modified":1714964121911},{"_id":"themes/freemind/layout/_partial/head.ejs","hash":"e1adfc2be16a7869d2295771fd239c73a37596b3","modified":1714964121911},{"_id":"themes/freemind/layout/_partial/index_pagination.ejs","hash":"fa818b1c87cd3b1df94b17587fe998c54a35976e","modified":1714964121911},{"_id":"themes/freemind/layout/_partial/search.ejs","hash":"a7c526c07a8af040ba285dc63f267004ce211dce","modified":1714964121914},{"_id":"themes/freemind/layout/_partial/sidebar.ejs","hash":"862ff700568ec5a00f222131b353475d0a3f2a9c","modified":1714964121914},{"_id":"themes/freemind/layout/_widget/recent_posts.ejs","hash":"8ef64298ff7d5576cbbc5d353f7cd026ce5dcbd5","modified":1714964121915},{"_id":"themes/freemind/layout/_widget/category.ejs","hash":"8f3b0aa1fa02ebdbacc23bc3bc26f90f96dbad5b","modified":1714964121914},{"_id":"themes/freemind/layout/_widget/links.ejs","hash":"c0452a56e4513efe03867734f5fbcb6715f9a852","modified":1714964121915},{"_id":"themes/freemind/layout/_widget/recent_comments.ejs","hash":"b7f35a28bfafc858921f9065965ebbfb034ba781","modified":1714964121915},{"_id":"themes/freemind/layout/_widget/rss.ejs","hash":"7e24b248e4b9992ef5237ec28767aea50577bae7","modified":1714964121915},{"_id":"themes/freemind/layout/_widget/search.ejs","hash":"620dd8a93a9f0fca63f6f0b520cf192ce7b5a645","modified":1714964121915},{"_id":"themes/freemind/layout/_widget/tagcloud.ejs","hash":"7ee4fefcd60c3b5ca918d4044ec4c60dd702673d","modified":1714964121915},{"_id":"themes/freemind/source/fonts/fontawesome-webfont.eot","hash":"0183979056f0b87616cd99d5c54a48f3b771eee6","modified":1684294058245},{"_id":"themes/freemind/source/fonts/fontawesome-webfont.woff","hash":"7d65e0227d0d7cdc1718119cd2a7dce0638f151c","modified":1684294058249},{"_id":"themes/freemind/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1684294058243},{"_id":"themes/freemind/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1684294058243},{"_id":"themes/freemind/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1684294058243},{"_id":"themes/freemind/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1684294058243},{"_id":"themes/freemind/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1684294058244},{"_id":"themes/freemind/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1684294058243},{"_id":"themes/freemind/source/fancybox/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1714964121940},{"_id":"themes/freemind/source/css/highlight.css","hash":"98a031dd0991929ec23098db9dfde15ae662f031","modified":1714964121918},{"_id":"themes/freemind/source/fancybox/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1714964121940},{"_id":"themes/freemind/source/css/comment.css","hash":"acbef2bb5327b74fb68036ae238bc03514e4b4d8","modified":1714964121917},{"_id":"themes/freemind/source/css/responsive.css","hash":"25136a75af5957a669d5c4782da8b8fa95f8fc55","modified":1714964121918},{"_id":"themes/freemind/source/img/github-sprite.png","hash":"4d7ee33beaaebf002ba57a172d159e46194ae481","modified":1684294058253},{"_id":"themes/freemind/source/css/style.css","hash":"1c6958e4fa8ab11aca518b9a556fe2fad4976675","modified":1714964121918},{"_id":"themes/freemind/source/img/grid-18px-masked.png","hash":"1379b689836f9fcccd88aa729c4034d6b36e1f3c","modified":1684294058254},{"_id":"themes/freemind/source/img/glyphicons-halflings-white.png","hash":"a25c4705320fd63c33790e666872910e702b9bf6","modified":1684294058254},{"_id":"themes/freemind/source/img/glyphicons-halflings.png","hash":"84f613631b07d4fe22acbab50e551c0fe04bd78b","modified":1684294058254},{"_id":"themes/freemind/source/img/grid-baseline-20px.png","hash":"43b8d0c9b39f5ce07ecfde036fd13f835c129238","modified":1684294058254},{"_id":"themes/freemind/source/css/google-fonts.css","hash":"91e629d0a0a531e920252788ed8863c26608c2b2","modified":1714964121917},{"_id":"themes/freemind/source/css/highlight-default.min.css","hash":"6ad10fd07f492660d5c8c8eaec6e74a94d277b4a","modified":1684294058220},{"_id":"themes/freemind/source/js/bootstrap.min.js","hash":"6c264e0e0026ab5ece49350c6a8812398e696cbb","modified":1714964121954},{"_id":"themes/freemind/source/js/comment.js","hash":"5cdafe054baa2ef66670ed46e6f862718e77bfcb","modified":1714964121956},{"_id":"themes/freemind/source/js/gallery.js","hash":"d19f1b1cc5b75e21ca1d643b6dae9490ead28b55","modified":1714964121957},{"_id":"themes/freemind/source/css/font-awesome.css","hash":"6df51eee1e75e450cb9cd71e925e6aa9ac2d6a9d","modified":1714964121917},{"_id":"themes/freemind/source/js/highlight.min.js","hash":"02bb4cdaf43c85b7ee4ef6ccf1f3fe8e82fd3ceb","modified":1714964121957},{"_id":"themes/freemind/source/js/jquery.imagesloaded.min.js","hash":"3eb6381d2ed4b706020e4be5aff024aab4bcabc5","modified":1684294058257},{"_id":"themes/freemind/source/js/main.js","hash":"d78290344d95646172e488e0af2dade9740288f8","modified":1714964121958},{"_id":"themes/freemind/source/js/marked.js","hash":"b1d4ef560ea01a5fe3a391a5933be5e7016f1d6a","modified":1714964121958},{"_id":"themes/freemind/layout/_partial/post/analytics.ejs","hash":"31a0a3e5bc616b847c1ed82293fb3a3fc97054be","modified":1714964121912},{"_id":"themes/freemind/source/js/search.js","hash":"6197e425941f107761d3cbfb0f06ad4a3f5f7427","modified":1714964121959},{"_id":"themes/freemind/layout/_partial/post/bdshare.ejs","hash":"24c91ac17714ea39120a18633c3611b15464e5ab","modified":1684294058213},{"_id":"themes/freemind/layout/_partial/post/category.ejs","hash":"6ea00603f6a93b68aa2ca1cab9f459902ec95e1a","modified":1714964121912},{"_id":"themes/freemind/layout/_partial/post/comment.ejs","hash":"884ea68df119de6d731665b981ccc0a5a746449c","modified":1714964121912},{"_id":"themes/freemind/layout/_partial/post/jiathis.ejs","hash":"6fbf47f67e6f18fe4fea7fff6b564d29512469b5","modified":1684294058214},{"_id":"themes/freemind/layout/_partial/post/comment_footer.ejs","hash":"fefc355eb4d61d08ffca7f6439fecb146696265e","modified":1714964121912},{"_id":"themes/freemind/source/js/spin.min.js","hash":"f91e2b661f4feb976b5e260bdc2366763ad13562","modified":1714964121959},{"_id":"themes/freemind/source/js/timeago.min.js","hash":"d220fcc47be00effec6b5181b97cc0929d10031e","modified":1684294058258},{"_id":"themes/freemind/layout/_partial/post/pagination.ejs","hash":"68ea473404ec0606f7855c06eb1cd4fb3dafe550","modified":1714964121913},{"_id":"themes/freemind/layout/_partial/post/share.ejs","hash":"24c04b319f1b19e887c42db961b90a7e0ab26fdc","modified":1714964121913},{"_id":"themes/freemind/layout/_partial/post/meta.ejs","hash":"70b3b1dc3b039db3ef6f5e88709d0d4d5a8034a5","modified":1714964121913},{"_id":"themes/freemind/layout/_partial/post/entry.ejs","hash":"4d152fc69ba6042b652aa70584564e20ef070e9b","modified":1714964121912},{"_id":"themes/freemind/layout/_partial/post/recommended_posts.ejs","hash":"68c27c333534a23d1037a2bfd136bef1468389cb","modified":1714964121913},{"_id":"themes/freemind/layout/_partial/post/tag.ejs","hash":"db79c3d2b77c64c354f48f2eb6b648108e986857","modified":1714964121913},{"_id":"themes/freemind/layout/_partial/post/slogan.ejs","hash":"99b66f7b36f1bf1707c5ce5156c79359799539eb","modified":1714964121913},{"_id":"themes/freemind/layout/_partial/post/title_top.ejs","hash":"b8558cf461df2211a072180bdf8b709eb7d135c4","modified":1714964121914},{"_id":"themes/freemind/layout/_partial/post/title.ejs","hash":"a22fb024c8aaefdc04eee8587a184309e17e9232","modified":1714964121914},{"_id":"themes/freemind/source/fonts/google-fonts/0AKsP294HTD-nvJgucYTaIbN6UDyHWBl620a-IRfuBk.woff","hash":"1d9bb14c006d39d7eb0812a85567c7431f899b8d","modified":1684294058250},{"_id":"themes/freemind/source/fonts/google-fonts/LKf8nhXsWg5ybwEGXk8UBQ.woff","hash":"f401d51152681048c06187c5d3919b1407b899c5","modified":1684294058251},{"_id":"themes/freemind/source/fonts/google-fonts/0XxGQsSc1g4rdRdjJKZrNBsxEYwM7FgeyaSgU71cLG0.woff","hash":"33225e85c33279e7b4f0c5c65ff93bec740dd59c","modified":1684294058250},{"_id":"themes/freemind/source/fonts/google-fonts/PIPMHY90P7jtyjpXuZ2cLD8E0i7KZn-EPnyo3HZu7kw.woff","hash":"18dc51e642b4df958098d3bbc6d3ba0237ef6150","modified":1684294058252},{"_id":"themes/freemind/source/fonts/google-fonts/UyYrYy3ltEffJV9QueSi4RdbPw3QSf9R-kE0EsQUn2A.woff","hash":"d9f913d09bb3c25749daf8e7ab829c850a842929","modified":1684294058252},{"_id":"themes/freemind/source/fonts/google-fonts/lILlYDvubYemzYzN7GbLkHhCUOGz7vYGh680lGh-uXM.woff","hash":"e6c9f1e5a6a966a8f7250201356f351890a48921","modified":1684294058253},{"_id":"themes/freemind/source/fonts/google-fonts/cj2hUnSRBhwmSPr9kS5899kZXW4sYc4BjuAIFc1SXII.woff","hash":"17a484b92c0dacc8e8b4f0d38ccc1db400819d1d","modified":1684294058252},{"_id":"themes/freemind/source/css/themes/default.css","hash":"32f758d295c7037f247d300f2481b5d7d4f3b100","modified":1714964121923},{"_id":"themes/freemind/source/fonts/google-fonts/2UX7WLTfW3W8TclTUvlFyQ.woff","hash":"87deb174af2e2beebb9f09d618a5159ca299a3d0","modified":1684294058251},{"_id":"themes/freemind/source/fonts/FontAwesome.otf","hash":"6270a4a561a69fef5f5cc18cdf9efc256ec2ccbe","modified":1684294058245},{"_id":"themes/freemind/source/fonts/fontawesome-webfont.ttf","hash":"6225ccc4ec94d060f19efab97ca42d842845b949","modified":1684294058249},{"_id":"themes/freemind/source/js/jquery-2.0.3.min.js","hash":"28daf1b2a995cc4de81154a9a9ebdbb98f7c9997","modified":1714964121957},{"_id":"themes/freemind/source/css/themes/bootstrap.css","hash":"11197c2fc2925b34cc98a3f4ec67ffdd9f36a760","modified":1714964121919},{"_id":"themes/freemind/source/css/themes/cosmo.css","hash":"bcb36ab2b547571fa4125e05e1074abba6bd5670","modified":1714964121921},{"_id":"themes/freemind/source/css/themes/cyborg.css","hash":"4320dbfd9543f6ef1cc703d83d85c6652f9272d0","modified":1714964121922},{"_id":"themes/freemind/source/css/themes/cerulean.css","hash":"7fee0903cce12483ae3f37d330ef693826a5a61f","modified":1714964121921},{"_id":"themes/freemind/source/css/themes/journal.css","hash":"b77cda6baedc3852c64f5664206356b3057b4781","modified":1714964121925},{"_id":"themes/freemind/source/css/themes/paper.css","hash":"1ae57ddb500a85b8ca8e7d2897e55cb2ba4cf1bc","modified":1714964121926},{"_id":"themes/freemind/source/css/themes/flatly.css","hash":"a95865761e69d0daf75660e24d9f5f316482ea55","modified":1714964121924},{"_id":"themes/freemind/source/css/themes/readable.css","hash":"af59c50f83bba69a4fef7d0ac32e309c903b4511","modified":1714964121928},{"_id":"themes/freemind/source/css/themes/sandstone.css","hash":"5878440ffa7e1656214bafd8b7f39d736219807a","modified":1714964121929},{"_id":"themes/freemind/source/css/themes/simplex.css","hash":"b8165c48cf72e54c1f8ae1a550a04a64e6ce1929","modified":1714964121931},{"_id":"themes/freemind/source/css/themes/slate.css","hash":"3859265e9fcdb579f40a2ef7a5bd8dbead2d13ca","modified":1714964121934},{"_id":"themes/freemind/source/css/themes/spacelab.css","hash":"fa4efbf50ca392c25e9b6395d6221696ec6573b6","modified":1714964121935},{"_id":"themes/freemind/source/css/themes/superhero.css","hash":"cc4ce979e1def77b7c9b250d97d0baf3e0a3f845","modified":1714964121935},{"_id":"themes/freemind/source/css/themes/united.css","hash":"857151fa534842d0f8e862b2067f22905a1b3382","modified":1714964121936},{"_id":"themes/freemind/source/css/themes/lumen.css","hash":"5c23c4a98aec86b8483040e0ca602d3a4574f32c","modified":1714964121925},{"_id":"themes/freemind/source/css/themes/darkly.css","hash":"581ff4339a616fe26b4dc1b6c1d1ad7946b83de6","modified":1714964121923},{"_id":"themes/freemind/source/css/themes/yeti.css","hash":"7cb64c45bed521321e0a4a57e05e3d1c87721f16","modified":1714964121937},{"_id":"themes/freemind/source/fonts/fontawesome-webfont.svg","hash":"cd980eab6db5fa57db670cb2e4278e67e1a4d6c9","modified":1684294058248},{"_id":"source/_posts/lsm-tree-1-2023-05-17.md","hash":"ecdafb4abc12597fba98eaa56f7b5fdcb6d92f0b","modified":1714963932101},{"_id":"source/.DS_Store","hash":"37ceb0388a0906668beeaa650214972b0af7c789","modified":1764037246898},{"_id":"source/_drafts/lsm-tree-2-20230517.md","hash":"c0d0ca02a8471176e528b0e0ee8ed96fa6845de4","modified":1714963891126},{"_id":"source/HTML/2010/12/15/xampp-apache-cant-work-80-port/index.html","hash":"d00f26d86a9ed0f18217896e5ed67a877836d8ab","modified":1643724682008},{"_id":"source/_posts/big-data-paper-big-picture.md","hash":"ccbcf56371d1e5d3db66a4e80620bb5983f32569","modified":1714963932101},{"_id":"source/HTML/2010/12/09/hello-world-1/index.html","hash":"b7f672733e1544662e607889962dc7e2ff1dece4","modified":1643724682006},{"_id":"source/HTML/2010/12/15/vmware-redhat9-cant-mount/index.html","hash":"0ebfa804c365dc70ea2e37a323fbc48e2963857d","modified":1643724682008},{"_id":"source/HTML/2010/12/14/red-hat9-command-messy-code/index.html","hash":"b8511a068efe0a825516424a6a807f518834fa50","modified":1643724682008},{"_id":"source/HTML/2010/12/12/usaco-4-1-4-cryptcowgraphy/index.html","hash":"a0b458ff43182267b6a0bb6d85d03ffa142b8f78","modified":1643724682007},{"_id":"source/HTML/2010/12/22/linux-shell-problem/index.html","hash":"4e01c5a3d4746a7e9f8cdeeb4d8a70009c62aeec","modified":1643724682009},{"_id":"source/HTML/2010/12/16/wordpress-link-order/index.html","hash":"4112ccf19e134969ef45dd6f982933f36bb8f093","modified":1643724682009},{"_id":"source/HTML/2010/12/14/linux-rename/index.html","hash":"9d612e51ee296c6ce0e9baaa750f72c49f99470d","modified":1643724682007},{"_id":"source/HTML/2010/12/30/linux-fork-test/index.html","hash":"d70a5871ad8b47faf6a41be054559ed2099699d8","modified":1643724682010},{"_id":"source/HTML/2010/12/23/linux-single-user-config/index.html","hash":"41a1c7ca16e86feba1e6bdc0cfc64e5a47668a44","modified":1643724682010},{"_id":"source/HTML/2010/12/31/linux-fork-2/index.html","hash":"9ddcf3b5ef334232628a464c054176ca39a325c5","modified":1643724682011},{"_id":"source/HTML/2010/12/30/wordpress-clickchar-plugin/index.html","hash":"f29d93933c20f5cbecbc332ed620e24481940de3","modified":1643724682011},{"_id":"source/HTML/2011/02/10/usaco-4-1-2-fence-rails/index.html","hash":"8792c869577319964af72d1e12680887faf5d65f","modified":1643724682012},{"_id":"source/HTML/2011/02/10/usaco-4-2-1-drainage-ditches/index.html","hash":"c7671d8d7bb5d368a426bd4dbb9d77bff2659754","modified":1643724682012},{"_id":"source/HTML/2011/02/10/networkflow-1-maximum-matching/index.html","hash":"bcdb2deb83feb707c0125e6c7430e5fab733cf25","modified":1643724682012},{"_id":"source/HTML/2011/02/11/usaco-4-2-2-the-perfect-stall-dinic/index.html","hash":"103e1306fe629a15de363c25db4194d1c8aa0e61","modified":1643724682013},{"_id":"source/HTML/2011/02/21/usaco-4-2-4-cowcycle/index.html","hash":"9cbf3bd17f36d430e18187c241aae6377ad0da39","modified":1643724682014},{"_id":"source/HTML/2010/12/23/linux-grub-encrypt/index.html","hash":"4f414c75abba66766dfb58c1ba0f655d25dfc668","modified":1643724682010},{"_id":"source/HTML/2011/02/26/usaco-4-3-1-buy-low-buy-lower/index.html","hash":"a6870b51f201fc9cc1f460a5f36bd87c3b96c13c","modified":1643724682014},{"_id":"source/HTML/2011/03/06/usaco-4-3-2-the-primes/index.html","hash":"0bfc284b03ed350bb4227fe04396a5bd44a3cb1c","modified":1643724682015},{"_id":"source/HTML/2011/03/07/usaco-4-3-3-street-race/index.html","hash":"bf00799ad8ac89113d39464e8bf08dd6299f920e","modified":1643724682016},{"_id":"source/HTML/2011/03/03/networkflow-24-2-minimum-cut/index.html","hash":"42f2bcc74e794aa3757c92ca9c29ab8b9da8f5a9","modified":1643724682015},{"_id":"source/HTML/2011/02/27/networkflow-sap/index.html","hash":"72f316e2e41aaaa4fe89bb4dd98d4317d8cfae6d","modified":1643724682015},{"_id":"source/HTML/2011/02/12/usaco-4-2-3-job-processing/index.html","hash":"367c0d2ebaaa6e7a348b3862e34358eba6490f68","modified":1643724682013},{"_id":"source/HTML/2011/03/18/usaco-4-4-1-shuttle-puzzle/index.html","hash":"036e41c9402c101a928cb8b8ca958dd1bf82c8c9","modified":1643724682018},{"_id":"source/HTML/2011/03/17/poj-1704-game/index.html","hash":"fddc4e2410614c3a7078395254ace1797cf5fc3a","modified":1643724682017},{"_id":"source/HTML/2011/03/14/usaco-4-3-4-letter-game/index.html","hash":"c9c0874db9d75d18fea253724226f928cee1b29f","modified":1643724682016},{"_id":"source/HTML/2011/03/18/another-ux-strong-password/index.html","hash":"ce2d0804d9df70cce8a61d12d1306a8428dc10b4","modified":1643724682018},{"_id":"source/HTML/2011/03/22/c-cow-problem/index.html","hash":"9b6583d3037c8507c697d948de624b4ff1a2411f","modified":1643724682019},{"_id":"source/HTML/2011/03/15/hdu-1730-game/index.html","hash":"86d41ced94481000ffc8df4a012af2efe4e6f81a","modified":1643724682017},{"_id":"source/HTML/2011/03/19/networkflow-5-round-table/index.html","hash":"ea36968262bacdeb21939f52b2d38277f804753f","modified":1643724682019},{"_id":"source/HTML/2011/03/22/usaco-4-4-3-frame-up/index.html","hash":"e3452f98ef670c2ed7444846a103a4c301eb60df","modified":1643724682020},{"_id":"source/HTML/2011/03/24/hdu-3389/index.html","hash":"1337e0432e89c41b226dde340a01e0ca699ba4e8","modified":1643724682020},{"_id":"source/HTML/2011/03/28/usaco-5-1-3-musical-themes/index.html","hash":"36c1fdb176ea126f01d21a9e1c53b375136e2869","modified":1643724682021},{"_id":"source/HTML/2011/03/29/pointers-on-c-8-array/index.html","hash":"d349f5f698b296af66067118a0705d4544f0548b","modified":1643724682022},{"_id":"source/HTML/2011/03/16/usaco-4-4-2-pollutant-control/index.html","hash":"6ca3126283b597c9d5148ad698015cc407df8996","modified":1643724682017},{"_id":"source/HTML/2011/03/29/segment-tree-my-templete/index.html","hash":"355b3a7fa94eec5e5f478280f43fa8b6e3bc91e3","modified":1643724682022},{"_id":"source/HTML/2011/03/19/networkflow-24-3-minimum-path-cover/index.html","hash":"2949947bc26404766155bbaeacc5ef4dbe237632","modified":1643724682018},{"_id":"source/HTML/2011/03/30/pointers-on-c-9-string/index.html","hash":"424b0332899bd8e3c356f7cf5964b0fd6cdc1211","modified":1643724682024},{"_id":"source/HTML/2011/03/25/usaco-5-1-1-fencing-the-cows/index.html","hash":"82579e26e984e553bb0f2adb471823c6bfebb75f","modified":1643724682021},{"_id":"source/HTML/2011/03/31/poj-2478-eular-function/index.html","hash":"fa99d98b10fd1e5db61489036eed11294b79b29d","modified":1643724682025},{"_id":"source/HTML/2011/03/30/pointers-on-c-10-struct-union/index.html","hash":"524c4c732ec73544fd340fae7ee53a9b6d77b239","modified":1643724682023},{"_id":"source/HTML/2011/03/30/c-string-point-two-dimension/index.html","hash":"58708fcb8ffba3acaa38b9c882cbf959bb7b598d","modified":1643724682023},{"_id":"source/HTML/2011/05/02/ball-union-zoj-3350/index.html","hash":"8cbb82a3be70cc60a24e129b740a2012560b6d08","modified":1643724682034},{"_id":"source/HTML/2011/05/04/permalink-change/index.html","hash":"69b1c5b855b539e77084fc25a41dd73873f4ed2a","modified":1643724682034},{"_id":"source/HTML/2011/05/12/recent-life/index.html","hash":"883c2a340ed6bb52561b4e83725370b3958c9bfa","modified":1643724682035},{"_id":"source/HTML/2011/05/08/gcj-2011-klion26/index.html","hash":"ad887c11e2a3ed3d61d47ef1b98604658ddede50","modified":1643724682035},{"_id":"source/HTML/2011/03/30/usaco-5-2-1-snail-trails/index.html","hash":"5ab2c014286103dd584f13a3f550faa9799b5cb6","modified":1643724682024},{"_id":"source/HTML/2011/05/05/computational-geometry-hdu-2857/index.html","hash":"d1d7cbee12bc15dca86d0aa89774670aeb4a46e7","modified":1643724682034},{"_id":"source/HTML/2011/05/13/factor-num-hdu-1299/index.html","hash":"b9113a538cee1221fe008d3096fdf96ff31cbbad","modified":1643724682036},{"_id":"source/HTML/2011/05/30/south-central-china-invite-competition-by-klion26/index.html","hash":"18d3f7f49503c036f21edf5dd3c0fa81ff327f9e","modified":1643724682037},{"_id":"source/HTML/2011/03/25/undefined-reference-to-sqrt-c/index.html","hash":"addd4a410964b3e69498495ed082ade0a430c8f6","modified":1643724682020},{"_id":"source/HTML/2011/07/09/fedora13-h3c/index.html","hash":"59a8264b0c5cedc1e9bf67fb63015dc489dbb82d","modified":1643724682038},{"_id":"source/HTML/2011/05/16/sg-function-hdu-2873/index.html","hash":"cb57dc1f27fad14dd8acb0c0b80e7bd5731f55e5","modified":1643724682036},{"_id":"source/HTML/2011/07/19/cg-hdu-3834/index.html","hash":"39d047e463509a230b67c0edd776580fc5db4824","modified":1643724682039},{"_id":"source/HTML/2011/05/18/number-theory-hdu-2879/index.html","hash":"ef7ec4bd95b42f7ee4ec9e7bde96e1710c972d1a","modified":1643724682036},{"_id":"source/HTML/2011/07/25/half-plan-cross/index.html","hash":"fe71d156e99bc3c25b2cadf11c1cf658cd63f0bd","modified":1643724682039},{"_id":"source/HTML/2011/05/12/number-theory-poj-3358/index.html","hash":"7fb44db3ffb65ed728614dd429adc6c141c3c0bd","modified":1643724682035},{"_id":"source/HTML/2011/04/02/pointers-on-c-11-dynamical-memory/index.html","hash":"3908576594d237c6c804c1b8752446488abd9129","modified":1643724682025},{"_id":"source/HTML/2011/07/03/hdu-3074-bit-inver/index.html","hash":"f9f58fc223530af8f2b69f75c8f65ecfb5d8f17d","modified":1643724682038},{"_id":"source/HTML/2011/05/23/mon-monsterkill-xiangtan-by-klion26/index.html","hash":"9fd5ba0ed21ee57515033fba964f0990d9dc4d62","modified":1643724682037},{"_id":"source/HTML/2011/04/06/pointers-on-c-link-list/index.html","hash":"8d9bff69889c75f147862cc0a01d8cd43005803d","modified":1643724682025},{"_id":"source/HTML/2011/04/09/pointers-on-c-advanced-point/index.html","hash":"2f4367843a73a7bd90426a48ef7a09094397db9e","modified":1643724682028},{"_id":"source/HTML/2011/04/08/why-am-i-cancer/index.html","hash":"ce0296801768a68ba57cfb69a860e2298d61ae2b","modified":1643724682027},{"_id":"source/HTML/2011/04/07/usaco-5-2-2-electric-fences/index.html","hash":"ce65978cdce22f4dffa5d2c29660edec522a1376","modified":1643724682026},{"_id":"source/HTML/2011/04/10/usaco-5-3-4big-barn/index.html","hash":"8860de52be4ed4ea9b0765ab2d3bbdac5fa5362e","modified":1643724682028},{"_id":"source/HTML/2011/04/10/usaco-5-2-3-wisconsin-squares/index.html","hash":"e6095a0851aa63f8819f3b3154ebe1229c2bf651","modified":1643724682028},{"_id":"source/HTML/2011/04/18/poj-2480/index.html","hash":"4143146c12ad472ca5c32d1c178061f1e556d715","modified":1643724682031},{"_id":"source/HTML/2011/04/12/pointers-on-c-preprocessor/index.html","hash":"1e915680cefc0d37eb7fc9057f73f80640f3c361","modified":1643724682029},{"_id":"source/HTML/2011/04/15/eular-function-2/index.html","hash":"1c77fb3ed96cc13efd55da70f9fa5898fb274c88","modified":1643724682030},{"_id":"source/HTML/2011/04/20/math-education/index.html","hash":"c9ee2a68ccf1e2e110b841dcaac6df9a079fcf10","modified":1643724682032},{"_id":"source/HTML/2011/04/11/drab-queue-poj-2823/index.html","hash":"7f2834f5709489d837e70785b3dc8d81909a125c","modified":1643724682029},{"_id":"source/HTML/2011/04/19/eular-function-hdu-3307/index.html","hash":"85eadd67b4e3e79aa3dd45a864a293ab1fffccb4","modified":1643724682031},{"_id":"source/HTML/2011/04/23/5th-csu-acm-competition/index.html","hash":"c5f5f1dfafb7a0b2c88532cdc766e4a05924723e","modified":1643724682032},{"_id":"source/HTML/2011/08/03/csu-summer-training-team-1/index.html","hash":"a9146de61bc23003df5ed8803d90f9c5a913c8e0","modified":1643724682040},{"_id":"source/HTML/2011/11/27/fuzhou-a-hdu-4121/index.html","hash":"741a65ff9e2f723f6f73f15297eae911addf20e9","modified":1643724682041},{"_id":"source/HTML/2011/12/13/windows-mpi/index.html","hash":"1e17e6ae682e6bda42f3d29175152a13262ee133","modified":1643724682041},{"_id":"source/HTML/2012/03/26/replay-email/index.html","hash":"b62467076fd17850deceaf7ecbcc45b589c17f7f","modified":1643724682044},{"_id":"source/HTML/2011/08/20/reverse-poj-3761/index.html","hash":"eaa188dc8535815d7ce9bffa1a1d0f6ab832a747","modified":1643724682040},{"_id":"source/HTML/2011/12/22/fuck-csdn/index.html","hash":"85bf2255512e61dce31cc6b814a16bb1a06b9e50","modified":1643724682042},{"_id":"source/HTML/2012/03/29/game-theory-prove/index.html","hash":"359138454377c3be0c1b56514c52ca5b3c92fda5","modified":1643724682044},{"_id":"source/HTML/2011/06/22/xp-fedora-double-os/index.html","hash":"6201f0b3b333237c1bae23a2ddac8772eeec2fb6","modified":1643724682037},{"_id":"source/HTML/2012/03/29/github-create-project/index.html","hash":"0dfe30c40e5eb7844774431c3a2f23198c3aa98e","modified":1643724682045},{"_id":"source/HTML/2012/03/29/user-chrome-cross-gfw/index.html","hash":"4513b37b2fa4274bf23f3d26d416ff6e3789059e","modified":1643724682045},{"_id":"source/HTML/2012/03/02/e3-80-8a-e6-ad-a4-e7-94-9f-e6-9c-aa-e5-ae-8c-e6-88-90-e3-80-8b-e4-ba-8e-e5-a8-9f/index.html","hash":"9b9fb81db0fda767d55b5e78a4f2fa6e757edd76","modified":1643724682044},{"_id":"source/HTML/2012/04/19/vmware-ubuntu-fedora/index.html","hash":"8311e538ee43fc48dc8336f1e8aeea5c6331718b","modified":1643724682046},{"_id":"source/HTML/2011/08/29/usaco-5-4-5-5/index.html","hash":"769be6d46db0548217c05c07e4860129033f79aa","modified":1643724682041},{"_id":"source/HTML/2012/03/29/github-port-22-error-bad-file-number/index.html","hash":"e157551e80201ba43816db752149292b8652428f","modified":1643724682045},{"_id":"source/HTML/2011/04/30/primitive-root-poj-1284/index.html","hash":"3677d61cb738099c66dfb5b5b236b8121b0e7166","modified":1643724682033},{"_id":"source/HTML/2012/10/08/scheme-and-the-little-scheme/index.html","hash":"56664152df6cf144b1975769db42c2b981d15bfc","modified":1643724682047},{"_id":"source/HTML/2012/02/12/xp-office-2010-error-1406/index.html","hash":"309a061c7eb2f3112632e8bf7490d189503990b7","modified":1643724682043},{"_id":"source/HTML/2012/10/17/structure-and-interpretation-of-computer-programs-1-2/index.html","hash":"85984e0025114e68467f589991a06c8ffaa4d51b","modified":1643724682048},{"_id":"source/HTML/2012/02/12/2011-2012-plan/index.html","hash":"71634c372770d753da885f58a7bf60878ab33cd1","modified":1643724682042},{"_id":"source/HTML/2012/10/16/structure-and-interpretation-of-computer-programs-1-1/index.html","hash":"debdbac50dc17fd3c5b614f03bb21a00ecca4546","modified":1643724682048},{"_id":"source/HTML/2012/09/21/wordpress-fatal-error/index.html","hash":"2a442a68173b4fce7e336794c2ff3838c549681c","modified":1643724682046},{"_id":"source/HTML/2012/10/23/structure-and-interpretation-of-computer-programs-1-3/index.html","hash":"76ad45bbf89459b45a081ab691182a4f0a39e2fd","modified":1643724682049},{"_id":"source/HTML/2012/10/23/google-adsense/index.html","hash":"7f28cdd569711be433560f1e31463818286911d4","modified":1643724682048},{"_id":"source/HTML/2015/02/18/everything-about-2014/index.html","hash":"2f493ee0acf299b62fb842834a40b0b20ab74501","modified":1643724682071},{"_id":"source/HTML/2012/09/26/concrete-mathmatics-chapter-1/index.html","hash":"ff019f186e2020408b4af8aac5da3ce078a2b3ed","modified":1643724682046},{"_id":"source/HTML/2012/09/27/concrete-mathematics-chapter-1-homework-exercises/index.html","hash":"4ebd787ed4427933d25ba086df66812dc3ca969e","modified":1643724682047},{"_id":"source/HTML/2012/11/06/chrome-https-connection/index.html","hash":"8817e0e1990c6271d34c574b496746e1fdaf9e96","modified":1643724682049},{"_id":"source/HTML/2012/11/13/fedora-13-opengl/index.html","hash":"223fe001ae8c8eaad09243692c58f39797a1d3a1","modified":1643724682050},{"_id":"source/HTML/2012/11/21/apue-chapter-3-excise-3-2/index.html","hash":"e6dcd1b34818b59331bd5421e68807b8375e7cbc","modified":1643724682051},{"_id":"source/HTML/2012/12/03/first-linux-module-lvm/index.html","hash":"50363b09aab678ec614add1999e312fc028eccab","modified":1643724682052},{"_id":"source/HTML/2015/03/08/github-blog-math-expression-support/index.html","hash":"b3707a34d281f86d99634603ad6c86682022f539","modified":1643724682071},{"_id":"source/HTML/2012/12/12/fedora-13-texlive2012-install-chinese-configure/index.html","hash":"c779ecf5bb840156602d4e4a9b75f854270e798a","modified":1643724682053},{"_id":"source/HTML/2012/12/10/implicit-declaration-of-function-class-device-create/index.html","hash":"d1514c712d734a68cc4a21a7b262b54338d6c68f","modified":1643724682052},{"_id":"source/HTML/2012/12/28/vi-basic-command/index.html","hash":"c1fd2538f7ed5779741cca84cb53c47747de1080","modified":1643724682054},{"_id":"source/HTML/2012/12/27/too-many-levels-of-symbolic-links/index.html","hash":"d76f0134014c6008e0bf5627769a3808f9c196d9","modified":1643724682054},{"_id":"source/HTML/2012/11/15/advanced-programming-in-the-unix-environment-apue-h/index.html","hash":"eae4508b0e08848cc07061a2edf65136c047f367","modified":1643724682050},{"_id":"source/HTML/2012/11/05/display-views-count-without-plugin/index.html","hash":"170455239edd0b92cb00f015c71c534caa6f239f","modified":1643724682049},{"_id":"source/HTML/2015/07/16/a-brief-view-of-storm/index.html","hash":"18ad2ee494e1e375be7cf151bcf560e25b380597","modified":1643724682072},{"_id":"source/HTML/2015/07/17/experiment-of-storm-grouping/index.html","hash":"ceba78b47c4b939eaa92f10b2a60d863dff64927","modified":1643724682072},{"_id":"source/HTML/2012/12/26/fedora-13-update-to-fedora-15/index.html","hash":"959eb55f92a0557fadc1cf98d8077aa616a16943","modified":1643724682053},{"_id":"source/HTML/2012/11/08/vc-6-clistctr-add-image-and-cant-display/index.html","hash":"b0fc82a4eb3e6dabce657dd181d82f9b4579c767","modified":1643724682050},{"_id":"source/HTML/2013/06/21/linux-command-shell-scripts-3/index.html","hash":"cc02b67fe6b334d3cdb5a591f2c6a3ff6ddc1c2d","modified":1643724682057},{"_id":"source/HTML/2015/01/03/algorithm-series/index.html","hash":"ed92e0310f87d3c364dcd78c774400e6903920d5","modified":1643724682070},{"_id":"source/HTML/2013/03/26/some-easy-math-problems/index.html","hash":"bd52608dc88b955289ab0b83fcbb70f6a28ba3a9","modified":1643724682056},{"_id":"source/HTML/2015/01/17/recursion/index.html","hash":"dc0b244273f32538a38fcfab2c5b21a3f17bcad1","modified":1643724682071},{"_id":"source/HTML/2013/03/07/matlab-2012-libsvm/index.html","hash":"1ecbc0ff571a3ff77a0a2f173803cd0058537506","modified":1643724682055},{"_id":"source/HTML/2013/01/02/fedora-15-install-opencv-2-4/index.html","hash":"9dd9d42dddcd5cc12c3eabf6c3221957269072f8","modified":1643724682054},{"_id":"source/HTML/2013/01/21/github-pages-jekyll-blog-free/index.html","hash":"88b9e5845a51380275b92d7f946b3d6c648d0317","modified":1643724682055},{"_id":"source/HTML/2013/05/24/linux-command-shell-script/index.html","hash":"e4f74909181a7993d7a169db1bbf5bc91f13a7dc","modified":1643724682056},{"_id":"source/HTML/2013/01/03/fedora-15-yum-rpm-problem/index.html","hash":"9b581bf973ffb69fb6ef3876abf189df2f270d24","modified":1643724682055},{"_id":"source/HTML/2013/05/25/linux-command-shell-script-2/index.html","hash":"660de3bdba29ae879081204cbeb700fe6c0dd592","modified":1643724682057},{"_id":"source/HTML/2013/09/11/algorithms-chapter-5/index.html","hash":"c564bc5386b16a1d705a34a56050844c3a994a78","modified":1643724682059},{"_id":"source/HTML/2015/07/26/redis-pqsort-c/index.html","hash":"bba306f57d736b57d049aafa8ed46c2065888575","modified":1643724682073},{"_id":"source/HTML/2013/11/23/nonviolent-communication/index.html","hash":"d406c0c3172245f6a82cf5deee6ce166eae38dca","modified":1643724682060},{"_id":"source/HTML/2012/11/26/fedora-13-movie-mkv-mp4-rmvb-rm-song/index.html","hash":"82d36c8517042ef23e2d8332c1597e64d5fcb7a3","modified":1643724682051},{"_id":"source/HTML/2013/07/20/algorithms-chapter-3-homework-sol/index.html","hash":"9257cd557d24b0bcf7e9507aade7661b45550c14","modified":1643724682058},{"_id":"source/HTML/2013/11/28/use-vundle-to-manage-vim-plugin/index.html","hash":"6ead7918a944d417397e5868072fdf1fab346114","modified":1643724682060},{"_id":"source/HTML/2013/10/16/algorithms-chapter-6-dynamic-programming/index.html","hash":"c2bcf4368c7f66803db18f0bdca992b62589ce13","modified":1643724682059},{"_id":"source/HTML/2013/12/22/spiral-matrix/index.html","hash":"8e60f7d0cd3aa07bce75d7ccc2429f48f297c40f","modified":1643724682061},{"_id":"source/HTML/2013/07/28/algorithms-chapter-4-and-some-exercises/index.html","hash":"653cc7e6134f408d2bf6ef5b4baef2ff6a9a5213","modified":1643724682058},{"_id":"source/HTML/2015/01/05/dynamic-programming/index.html","hash":"5c2b33b12f3678d29b218f7dd9156aa0f4837382","modified":1643724682070},{"_id":"source/HTML/2013/12/20/level-order-of-a-tree/index.html","hash":"285fb2b9009dc7a3e669606966f6397a15a8f359","modified":1643724682061},{"_id":"source/HTML/2013/12/25/string-to-integer-atoi/index.html","hash":"22bb768145b16cfcb5d0aa8d3f53d68620955fa9","modified":1643724682062},{"_id":"source/HTML/2014/01/04/reverse-linked-list/index.html","hash":"83f47b7831e6bac426b97c0b5e702a34b9d8fe32","modified":1643724682062},{"_id":"source/HTML/2014/05/17/srm-620-randomgraph/index.html","hash":"8d270188239744e368be7712f76434b660733e99","modified":1643724682065},{"_id":"source/HTML/2014/05/02/linux-daemon/index.html","hash":"abc0023d724844942b9e18c817a9834c672d2180","modified":1643724682063},{"_id":"source/HTML/2014/07/08/select-and-poll/index.html","hash":"7a14b906892095d57df1a2bca4ebfa373c7b8ff4","modified":1643724682067},{"_id":"source/HTML/2014/05/09/linux-dbm/index.html","hash":"55ed02163c72f206e8f6c161da26d8f95829d1c0","modified":1643724682064},{"_id":"source/HTML/2014/05/27/using-gdb-to-debug-nginx/index.html","hash":"db9ef606df87803f8aa1f03cfac9d420b836815b","modified":1643724682065},{"_id":"source/HTML/2014/06/16/nginx-advancd-data-struct-1/index.html","hash":"b998856c1cd03791f9871e29a3fb67f0419ee31f","modified":1643724682066},{"_id":"source/HTML/2014/12/29/show-me-the-code/index.html","hash":"33839380a5fc0bfd350b37984d773fd03bca4e08","modified":1643724682069},{"_id":"source/HTML/2014/10/01/2014-code-interview/index.html","hash":"e96908acaf4524dc8212a525462d3692c1247f44","modified":1643724682068},{"_id":"source/HTML/2014/08/25/the-hardwaresoftware-interface-csapp-lab2-bomb/index.html","hash":"f8cd2064c6e5e8a86fab6eac020c68047f3a1763","modified":1643724682067},{"_id":"source/HTML/2014/11/02/least-recently-used-algorithm/index.html","hash":"96ef6699657a2ba1ad3c0ca82d31f731ab76061b","modified":1643724682068},{"_id":"source/HTML/2017/06/01/如何在不重启-Spark-Streaming-作业的情况下，增加消费的-topic/index.html","hash":"8daaf24f274afa5f0327662a71b2613b1fab1783","modified":1643724682086},{"_id":"source/HTML/2017/02/16/spark-streaming-consume-kafka-at-00-second-of-every-minute/index.html","hash":"d882f309c5f1a39ae7ca429a961f532ea8b8882a","modified":1643724682079},{"_id":"source/HTML/2014/01/07/binary-tree-traversal-without-recursive/index.html","hash":"ec31779b528ed09f506877e2bcf6adfa7383649f","modified":1643724682063},{"_id":"source/HTML/2017/01/15/spark-streaming-e5-be-80-hdfs-e8-bf-bd-e5-8a-a0-lzo-e6-96-87-e4-bb-b6/index.html","hash":"2d9da928131019bf15c6744f60bc02c07b0d8c33","modified":1643724682079},{"_id":"source/HTML/2017/06/20/风险不仅仅是事件发生的概率/index.html","hash":"f4f7fec1b22bccabe1bd7a79bb6352f3e489b922","modified":1643724682088},{"_id":"source/HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/executor.jpg","hash":"7699406d15851ad17f951a1f7660d4deb92c36c5","modified":1643724682086},{"_id":"source/HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/index.html","hash":"aff0e9812ba29b116f0f96926f0e33a3836f3859","modified":1643724682088},{"_id":"source/HTML/2017/04/15/从现在开始写作/index.html","hash":"87050076f545bf2bbb92e5671c77cf5acb5d7df8","modified":1643724682080},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/heap.png","hash":"0c1fef5a8029ad0b014accabb99643d379fe9728","modified":1643724682102},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/bitmap.jpeg","hash":"803ccaa5a84e2038a71c241c8f0c20cec8fc92b8","modified":1643724682102},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/bibop.jpeg","hash":"93df46d81b75a432d96f265ea284f7ebe6b618bd","modified":1643724682101},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/lazy-sweep.png","hash":"619be4d8137910edeb88a0b15244bb6b98cf149d","modified":1643724682103},{"_id":"source/HTML/2014/02/28/how-to-think-like-a-computer-scientist/index.html","hash":"b8933906174963a6adcf1bc2f8dcd6780028647c","modified":1643724682063},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/multilink.jpeg","hash":"80a4c4addd3d2a14b5b3962b3ddf8bbff05ba94a","modified":1643724682104},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/index.html","hash":"0139042152839a6f409b95cc265f43458ef5b085","modified":1643724682102},{"_id":"source/HTML/2017/07/14/tmux-简单使用指南/index.html","hash":"d8549ae2fa5ff6b5b5158f9aacc76e7cf52f6ef9","modified":1643724682088},{"_id":"source/HTML/2017/11/09/django-configuration-in-action/index.html","hash":"8b251415b5c8b8baffe7dbb2d559f6250b404493","modified":1643724682111},{"_id":"source/HTML/2017/11/20/git-inside/index.html","hash":"6b66a98b48161b57054a387c0f08ddc62ca80482","modified":1643724682125},{"_id":"source/HTML/2017/11/20/git-inside/second_version.png","hash":"e59d7a09b90276cf2b4e5549d536e6eb4baec1e3","modified":1643724682125},{"_id":"source/HTML/2017/11/20/git-inside/third_version.png","hash":"9709165c96e8819d43a4883c6e298a3bb0880b2b","modified":1643724682126},{"_id":"source/HTML/2017/11/27/TaskScheduler/index.html","hash":"8e038fa63a5d4b94e100333bf8725d5c20707246","modified":1643724682126},{"_id":"source/HTML/2017/11/20/git-inside/project.png","hash":"5d67e33edc164fba66bad512494a9150a5f30a43","modified":1643724682125},{"_id":"source/HTML/2017/11/20/git-inside/first_version.png","hash":"54e8ea80ea1cb233d004ac59187bef668760a5a5","modified":1643724682124},{"_id":"source/HTML/2017/10/16/spark-dagscheduler/index.html","hash":"a0af3351a38a4b7d5c56335a70b46a5f96f849a0","modified":1643724682104},{"_id":"source/HTML/2017/05/10/Python-代码实践小结/index.html","hash":"2401c3b0b3d81a6cfa7f6f32c5f3e09808e9e10f","modified":1643724682080},{"_id":"source/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/index.html","hash":"417ed4955c04a665047a8c1d4a047c2e319ffb7d","modified":1643724682085},{"_id":"source/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver_sample.png","hash":"1854eb10195cf3c7d8bee5af081cf6c366c0d081","modified":1643724682085},{"_id":"source/HTML/2017/05/29/从源码级别分析-metric-core-的抽样算法/index.html","hash":"ae0679f95981e1d47528d18577fceeace85a6789","modified":1643724682086},{"_id":"source/HTML/2017/12/03/tasksetmanager/index.html","hash":"6cb3f510289f2ba55cbafebf54a991d3c184b761","modified":1643724682126},{"_id":"source/HTML/2018/01/06/线程堆栈分析/dead_lock.png","hash":"1907d024bd977bd2cdcd4fd7087a570f85cd03f1","modified":1643724682133},{"_id":"source/HTML/2014/09/26/epoll-and-select/index.html","hash":"5780e77e5115af9153c6c9e853b8c16e2ba53d99","modified":1643724682068},{"_id":"source/HTML/2017/12/22/millwheel/index.html","hash":"465f898abc9391335f0077756166b6b5fdc38c02","modified":1643724682132},{"_id":"source/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image3.png","hash":"64d49ecfd0dfa44aa5e190d1a1ba95cefa05a4bf","modified":1643724682136},{"_id":"source/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image2.png","hash":"1b6baef088696107131a6d42f7e276a6e7f31b54","modified":1643724682135},{"_id":"source/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/index.html","hash":"542074b5807114f4b5826beb68959eb739fdc307","modified":1643724682136},{"_id":"source/HTML/2014/06/20/nginx-http-filter-module/index.html","hash":"c711dde8d5e3be8ec04d31067b5e7c6ec76d10ad","modified":1643724682066},{"_id":"source/HTML/2012/11/27/why-can-not-use-weixin-miliao/index.html","hash":"692e03184900637b7403d0c5971fb16623f96507","modified":1643724682052},{"_id":"source/HTML/2016/03/30/mit-6-824-lab-2-part-a/index.html","hash":"ca3ca02c20f8241a56ce39e201b0cfe3be05a05e","modified":1643724682074},{"_id":"source/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image1.png","hash":"28bd4bf7dc6e99e099e3ab4a2f7d52c496ccee2e","modified":1643724682135},{"_id":"source/HTML/2017/05/20/hello-world/index.html","hash":"145a865036933138f693a8cdfb9f33b13b335227","modified":1643724682085},{"_id":"source/HTML/2016/03/23/mit-6-824-2015-lab-1/index.html","hash":"82d39cc63cd0c81393792642c85ac32a3d6f8fa3","modified":1643724682073},{"_id":"source/HTML/2016/05/03/e6-88-91-e5-bf-83-e7-9b-ae-e4-b8-ad-e7-9a-84-e8-80-81-e5-b8-88/index.html","hash":"39e325676157faa1b7e3ec20d904269061e91563","modified":1643724682074},{"_id":"source/HTML/2018/09/09/一次-InputStream-read-使用不当导致的问题/index.html","hash":"d767079446a5a30613f66ac1675fed2efb49ec25","modified":1643724682143},{"_id":"source/HTML/2016/07/14/spark-streaming-save-offset-to-zookeeper/index.html","hash":"e49d498bcee312ae53d3d169fb74ded91cbe40ae","modified":1643724682075},{"_id":"source/HTML/2016/07/15/spark-streaming-saving-offset-in-zookeeper-2/index.html","hash":"bdea1f44fa837be7018ce252df06f7e2deee7d62","modified":1643724682075},{"_id":"source/HTML/2016/08/27/spark-streaming-kafka-read-binlog-to-json/index.html","hash":"95986ac60590773d6f13c7c52d51b1f661f6b8c3","modified":1643724682076},{"_id":"source/HTML/2016/10/26/e8-a6-81-e5-a4-9a-e5-bf-ab-e6-89-8d-e8-83-bd-e8-b7-91-e5-ae-8c-e4-b8-80-e5-9c-ba-e9-a9-ac-e6-8b-89-e6-9d-be/index.html","hash":"d434e15f34b66346cd8103aba9d995b06b1138d0","modified":1643724682077},{"_id":"source/HTML/2016/10/22/storm-e7-9a-84-e5-8f-af-e9-9d-a0-e6-80-a7-e4-bf-9d-e8-af-81-e6-b5-8b-e8-af-95/index.html","hash":"01defd7cefffce8fdb83c051a7e04b2b36aac52d","modified":1643724682076},{"_id":"source/HTML/2016/09/26/e4-b8-80-e7-a7-8d-e5-8f-af-e8-a1-8c-e7-9a-84-e8-8b-b1-e8-af-ad-e9-98-85-e8-af-bb-e5-ad-a6-e4-b9-a0-e6-96-b9-e6-b3-95/index.html","hash":"7b43c9caf380a235e3e5cdac32b2fc80ee7408da","modified":1643724682076},{"_id":"source/HTML/2016/01/20/how-to-read-a-book/index.html","hash":"81753186b230d3ff472bdace328e8d00216cb942","modified":1643724682073},{"_id":"source/HTML/2016/06/11/asking-the-right-questions/index.html","hash":"0e6c9eb110ffb864faba87efb79df9d073278ff0","modified":1643724682074},{"_id":"source/HTML/2016/11/26/spark-streaming-e5-be-80-hdfs-e5-86-99-e6-96-87-e4-bb-b6-ef-bc-8c-e8-87-aa-e5-ae-9a-e4-b9-89-e6-96-87-e4-bb-b6-e5-90-8d/index.html","hash":"c695ff41752a3b2d3fd5ffcfda5badfd1e068947","modified":1643724682078},{"_id":"source/HTML/2016/11/01/spark-streaming-topic-partition-change-auto-adaptive/index.html","hash":"a25ebfb11f7eb8afdedbb23d518bbd680747a0c9","modified":1643724682077},{"_id":"source/HTML/2018/04/06/Flink-State/index.html","hash":"b8572bef962a1ca47403498c2ec6e006c23a5075","modified":1643724682138},{"_id":"source/HTML/2016/12/02/spark-streaming-consume-kafka-message-from-specify-timestamp/index.html","hash":"517f6d0ca1bc55b7055756a884089c4738eeaae5","modified":1643724682078},{"_id":"source/HTML/2020/05/20/RocksDB-Single-CF-Result/list_state_result.html","hash":"1bcc9daeeb35f814bd11bd85b928d40121dccec2","modified":1643724682144},{"_id":"source/HTML/2020/05/20/RocksDB-Single-CF-Result/map_state_result.html","hash":"9cd11ba354c60652df9db5e8ed5286b423403ea0","modified":1643724682144},{"_id":"source/HTML/2020/05/20/RocksDB-Single-CF-Result/value_state_result.html","hash":"e7aa6ff7dc089ca8dad134e8ac2eebbdbb79ab46","modified":1643724682144},{"_id":"source/HTML/2016/12/16/spark-streaming-ran-out-of-messages-before-reaching-ending-offset/index.html","hash":"703c859e1cfd53f019ea18d4d3f6231a7226b09c","modified":1643724682078},{"_id":"source/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image1.png","hash":"3f226ad5ca9b70a361a8bca470a3c004a0d1df52","modified":1643724682137},{"_id":"source/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/index.html","hash":"f7af32b296824e12591be667d703c9ed1a1a2131","modified":1643724682138},{"_id":"source/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image2.png","hash":"e472be0e0f5bd1b3277fa70e36237f5dd08125ce","modified":1643724682137},{"_id":"source/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image3.png","hash":"2d64e51ba17035c65a910b37307ddb86b24715ad","modified":1643724682137},{"_id":"source/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image4.png","hash":"acb23a5745277e2ce339293d305b344c1b8341f4","modified":1643724682137},{"_id":"source/HTML/2011/03/27/usaco-5-1-2-starry-night/index.html","hash":"4eb8b29c028144121b843ba6f0bf4ef58ad8cab1","modified":1643724682021},{"_id":"source/HTML/2017/10/16/spark-dagscheduler/stage.jpg","hash":"4367aad746772f13fcd5deea7e5d447227ec733f","modified":1643724682110},{"_id":"source/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver_ReceiverSupervisor.png","hash":"976cca190ae3cb79be8723d653b16827cd14b079","modified":1643724682084},{"_id":"source/HTML/2018/01/06/线程堆栈分析/index.html","hash":"0fd08b6223e764cd3e473a258587b21761c3c2a0","modified":1643724682133},{"_id":"source/HTML/2017/12/22/millwheel/figure14_latency_scalability.jpg","hash":"6e8f4af4b02a6ad9237f8351b6b112db17fb4ae3","modified":1643724682130},{"_id":"source/HTML/2017/12/22/millwheel/figure13_latency.jpg","hash":"e342fda0902b5f6f1078834d0e24f8edc83ba6e7","modified":1643724682129},{"_id":"source/HTML/2017/12/22/millwheel/figure16_cache.jpg","hash":"00dd49d86f87be1213470c27b2ccec755c3bc824","modified":1643724682131},{"_id":"source/HTML/2017/12/22/millwheel/figure15_lowwatermark.jpg","hash":"85afa904c53280fa8b872da8425d517c5985203c","modified":1643724682131},{"_id":"source/HTML/2018/04/06/Flink-State/state-hierarchy.png","hash":"03bafd829b1f6e57121911ad584a0e12407593ae","modified":1643724682139},{"_id":"source/HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/hang_job.jpg","hash":"ab3352884e349d7418c3ad3a5492526adf21eec5","modified":1643724682087},{"_id":"source/HTML/2017/12/22/millwheel/figure11_checkpoint.jpg","hash":"cb2a883863b50fc6daa50edddfccdd4233a758d0","modified":1643724682128},{"_id":"source/HTML/2017/12/22/millwheel/figure12_transaction.jpg","hash":"70a5993db631cfaec318db3736ac22aae312b434","modified":1643724682129},{"_id":"source/HTML/2017/07/14/tmux-简单使用指南/tmux_pic.png","hash":"a2db1790b8cde62c95d1842364764743a4fe4fea","modified":1643724682090},{"_id":"source/HTML/2018/01/06/线程堆栈分析/wait_sleep.png","hash":"9a1ddf0166cd279ff294d08436c5cd0be9c89dd6","modified":1643724682134},{"_id":"source/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver.png","hash":"f77ee44c9974e019b0682db58ddb8bc3292a6f71","modified":1643724682083},{"_id":"source/HTML/2017/10/16/spark-dagscheduler/procesure.jpg","hash":"3a9919b0782b34a3814109f78d01c2a1d90d7322","modified":1643724682108},{"_id":"source/HTML/2018/04/06/Flink-State/state-rescale.png","hash":"82c7ba867236708d14bd489ecafd20b57e39b392","modified":1643724682143},{"_id":"source/HTML/2017/09/17/GC-标记-清除算法/BFS_DFS.jpeg","hash":"8a0149f4a702fc3cd3beb85019a2668a4aa7ac1d","modified":1643724682099},{"_id":"source/HTML/2017/11/20/git-inside/file_tree.png","hash":"5febfd253e17c6678e82659af7546d77ef7b0a82","modified":1643724682122},{"_id":"public/search.xml","hash":"1d87aaf4b95f61600e5e4312d35484dc46de0d64","modified":1768631830024},{"_id":"public/2022/04/16/big-data-paper-big-picture/index.html","hash":"e454693d36aa3d70a6c17bcfb6b741cd3ccd6d1c","modified":1735806225965},{"_id":"public/archives/index.html","hash":"17d6b334439983f3f87537eea185f8f7070874d2","modified":1768631830024},{"_id":"public/archives/2022/index.html","hash":"3859378943f10360652f78cecdf2bd3b13f996d0","modified":1735806330138},{"_id":"public/archives/2022/04/index.html","hash":"9d72852094c96fa2e86a2be23c5bc0324f839852","modified":1735806330138},{"_id":"public/archives/2023/index.html","hash":"24cd42ff56bdd5137507ac808d7e823d1293ef0c","modified":1768631830024},{"_id":"public/archives/2023/04/index.html","hash":"c8b6e4bef5e69de58ad0bbe8f8672e6774dc4e8d","modified":1768631830024},{"_id":"public/index.html","hash":"4f8c6338696b3aec78b533e015009f2e165129c6","modified":1768631830024},{"_id":"public/tags/大数据-全局认识-偏见-论文-系统/index.html","hash":"538ffa2b12e3026efb8fa750341daa42379ed76f","modified":1735806330138},{"_id":"public/tags/lsm/index.html","hash":"1c13eb003a7b802a6a6461ef3af7014b3e092cea","modified":1768631830024},{"_id":"public/tags/lsm-tree/index.html","hash":"9e7123fb4b238538d6de7cc4938b4c9c4d4973ca","modified":1768631830024},{"_id":"public/tags/minimum-global-awareness/index.html","hash":"85a3a0d21d6afc54b96b6c57b1ac28dca51ab5ee","modified":1768631830024},{"_id":"public/tags/paper/index.html","hash":"3e982112342b2726c356ba3d4dd634c910508b58","modified":1768631830024},{"_id":"public/2023/04/24/lsm-tree-1-2023-05-17/index.html","hash":"58c28e691326609698e33c34fc9146014442287e","modified":1768627145718},{"_id":"public/fonts/fontawesome-webfont.eot","hash":"0183979056f0b87616cd99d5c54a48f3b771eee6","modified":1684381410492},{"_id":"public/fonts/fontawesome-webfont.woff","hash":"7d65e0227d0d7cdc1718119cd2a7dce0638f151c","modified":1684381410492},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1684381410492},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1684381410492},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1684381410492},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1684381410492},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1684381410492},{"_id":"public/img/github-sprite.png","hash":"4d7ee33beaaebf002ba57a172d159e46194ae481","modified":1684381410492},{"_id":"public/img/glyphicons-halflings-white.png","hash":"a25c4705320fd63c33790e666872910e702b9bf6","modified":1684381410492},{"_id":"public/img/glyphicons-halflings.png","hash":"84f613631b07d4fe22acbab50e551c0fe04bd78b","modified":1684381410492},{"_id":"public/img/grid-18px-masked.png","hash":"1379b689836f9fcccd88aa729c4034d6b36e1f3c","modified":1684381410492},{"_id":"public/img/grid-baseline-20px.png","hash":"43b8d0c9b39f5ce07ecfde036fd13f835c129238","modified":1684381410492},{"_id":"public/fonts/google-fonts/0AKsP294HTD-nvJgucYTaIbN6UDyHWBl620a-IRfuBk.woff","hash":"1d9bb14c006d39d7eb0812a85567c7431f899b8d","modified":1684381410492},{"_id":"public/fonts/google-fonts/0XxGQsSc1g4rdRdjJKZrNBsxEYwM7FgeyaSgU71cLG0.woff","hash":"33225e85c33279e7b4f0c5c65ff93bec740dd59c","modified":1684381410492},{"_id":"public/fonts/google-fonts/LKf8nhXsWg5ybwEGXk8UBQ.woff","hash":"f401d51152681048c06187c5d3919b1407b899c5","modified":1684381410492},{"_id":"public/fonts/google-fonts/PIPMHY90P7jtyjpXuZ2cLD8E0i7KZn-EPnyo3HZu7kw.woff","hash":"18dc51e642b4df958098d3bbc6d3ba0237ef6150","modified":1684381410492},{"_id":"public/fonts/google-fonts/UyYrYy3ltEffJV9QueSi4RdbPw3QSf9R-kE0EsQUn2A.woff","hash":"d9f913d09bb3c25749daf8e7ab829c850a842929","modified":1684381410492},{"_id":"public/fonts/google-fonts/cj2hUnSRBhwmSPr9kS5899kZXW4sYc4BjuAIFc1SXII.woff","hash":"17a484b92c0dacc8e8b4f0d38ccc1db400819d1d","modified":1684381410492},{"_id":"public/fonts/google-fonts/lILlYDvubYemzYzN7GbLkHhCUOGz7vYGh680lGh-uXM.woff","hash":"e6c9f1e5a6a966a8f7250201356f351890a48921","modified":1684381410492},{"_id":"public/HTML/2010/12/12/usaco-4-1-4-cryptcowgraphy/index.html","hash":"a0b458ff43182267b6a0bb6d85d03ffa142b8f78","modified":1684381410492},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1684381410492},{"_id":"public/HTML/2010/12/09/hello-world-1/index.html","hash":"b7f672733e1544662e607889962dc7e2ff1dece4","modified":1684381410492},{"_id":"public/HTML/2010/12/15/xampp-apache-cant-work-80-port/index.html","hash":"d00f26d86a9ed0f18217896e5ed67a877836d8ab","modified":1684381410492},{"_id":"public/HTML/2010/12/15/vmware-redhat9-cant-mount/index.html","hash":"0ebfa804c365dc70ea2e37a323fbc48e2963857d","modified":1684381410492},{"_id":"public/HTML/2010/12/14/red-hat9-command-messy-code/index.html","hash":"b8511a068efe0a825516424a6a807f518834fa50","modified":1684381410492},{"_id":"public/fonts/google-fonts/2UX7WLTfW3W8TclTUvlFyQ.woff","hash":"87deb174af2e2beebb9f09d618a5159ca299a3d0","modified":1684381410492},{"_id":"public/HTML/2010/12/16/wordpress-link-order/index.html","hash":"4112ccf19e134969ef45dd6f982933f36bb8f093","modified":1684381410492},{"_id":"public/HTML/2010/12/22/linux-shell-problem/index.html","hash":"4e01c5a3d4746a7e9f8cdeeb4d8a70009c62aeec","modified":1684381410492},{"_id":"public/HTML/2010/12/30/linux-fork-test/index.html","hash":"d70a5871ad8b47faf6a41be054559ed2099699d8","modified":1684381410492},{"_id":"public/HTML/2010/12/31/linux-fork-2/index.html","hash":"9ddcf3b5ef334232628a464c054176ca39a325c5","modified":1684381410492},{"_id":"public/HTML/2010/12/14/linux-rename/index.html","hash":"9d612e51ee296c6ce0e9baaa750f72c49f99470d","modified":1684381410492},{"_id":"public/HTML/2010/12/23/linux-single-user-config/index.html","hash":"41a1c7ca16e86feba1e6bdc0cfc64e5a47668a44","modified":1684381410492},{"_id":"public/HTML/2010/12/23/linux-grub-encrypt/index.html","hash":"4f414c75abba66766dfb58c1ba0f655d25dfc668","modified":1684381410492},{"_id":"public/HTML/2010/12/30/wordpress-clickchar-plugin/index.html","hash":"f29d93933c20f5cbecbc332ed620e24481940de3","modified":1684381410492},{"_id":"public/HTML/2011/02/10/usaco-4-1-2-fence-rails/index.html","hash":"8792c869577319964af72d1e12680887faf5d65f","modified":1684381410492},{"_id":"public/HTML/2011/02/11/usaco-4-2-2-the-perfect-stall-dinic/index.html","hash":"103e1306fe629a15de363c25db4194d1c8aa0e61","modified":1684381410492},{"_id":"public/HTML/2011/02/10/networkflow-1-maximum-matching/index.html","hash":"bcdb2deb83feb707c0125e6c7430e5fab733cf25","modified":1684381410492},{"_id":"public/HTML/2011/02/10/usaco-4-2-1-drainage-ditches/index.html","hash":"c7671d8d7bb5d368a426bd4dbb9d77bff2659754","modified":1684381410492},{"_id":"public/HTML/2011/02/21/usaco-4-2-4-cowcycle/index.html","hash":"9cbf3bd17f36d430e18187c241aae6377ad0da39","modified":1684381410492},{"_id":"public/HTML/2011/02/26/usaco-4-3-1-buy-low-buy-lower/index.html","hash":"a6870b51f201fc9cc1f460a5f36bd87c3b96c13c","modified":1684381410492},{"_id":"public/HTML/2011/02/12/usaco-4-2-3-job-processing/index.html","hash":"367c0d2ebaaa6e7a348b3862e34358eba6490f68","modified":1684381410492},{"_id":"public/HTML/2011/03/06/usaco-4-3-2-the-primes/index.html","hash":"0bfc284b03ed350bb4227fe04396a5bd44a3cb1c","modified":1684381410492},{"_id":"public/HTML/2011/03/14/usaco-4-3-4-letter-game/index.html","hash":"c9c0874db9d75d18fea253724226f928cee1b29f","modified":1684381410492},{"_id":"public/HTML/2011/03/07/usaco-4-3-3-street-race/index.html","hash":"bf00799ad8ac89113d39464e8bf08dd6299f920e","modified":1684381410492},{"_id":"public/HTML/2011/02/27/networkflow-sap/index.html","hash":"72f316e2e41aaaa4fe89bb4dd98d4317d8cfae6d","modified":1684381410492},{"_id":"public/HTML/2011/03/03/networkflow-24-2-minimum-cut/index.html","hash":"42f2bcc74e794aa3757c92ca9c29ab8b9da8f5a9","modified":1684381410492},{"_id":"public/HTML/2011/03/17/poj-1704-game/index.html","hash":"fddc4e2410614c3a7078395254ace1797cf5fc3a","modified":1684381410492},{"_id":"public/HTML/2011/03/18/usaco-4-4-1-shuttle-puzzle/index.html","hash":"036e41c9402c101a928cb8b8ca958dd1bf82c8c9","modified":1684381410492},{"_id":"public/HTML/2011/03/22/c-cow-problem/index.html","hash":"9b6583d3037c8507c697d948de624b4ff1a2411f","modified":1684381410492},{"_id":"public/HTML/2011/03/22/usaco-4-4-3-frame-up/index.html","hash":"e3452f98ef670c2ed7444846a103a4c301eb60df","modified":1684381410492},{"_id":"public/HTML/2011/03/18/another-ux-strong-password/index.html","hash":"ce2d0804d9df70cce8a61d12d1306a8428dc10b4","modified":1684381410492},{"_id":"public/HTML/2011/03/15/hdu-1730-game/index.html","hash":"86d41ced94481000ffc8df4a012af2efe4e6f81a","modified":1684381410492},{"_id":"public/HTML/2011/03/19/networkflow-5-round-table/index.html","hash":"ea36968262bacdeb21939f52b2d38277f804753f","modified":1684381410492},{"_id":"public/HTML/2011/03/16/usaco-4-4-2-pollutant-control/index.html","hash":"6ca3126283b597c9d5148ad698015cc407df8996","modified":1684381410492},{"_id":"public/HTML/2011/03/28/usaco-5-1-3-musical-themes/index.html","hash":"36c1fdb176ea126f01d21a9e1c53b375136e2869","modified":1684381410492},{"_id":"public/HTML/2011/03/24/hdu-3389/index.html","hash":"1337e0432e89c41b226dde340a01e0ca699ba4e8","modified":1684381410492},{"_id":"public/HTML/2011/03/29/pointers-on-c-8-array/index.html","hash":"d349f5f698b296af66067118a0705d4544f0548b","modified":1684381410492},{"_id":"public/HTML/2011/03/29/segment-tree-my-templete/index.html","hash":"355b3a7fa94eec5e5f478280f43fa8b6e3bc91e3","modified":1684381410492},{"_id":"public/HTML/2011/03/30/pointers-on-c-10-struct-union/index.html","hash":"524c4c732ec73544fd340fae7ee53a9b6d77b239","modified":1684381410492},{"_id":"public/HTML/2011/03/19/networkflow-24-3-minimum-path-cover/index.html","hash":"2949947bc26404766155bbaeacc5ef4dbe237632","modified":1684381410492},{"_id":"public/HTML/2011/03/30/c-string-point-two-dimension/index.html","hash":"58708fcb8ffba3acaa38b9c882cbf959bb7b598d","modified":1684381410492},{"_id":"public/HTML/2011/03/30/pointers-on-c-9-string/index.html","hash":"424b0332899bd8e3c356f7cf5964b0fd6cdc1211","modified":1684381410492},{"_id":"public/HTML/2011/03/25/usaco-5-1-1-fencing-the-cows/index.html","hash":"82579e26e984e553bb0f2adb471823c6bfebb75f","modified":1684381410492},{"_id":"public/HTML/2011/05/04/permalink-change/index.html","hash":"69b1c5b855b539e77084fc25a41dd73873f4ed2a","modified":1684381410492},{"_id":"public/HTML/2011/03/31/poj-2478-eular-function/index.html","hash":"fa99d98b10fd1e5db61489036eed11294b79b29d","modified":1684381410492},{"_id":"public/HTML/2011/03/30/usaco-5-2-1-snail-trails/index.html","hash":"5ab2c014286103dd584f13a3f550faa9799b5cb6","modified":1684381410492},{"_id":"public/HTML/2011/05/02/ball-union-zoj-3350/index.html","hash":"8cbb82a3be70cc60a24e129b740a2012560b6d08","modified":1684381410492},{"_id":"public/HTML/2011/05/05/computational-geometry-hdu-2857/index.html","hash":"d1d7cbee12bc15dca86d0aa89774670aeb4a46e7","modified":1684381410492},{"_id":"public/HTML/2011/03/25/undefined-reference-to-sqrt-c/index.html","hash":"addd4a410964b3e69498495ed082ade0a430c8f6","modified":1684381410492},{"_id":"public/HTML/2011/05/12/recent-life/index.html","hash":"883c2a340ed6bb52561b4e83725370b3958c9bfa","modified":1684381410492},{"_id":"public/HTML/2011/05/08/gcj-2011-klion26/index.html","hash":"ad887c11e2a3ed3d61d47ef1b98604658ddede50","modified":1684381410492},{"_id":"public/HTML/2011/05/16/sg-function-hdu-2873/index.html","hash":"cb57dc1f27fad14dd8acb0c0b80e7bd5731f55e5","modified":1684381410492},{"_id":"public/HTML/2011/05/13/factor-num-hdu-1299/index.html","hash":"b9113a538cee1221fe008d3096fdf96ff31cbbad","modified":1684381410492},{"_id":"public/HTML/2011/07/09/fedora13-h3c/index.html","hash":"59a8264b0c5cedc1e9bf67fb63015dc489dbb82d","modified":1684381410492},{"_id":"public/HTML/2011/05/30/south-central-china-invite-competition-by-klion26/index.html","hash":"18d3f7f49503c036f21edf5dd3c0fa81ff327f9e","modified":1684381410492},{"_id":"public/HTML/2011/07/19/cg-hdu-3834/index.html","hash":"39d047e463509a230b67c0edd776580fc5db4824","modified":1684381410492},{"_id":"public/HTML/2011/05/18/number-theory-hdu-2879/index.html","hash":"ef7ec4bd95b42f7ee4ec9e7bde96e1710c972d1a","modified":1684381410492},{"_id":"public/HTML/2011/05/12/number-theory-poj-3358/index.html","hash":"7fb44db3ffb65ed728614dd429adc6c141c3c0bd","modified":1684381410492},{"_id":"public/HTML/2011/07/03/hdu-3074-bit-inver/index.html","hash":"f9f58fc223530af8f2b69f75c8f65ecfb5d8f17d","modified":1684381410492},{"_id":"public/HTML/2011/04/06/pointers-on-c-link-list/index.html","hash":"8d9bff69889c75f147862cc0a01d8cd43005803d","modified":1684381410492},{"_id":"public/HTML/2011/07/25/half-plan-cross/index.html","hash":"fe71d156e99bc3c25b2cadf11c1cf658cd63f0bd","modified":1684381410492},{"_id":"public/HTML/2011/05/23/mon-monsterkill-xiangtan-by-klion26/index.html","hash":"9fd5ba0ed21ee57515033fba964f0990d9dc4d62","modified":1684381410492},{"_id":"public/HTML/2011/04/02/pointers-on-c-11-dynamical-memory/index.html","hash":"3908576594d237c6c804c1b8752446488abd9129","modified":1684381410492},{"_id":"public/HTML/2011/04/07/usaco-5-2-2-electric-fences/index.html","hash":"ce65978cdce22f4dffa5d2c29660edec522a1376","modified":1684381410492},{"_id":"public/HTML/2011/04/09/pointers-on-c-advanced-point/index.html","hash":"2f4367843a73a7bd90426a48ef7a09094397db9e","modified":1684381410492},{"_id":"public/HTML/2011/04/10/usaco-5-2-3-wisconsin-squares/index.html","hash":"e6095a0851aa63f8819f3b3154ebe1229c2bf651","modified":1684381410492},{"_id":"public/HTML/2011/04/08/why-am-i-cancer/index.html","hash":"ce0296801768a68ba57cfb69a860e2298d61ae2b","modified":1684381410492},{"_id":"public/HTML/2011/04/10/usaco-5-3-4big-barn/index.html","hash":"8860de52be4ed4ea9b0765ab2d3bbdac5fa5362e","modified":1684381410492},{"_id":"public/HTML/2011/04/12/pointers-on-c-preprocessor/index.html","hash":"1e915680cefc0d37eb7fc9057f73f80640f3c361","modified":1684381410492},{"_id":"public/HTML/2011/04/18/poj-2480/index.html","hash":"4143146c12ad472ca5c32d1c178061f1e556d715","modified":1684381410492},{"_id":"public/HTML/2011/04/15/eular-function-2/index.html","hash":"1c77fb3ed96cc13efd55da70f9fa5898fb274c88","modified":1684381410492},{"_id":"public/HTML/2011/04/11/drab-queue-poj-2823/index.html","hash":"7f2834f5709489d837e70785b3dc8d81909a125c","modified":1684381410492},{"_id":"public/HTML/2011/04/19/eular-function-hdu-3307/index.html","hash":"85eadd67b4e3e79aa3dd45a864a293ab1fffccb4","modified":1684381410492},{"_id":"public/HTML/2011/04/20/math-education/index.html","hash":"c9ee2a68ccf1e2e110b841dcaac6df9a079fcf10","modified":1684381410492},{"_id":"public/HTML/2011/08/03/csu-summer-training-team-1/index.html","hash":"a9146de61bc23003df5ed8803d90f9c5a913c8e0","modified":1684381410492},{"_id":"public/HTML/2011/08/20/reverse-poj-3761/index.html","hash":"eaa188dc8535815d7ce9bffa1a1d0f6ab832a747","modified":1684381410492},{"_id":"public/HTML/2011/04/23/5th-csu-acm-competition/index.html","hash":"c5f5f1dfafb7a0b2c88532cdc766e4a05924723e","modified":1684381410492},{"_id":"public/HTML/2011/08/29/usaco-5-4-5-5/index.html","hash":"769be6d46db0548217c05c07e4860129033f79aa","modified":1684381410492},{"_id":"public/HTML/2011/11/27/fuzhou-a-hdu-4121/index.html","hash":"741a65ff9e2f723f6f73f15297eae911addf20e9","modified":1684381410492},{"_id":"public/HTML/2011/12/13/windows-mpi/index.html","hash":"1e17e6ae682e6bda42f3d29175152a13262ee133","modified":1684381410492},{"_id":"public/HTML/2012/03/26/replay-email/index.html","hash":"b62467076fd17850deceaf7ecbcc45b589c17f7f","modified":1684381410492},{"_id":"public/HTML/2011/06/22/xp-fedora-double-os/index.html","hash":"6201f0b3b333237c1bae23a2ddac8772eeec2fb6","modified":1684381410492},{"_id":"public/HTML/2011/12/22/fuck-csdn/index.html","hash":"85bf2255512e61dce31cc6b814a16bb1a06b9e50","modified":1684381410492},{"_id":"public/HTML/2012/03/29/github-create-project/index.html","hash":"0dfe30c40e5eb7844774431c3a2f23198c3aa98e","modified":1684381410492},{"_id":"public/HTML/2012/03/29/game-theory-prove/index.html","hash":"359138454377c3be0c1b56514c52ca5b3c92fda5","modified":1684381410492},{"_id":"public/HTML/2012/03/29/user-chrome-cross-gfw/index.html","hash":"4513b37b2fa4274bf23f3d26d416ff6e3789059e","modified":1684381410492},{"_id":"public/HTML/2012/03/29/github-port-22-error-bad-file-number/index.html","hash":"e157551e80201ba43816db752149292b8652428f","modified":1684381410492},{"_id":"public/HTML/2012/03/02/e3-80-8a-e6-ad-a4-e7-94-9f-e6-9c-aa-e5-ae-8c-e6-88-90-e3-80-8b-e4-ba-8e-e5-a8-9f/index.html","hash":"9b9fb81db0fda767d55b5e78a4f2fa6e757edd76","modified":1684381410492},{"_id":"public/HTML/2011/04/30/primitive-root-poj-1284/index.html","hash":"3677d61cb738099c66dfb5b5b236b8121b0e7166","modified":1684381410492},{"_id":"public/HTML/2012/04/19/vmware-ubuntu-fedora/index.html","hash":"8311e538ee43fc48dc8336f1e8aeea5c6331718b","modified":1684381410492},{"_id":"public/HTML/2012/10/17/structure-and-interpretation-of-computer-programs-1-2/index.html","hash":"85984e0025114e68467f589991a06c8ffaa4d51b","modified":1684381410492},{"_id":"public/HTML/2012/10/08/scheme-and-the-little-scheme/index.html","hash":"56664152df6cf144b1975769db42c2b981d15bfc","modified":1684381410492},{"_id":"public/HTML/2012/10/16/structure-and-interpretation-of-computer-programs-1-1/index.html","hash":"debdbac50dc17fd3c5b614f03bb21a00ecca4546","modified":1684381410492},{"_id":"public/HTML/2012/02/12/xp-office-2010-error-1406/index.html","hash":"309a061c7eb2f3112632e8bf7490d189503990b7","modified":1684381410492},{"_id":"public/HTML/2012/02/12/2011-2012-plan/index.html","hash":"71634c372770d753da885f58a7bf60878ab33cd1","modified":1684381410492},{"_id":"public/HTML/2012/10/23/google-adsense/index.html","hash":"7f28cdd569711be433560f1e31463818286911d4","modified":1684381410492},{"_id":"public/HTML/2012/09/27/concrete-mathematics-chapter-1-homework-exercises/index.html","hash":"4ebd787ed4427933d25ba086df66812dc3ca969e","modified":1684381410492},{"_id":"public/HTML/2012/09/21/wordpress-fatal-error/index.html","hash":"2a442a68173b4fce7e336794c2ff3838c549681c","modified":1684381410492},{"_id":"public/HTML/2012/10/23/structure-and-interpretation-of-computer-programs-1-3/index.html","hash":"76ad45bbf89459b45a081ab691182a4f0a39e2fd","modified":1684381410492},{"_id":"public/HTML/2015/02/18/everything-about-2014/index.html","hash":"2f493ee0acf299b62fb842834a40b0b20ab74501","modified":1684381410492},{"_id":"public/HTML/2012/09/26/concrete-mathmatics-chapter-1/index.html","hash":"ff019f186e2020408b4af8aac5da3ce078a2b3ed","modified":1684381410492},{"_id":"public/HTML/2012/11/06/chrome-https-connection/index.html","hash":"8817e0e1990c6271d34c574b496746e1fdaf9e96","modified":1684381410492},{"_id":"public/HTML/2012/11/21/apue-chapter-3-excise-3-2/index.html","hash":"e6dcd1b34818b59331bd5421e68807b8375e7cbc","modified":1684381410492},{"_id":"public/HTML/2012/11/08/vc-6-clistctr-add-image-and-cant-display/index.html","hash":"b0fc82a4eb3e6dabce657dd181d82f9b4579c767","modified":1684381410492},{"_id":"public/HTML/2012/11/13/fedora-13-opengl/index.html","hash":"223fe001ae8c8eaad09243692c58f39797a1d3a1","modified":1684381410492},{"_id":"public/HTML/2012/11/26/fedora-13-movie-mkv-mp4-rmvb-rm-song/index.html","hash":"82d36c8517042ef23e2d8332c1597e64d5fcb7a3","modified":1684381410492},{"_id":"public/HTML/2015/03/08/github-blog-math-expression-support/index.html","hash":"b3707a34d281f86d99634603ad6c86682022f539","modified":1684381410492},{"_id":"public/HTML/2012/12/12/fedora-13-texlive2012-install-chinese-configure/index.html","hash":"c779ecf5bb840156602d4e4a9b75f854270e798a","modified":1684381410492},{"_id":"public/HTML/2012/12/03/first-linux-module-lvm/index.html","hash":"50363b09aab678ec614add1999e312fc028eccab","modified":1684381410492},{"_id":"public/HTML/2012/12/10/implicit-declaration-of-function-class-device-create/index.html","hash":"d1514c712d734a68cc4a21a7b262b54338d6c68f","modified":1684381410492},{"_id":"public/HTML/2012/12/27/too-many-levels-of-symbolic-links/index.html","hash":"d76f0134014c6008e0bf5627769a3808f9c196d9","modified":1684381410492},{"_id":"public/HTML/2012/12/28/vi-basic-command/index.html","hash":"c1fd2538f7ed5779741cca84cb53c47747de1080","modified":1684381410492},{"_id":"public/HTML/2012/12/26/fedora-13-update-to-fedora-15/index.html","hash":"959eb55f92a0557fadc1cf98d8077aa616a16943","modified":1684381410492},{"_id":"public/HTML/2012/11/15/advanced-programming-in-the-unix-environment-apue-h/index.html","hash":"eae4508b0e08848cc07061a2edf65136c047f367","modified":1684381410492},{"_id":"public/HTML/2015/07/17/experiment-of-storm-grouping/index.html","hash":"ceba78b47c4b939eaa92f10b2a60d863dff64927","modified":1684381410492},{"_id":"public/HTML/2015/07/16/a-brief-view-of-storm/index.html","hash":"18ad2ee494e1e375be7cf151bcf560e25b380597","modified":1684381410492},{"_id":"public/HTML/2012/11/05/display-views-count-without-plugin/index.html","hash":"170455239edd0b92cb00f015c71c534caa6f239f","modified":1684381410492},{"_id":"public/HTML/2013/06/21/linux-command-shell-scripts-3/index.html","hash":"cc02b67fe6b334d3cdb5a591f2c6a3ff6ddc1c2d","modified":1684381410492},{"_id":"public/HTML/2013/03/26/some-easy-math-problems/index.html","hash":"bd52608dc88b955289ab0b83fcbb70f6a28ba3a9","modified":1684381410492},{"_id":"public/HTML/2015/01/17/recursion/index.html","hash":"dc0b244273f32538a38fcfab2c5b21a3f17bcad1","modified":1684381410492},{"_id":"public/HTML/2015/01/03/algorithm-series/index.html","hash":"ed92e0310f87d3c364dcd78c774400e6903920d5","modified":1684381410492},{"_id":"public/HTML/2013/03/07/matlab-2012-libsvm/index.html","hash":"1ecbc0ff571a3ff77a0a2f173803cd0058537506","modified":1684381410492},{"_id":"public/HTML/2013/01/02/fedora-15-install-opencv-2-4/index.html","hash":"9dd9d42dddcd5cc12c3eabf6c3221957269072f8","modified":1684381410492},{"_id":"public/HTML/2013/01/21/github-pages-jekyll-blog-free/index.html","hash":"88b9e5845a51380275b92d7f946b3d6c648d0317","modified":1684381410492},{"_id":"public/HTML/2013/01/03/fedora-15-yum-rpm-problem/index.html","hash":"9b581bf973ffb69fb6ef3876abf189df2f270d24","modified":1684381410492},{"_id":"public/HTML/2013/05/25/linux-command-shell-script-2/index.html","hash":"660de3bdba29ae879081204cbeb700fe6c0dd592","modified":1684381410492},{"_id":"public/HTML/2013/05/24/linux-command-shell-script/index.html","hash":"e4f74909181a7993d7a169db1bbf5bc91f13a7dc","modified":1684381410492},{"_id":"public/HTML/2013/11/23/nonviolent-communication/index.html","hash":"d406c0c3172245f6a82cf5deee6ce166eae38dca","modified":1684381410492},{"_id":"public/HTML/2013/09/11/algorithms-chapter-5/index.html","hash":"c564bc5386b16a1d705a34a56050844c3a994a78","modified":1684381410492},{"_id":"public/HTML/2015/07/26/redis-pqsort-c/index.html","hash":"bba306f57d736b57d049aafa8ed46c2065888575","modified":1684381410492},{"_id":"public/HTML/2013/11/28/use-vundle-to-manage-vim-plugin/index.html","hash":"6ead7918a944d417397e5868072fdf1fab346114","modified":1684381410492},{"_id":"public/HTML/2013/07/20/algorithms-chapter-3-homework-sol/index.html","hash":"9257cd557d24b0bcf7e9507aade7661b45550c14","modified":1684381410492},{"_id":"public/HTML/2013/10/16/algorithms-chapter-6-dynamic-programming/index.html","hash":"c2bcf4368c7f66803db18f0bdca992b62589ce13","modified":1684381410492},{"_id":"public/HTML/2013/12/22/spiral-matrix/index.html","hash":"8e60f7d0cd3aa07bce75d7ccc2429f48f297c40f","modified":1684381410492},{"_id":"public/HTML/2013/12/20/level-order-of-a-tree/index.html","hash":"285fb2b9009dc7a3e669606966f6397a15a8f359","modified":1684381410492},{"_id":"public/HTML/2013/12/25/string-to-integer-atoi/index.html","hash":"22bb768145b16cfcb5d0aa8d3f53d68620955fa9","modified":1684381410492},{"_id":"public/HTML/2015/01/05/dynamic-programming/index.html","hash":"5c2b33b12f3678d29b218f7dd9156aa0f4837382","modified":1684381410492},{"_id":"public/HTML/2013/07/28/algorithms-chapter-4-and-some-exercises/index.html","hash":"653cc7e6134f408d2bf6ef5b4baef2ff6a9a5213","modified":1684381410492},{"_id":"public/HTML/2014/05/17/srm-620-randomgraph/index.html","hash":"8d270188239744e368be7712f76434b660733e99","modified":1684381410492},{"_id":"public/HTML/2014/01/04/reverse-linked-list/index.html","hash":"83f47b7831e6bac426b97c0b5e702a34b9d8fe32","modified":1684381410492},{"_id":"public/HTML/2014/05/02/linux-daemon/index.html","hash":"abc0023d724844942b9e18c817a9834c672d2180","modified":1684381410492},{"_id":"public/HTML/2014/05/09/linux-dbm/index.html","hash":"55ed02163c72f206e8f6c161da26d8f95829d1c0","modified":1684381410492},{"_id":"public/HTML/2014/05/27/using-gdb-to-debug-nginx/index.html","hash":"db9ef606df87803f8aa1f03cfac9d420b836815b","modified":1684381410492},{"_id":"public/HTML/2014/07/08/select-and-poll/index.html","hash":"7a14b906892095d57df1a2bca4ebfa373c7b8ff4","modified":1684381410492},{"_id":"public/HTML/2014/06/16/nginx-advancd-data-struct-1/index.html","hash":"b998856c1cd03791f9871e29a3fb67f0419ee31f","modified":1684381410492},{"_id":"public/HTML/2014/08/25/the-hardwaresoftware-interface-csapp-lab2-bomb/index.html","hash":"f8cd2064c6e5e8a86fab6eac020c68047f3a1763","modified":1684381410492},{"_id":"public/HTML/2014/11/02/least-recently-used-algorithm/index.html","hash":"96ef6699657a2ba1ad3c0ca82d31f731ab76061b","modified":1684381410492},{"_id":"public/HTML/2014/10/01/2014-code-interview/index.html","hash":"e96908acaf4524dc8212a525462d3692c1247f44","modified":1684381410492},{"_id":"public/HTML/2014/12/29/show-me-the-code/index.html","hash":"33839380a5fc0bfd350b37984d773fd03bca4e08","modified":1684381410492},{"_id":"public/HTML/2017/01/15/spark-streaming-e5-be-80-hdfs-e8-bf-bd-e5-8a-a0-lzo-e6-96-87-e4-bb-b6/index.html","hash":"2d9da928131019bf15c6744f60bc02c07b0d8c33","modified":1684381410492},{"_id":"public/HTML/2017/06/01/如何在不重启-Spark-Streaming-作业的情况下，增加消费的-topic/index.html","hash":"8daaf24f274afa5f0327662a71b2613b1fab1783","modified":1684381410492},{"_id":"public/HTML/2017/02/16/spark-streaming-consume-kafka-at-00-second-of-every-minute/index.html","hash":"d882f309c5f1a39ae7ca429a961f532ea8b8882a","modified":1684381410492},{"_id":"public/HTML/2014/01/07/binary-tree-traversal-without-recursive/index.html","hash":"ec31779b528ed09f506877e2bcf6adfa7383649f","modified":1684381410492},{"_id":"public/HTML/2017/06/20/风险不仅仅是事件发生的概率/index.html","hash":"f4f7fec1b22bccabe1bd7a79bb6352f3e489b922","modified":1684381410492},{"_id":"public/HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/index.html","hash":"aff0e9812ba29b116f0f96926f0e33a3836f3859","modified":1684381410492},{"_id":"public/HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/executor.jpg","hash":"7699406d15851ad17f951a1f7660d4deb92c36c5","modified":1684381410492},{"_id":"public/HTML/2017/04/15/从现在开始写作/index.html","hash":"87050076f545bf2bbb92e5671c77cf5acb5d7df8","modified":1684381410492},{"_id":"public/HTML/2017/09/17/GC-标记-清除算法/bitmap.jpeg","hash":"803ccaa5a84e2038a71c241c8f0c20cec8fc92b8","modified":1684381410492},{"_id":"public/HTML/2017/09/17/GC-标记-清除算法/heap.png","hash":"0c1fef5a8029ad0b014accabb99643d379fe9728","modified":1684381410492},{"_id":"public/HTML/2017/09/17/GC-标记-清除算法/index.html","hash":"0139042152839a6f409b95cc265f43458ef5b085","modified":1684381410492},{"_id":"public/HTML/2017/09/17/GC-标记-清除算法/bibop.jpeg","hash":"93df46d81b75a432d96f265ea284f7ebe6b618bd","modified":1684381410492},{"_id":"public/HTML/2017/09/17/GC-标记-清除算法/lazy-sweep.png","hash":"619be4d8137910edeb88a0b15244bb6b98cf149d","modified":1684381410492},{"_id":"public/HTML/2017/09/17/GC-标记-清除算法/multilink.jpeg","hash":"80a4c4addd3d2a14b5b3962b3ddf8bbff05ba94a","modified":1684381410492},{"_id":"public/HTML/2014/02/28/how-to-think-like-a-computer-scientist/index.html","hash":"b8933906174963a6adcf1bc2f8dcd6780028647c","modified":1684381410492},{"_id":"public/HTML/2017/11/09/django-configuration-in-action/index.html","hash":"8b251415b5c8b8baffe7dbb2d559f6250b404493","modified":1684381410492},{"_id":"public/HTML/2017/07/14/tmux-简单使用指南/index.html","hash":"d8549ae2fa5ff6b5b5158f9aacc76e7cf52f6ef9","modified":1684381410492},{"_id":"public/HTML/2017/11/20/git-inside/second_version.png","hash":"e59d7a09b90276cf2b4e5549d536e6eb4baec1e3","modified":1684381410492},{"_id":"public/HTML/2017/11/20/git-inside/project.png","hash":"5d67e33edc164fba66bad512494a9150a5f30a43","modified":1684381410492},{"_id":"public/HTML/2017/11/20/git-inside/index.html","hash":"6b66a98b48161b57054a387c0f08ddc62ca80482","modified":1684381410492},{"_id":"public/HTML/2017/11/20/git-inside/third_version.png","hash":"9709165c96e8819d43a4883c6e298a3bb0880b2b","modified":1684381410492},{"_id":"public/HTML/2017/11/20/git-inside/first_version.png","hash":"54e8ea80ea1cb233d004ac59187bef668760a5a5","modified":1684381410492},{"_id":"public/HTML/2017/11/27/TaskScheduler/index.html","hash":"8e038fa63a5d4b94e100333bf8725d5c20707246","modified":1684381410492},{"_id":"public/HTML/2017/10/16/spark-dagscheduler/index.html","hash":"a0af3351a38a4b7d5c56335a70b46a5f96f849a0","modified":1684381410492},{"_id":"public/HTML/2017/05/10/Python-代码实践小结/index.html","hash":"2401c3b0b3d81a6cfa7f6f32c5f3e09808e9e10f","modified":1684381410492},{"_id":"public/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver_sample.png","hash":"1854eb10195cf3c7d8bee5af081cf6c366c0d081","modified":1684381410492},{"_id":"public/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/index.html","hash":"417ed4955c04a665047a8c1d4a047c2e319ffb7d","modified":1684381410492},{"_id":"public/HTML/2017/05/29/从源码级别分析-metric-core-的抽样算法/index.html","hash":"ae0679f95981e1d47528d18577fceeace85a6789","modified":1684381410492},{"_id":"public/HTML/2017/12/03/tasksetmanager/index.html","hash":"6cb3f510289f2ba55cbafebf54a991d3c184b761","modified":1684381410492},{"_id":"public/HTML/2018/01/06/线程堆栈分析/dead_lock.png","hash":"1907d024bd977bd2cdcd4fd7087a570f85cd03f1","modified":1684381410492},{"_id":"public/HTML/2014/09/26/epoll-and-select/index.html","hash":"5780e77e5115af9153c6c9e853b8c16e2ba53d99","modified":1684381410492},{"_id":"public/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image1.png","hash":"28bd4bf7dc6e99e099e3ab4a2f7d52c496ccee2e","modified":1684381410492},{"_id":"public/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image2.png","hash":"1b6baef088696107131a6d42f7e276a6e7f31b54","modified":1684381410492},{"_id":"public/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/index.html","hash":"542074b5807114f4b5826beb68959eb739fdc307","modified":1684381410492},{"_id":"public/HTML/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image3.png","hash":"64d49ecfd0dfa44aa5e190d1a1ba95cefa05a4bf","modified":1684381410492},{"_id":"public/HTML/2018/09/09/一次-InputStream-read-使用不当导致的问题/index.html","hash":"d767079446a5a30613f66ac1675fed2efb49ec25","modified":1684381410492},{"_id":"public/HTML/2016/03/23/mit-6-824-2015-lab-1/index.html","hash":"82d39cc63cd0c81393792642c85ac32a3d6f8fa3","modified":1684381410492},{"_id":"public/HTML/2014/06/20/nginx-http-filter-module/index.html","hash":"c711dde8d5e3be8ec04d31067b5e7c6ec76d10ad","modified":1684381410492},{"_id":"public/HTML/2016/03/30/mit-6-824-lab-2-part-a/index.html","hash":"ca3ca02c20f8241a56ce39e201b0cfe3be05a05e","modified":1684381410492},{"_id":"public/HTML/2012/11/27/why-can-not-use-weixin-miliao/index.html","hash":"692e03184900637b7403d0c5971fb16623f96507","modified":1684381410492},{"_id":"public/HTML/2016/05/03/e6-88-91-e5-bf-83-e7-9b-ae-e4-b8-ad-e7-9a-84-e8-80-81-e5-b8-88/index.html","hash":"39e325676157faa1b7e3ec20d904269061e91563","modified":1684381410492},{"_id":"public/HTML/2017/05/20/hello-world/index.html","hash":"145a865036933138f693a8cdfb9f33b13b335227","modified":1684381410492},{"_id":"public/HTML/2016/07/14/spark-streaming-save-offset-to-zookeeper/index.html","hash":"e49d498bcee312ae53d3d169fb74ded91cbe40ae","modified":1684381410492},{"_id":"public/HTML/2016/07/15/spark-streaming-saving-offset-in-zookeeper-2/index.html","hash":"bdea1f44fa837be7018ce252df06f7e2deee7d62","modified":1684381410492},{"_id":"public/HTML/2016/10/26/e8-a6-81-e5-a4-9a-e5-bf-ab-e6-89-8d-e8-83-bd-e8-b7-91-e5-ae-8c-e4-b8-80-e5-9c-ba-e9-a9-ac-e6-8b-89-e6-9d-be/index.html","hash":"d434e15f34b66346cd8103aba9d995b06b1138d0","modified":1684381410492},{"_id":"public/HTML/2017/12/22/millwheel/index.html","hash":"465f898abc9391335f0077756166b6b5fdc38c02","modified":1684381410492},{"_id":"public/HTML/2016/06/11/asking-the-right-questions/index.html","hash":"0e6c9eb110ffb864faba87efb79df9d073278ff0","modified":1684381410492},{"_id":"public/HTML/2016/10/22/storm-e7-9a-84-e5-8f-af-e9-9d-a0-e6-80-a7-e4-bf-9d-e8-af-81-e6-b5-8b-e8-af-95/index.html","hash":"01defd7cefffce8fdb83c051a7e04b2b36aac52d","modified":1684381410492},{"_id":"public/HTML/2016/08/27/spark-streaming-kafka-read-binlog-to-json/index.html","hash":"95986ac60590773d6f13c7c52d51b1f661f6b8c3","modified":1684381410492},{"_id":"public/HTML/2016/09/26/e4-b8-80-e7-a7-8d-e5-8f-af-e8-a1-8c-e7-9a-84-e8-8b-b1-e8-af-ad-e9-98-85-e8-af-bb-e5-ad-a6-e4-b9-a0-e6-96-b9-e6-b3-95/index.html","hash":"7b43c9caf380a235e3e5cdac32b2fc80ee7408da","modified":1684381410492},{"_id":"public/HTML/2016/11/01/spark-streaming-topic-partition-change-auto-adaptive/index.html","hash":"a25ebfb11f7eb8afdedbb23d518bbd680747a0c9","modified":1684381410492},{"_id":"public/HTML/2016/01/20/how-to-read-a-book/index.html","hash":"81753186b230d3ff472bdace328e8d00216cb942","modified":1684381410492},{"_id":"public/HTML/2016/11/26/spark-streaming-e5-be-80-hdfs-e5-86-99-e6-96-87-e4-bb-b6-ef-bc-8c-e8-87-aa-e5-ae-9a-e4-b9-89-e6-96-87-e4-bb-b6-e5-90-8d/index.html","hash":"c695ff41752a3b2d3fd5ffcfda5badfd1e068947","modified":1684381410492},{"_id":"public/HTML/2016/12/02/spark-streaming-consume-kafka-message-from-specify-timestamp/index.html","hash":"517f6d0ca1bc55b7055756a884089c4738eeaae5","modified":1684381410492},{"_id":"public/HTML/2018/04/06/Flink-State/index.html","hash":"b8572bef962a1ca47403498c2ec6e006c23a5075","modified":1684381410492},{"_id":"public/HTML/2020/05/20/RocksDB-Single-CF-Result/list_state_result.html","hash":"1bcc9daeeb35f814bd11bd85b928d40121dccec2","modified":1684381410492},{"_id":"public/HTML/2020/05/20/RocksDB-Single-CF-Result/map_state_result.html","hash":"9cd11ba354c60652df9db5e8ed5286b423403ea0","modified":1684381410492},{"_id":"public/HTML/2020/05/20/RocksDB-Single-CF-Result/value_state_result.html","hash":"e7aa6ff7dc089ca8dad134e8ac2eebbdbb79ab46","modified":1684381410492},{"_id":"public/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image2.png","hash":"e472be0e0f5bd1b3277fa70e36237f5dd08125ce","modified":1684381410492},{"_id":"public/HTML/2016/12/16/spark-streaming-ran-out-of-messages-before-reaching-ending-offset/index.html","hash":"703c859e1cfd53f019ea18d4d3f6231a7226b09c","modified":1684381410492},{"_id":"public/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image1.png","hash":"3f226ad5ca9b70a361a8bca470a3c004a0d1df52","modified":1684381410492},{"_id":"public/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image4.png","hash":"acb23a5745277e2ce339293d305b344c1b8341f4","modified":1684381410492},{"_id":"public/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/index.html","hash":"f7af32b296824e12591be667d703c9ed1a1a2131","modified":1684381410492},{"_id":"public/HTML/2018/03/14/Java-内存泄漏分析和对内存设置/image3.png","hash":"2d64e51ba17035c65a910b37307ddb86b24715ad","modified":1684381410492},{"_id":"public/fonts/FontAwesome.otf","hash":"6270a4a561a69fef5f5cc18cdf9efc256ec2ccbe","modified":1684381410492},{"_id":"public/fonts/fontawesome-webfont.ttf","hash":"6225ccc4ec94d060f19efab97ca42d842845b949","modified":1684381410492},{"_id":"public/HTML/2011/03/27/usaco-5-1-2-starry-night/index.html","hash":"4eb8b29c028144121b843ba6f0bf4ef58ad8cab1","modified":1684381410492},{"_id":"public/HTML/2017/10/16/spark-dagscheduler/stage.jpg","hash":"4367aad746772f13fcd5deea7e5d447227ec733f","modified":1684381410492},{"_id":"public/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver_ReceiverSupervisor.png","hash":"976cca190ae3cb79be8723d653b16827cd14b079","modified":1684381410492},{"_id":"public/HTML/2018/01/06/线程堆栈分析/index.html","hash":"0fd08b6223e764cd3e473a258587b21761c3c2a0","modified":1684381410492},{"_id":"public/HTML/2017/12/22/millwheel/figure14_latency_scalability.jpg","hash":"6e8f4af4b02a6ad9237f8351b6b112db17fb4ae3","modified":1684381410492},{"_id":"public/HTML/2017/12/22/millwheel/figure13_latency.jpg","hash":"e342fda0902b5f6f1078834d0e24f8edc83ba6e7","modified":1684381410492},{"_id":"public/HTML/2017/12/22/millwheel/figure16_cache.jpg","hash":"00dd49d86f87be1213470c27b2ccec755c3bc824","modified":1684381410492},{"_id":"public/HTML/2017/12/22/millwheel/figure15_lowwatermark.jpg","hash":"85afa904c53280fa8b872da8425d517c5985203c","modified":1684381410492},{"_id":"public/HTML/2018/04/06/Flink-State/state-hierarchy.png","hash":"03bafd829b1f6e57121911ad584a0e12407593ae","modified":1684381410492},{"_id":"public/fancybox/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1684381410492},{"_id":"public/css/comment.css","hash":"acbef2bb5327b74fb68036ae238bc03514e4b4d8","modified":1684381410492},{"_id":"public/css/highlight-default.min.css","hash":"6ad10fd07f492660d5c8c8eaec6e74a94d277b4a","modified":1684381410492},{"_id":"public/css/google-fonts.css","hash":"91e629d0a0a531e920252788ed8863c26608c2b2","modified":1684381410492},{"_id":"public/css/highlight.css","hash":"98a031dd0991929ec23098db9dfde15ae662f031","modified":1684381410492},{"_id":"public/css/responsive.css","hash":"25136a75af5957a669d5c4782da8b8fa95f8fc55","modified":1684381410492},{"_id":"public/css/style.css","hash":"1c6958e4fa8ab11aca518b9a556fe2fad4976675","modified":1684381410492},{"_id":"public/js/jquery.imagesloaded.min.js","hash":"3eb6381d2ed4b706020e4be5aff024aab4bcabc5","modified":1684381410492},{"_id":"public/js/gallery.js","hash":"d19f1b1cc5b75e21ca1d643b6dae9490ead28b55","modified":1684381410492},{"_id":"public/js/spin.min.js","hash":"f91e2b661f4feb976b5e260bdc2366763ad13562","modified":1684381410492},{"_id":"public/js/search.js","hash":"6197e425941f107761d3cbfb0f06ad4a3f5f7427","modified":1684381410492},{"_id":"public/js/main.js","hash":"d78290344d95646172e488e0af2dade9740288f8","modified":1684381410492},{"_id":"public/js/timeago.min.js","hash":"d220fcc47be00effec6b5181b97cc0929d10031e","modified":1684381410492},{"_id":"public/css/themes/common.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1684381410492},{"_id":"public/css/themes/default.css","hash":"32f758d295c7037f247d300f2481b5d7d4f3b100","modified":1684381410492},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1684381410492},{"_id":"public/css/font-awesome.css","hash":"6df51eee1e75e450cb9cd71e925e6aa9ac2d6a9d","modified":1684381410492},{"_id":"public/js/bootstrap.min.js","hash":"6c264e0e0026ab5ece49350c6a8812398e696cbb","modified":1684381410492},{"_id":"public/js/comment.js","hash":"5cdafe054baa2ef66670ed46e6f862718e77bfcb","modified":1684381410492},{"_id":"public/js/highlight.min.js","hash":"02bb4cdaf43c85b7ee4ef6ccf1f3fe8e82fd3ceb","modified":1684381410492},{"_id":"public/js/marked.js","hash":"b1d4ef560ea01a5fe3a391a5933be5e7016f1d6a","modified":1684381410492},{"_id":"public/js/jquery-2.0.3.min.js","hash":"28daf1b2a995cc4de81154a9a9ebdbb98f7c9997","modified":1684381410492},{"_id":"public/css/themes/bootstrap.css","hash":"11197c2fc2925b34cc98a3f4ec67ffdd9f36a760","modified":1684381410492},{"_id":"public/css/themes/cyborg.css","hash":"4320dbfd9543f6ef1cc703d83d85c6652f9272d0","modified":1684381410492},{"_id":"public/css/themes/cosmo.css","hash":"bcb36ab2b547571fa4125e05e1074abba6bd5670","modified":1684381410492},{"_id":"public/css/themes/darkly.css","hash":"581ff4339a616fe26b4dc1b6c1d1ad7946b83de6","modified":1684381410492},{"_id":"public/css/themes/journal.css","hash":"b77cda6baedc3852c64f5664206356b3057b4781","modified":1684381410492},{"_id":"public/css/themes/cerulean.css","hash":"7fee0903cce12483ae3f37d330ef693826a5a61f","modified":1684381410492},{"_id":"public/css/themes/flatly.css","hash":"a95865761e69d0daf75660e24d9f5f316482ea55","modified":1684381410492},{"_id":"public/css/themes/paper.css","hash":"1ae57ddb500a85b8ca8e7d2897e55cb2ba4cf1bc","modified":1684381410492},{"_id":"public/css/themes/sandstone.css","hash":"5878440ffa7e1656214bafd8b7f39d736219807a","modified":1684381410492},{"_id":"public/css/themes/readable.css","hash":"af59c50f83bba69a4fef7d0ac32e309c903b4511","modified":1684381410492},{"_id":"public/css/themes/slate.css","hash":"3859265e9fcdb579f40a2ef7a5bd8dbead2d13ca","modified":1684381410492},{"_id":"public/css/themes/united.css","hash":"857151fa534842d0f8e862b2067f22905a1b3382","modified":1684381410492},{"_id":"public/css/themes/spacelab.css","hash":"fa4efbf50ca392c25e9b6395d6221696ec6573b6","modified":1684381410492},{"_id":"public/css/themes/superhero.css","hash":"cc4ce979e1def77b7c9b250d97d0baf3e0a3f845","modified":1684381410492},{"_id":"public/css/themes/simplex.css","hash":"b8165c48cf72e54c1f8ae1a550a04a64e6ce1929","modified":1684381410492},{"_id":"public/css/themes/lumen.css","hash":"5c23c4a98aec86b8483040e0ca602d3a4574f32c","modified":1684381410492},{"_id":"public/css/themes/yeti.css","hash":"7cb64c45bed521321e0a4a57e05e3d1c87721f16","modified":1684381410492},{"_id":"public/HTML/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/hang_job.jpg","hash":"ab3352884e349d7418c3ad3a5492526adf21eec5","modified":1684381410492},{"_id":"public/HTML/2017/12/22/millwheel/figure11_checkpoint.jpg","hash":"cb2a883863b50fc6daa50edddfccdd4233a758d0","modified":1684381410492},{"_id":"public/HTML/2017/12/22/millwheel/figure12_transaction.jpg","hash":"70a5993db631cfaec318db3736ac22aae312b434","modified":1684381410492},{"_id":"public/fonts/fontawesome-webfont.svg","hash":"cd980eab6db5fa57db670cb2e4278e67e1a4d6c9","modified":1684381410492},{"_id":"public/HTML/2017/07/14/tmux-简单使用指南/tmux_pic.png","hash":"a2db1790b8cde62c95d1842364764743a4fe4fea","modified":1684381410492},{"_id":"public/HTML/2018/01/06/线程堆栈分析/wait_sleep.png","hash":"9a1ddf0166cd279ff294d08436c5cd0be9c89dd6","modified":1684381410492},{"_id":"public/HTML/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver.png","hash":"f77ee44c9974e019b0682db58ddb8bc3292a6f71","modified":1684381410492},{"_id":"public/HTML/2017/10/16/spark-dagscheduler/procesure.jpg","hash":"3a9919b0782b34a3814109f78d01c2a1d90d7322","modified":1684381410492},{"_id":"public/HTML/2018/04/06/Flink-State/state-rescale.png","hash":"82c7ba867236708d14bd489ecafd20b57e39b392","modified":1684381410492},{"_id":"public/HTML/2017/09/17/GC-标记-清除算法/BFS_DFS.jpeg","hash":"8a0149f4a702fc3cd3beb85019a2668a4aa7ac1d","modified":1684381410492},{"_id":"public/HTML/2017/11/20/git-inside/file_tree.png","hash":"5febfd253e17c6678e82659af7546d77ef7b0a82","modified":1684381410492},{"_id":"source/HTML/index.html","hash":"8745060c44b14b220875c178d8847406a85d5d93","modified":1684389826803},{"_id":"source/CNAME","hash":"eb7b0e24dca15e45f872f668a9aaa07f7af695f3","modified":1735806128524},{"_id":"public/CNAME","hash":"eb7b0e24dca15e45f872f668a9aaa07f7af695f3","modified":1735806225965},{"_id":"source/_drafts/big-data-paper-big-picture.md","hash":"ccbcf56371d1e5d3db66a4e80620bb5983f32569","modified":1735806049866},{"_id":"source/_posts/maotai-basic-2025-02-08.md","hash":"ed1e6bf5cbb9c4dbf053969f13a0e1fffc00c212","modified":1740213214890},{"_id":"source/_posts/.maotai-basic-2025-02-08.md.swp","hash":"4ef745ceeaa8a8bb7a674ea4b4b6b92648ea73a5","modified":1739968238244},{"_id":"public/2025/02/22/maotai-basic-2025-02-08/index.html","hash":"208796c26314dfe7f46ba4b3ff70dff7070e2907","modified":1768627145718},{"_id":"public/archives/2025/index.html","hash":"63970ba860d8dad0df7e6a145cd4dfbc2f98a7ec","modified":1768631830024},{"_id":"public/archives/2025/02/index.html","hash":"f1ef9833c35ada31ff608237235679bc91d2768c","modified":1768631830024},{"_id":"public/tags/stock/index.html","hash":"abf784809cdc5f910df8871bdd899bb13018e4bf","modified":1768631830024},{"_id":"public/tags/maotai/index.html","hash":"54429a8e2bc154a3142f0611ac95ec571a2a2e12","modified":1768631830024},{"_id":"public/tags/company-analysis/index.html","hash":"0fd45da69ad3451f9b8c2f1e78c37dbb7f8df0a3","modified":1768631830024},{"_id":"public/tags/wine/index.html","hash":"530eb5d97395d0a8172865d204b14707690d4048","modified":1768631830024},{"_id":"source/_posts/40-questions-2024.md","hash":"c1279193c4a45fc88629aae89c26f43b5c91415e","modified":1741863605295},{"_id":"source/_posts/maotai-input-output.md","hash":"108953825c7c6847f2e2fd185a4b730c0585b6ae","modified":1743643089647},{"_id":"source/_drafts/sync-data-without-lock.md","hash":"02493f8ef9792eba9007740e080243131515bc65","modified":1742108963094},{"_id":"source/_drafts/40-questions-2024.md","hash":"c1279193c4a45fc88629aae89c26f43b5c91415e","modified":1741863605295},{"_id":"source/_posts/.maotai-input-output.md.swp","hash":"941a3045dc03b47dfdaee23af6f893a7b1fa3d38","modified":1743643100537},{"_id":"public/2025/03/16/maotai-input-output/index.html","hash":"7397a981eb432df595d9574dfd9aeb5a90affc39","modified":1768627145718},{"_id":"public/archives/2025/03/index.html","hash":"18ba34696c54bea962b0d0ece351abe942143bb3","modified":1768631830024},{"_id":"public/tags/profit/index.html","hash":"97f5c6d886922a3966974fa06688f1d2f84946b3","modified":1768631830024},{"_id":"public/tags/cost/index.html","hash":"25bfaea43d4be2b23f6296f296c3463e02a81d0d","modified":1768631830024},{"_id":"source/_posts/invest-compond.md","hash":"6372c9e01286b33f051d2d5b2fdc0e350160e8ec","modified":1744453558542},{"_id":"source/_posts/.invest-compond.md.swp","hash":"a111aac69ac66fecff0a19b848d8251203795085","modified":1744248096610},{"_id":"public/2025/04/09/invest-compond/index.html","hash":"b4c36390fab92b633b5367b8144c76c7513b2fe0","modified":1768627145718},{"_id":"public/archives/2025/04/index.html","hash":"da7f856ca72035b6cdfe3bccdd2033e247383c6c","modified":1768631830024},{"_id":"public/tags/investment/index.html","hash":"f9b0ed032aee6f57aaeb86a14bc6a6f44470d629","modified":1768631830024},{"_id":"public/tags/分红/index.html","hash":"1f2fa9593682e75679023332ab3740075735d306","modified":1768631830024},{"_id":"public/tags/compond/index.html","hash":"822fd9ab3f8fc9010718560f333643964e798a51","modified":1768631830024},{"_id":"source/_posts/compare-opportunity-cost-and-ratio.md","hash":"6e6c7db914d0ba7a55d4a7515ff413210eb872dc","modified":1745073585796},{"_id":"source/_posts/differentiation.md","hash":"abdac0a87df4d49d646c1b60c6324067d5d5b59c","modified":1745670172848},{"_id":"source/_drafts/clear-thinking.md","hash":"8c5f3306571475880fb84c915ee4eca5052461f8","modified":1746499731645},{"_id":"source/_posts/.clear-thinking.md.swp","hash":"1ac37581f9953f581e52e45bcfe83bc2fb87447a","modified":1745283807012},{"_id":"source/_drafts/iceberg-summit-2025.md","hash":"f69451617e53d22199ea477987eaadb2ef1d9036","modified":1747574355158},{"_id":"source/_drafts/iceberg-summit-2025.md.backup","hash":"75954f25c934d7a035ca5b52519edf3f9dcd4d5b","modified":1747721114009},{"_id":"source/_posts/clear-thinking.md","hash":"8c5f3306571475880fb84c915ee4eca5052461f8","modified":1746499731645},{"_id":"source/_posts/iceberg-summit-2025.md","hash":"9c3fea4efeeb6d49ec9be856379c3f1848549979","modified":1747730757588},{"_id":"source/_posts/.iceberg-summit-2025.md.swp","hash":"9d69ffaf0f08e3352a6f3700878e112ec94a8d70","modified":1747703029700},{"_id":"public/2025/05/20/iceberg-summit-2025/index.html","hash":"5a23ecaede06f655595aa61bbd4fab4779468d7f","modified":1768627145718},{"_id":"public/2025/05/06/clear-thinking/index.html","hash":"f7ee6d3a0aa6795aa997cd88a26b65382abee2da","modified":1747723185632},{"_id":"public/2025/04/26/differentiation/index.html","hash":"cdabfc7af1a33bf2f5bf4c70f8d25e1388be4edd","modified":1768627145718},{"_id":"public/2025/04/17/compare-opportunity-cost-and-ratio/index.html","hash":"b08c66c4deddd0a8c390f307473b607c3c3a02bb","modified":1768627145718},{"_id":"public/archives/2025/05/index.html","hash":"43507dc826b10480f2ff718de7c50eec8918764d","modified":1768631830024},{"_id":"public/tags/compare/index.html","hash":"ad4224a45711a002c687242224a8638ef571f1fb","modified":1768631830024},{"_id":"public/tags/opportunity-cost/index.html","hash":"fabc65081ead5b26d4fd390eb62895ac2f5ef980","modified":1768631830024},{"_id":"public/tags/differentiation/index.html","hash":"a8aebf26a7b6557e14650d156b83456ff8bef57c","modified":1768631830024},{"_id":"public/tags/iterative-velocity/index.html","hash":"af421bf13e15d87b166bd8f591ed752ee223e7ac","modified":1768631830024},{"_id":"public/tags/iceberg-summit/index.html","hash":"5f18b185459fab3f0afb28be053dce6f09a5fea1","modified":1768631830024},{"_id":"public/tags/strategy/index.html","hash":"046eb68b1ed135c8fc924b1f41ab67b017809553","modified":1768631830024},{"_id":"public/tags/notes/index.html","hash":"93c671bbb771f4b1e4fba1b42e01aefe8ff1cda9","modified":1768631830024},{"_id":"source/_posts/maotai-price-decreasing.md","hash":"0287eab5511ff11462e355d896d3a99b81163473","modified":1751677634520},{"_id":"source/_posts/.maotai-price-decreasing.md.swp","hash":"73aaea1eb841e2f8948d810d75a4fecea1b33d5b","modified":1751643529851},{"_id":"source/_drafts/better-me.md","hash":"0ec59d3ee930f3ad33fd0c70f9de0851171629b4","modified":1751597078728},{"_id":"public/2025/07/05/maotai-price-decreasing/index.html","hash":"ee5ba5b4305842b696f3691f03cc8d4394c95eec","modified":1768627145718},{"_id":"public/tags/price/index.html","hash":"797d9be0b76104b50982fbcf14250e6700724228","modified":1768631830024},{"_id":"public/archives/2025/07/index.html","hash":"bd7527b05635b69e54b92352c21e5ddf90bebfaa","modified":1768631830024},{"_id":"source/_drafts/how_could_the_multimode_lakehouse_be.md","hash":"a2f137052547f54d1e8c9c7888f106e823a9bb5c","modified":1768296817750},{"_id":"source/_posts/arrow_variant_optimize.md","hash":"0bad1d357e76ca52327c5f315f9794d0443b73c3","modified":1758158838224},{"_id":"source/_drafts/a-perspective-of-investment.md","hash":"0290408bfc6105388e32614f6071f5da01a93ed2","modified":1758162084424},{"_id":"source/_posts/.arrow_variant_optimize.md.swp","hash":"756b755b1d4e111db0610b3414a09312090a34f9","modified":1753787447499},{"_id":"source/_posts/investment-startup-innovation.md","hash":"b27cea0c7a3ecd66d1ae1b65af7647f4e2709fce","modified":1758287053823},{"_id":"public/2025/07/29/arrow_variant_optimize/index.html","hash":"36a62744b9b01f8e3689c8c2e6f036c44e8fe37d","modified":1768627145718},{"_id":"public/2025/09/19/investment-startup-innovation/index.html","hash":"697bf7862fc022b454f57ab6f42bf93346669bb7","modified":1768627145718},{"_id":"public/archives/2025/09/index.html","hash":"058dee76d1df159df1e97fca6996d01dfb950f48","modified":1768631830024},{"_id":"public/tags/arrow/index.html","hash":"44681dc286c552b11bc5e95ca84db238dfc574c7","modified":1768631830024},{"_id":"public/tags/parquet/index.html","hash":"bebb46fe99d701b07008e803ece0f67bab111f0a","modified":1768631830024},{"_id":"public/tags/variant/index.html","hash":"4ecba810a3ace1f648f61ce567114b59c92d9c97","modified":1768631830024},{"_id":"public/tags/rust/index.html","hash":"261c8efbed86ccaa1285c50bae566d1502c52e16","modified":1768631830024},{"_id":"public/tags/optimization/index.html","hash":"ff83bba015dcd6db53990d76864f87804cc0a5c6","modified":1768631830024},{"_id":"public/tags/innovation/index.html","hash":"6757bfe97248d39d89badad3d14e5f2bc6b0fb71","modified":1768631830024},{"_id":"public/tags/startup/index.html","hash":"dd4582f156ee135b6616ba3ff9852eec472f19ad","modified":1768631830024},{"_id":"source/_posts/a-perspective-of-investment.md","hash":"4029864e2f82263f296386823b49c8217039a998","modified":1759805208338},{"_id":"source/_drafts/column-format-compare.md","hash":"f3d40348288a82d91be7567ba7d1268d324543eb","modified":1763278572306},{"_id":"source/_drafts/.zhong-guo-shen-hua-init.md.swp","hash":"86b06e4c4d17fcfd7e13f546cc6bfd502257a04d","modified":1761045502392},{"_id":"source/_drafts/meitan.md","hash":"d9ada5f8afd38f8256097db3fbcef5e977ac5385","modified":1764205654757},{"_id":"source/_drafts/.col-industry-20-24.md.swp","hash":"78b9a6dd32a0058d538038f111a0fa944f5a94c9","modified":1761717455179},{"_id":"source/_drafts/zhong-guo-shen-hua.md","hash":"af3ffcdbb5a09b7998accd09a5368867a4067318","modified":1759921379437},{"_id":"source/_drafts/zhong-guo-shen-hua-init.md","hash":"16f39b5913497ef99902c2ed95ef8563d399441d","modified":1760443529314},{"_id":"themes/freemind/layout/.DS_Store","hash":"09fc9e7dea546a996cdae6374255a591ce47ec3a","modified":1762995694954},{"_id":"source/_drafts/.column-format-compare.md.swp","hash":"11f2b95b0c20ce81053ad9fc4718034551b804dd","modified":1763278578178},{"_id":"source/_posts/column-format-compare.md","hash":"b31fad43cd69a4b6c4874fe30386935f26761771","modified":1763691487633},{"_id":"source/_posts/.column-format-compare.md.swp","hash":"f3f39c1392d77bcedf1e063bc7c40a8f4d99124d","modified":1763464321074},{"_id":"source/_drafts/read-write-group.md","hash":"7345accad0076ccc9dc753319a907c00be771b76","modified":1765620718963},{"_id":"source/_drafts/tencent.md","hash":"fa3132138c2b7d6bbfef7fb32beddf447d3abb31","modified":1763955819709},{"_id":"source/_drafts/AI-and-others.md","hash":"64160e8ee18ae3b8ff8f28bcefc5b0c5e23edac4","modified":1764126883947},{"_id":"source/_drafts/.how_could_the_multimode_lakehouse_be.md.swp","hash":"2116148761d7c9e8945988ea5e3ea5b1be05ed50","modified":1768296823305},{"_id":"source/about/index.md","hash":"2a704f7ba40e11e026d18a4d77adbd91ad75e10a","modified":1766970558348},{"_id":"public/about/index.html","hash":"bdf1c71b33ab57b0b9a69671777a8823323b7a76","modified":1768627145718},{"_id":"public/2025/10/07/a-perspective-of-investment/index.html","hash":"3d7f68306d37d2552078165866a4c694e50370ee","modified":1768627145718},{"_id":"public/2025/11/16/column-format-compare/index.html","hash":"aed5cf81aedceaa4c9855956efa8408c5cbd45a6","modified":1768627145718},{"_id":"public/archives/page/2/index.html","hash":"d96ea5e2ff387ba22bb879f603219def5ef8b57b","modified":1768631830024},{"_id":"public/archives/2025/page/2/index.html","hash":"b97d59de603d17e7ab8a7011c00c246e40ba169d","modified":1768631830024},{"_id":"public/archives/2025/11/index.html","hash":"86613e5e5401406ae577d5a120ecf19dd7f181c6","modified":1768631830024},{"_id":"public/archives/2025/10/index.html","hash":"88847cf988160645dc799c9e4488ac1d518d25ba","modified":1768631830024},{"_id":"public/tags/theory/index.html","hash":"b5d9611725614a657c84bfcb1369d28e2992fbfd","modified":1768631830024},{"_id":"public/tags/pattern/index.html","hash":"854478dff55a8dba70bd0f25a6e1ffa27c767fd3","modified":1768631830024},{"_id":"public/tags/arbitrage/index.html","hash":"2d4c735b30836c2a6360a1913ff2c2bc099c78b1","modified":1768631830024},{"_id":"public/tags/file-format/index.html","hash":"b8cd8b3857063513e8c5ffd05426df4982769022","modified":1768631830024},{"_id":"public/tags/column-fiel-format/index.html","hash":"0fab136b917374a71b086225bb6bfc3db52b272c","modified":1768631830024},{"_id":"public/tags/lance/index.html","hash":"9a8cba18ca5f67f288be94f82df0eacc2ba2c940","modified":1768631830024},{"_id":"public/tags/vortex/index.html","hash":"964dbd344cde4a6e5ece11226b4fc7f724bfdd57","modified":1768631830024},{"_id":"public/tags/nimble/index.html","hash":"9a1f0992546d45759b3f81fffe5e33f978c8703a","modified":1768631830024},{"_id":"public/page/2/index.html","hash":"a9a37e94181cc62ca2fb4888e10380e7742e74dc","modified":1768631830024},{"_id":"source/_drafts/chu-neng.md","hash":"837d897843ddfeca86fbe17132341599b5b70952","modified":1768466312160},{"_id":"source/_posts/601088-company-ana.md","hash":"aa1fe2a3ee05aa605f96c5ac27dd5f18f9861a80","modified":1768631817387},{"_id":"source/_drafts/keywords-in-mine-and-electric.md","hash":"4e537b28bf107bd9f3308275588045ce62a6fa30","modified":1766970558333},{"_id":"source/_drafts/review-2025.md","hash":"f6af7abd1225bd7c7c1e539570ca531929631466","modified":1768546608694},{"_id":"source/_drafts/demand-supply-curve-andelasticity.md","hash":"c6c80632471368970502845eb2e34065c9aaf521","modified":1768612690558},{"_id":"source/_drafts/601088.md","hash":"146ea7b8736bf564da6295088cfd6fd6e751611b","modified":1768545370398},{"_id":"source/_posts/.601088-company-ana.md.swp","hash":"3b82d15f056f7253d03e47a895523a1a6fb0fa87","modified":1768572672035},{"_id":"source/_posts/.a-perspective-of-investment.md.swp","hash":"45ac1882fe61fa26e7e2c2661ca857b96b20622b","modified":1768542689213},{"_id":"public/2026/01/18/601088-company-ana/index.html","hash":"06e6f279c620ecf97842b296fca5070fa14c7eec","modified":1768631830024},{"_id":"public/archives/2026/index.html","hash":"40983fe794f16d805b1124f7726b750325b98fa7","modified":1768631830024},{"_id":"public/archives/2026/01/index.html","hash":"d3753303dc44bd76bc06aa746261138d4d374914","modified":1768631830024},{"_id":"public/tags/601088/index.html","hash":"e09b2a35c49b0a1103760d3f319d0572988e378b","modified":1768631830024}],"Category":[],"Data":[],"Page":[{"title":"About Me","date":"2025-12-15T16:00:00.000Z","_content":"\n# 主要工作\n工作主要围绕大数据实时计算与数据湖展开，主要在 Data Infra 团队工作，也贴身支持过业务团队，对 Data Infra 以及上层团队如何使用 Data Infra 有一定自己的理解。\n\n主要一些工作包括\n- [美团] 基于 Storm 搭建一套实时大屏全链路，其中为酒旅提供的效果在中央十台播出\n- [美团] 基于 SparkStreaming 的 ODS 数据同步系统，日均同步数据 10T，TPS 峰值 60W/s\n- [阿里] Blink -- 阿里内部 Flink 版 -- 开发：主要包括 Java 版 KV-Store，在客户线上获得 2.5 倍性能提升；Flink Checkpoint 小文件合并解决 HDFS 压力大的问题；其他各项功能特性\n- [阿里] Flink 社区中 State/Checkpoint 多项重大特性开发支持，包括 State 多线程上传下载、Savepoint relocation、State Migration、StateBackend 丢数等\n- [腾讯] 内部 Flink 版本开发：Flink 单点重启功能，单 task failvoer 耗时降为 0；Flink 大状态快速恢复功能，40TB state 恢复耗时从 20 分钟优化到 1 分钟\n- [腾讯] 广告提效项目支持：支持 实时样本、特性、训练等使用 Flink，并支持 Native K8S 相关功能，为广告节省成本 40%。\n- [腾讯] Flink 作业管理平台开发，支持多种作业类型（代码、SQL、拖拽式画布），支持多环境部署\n- [天翼云]\n\n# Talks\n- 2019 年 Flink Forward Asia\n- 2021 年 Flink Forward Asia\n- 2022 年 DataFun Summit\n- 2022 年 CommunityOverCode Asia\n- 2024 年 Flink Forward Asia\n- 2025 年 CommunityOverCode Asia\n\n# 经历\n- 2023.8 - 天翼云 大数据产线\n- 2020.5 - 2023.8 腾讯科技有限公司  数据平台部\n- 2018.3 - 2020.5 阿里巴巴 Blink 团队\n- 2015.7 - 2018.3 美团 数据平台部\n- 2008.9 - 2015.6 中南大学 计算机学院\n- 2020.10 Apache Flink Committer\n- 2024.12 Apache Amoro PMC member\n","source":"about/index.md","raw":"---\ntitle: About Me\ndate: 2025-12-16\n---\n\n# 主要工作\n工作主要围绕大数据实时计算与数据湖展开，主要在 Data Infra 团队工作，也贴身支持过业务团队，对 Data Infra 以及上层团队如何使用 Data Infra 有一定自己的理解。\n\n主要一些工作包括\n- [美团] 基于 Storm 搭建一套实时大屏全链路，其中为酒旅提供的效果在中央十台播出\n- [美团] 基于 SparkStreaming 的 ODS 数据同步系统，日均同步数据 10T，TPS 峰值 60W/s\n- [阿里] Blink -- 阿里内部 Flink 版 -- 开发：主要包括 Java 版 KV-Store，在客户线上获得 2.5 倍性能提升；Flink Checkpoint 小文件合并解决 HDFS 压力大的问题；其他各项功能特性\n- [阿里] Flink 社区中 State/Checkpoint 多项重大特性开发支持，包括 State 多线程上传下载、Savepoint relocation、State Migration、StateBackend 丢数等\n- [腾讯] 内部 Flink 版本开发：Flink 单点重启功能，单 task failvoer 耗时降为 0；Flink 大状态快速恢复功能，40TB state 恢复耗时从 20 分钟优化到 1 分钟\n- [腾讯] 广告提效项目支持：支持 实时样本、特性、训练等使用 Flink，并支持 Native K8S 相关功能，为广告节省成本 40%。\n- [腾讯] Flink 作业管理平台开发，支持多种作业类型（代码、SQL、拖拽式画布），支持多环境部署\n- [天翼云]\n\n# Talks\n- 2019 年 Flink Forward Asia\n- 2021 年 Flink Forward Asia\n- 2022 年 DataFun Summit\n- 2022 年 CommunityOverCode Asia\n- 2024 年 Flink Forward Asia\n- 2025 年 CommunityOverCode Asia\n\n# 经历\n- 2023.8 - 天翼云 大数据产线\n- 2020.5 - 2023.8 腾讯科技有限公司  数据平台部\n- 2018.3 - 2020.5 阿里巴巴 Blink 团队\n- 2015.7 - 2018.3 美团 数据平台部\n- 2008.9 - 2015.6 中南大学 计算机学院\n- 2020.10 Apache Flink Committer\n- 2024.12 Apache Amoro PMC member\n","updated":"2025-12-29T01:09:18.348Z","path":"about/index.html","_id":"cmj89l7n10000vemk6autabaa","comments":1,"layout":"page","content":"<h1 id=\"主要工作\"><a href=\"#主要工作\" class=\"headerlink\" title=\"主要工作\"></a>主要工作</h1><p>工作主要围绕大数据实时计算与数据湖展开，主要在 Data Infra 团队工作，也贴身支持过业务团队，对 Data Infra 以及上层团队如何使用 Data Infra 有一定自己的理解。</p>\n<p>主要一些工作包括</p>\n<ul>\n<li>[美团] 基于 Storm 搭建一套实时大屏全链路，其中为酒旅提供的效果在中央十台播出</li>\n<li>[美团] 基于 SparkStreaming 的 ODS 数据同步系统，日均同步数据 10T，TPS 峰值 60W/s</li>\n<li>[阿里] Blink — 阿里内部 Flink 版 — 开发：主要包括 Java 版 KV-Store，在客户线上获得 2.5 倍性能提升；Flink Checkpoint 小文件合并解决 HDFS 压力大的问题；其他各项功能特性</li>\n<li>[阿里] Flink 社区中 State/Checkpoint 多项重大特性开发支持，包括 State 多线程上传下载、Savepoint relocation、State Migration、StateBackend 丢数等</li>\n<li>[腾讯] 内部 Flink 版本开发：Flink 单点重启功能，单 task failvoer 耗时降为 0；Flink 大状态快速恢复功能，40TB state 恢复耗时从 20 分钟优化到 1 分钟</li>\n<li>[腾讯] 广告提效项目支持：支持 实时样本、特性、训练等使用 Flink，并支持 Native K8S 相关功能，为广告节省成本 40%。</li>\n<li>[腾讯] Flink 作业管理平台开发，支持多种作业类型（代码、SQL、拖拽式画布），支持多环境部署</li>\n<li>[天翼云]</li>\n</ul>\n<h1 id=\"Talks\"><a href=\"#Talks\" class=\"headerlink\" title=\"Talks\"></a>Talks</h1><ul>\n<li>2019 年 Flink Forward Asia</li>\n<li>2021 年 Flink Forward Asia</li>\n<li>2022 年 DataFun Summit</li>\n<li>2022 年 CommunityOverCode Asia</li>\n<li>2024 年 Flink Forward Asia</li>\n<li>2025 年 CommunityOverCode Asia</li>\n</ul>\n<h1 id=\"经历\"><a href=\"#经历\" class=\"headerlink\" title=\"经历\"></a>经历</h1><ul>\n<li>2023.8 - 天翼云 大数据产线</li>\n<li>2020.5 - 2023.8 腾讯科技有限公司  数据平台部</li>\n<li>2018.3 - 2020.5 阿里巴巴 Blink 团队</li>\n<li>2015.7 - 2018.3 美团 数据平台部</li>\n<li>2008.9 - 2015.6 中南大学 计算机学院</li>\n<li>2020.10 Apache Flink Committer</li>\n<li>2024.12 Apache Amoro PMC member</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"主要工作\"><a href=\"#主要工作\" class=\"headerlink\" title=\"主要工作\"></a>主要工作</h1><p>工作主要围绕大数据实时计算与数据湖展开，主要在 Data Infra 团队工作，也贴身支持过业务团队，对 Data Infra 以及上层团队如何使用 Data Infra 有一定自己的理解。</p>\n<p>主要一些工作包括</p>\n<ul>\n<li>[美团] 基于 Storm 搭建一套实时大屏全链路，其中为酒旅提供的效果在中央十台播出</li>\n<li>[美团] 基于 SparkStreaming 的 ODS 数据同步系统，日均同步数据 10T，TPS 峰值 60W/s</li>\n<li>[阿里] Blink — 阿里内部 Flink 版 — 开发：主要包括 Java 版 KV-Store，在客户线上获得 2.5 倍性能提升；Flink Checkpoint 小文件合并解决 HDFS 压力大的问题；其他各项功能特性</li>\n<li>[阿里] Flink 社区中 State/Checkpoint 多项重大特性开发支持，包括 State 多线程上传下载、Savepoint relocation、State Migration、StateBackend 丢数等</li>\n<li>[腾讯] 内部 Flink 版本开发：Flink 单点重启功能，单 task failvoer 耗时降为 0；Flink 大状态快速恢复功能，40TB state 恢复耗时从 20 分钟优化到 1 分钟</li>\n<li>[腾讯] 广告提效项目支持：支持 实时样本、特性、训练等使用 Flink，并支持 Native K8S 相关功能，为广告节省成本 40%。</li>\n<li>[腾讯] Flink 作业管理平台开发，支持多种作业类型（代码、SQL、拖拽式画布），支持多环境部署</li>\n<li>[天翼云]</li>\n</ul>\n<h1 id=\"Talks\"><a href=\"#Talks\" class=\"headerlink\" title=\"Talks\"></a>Talks</h1><ul>\n<li>2019 年 Flink Forward Asia</li>\n<li>2021 年 Flink Forward Asia</li>\n<li>2022 年 DataFun Summit</li>\n<li>2022 年 CommunityOverCode Asia</li>\n<li>2024 年 Flink Forward Asia</li>\n<li>2025 年 CommunityOverCode Asia</li>\n</ul>\n<h1 id=\"经历\"><a href=\"#经历\" class=\"headerlink\" title=\"经历\"></a>经历</h1><ul>\n<li>2023.8 - 天翼云 大数据产线</li>\n<li>2020.5 - 2023.8 腾讯科技有限公司  数据平台部</li>\n<li>2018.3 - 2020.5 阿里巴巴 Blink 团队</li>\n<li>2015.7 - 2018.3 美团 数据平台部</li>\n<li>2008.9 - 2015.6 中南大学 计算机学院</li>\n<li>2020.10 Apache Flink Committer</li>\n<li>2024.12 Apache Amoro PMC member</li>\n</ul>\n"}],"Post":[{"_content":"# 现在的研究\n\n主要参考两个论文：LSM-Based Storage Techniques：A Survey；《Constructing and analyzing the LSM design space》\n\n1 LSM 现在的现状，以及可能的优化方向，不同优化的收益\n\n# 开源实现\n都有哪些开源的实现\n在 《Constructing and Analyzing the LSM compaction Design Space》的 Instruction 中有提到很多具体的实现\n\n现在 OceanBase 中的 L0 使用 B-Treee & Hash 的结构实现。\n\nOceanBase 中有多种 compaction，且作用都不一样\n","source":"_drafts/lsm-tree-2-20230517.md","raw":"# 现在的研究\n\n主要参考两个论文：LSM-Based Storage Techniques：A Survey；《Constructing and analyzing the LSM design space》\n\n1 LSM 现在的现状，以及可能的优化方向，不同优化的收益\n\n# 开源实现\n都有哪些开源的实现\n在 《Constructing and Analyzing the LSM compaction Design Space》的 Instruction 中有提到很多具体的实现\n\n现在 OceanBase 中的 L0 使用 B-Treee & Hash 的结构实现。\n\nOceanBase 中有多种 compaction，且作用都不一样\n","slug":"lsm-tree-2-20230517","published":0,"date":"2024-05-06T02:51:31.126Z","updated":"2024-05-06T02:51:31.126Z","_id":"clhsl7av800002uv95nyq507i","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"现在的研究\"><a href=\"#现在的研究\" class=\"headerlink\" title=\"现在的研究\"></a>现在的研究</h1><p>主要参考两个论文：LSM-Based Storage Techniques：A Survey；《Constructing and analyzing the LSM design space》</p>\n<p>1 LSM 现在的现状，以及可能的优化方向，不同优化的收益</p>\n<h1 id=\"开源实现\"><a href=\"#开源实现\" class=\"headerlink\" title=\"开源实现\"></a>开源实现</h1><p>都有哪些开源的实现<br>在 《Constructing and Analyzing the LSM compaction Design Space》的 Instruction 中有提到很多具体的实现</p>\n<p>现在 OceanBase 中的 L0 使用 B-Treee &amp; Hash 的结构实现。</p>\n<p>OceanBase 中有多种 compaction，且作用都不一样</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"现在的研究\"><a href=\"#现在的研究\" class=\"headerlink\" title=\"现在的研究\"></a>现在的研究</h1><p>主要参考两个论文：LSM-Based Storage Techniques：A Survey；《Constructing and analyzing the LSM design space》</p>\n<p>1 LSM 现在的现状，以及可能的优化方向，不同优化的收益</p>\n<h1 id=\"开源实现\"><a href=\"#开源实现\" class=\"headerlink\" title=\"开源实现\"></a>开源实现</h1><p>都有哪些开源的实现<br>在 《Constructing and Analyzing the LSM compaction Design Space》的 Instruction 中有提到很多具体的实现</p>\n<p>现在 OceanBase 中的 L0 使用 B-Treee &amp; Hash 的结构实现。</p>\n<p>OceanBase 中有多种 compaction，且作用都不一样</p>\n"},{"title":"lsm-tree","date":"2023-04-24T08:53:32.000Z","toc":true,"_content":"\n> 文章内容基于原论文，结合自己的理解和思考，发现有错漏的地方，欢迎反馈探讨，感谢。\n\nLSM-Tree 拥有优异的性能出现在各种存储引擎中，本文希望对 LSM-Tree 进行一个最小全局认识，对其有个骨架结构认识，从 LSM-Tree 的原始论文开始，到现在的进展以及 LSM-Tree 中各种影响的因素。\n\n<!-- more -->\n\n# 起始\n## 1 LSM-Tree 的缘起\n\nLSM-Tree 从论文[1] 中出生，在该论文中谈及了 LSM-Tree 诞生的原因，主要流程，优缺点，适合场景，以及决定性能的相关参数等。首先接下来重点介绍这篇 LSM-Tree 的原始论文。\n\n在论文[1] 之前的年代中，存储引擎主要使用 B-Tree 系列的数据结构，这种数据结构并不是 I/O 友好型的，随机 I/O 所带来的成本会比较高，尤其是写多读少的情况下，更新叶子节点会有两次随机 I/O（读+写），会有性能瓶颈。LSM-Tree 则以两个 batch 操作来优化 I/O 成本：1）首先写入 memory，然后 memory 的数据以 batch 形式写入磁盘；2）磁盘顺序读写，减少 seek 的成本（次数减少），均摊后单次成本更低。\n\n由论文[2] 中的结论可知，在一定范围内使用内存换 I/O 能减少整体成本。随着硬件的更新换代，内存和磁盘的成本关系也在变化，可根据具体使用的硬件进行对比。\n\n## 2 LSM-Tree 的结构，以及主要流程\nLSM-Tree 是一个多层的数据结构，其中第一层（最上层）保持在内存中，除第一层外的其他层均在磁盘（部分频繁访问的数据会 cache 在内存）。最简单的 LSM-Tree 拥有两层：内存中一层，磁盘中一层。接下来首先以两层 LSM-Tree 介绍相关功能，后续在定量分析过程中，会详细介绍多层 LSM-Tree 结构。\n\n两层 LSM-Tree 的结构如下所示：\n\n![tow-component-lsm](https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516141825.png)\n\n上图中 L0 与 L1 均是 tree-like 的数据结构，由于 L0 不需要特别考虑 tree high（都在内存，无 I/O），因此 B-Tree、AVL-Tree 以及 2-3-tree 等各种 tree like 数据结构读可以。 L1 保存在磁盘，需要考虑 tree high，使用 B-Tree。\n\n对 LSM-Tree 数据结构，首先看一下基本操作的流程(为了描述方便，L0 中的结构也以 B-Tree 为例）:\n\n- insert：数据直接写入内存 L0 中。在 L0 大小达到一定阈值后，会进行 rolling merge 操作（后面详述），将数据从 L0 转移到 L1。\n- get：读取数据的时候，首先从 L0 中进行查找，找到后直接返回（不管是否带 delete meta 信息的 key/value），否则继续从 L1 进行查找。\n- delete：如果 L0 中没有 key/value 对，则在 L0 中增加一个 key/value 对，且 value 包括 delete 相关的 meta 信息；如果 L0 中有对应的 key/value，则将 value 更改为包括 delete meta 信息的值。rolling merge 的时候将带有 delete meta 信息的 key/value 从 L_i 写入到 L_(i+1) 删除 L_i & L_(i + 1) 中的 key/value 对，然后在 L_(i+1) 插入一个带有 delete meta 信息的 key/value 对，当达到最底层的时候，将 key/value 对进行物理删除。同样 delete 的操作和 insert 一样，支持 batch 操作。\n- update：update 可以看作是 delete&insert 的组合\n\nLSM-Tree 为了保证更上层有空间接受插入的新数据，维护一个 rolling merge 的后台流程，该流程会从相邻两层中分别读取数据，写入到下层中，在 rolling merge 的过程中也可以进行部分逻辑处理：比如 ttl 的数据可以直接删除等。下图是一个 rolling merge 的示意图： \n\n![rolling-merge](https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516141924.png)\n\n## 3 LSM-Tree 相关的定量分析\n上文介绍了 LSM-Tree 诞生的原因，以及基本的流程，下面着重进行性能相关的定量分析，包括双层 LSM-Tree 以及多层 LSM-Tree。\n\n### 双层 LSM-Tree 的 IO 定量分析\n本节介绍双层 LSM-Tree 的 I/O 定量分析，以及和 B-Tree 的相关对比情况。\n\n以下对比内容基于 1995 年的硬件架构：\n\n- 1MByte 内存需要 100$\n- 1MByte 磁盘的存储需要 1$\n- 随机访问 I/O 成本是 25$\n- 顺序访问的 I/O 成本是 2.5$\n\n同时为了后面描述方便，定义变量如下:\n\n- $COST_d$ 表示磁盘存储 1MByte 所需要的成本\n- $COST_m $ 表示内存中存储 1MByte 所需要的成本\n- $ COST_P $ 表示提供 1 page 每秒所需要的磁盘成本（随机访问）\n- $ COST_\\pi $ 表示提供 1 page 每秒所需要的磁盘成本（顺序访问）\n\n内存的成本由存储空间决定，而磁盘的成本则由存储空间和访问频率的更大者决定。\n\n假设需要存储 S MByte 大小的数据，且每秒 H 的随机 I/O 访问（数据无缓存），则磁盘的开销是 $ COST_D = max(S * COST_d, H * COST_P $，其中 $ S*COST_d $ 表示存储所需成本，$ H * COST_P $ 则表示随机 I/O 访问的成本。\n\n当使用内存来缓存部分数据后，使得磁盘的瓶颈变为存储量后，则对应总成本是 $ COST-B = S * COST_m + S*COST_d $ 其中， $ S*COST_M $ 表示内存的成本，$ S*COST_d $ 表示磁盘的存储所需成本。\n\n综合上面两种情况可得，总共存储 S MByte 大小的数据，且每秒 H 随机访问的总成本公式如下所示：\n\n$ COST-TOT = min(max(S*COST_d, H*COST_P), S*COST_m + S*COST_d) $\n\n通过上述公式我们可以看到，整体的成本受总存储量，以及访问频率的影响，我们将 H/S（访问热度） 作为横轴，COST-TOT 作为纵轴画图得到如下曲线\n<Graph-of-cost-of-access-per-MByte-vs-Temperature.jpg> \n\n通过上图可知，总成本会随着访问热度的增长而增长，当达到一定程度后不在增长。上图中两个拐点将数据分为三段：cold，warm，hot。其中第一段的成本主要来源磁盘存储量，第二段则随着访问频率的增加而变多，第三段主要是内存与磁盘容量的成本。其中两个拐点则用如下公式定义\n\n- $ T_f = COST_d / COST_P = 1 / 25 = 0.04 $ 表示 cold 和 warm data 之间的拐点\n- $ T_b = COST_m / COST_P = 100 / 25 = 4 $ 表示 warm 和 hot data 之间的拐点\n\n> 对于连续 I/O 访问来说，也有类似上图的分析，而其中 warm 和 hot 的划分则是对 “The Five Minute Rule”[2] 的概括。\n\n根据论文[3] 中的说法，访问热度与实际的磁盘访问有关，而不是逻辑插入速度，LSM 也是通过减少实际的磁盘访问量来提效，LSM-Tree 有两个减少磁盘访问的点：1）先写内存，然后 batch 写磁盘；2）顺序访问磁盘。接下来接下下顺序 I/O 的收益。\n\n根据[4] 给的数据，随机读取一个磁盘页的耗时大概是 20ms（其中 10ms 用于磁道寻址，8.3ms 来源于旋转延迟，1.7ms 来源实际读取）。顺序读取 64 个磁盘页的耗时大概是 125ms（其中 10ms 来源于磁道寻址，8.3ms 来源于旋转延迟，106.9ms 来源于实际的数据读取），-- 平均后大概只需要 2ms 读取一个磁盘页，是随机访问的 1/10。也就是 $ COST_{\\pi} / COST_P = \\frac{1}{10} $。通过前面计算也能直观感受到顺序 I/O 所带来的(均摊)具巨大性能收益。\n\n\n我们使用[3] 中的给的结论来计算 \"五分钟规则\" 的参考区间 --  $ \\tau $，规则指出“维持每秒 1 page 访问所需要的成本与保存它所需的内存成本一致”，我们得到如下公式\n\n- $ \\frac{1}{ \\tau } * COST_P = pagesize * COST_m $  （I/O 速率 * 随机 I/O 的成本 = 内存存储的成本）\n\n那么 $ \\tau = (\\frac{1}{pagesize} * \\frac{COST_P}{COST_m}) = \\frac{1}{pagesize * T_b} $，如果每个 page 是 4k(0.004 Mb) 的话我们可以得到 `$\\tau = 1/(0.004 * 4) = 62.5 seconds/IO`。换句话说在访问间隔小于 62.5 seconds/IO 的时候，用内存换磁盘是合理的（现在需要根据硬件成本进行具体计算）。\n\n### B-Tree 和 LSM-Tree 的定量分析对比\n在进行 B-Tree 和 LSM-Tree 的对比分析之前，先单独进行 B-Tree 和 LSM-Tree 的分析。主要对比 insert 的性能，同时忽略了 index 更新过程中所带来的微小 I/O 成本。\n\n#### B-Tree 的定量分析\n> 假设所有的 insert 是完全随机的，因此不会有叶子节点 buffer 在内存的情况。\n\n根据论文[5] 的结论，B-Tree 中的有效深度 - $D_e$ - 表示随机查找中，未在 buffer 中命中的平均 page 数目。在 B-Tree 的插入中，首先需要进行 $D_e$ 次 I/O 查找对应的叶子节点，更新改节点，然后将脏页写回（1 I/O），因此整个 I/O 的开销如下所示\n\n$ COST_{B-ins} = COST_P * (D_e + 1) $\n\n#### LSM 的定量分析\n\n由于 LSM 的单 entry insert 时直接写入内存，可能没有 I/O 开销，因此分析 LSM-Tree 的 insert I/O 开销时，使用均摊分析进行。\n\n首先定义一些变量如下\n\n- $ S_e $ 表示 entry（index entry） 的大小（byte 为单位）\n- $ S_p $ 表示 page size 的大小（byte 为单位）\n- $ S_0 $ 表示 C0 中叶子节点的大小（MByte 为单位）\n- $ S_1 $ 表示 C1 中叶子节点的大小（MByte 为单位）\n- M 表示 rolling merge 的过程中平均有多少个 entry 插入到 __每个__ C1 的叶子节点 (a given LSM-tree as the average number of entries in the C0 tree inserted into __each__ single page leaf node of the C1 tree during the rolling merge)\n\n每个 page 中的 entry 数目大致为 $ S_p / S_e $，整个 LSM-tree 中在 C0 中的数据比例是 $ S_0 / (S_0 + S_1) $ )，因此 rolling merge 过程中会平均插入到每个 C1 叶子节点的 entry 数 M 可以通过其他公式计算得到 $ M = (S_p/S_e) * (S_0/(S_0 + S_1)) $。\n\n根据上述公式可以得到 LSM-Tree insert 的均摊开销为（将 C1 叶子节点读入和写出内存的开销均摊到 M 个 entry 上）\n\n$ COST_{LSM-ins} = 2 * COST_{\\pi} / M $ （读写一次 C1 的叶子节点，平均涉及到 M 个 entry）\n\n#### 对比\n\n观察 B-Tree 和 LSM-Tree 的 insert I/O 开销我们可以得到如下的公式\n\n$ COST_{LSM-ins} / COST_{B-ins} = K1 * (COST_{\\pi}/COST_{P}) * (1 / M) $  \n\n其中 $ K1 ~ 2/(D_e + 1) $ 是一个常数\n\n上述公式对比展示出，LSM-Tree 比 B-Tree 的优势主要来自于两方面：1）$COST_{\\pi}/COST_{P}$ 也就是磁盘的连续访问相比随机访问所带来的优势；2）M 也就是 rolling merge 时批量写入到 C1 中单个叶子节点的平均 entry 数目（注意 M 并不是一定会大于 1）。\n\n在 B-Tree 作为索引的情况下，如果整体访问热度比较高的话，则可以使用上述公式进行粗略的估算，使用 LSM-Tree 之后大概会有多少收益。\n\n### 多 component LSM-Tree 的分析\n上面所有关于 LSM-Tree 的讨论均假设 LSM-Tree 是两层的，在实际的生成中，LSM-Tree 则可能会有多层，具体的层数，以及相邻层之间的大小比例等可以通过分析得出，本节介绍多层 LSM-Tree 相关的分析。\n\n> 为了方便讨论，下面的描述中，假设 LSM-Tree 中的 entry 在插入后，仅在最底层进行删除。\n\n上面几节中的分析可以得到从 C0 写入到 C1 每个叶子节点的平均 entry 数目 M 并不一定大于 1，如果 M <= 1 的话，则 LSM-Tree 两个优势中的一个：“批量更新” 就失效了，因此如果分析得知 $ M < K1 * COST_{\\pi} / COSTP $ 的话则 B-Treee 比 LSM-Tree 会更好。另外一方面，为了更好的利用 LSM-Tree 的优势，则需要尽可能增大 M（也就是 C0 和 C1 的比值需要更大）；同时无限增大 C0  则会由于内存消耗更高造成成本过高，因此需要综合考虑计算一个总成本更小的参数值。\n\n为了保持 LSM-Tree 中上层有空间持续接受新数据，因此 rolling merge 从上层读取并删除的速度与 C0 接受到插入速度需要保持一致。\n\n在两层的 LSM-Tree 中，可以从 LSM-Tree 的总成本出发，寻找更合适的 C0 大小。首先从一个较大的 C0 开始，逐渐减小 C0 的大小（同时 I/O 开销会增加，I/O 的访问频率和存储成本会越来越小），直到达到一个平衡（此情况下再减少 C0 的大小会导致总成本增加）。另外的一个思路则是使用多层的 LSM-Tree 结构（这可以减少 C0 的大小，同时减少 I/O 的访问频率），同时没多一层会多部分 I/O 操作，因此需要综合考虑。\n\n下图是一个多层 LSM-Tree 的结构\n\n![multi-component-lsm-tree](https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516142001.png)\n\n对于 K+1 层的 LSM-Tree 来说，总共有 C0, C1, C2, ... C_{K-1} 以及 C_K，并且每层的大小递增（C1 比 C0 大，C2 比 C1 大，依次类推，最小的层 C0 在内存，其他的所有均在磁盘），相邻层之间会有异步的 rolling merge 过程，将 C_{i - 1} 层的数据迁移到 C_i 层中。对于一个插入后从未删除的 entry 来说，会从最上层 C0 逐步迁移到最底层 C_K 中。\n\n接下来会通过定量的分析来说明多层 LSM-Tree 中不同参数对总成本的影响，并且推导得出一个总成本更低的参数组合。\n\n首先定义一些在定量分析中需要的参数与假设\n- $ S(C_i) $ -- 表示 LSM-Tree 第 i 层叶子层所有 entry 的总大小（单位是 byte）\n- $ S_i $ -- 表示 LSM-Tree 中第 i 层所有 entry 的总大小（单位是 byte），也就是 $S(C_i) = S_i$\n- $ r_i = S_i / S_{i-1} $  -- 表示相邻两层中的总大小比例\n- S -- 表示所有层中叶子节点的总大小，也就是 $S = \\sigma{1}{i} S_i$\n- R -- C0 接受到的插入速度（假设速度相对稳定），单位 byte/s\n- 每层的中数据量保持稳定，且接近该层的阈值\n- 每个 entry 只从 C0 插入，从 C_K 删除，中间层不删除 entry\n- C_K 的大小保持相对恒定，删除与插入保持相对的平衡，C_K 层的删除，可以理解为不增加插入速度的情况下将 entry 从 C_0 删除\n\n\n假定 LSM-Tree 有 K + 1 层，其中 S_0 和 S_K 固定，S_0 接受到的插入速度 R 恒定\n问题：求所有的 $ r_i $ 使得整个 LSM-Tree 的总 I/O  速度 H 最小。\n\n证明过程如下：\n1. 由于假设每条数据从 C_0 插入后，一直到最底层 C_{K} 才会被删除，则所有相邻层 (C_{i-1}, C_{i}) 的 I/O 速度和 C_0 接受到的 I/O 速度一致，均是 C_0 接受的插入速度 R。\n2. 如果 C_{i-1} 和 C_{i} 都在磁盘上，那么 C_{i-1} 层从磁盘上读取的 I/O 速度就是 $ R/S_P $（这部分数据会被移入到 $C_{i}$ 层，其中 $S_P$ 是单 page 的字节数大小，从 C_{i} 层会有 $r_i * R/S_P$ 的读取 I/O（一个 C_{i-1} 层平均对应 C_{i} 层 r_i 个 page），然后所有读取的数据会写入到 $C_i$ 层，其速度是 $ (r_i + 1) * R / S_p $ (从 C_{i-1] 与 C_{i} 读取的数据都会写入到 C_{i} 层中，不会中途删除)，因此整个 LSM-Tree 的总 I/O 速度 H 可以用公式计算如下： $ H = (R / S_P) * ((2 * r_1 + 1) + (2 * r_2 + 2) + ... + (2*r_{K-1} + 2) + (2*r_K + 1)). 其中 $ (2 * r_i + k) $ 表示 rolling merge 过程中第 i 层的总 I/O 量，其中 $ r_i * R / S_p $ 表示从 C_{i-1} merge 到 C_{i} 中从第 i 层读取的 I/O 量，(r_i + 1)*R/S_P 表示从 C_{i-1} merge 到 C_{i』 层后写入到第 i 层的 I/O 量，R/S_P 表示从第 i 层 rolling merge 到第 i + 1 层时的读取 I/O （C_0 没有 I/O，C_K 不需要合并到更下一层，没有下一层对应的 I/O)\n6. 简化 H 后得到 $ H + (R / S_P) * ((2 * r_1 + 2) + (2 * r_2 + 2) + ... + (2*r_{K-1} + 1) + (2 * r_K + 1))  = (2R/S_p) (\\sigma{1}{K} r_i + K - \\frac{1}{2}) $\n7. 需要在已知条件下求 H 的最小值，其中 S_K 和 S_0 恒定，可以换算为同等已知条件 $ \\prod\\limits_{1}^K r_i = (S_k / S_0) = C $\n8. 也就是希望在 $ \\prod\\limits_{1}^K r_i = (S_k / S_0) = C $ 的情况下求 $ \\sigma{1}{K} r_i $ 的最小值。\n9. 通过求偏导，得到 $ 0 = 1 - \\frac{1}{r_j} * C * \\prod\\limits_{1}^{K-1} r_j^{-1}.  然后求的每个 r_j 等于 $ C * \\prod\\limits_{1}^{K-1} r_j^{-1} $ 或者 $ C^{\\frac{1}/{K}} $ 情况下求的最小值。\n9. 在 LSM-Tree 中，相邻层然后把条件放宽（也就是不固定最大层的大小），每一层是上一层的 r 倍，由于正常情况下 r 会比较大，因此最大层会占据所有数据的大头（S_K ~~ S），那么固定整体大小 S 和 固定 S_K 就近似（上面的推导过程）\n\n> 其中通过求偏导得到最小值的过程，自己推导的结果与论文中有差异，如果有人知道，恳请告知，自己推导的结果是 $ 0 = -\\frac{1}{r_j} * C * \\prod\\limits_{1}^{K-1} r_j^{-1} $ 不是论文中的 $ 0 = 1 - \\frac{1}{r_j} * C * \\prod\\limits_{1}^{K-1} r_j^{-1} $。\n\n根据已知条件与上述证明可得\n- $ S = S_0 + r * S_0 + r^2 * S_0 + ... + r^K * S_0 $\n- $ H = (2R / S_p)*(K * (1 + r) - 1/ 2) -- 其中 R 是插入速度，S_p 是页大小，K 是磁盘上的层数，r 是相邻层的比值大小\n\n也就是 R 和 S_K 均保持不变的情况下，H 于 S_0 负相关（内存大小），与 r （相邻层的大小比例）正相关。\n\n\n可以使用两层 LSM-Tree 进行具体的推演\n```\n两层的 LSM-Tree 中\n- K = 1， r = S_1 / S_0\n- H  = \\frac{2R}{S_P}(K*(1+r) - \\frac{1}{2})\n- COST_tot = COST_m * S_0 + max(COST_d * S_1, COST_\\pi * H)\n- s = (COST_m * S_0) / (COST_d * S_1) -- cost of memory relative to storage cost for S_1 data\n- t = 2 ((R/S_p) / S_1) * (COST_\\pi /COST_d) * (COST_m / COST_d)\n- C = COST_tot / (COST_d * S_1)\n\n当 S_0 / S1 比较小的时候， C ~ s + max(1, t/s) \n```\n\n其中 C 是 t 和 s 的函数，其中 t 是应用的平均访问热度（the variable t is a kind of normalized temperature measuring the basic multi-page block I/O rate required by the application），s 表示使用的内存大小。\n\n最简单的来说，可以让 s = t, 这样 C  = s + 1，这样磁盘得到充分利用（I/O 的存储和访问量都打满）。\n\n> 个人理解这里是假定总存储量（磁盘所需空间）已知，且访问热度已知，也就是说 C 的最小值就是总成本的最小值。\n\n对于 t < 1 的情况，s = t 的成本是最小的，但是 t > 1 的情况下，C 在 s = t^{1/2} 的时候取得最小值，也就是 C = 2s = 2 t^{1/2}. 这个情况下 COST_tot = 2[(COST_m*S_1) * (2*COST_\\pi*R/S_p)]^{1/2}（通过 C = 2*t^{1/2} 以及 C = COST_tot / (COST_d * S_1) 然后换算得到），也就是说当 t > 1 的时候（两层的 LSM-Tree 最小代价如前所是），整体代价来源于两方面：1）内存的开销；2）I/O 访问的开销（由于 t 足够高，因此 I/O 开销比 I/O 存储代价更大）\n\n对于 t <= 1 的情况来说，C = s + 1 = t + 1 <= 2. 也就是说总在成本总是小于存储成本的两倍，因此通过存储需求来确定磁盘使用大小，然后利用所有的 I/O 能力来最小化内存使用。（尽可能打满对应存储所能提供的 I/O)\n\n### 具体例子计算 B-Tree 和 LSM-Tree 的成本分析\n上面对 LSM-Tree 和 B-Tree 做了定量分析，接下来使用具体例子计算 B-Tree 和 LSM-Tree 在具体场景下的成本对比。\n\n\n1 给定如下场景，计算 B-Tree 以及两层 LSM-Tree 的成本\n- R = 16000 byte（每个 entry 16 byte，也就是 1000 个 entry 每秒）\n- 总共 576 million entries（总存储空间 9.2Gbyte），每个 entry 的 ttl 是 20 days\n\n如果使用 B-Tree 的话，成本如下\n\n- 由于 I/O 访问是瓶颈，因此需要更多的磁盘存储空间才能满足对应的 I/O 访问（H = 2 * 1000 = 2000 随机访问），COST_P = 25$，那么随机访问的成本是 2000 * 25$ = 50,000$\n- 然后非叶子节点需要缓存，具体的缓存成本计算如下\n\t- 假设叶子节点 70% 满，也就是每个叶子节点有 0.7 * (4K / 16) = 180 个 entry，上层节点需要 576 million/180 = 3.2 million 数据，在加上部分前缀压缩的技术后，假设每个非叶子节点可以存储 200 条数据，也就是 3.2 million / 200 = 16000 个节点，每个 4KB，总共有 64MB 的内存存储空间\n\t- 64MB 的存储空间总成本是 64MB * 100$/MB  = 6400 $\n\t- 忽略其他一些细小的成本开销\n- B-Tree 的总成本 = 50000$ + 6400$ = 56400 $\n\n两层 LSM-Tree 的话，成本如下\n- 首先 C1 需要的总存储空间是 9.2Gbyte，总成本是 .1$/Mbyte * 92000Mbyte = 9200$\n- 根据 C1 的大小计算出打满情况下的 H  = 92000 / COST_\\pi = 9200 / 2.5 ~ 3700 page/s\n- 假设单 page 大小 4K 的情况下，根据 H 以及 H = (2*R/S_P)*(K*(1 + r) - 1/2) 计算得到 r ~ 460，可以得到 C_0 = C_1/460 = 9.2G / 460 = 20Mb\n- 20Mbyte C_0 的成本是 20MB * 100$/MB = 2000$，另外增加 2MB 用于 rolling merge 时使用，也就是 2000$ + 200$ = 2200$\n- 总成本是 9200 + 2200 = 11400$\n\n大致计算之后 LSM-Tree 比 B-Tree 的成本会低很多（11400 VS 56400)，相当于 B-Tree 的 1/5 左右\n\n2 如果 R 增加 10 倍，也就是 160000 byte/s，再计算 B-Tree，两层 LSM-Tree 以及三层 LSM-Tree 的成本\n- R = 160000 byte（单 entry 16 byte，也就是 10000 entry/s）\n- 576 million entries（总存储量 9.2GByte），每个 entry 的 ttl 是 20 days\n\nB-Tree 的情况下\n- 需要使用更多的磁盘来满足相应需求（主要是为了满足 I/O 的读写） 随机访问的总成本是 (2 * (160000 / 16)) * 25$ = 500,000$（相当于 500G 的存储，实际只需要 9.2G，也就是有 491G 的存储浪费）\n- buffer 非叶子节点的成本不变，也就是 6400$\n- 总成本 = 500,000$ + 6400$ = 506400$\n\n两层 LSM-Tree 的情况\n- 首先通过 t 的公式计算得到 t = 2*((R/S_p)/S_1)*(COST_\\pi/COST_d)*(COST_m/COST_d) ~ 2.2 > 1\n- 通过公式得到最低成本 = 2[(COST_m*S_1) * (2*COST_\\pi*R/S_p)]^{1/2} ~ 27129$，其中一半用于磁盘，一半用于内存开销，磁盘的总存储空间是 13.5G（27129/2/1 Mb），135M 的内存\n- 额外增加 2M 的内存用于 merge，200$ \n- 总成本 ~ 27329$\n\n对于三层 LSM-Tree 的情况\n- C_2 需要 9.2G 存储，总成本 9.2*1000*1$/Mb =9200$, 能提供的 I/O 访问频率 H  = 9.2 * 1000 / 2.5 ~ 3700\n- 根据 H  = (2R/S_p)*(K ( 1 + r) - 1/2) 计算得到 r ~ 23\n- C_0 = C_2 / r / r ~ 17MB，成本为 17 * 100$/Mb = 1700$\n- C_1 的成本是 C_2 的 1/r =  1/23 也就是 9200/23 * 1$/Mb = 400$ （由于是最大层成本的 1/23，因此在估算时也可以忽略）\n- 另外增加 4MB 用于 rolling merge，也就是 400$\n- 总成本 ~ 9200$ +  1700$ + 400$ + 400$ = 11700$\n\n对比可知 三层 LSM 的成本（11700$） < 两层 LSM 的成本（27329$） < B-Tree 的成本（506400$）\n\n## 4 未来可能的优化\n- 为了更好的平衡插入和查询性能，留取部分 I/O 供查询使用；另外在 rolling merge 的时候，可以适当保留部分上层数据（并不完全迁移）\n- 插入/合并的时候，CPU 做隔离，使用单独的 CPU 做合并，以及 LSM-Tree 结构的维护，这样可以在基本不增加延迟的情况下完成查找。\n\n\n# Ref\n[1] [The Log-Structured Merge-Tree (LSM-Tree)](https://www.cs.umb.edu/~poneil/lsmtree.pdf)  \n[2] [The Five Minute Rule](https://www.hpl.hp.com/techreports/tandem/TR-86.1.pdf)  \n[3] [Database Buffer and Disk Configuring and the Battle of the Bottlenecks]()  \n[4] [GPD Performance Evaluation Lab Database 2 Version 2 Utility Analysis, IBM Document Number GG09-1031-0, September 28, 1989]()  \n","source":"_posts/lsm-tree-1-2023-05-17.md","raw":"---\ntitle: lsm-tree\ndate: 2023-04-24 16:53:32\ntags: \n    - lsm\n    - lsm-tree\n    - minimum-global-awareness\n    - paper\ntoc: true\n---\n\n> 文章内容基于原论文，结合自己的理解和思考，发现有错漏的地方，欢迎反馈探讨，感谢。\n\nLSM-Tree 拥有优异的性能出现在各种存储引擎中，本文希望对 LSM-Tree 进行一个最小全局认识，对其有个骨架结构认识，从 LSM-Tree 的原始论文开始，到现在的进展以及 LSM-Tree 中各种影响的因素。\n\n<!-- more -->\n\n# 起始\n## 1 LSM-Tree 的缘起\n\nLSM-Tree 从论文[1] 中出生，在该论文中谈及了 LSM-Tree 诞生的原因，主要流程，优缺点，适合场景，以及决定性能的相关参数等。首先接下来重点介绍这篇 LSM-Tree 的原始论文。\n\n在论文[1] 之前的年代中，存储引擎主要使用 B-Tree 系列的数据结构，这种数据结构并不是 I/O 友好型的，随机 I/O 所带来的成本会比较高，尤其是写多读少的情况下，更新叶子节点会有两次随机 I/O（读+写），会有性能瓶颈。LSM-Tree 则以两个 batch 操作来优化 I/O 成本：1）首先写入 memory，然后 memory 的数据以 batch 形式写入磁盘；2）磁盘顺序读写，减少 seek 的成本（次数减少），均摊后单次成本更低。\n\n由论文[2] 中的结论可知，在一定范围内使用内存换 I/O 能减少整体成本。随着硬件的更新换代，内存和磁盘的成本关系也在变化，可根据具体使用的硬件进行对比。\n\n## 2 LSM-Tree 的结构，以及主要流程\nLSM-Tree 是一个多层的数据结构，其中第一层（最上层）保持在内存中，除第一层外的其他层均在磁盘（部分频繁访问的数据会 cache 在内存）。最简单的 LSM-Tree 拥有两层：内存中一层，磁盘中一层。接下来首先以两层 LSM-Tree 介绍相关功能，后续在定量分析过程中，会详细介绍多层 LSM-Tree 结构。\n\n两层 LSM-Tree 的结构如下所示：\n\n![tow-component-lsm](https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516141825.png)\n\n上图中 L0 与 L1 均是 tree-like 的数据结构，由于 L0 不需要特别考虑 tree high（都在内存，无 I/O），因此 B-Tree、AVL-Tree 以及 2-3-tree 等各种 tree like 数据结构读可以。 L1 保存在磁盘，需要考虑 tree high，使用 B-Tree。\n\n对 LSM-Tree 数据结构，首先看一下基本操作的流程(为了描述方便，L0 中的结构也以 B-Tree 为例）:\n\n- insert：数据直接写入内存 L0 中。在 L0 大小达到一定阈值后，会进行 rolling merge 操作（后面详述），将数据从 L0 转移到 L1。\n- get：读取数据的时候，首先从 L0 中进行查找，找到后直接返回（不管是否带 delete meta 信息的 key/value），否则继续从 L1 进行查找。\n- delete：如果 L0 中没有 key/value 对，则在 L0 中增加一个 key/value 对，且 value 包括 delete 相关的 meta 信息；如果 L0 中有对应的 key/value，则将 value 更改为包括 delete meta 信息的值。rolling merge 的时候将带有 delete meta 信息的 key/value 从 L_i 写入到 L_(i+1) 删除 L_i & L_(i + 1) 中的 key/value 对，然后在 L_(i+1) 插入一个带有 delete meta 信息的 key/value 对，当达到最底层的时候，将 key/value 对进行物理删除。同样 delete 的操作和 insert 一样，支持 batch 操作。\n- update：update 可以看作是 delete&insert 的组合\n\nLSM-Tree 为了保证更上层有空间接受插入的新数据，维护一个 rolling merge 的后台流程，该流程会从相邻两层中分别读取数据，写入到下层中，在 rolling merge 的过程中也可以进行部分逻辑处理：比如 ttl 的数据可以直接删除等。下图是一个 rolling merge 的示意图： \n\n![rolling-merge](https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516141924.png)\n\n## 3 LSM-Tree 相关的定量分析\n上文介绍了 LSM-Tree 诞生的原因，以及基本的流程，下面着重进行性能相关的定量分析，包括双层 LSM-Tree 以及多层 LSM-Tree。\n\n### 双层 LSM-Tree 的 IO 定量分析\n本节介绍双层 LSM-Tree 的 I/O 定量分析，以及和 B-Tree 的相关对比情况。\n\n以下对比内容基于 1995 年的硬件架构：\n\n- 1MByte 内存需要 100$\n- 1MByte 磁盘的存储需要 1$\n- 随机访问 I/O 成本是 25$\n- 顺序访问的 I/O 成本是 2.5$\n\n同时为了后面描述方便，定义变量如下:\n\n- $COST_d$ 表示磁盘存储 1MByte 所需要的成本\n- $COST_m $ 表示内存中存储 1MByte 所需要的成本\n- $ COST_P $ 表示提供 1 page 每秒所需要的磁盘成本（随机访问）\n- $ COST_\\pi $ 表示提供 1 page 每秒所需要的磁盘成本（顺序访问）\n\n内存的成本由存储空间决定，而磁盘的成本则由存储空间和访问频率的更大者决定。\n\n假设需要存储 S MByte 大小的数据，且每秒 H 的随机 I/O 访问（数据无缓存），则磁盘的开销是 $ COST_D = max(S * COST_d, H * COST_P $，其中 $ S*COST_d $ 表示存储所需成本，$ H * COST_P $ 则表示随机 I/O 访问的成本。\n\n当使用内存来缓存部分数据后，使得磁盘的瓶颈变为存储量后，则对应总成本是 $ COST-B = S * COST_m + S*COST_d $ 其中， $ S*COST_M $ 表示内存的成本，$ S*COST_d $ 表示磁盘的存储所需成本。\n\n综合上面两种情况可得，总共存储 S MByte 大小的数据，且每秒 H 随机访问的总成本公式如下所示：\n\n$ COST-TOT = min(max(S*COST_d, H*COST_P), S*COST_m + S*COST_d) $\n\n通过上述公式我们可以看到，整体的成本受总存储量，以及访问频率的影响，我们将 H/S（访问热度） 作为横轴，COST-TOT 作为纵轴画图得到如下曲线\n<Graph-of-cost-of-access-per-MByte-vs-Temperature.jpg> \n\n通过上图可知，总成本会随着访问热度的增长而增长，当达到一定程度后不在增长。上图中两个拐点将数据分为三段：cold，warm，hot。其中第一段的成本主要来源磁盘存储量，第二段则随着访问频率的增加而变多，第三段主要是内存与磁盘容量的成本。其中两个拐点则用如下公式定义\n\n- $ T_f = COST_d / COST_P = 1 / 25 = 0.04 $ 表示 cold 和 warm data 之间的拐点\n- $ T_b = COST_m / COST_P = 100 / 25 = 4 $ 表示 warm 和 hot data 之间的拐点\n\n> 对于连续 I/O 访问来说，也有类似上图的分析，而其中 warm 和 hot 的划分则是对 “The Five Minute Rule”[2] 的概括。\n\n根据论文[3] 中的说法，访问热度与实际的磁盘访问有关，而不是逻辑插入速度，LSM 也是通过减少实际的磁盘访问量来提效，LSM-Tree 有两个减少磁盘访问的点：1）先写内存，然后 batch 写磁盘；2）顺序访问磁盘。接下来接下下顺序 I/O 的收益。\n\n根据[4] 给的数据，随机读取一个磁盘页的耗时大概是 20ms（其中 10ms 用于磁道寻址，8.3ms 来源于旋转延迟，1.7ms 来源实际读取）。顺序读取 64 个磁盘页的耗时大概是 125ms（其中 10ms 来源于磁道寻址，8.3ms 来源于旋转延迟，106.9ms 来源于实际的数据读取），-- 平均后大概只需要 2ms 读取一个磁盘页，是随机访问的 1/10。也就是 $ COST_{\\pi} / COST_P = \\frac{1}{10} $。通过前面计算也能直观感受到顺序 I/O 所带来的(均摊)具巨大性能收益。\n\n\n我们使用[3] 中的给的结论来计算 \"五分钟规则\" 的参考区间 --  $ \\tau $，规则指出“维持每秒 1 page 访问所需要的成本与保存它所需的内存成本一致”，我们得到如下公式\n\n- $ \\frac{1}{ \\tau } * COST_P = pagesize * COST_m $  （I/O 速率 * 随机 I/O 的成本 = 内存存储的成本）\n\n那么 $ \\tau = (\\frac{1}{pagesize} * \\frac{COST_P}{COST_m}) = \\frac{1}{pagesize * T_b} $，如果每个 page 是 4k(0.004 Mb) 的话我们可以得到 `$\\tau = 1/(0.004 * 4) = 62.5 seconds/IO`。换句话说在访问间隔小于 62.5 seconds/IO 的时候，用内存换磁盘是合理的（现在需要根据硬件成本进行具体计算）。\n\n### B-Tree 和 LSM-Tree 的定量分析对比\n在进行 B-Tree 和 LSM-Tree 的对比分析之前，先单独进行 B-Tree 和 LSM-Tree 的分析。主要对比 insert 的性能，同时忽略了 index 更新过程中所带来的微小 I/O 成本。\n\n#### B-Tree 的定量分析\n> 假设所有的 insert 是完全随机的，因此不会有叶子节点 buffer 在内存的情况。\n\n根据论文[5] 的结论，B-Tree 中的有效深度 - $D_e$ - 表示随机查找中，未在 buffer 中命中的平均 page 数目。在 B-Tree 的插入中，首先需要进行 $D_e$ 次 I/O 查找对应的叶子节点，更新改节点，然后将脏页写回（1 I/O），因此整个 I/O 的开销如下所示\n\n$ COST_{B-ins} = COST_P * (D_e + 1) $\n\n#### LSM 的定量分析\n\n由于 LSM 的单 entry insert 时直接写入内存，可能没有 I/O 开销，因此分析 LSM-Tree 的 insert I/O 开销时，使用均摊分析进行。\n\n首先定义一些变量如下\n\n- $ S_e $ 表示 entry（index entry） 的大小（byte 为单位）\n- $ S_p $ 表示 page size 的大小（byte 为单位）\n- $ S_0 $ 表示 C0 中叶子节点的大小（MByte 为单位）\n- $ S_1 $ 表示 C1 中叶子节点的大小（MByte 为单位）\n- M 表示 rolling merge 的过程中平均有多少个 entry 插入到 __每个__ C1 的叶子节点 (a given LSM-tree as the average number of entries in the C0 tree inserted into __each__ single page leaf node of the C1 tree during the rolling merge)\n\n每个 page 中的 entry 数目大致为 $ S_p / S_e $，整个 LSM-tree 中在 C0 中的数据比例是 $ S_0 / (S_0 + S_1) $ )，因此 rolling merge 过程中会平均插入到每个 C1 叶子节点的 entry 数 M 可以通过其他公式计算得到 $ M = (S_p/S_e) * (S_0/(S_0 + S_1)) $。\n\n根据上述公式可以得到 LSM-Tree insert 的均摊开销为（将 C1 叶子节点读入和写出内存的开销均摊到 M 个 entry 上）\n\n$ COST_{LSM-ins} = 2 * COST_{\\pi} / M $ （读写一次 C1 的叶子节点，平均涉及到 M 个 entry）\n\n#### 对比\n\n观察 B-Tree 和 LSM-Tree 的 insert I/O 开销我们可以得到如下的公式\n\n$ COST_{LSM-ins} / COST_{B-ins} = K1 * (COST_{\\pi}/COST_{P}) * (1 / M) $  \n\n其中 $ K1 ~ 2/(D_e + 1) $ 是一个常数\n\n上述公式对比展示出，LSM-Tree 比 B-Tree 的优势主要来自于两方面：1）$COST_{\\pi}/COST_{P}$ 也就是磁盘的连续访问相比随机访问所带来的优势；2）M 也就是 rolling merge 时批量写入到 C1 中单个叶子节点的平均 entry 数目（注意 M 并不是一定会大于 1）。\n\n在 B-Tree 作为索引的情况下，如果整体访问热度比较高的话，则可以使用上述公式进行粗略的估算，使用 LSM-Tree 之后大概会有多少收益。\n\n### 多 component LSM-Tree 的分析\n上面所有关于 LSM-Tree 的讨论均假设 LSM-Tree 是两层的，在实际的生成中，LSM-Tree 则可能会有多层，具体的层数，以及相邻层之间的大小比例等可以通过分析得出，本节介绍多层 LSM-Tree 相关的分析。\n\n> 为了方便讨论，下面的描述中，假设 LSM-Tree 中的 entry 在插入后，仅在最底层进行删除。\n\n上面几节中的分析可以得到从 C0 写入到 C1 每个叶子节点的平均 entry 数目 M 并不一定大于 1，如果 M <= 1 的话，则 LSM-Tree 两个优势中的一个：“批量更新” 就失效了，因此如果分析得知 $ M < K1 * COST_{\\pi} / COSTP $ 的话则 B-Treee 比 LSM-Tree 会更好。另外一方面，为了更好的利用 LSM-Tree 的优势，则需要尽可能增大 M（也就是 C0 和 C1 的比值需要更大）；同时无限增大 C0  则会由于内存消耗更高造成成本过高，因此需要综合考虑计算一个总成本更小的参数值。\n\n为了保持 LSM-Tree 中上层有空间持续接受新数据，因此 rolling merge 从上层读取并删除的速度与 C0 接受到插入速度需要保持一致。\n\n在两层的 LSM-Tree 中，可以从 LSM-Tree 的总成本出发，寻找更合适的 C0 大小。首先从一个较大的 C0 开始，逐渐减小 C0 的大小（同时 I/O 开销会增加，I/O 的访问频率和存储成本会越来越小），直到达到一个平衡（此情况下再减少 C0 的大小会导致总成本增加）。另外的一个思路则是使用多层的 LSM-Tree 结构（这可以减少 C0 的大小，同时减少 I/O 的访问频率），同时没多一层会多部分 I/O 操作，因此需要综合考虑。\n\n下图是一个多层 LSM-Tree 的结构\n\n![multi-component-lsm-tree](https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516142001.png)\n\n对于 K+1 层的 LSM-Tree 来说，总共有 C0, C1, C2, ... C_{K-1} 以及 C_K，并且每层的大小递增（C1 比 C0 大，C2 比 C1 大，依次类推，最小的层 C0 在内存，其他的所有均在磁盘），相邻层之间会有异步的 rolling merge 过程，将 C_{i - 1} 层的数据迁移到 C_i 层中。对于一个插入后从未删除的 entry 来说，会从最上层 C0 逐步迁移到最底层 C_K 中。\n\n接下来会通过定量的分析来说明多层 LSM-Tree 中不同参数对总成本的影响，并且推导得出一个总成本更低的参数组合。\n\n首先定义一些在定量分析中需要的参数与假设\n- $ S(C_i) $ -- 表示 LSM-Tree 第 i 层叶子层所有 entry 的总大小（单位是 byte）\n- $ S_i $ -- 表示 LSM-Tree 中第 i 层所有 entry 的总大小（单位是 byte），也就是 $S(C_i) = S_i$\n- $ r_i = S_i / S_{i-1} $  -- 表示相邻两层中的总大小比例\n- S -- 表示所有层中叶子节点的总大小，也就是 $S = \\sigma{1}{i} S_i$\n- R -- C0 接受到的插入速度（假设速度相对稳定），单位 byte/s\n- 每层的中数据量保持稳定，且接近该层的阈值\n- 每个 entry 只从 C0 插入，从 C_K 删除，中间层不删除 entry\n- C_K 的大小保持相对恒定，删除与插入保持相对的平衡，C_K 层的删除，可以理解为不增加插入速度的情况下将 entry 从 C_0 删除\n\n\n假定 LSM-Tree 有 K + 1 层，其中 S_0 和 S_K 固定，S_0 接受到的插入速度 R 恒定\n问题：求所有的 $ r_i $ 使得整个 LSM-Tree 的总 I/O  速度 H 最小。\n\n证明过程如下：\n1. 由于假设每条数据从 C_0 插入后，一直到最底层 C_{K} 才会被删除，则所有相邻层 (C_{i-1}, C_{i}) 的 I/O 速度和 C_0 接受到的 I/O 速度一致，均是 C_0 接受的插入速度 R。\n2. 如果 C_{i-1} 和 C_{i} 都在磁盘上，那么 C_{i-1} 层从磁盘上读取的 I/O 速度就是 $ R/S_P $（这部分数据会被移入到 $C_{i}$ 层，其中 $S_P$ 是单 page 的字节数大小，从 C_{i} 层会有 $r_i * R/S_P$ 的读取 I/O（一个 C_{i-1} 层平均对应 C_{i} 层 r_i 个 page），然后所有读取的数据会写入到 $C_i$ 层，其速度是 $ (r_i + 1) * R / S_p $ (从 C_{i-1] 与 C_{i} 读取的数据都会写入到 C_{i} 层中，不会中途删除)，因此整个 LSM-Tree 的总 I/O 速度 H 可以用公式计算如下： $ H = (R / S_P) * ((2 * r_1 + 1) + (2 * r_2 + 2) + ... + (2*r_{K-1} + 2) + (2*r_K + 1)). 其中 $ (2 * r_i + k) $ 表示 rolling merge 过程中第 i 层的总 I/O 量，其中 $ r_i * R / S_p $ 表示从 C_{i-1} merge 到 C_{i} 中从第 i 层读取的 I/O 量，(r_i + 1)*R/S_P 表示从 C_{i-1} merge 到 C_{i』 层后写入到第 i 层的 I/O 量，R/S_P 表示从第 i 层 rolling merge 到第 i + 1 层时的读取 I/O （C_0 没有 I/O，C_K 不需要合并到更下一层，没有下一层对应的 I/O)\n6. 简化 H 后得到 $ H + (R / S_P) * ((2 * r_1 + 2) + (2 * r_2 + 2) + ... + (2*r_{K-1} + 1) + (2 * r_K + 1))  = (2R/S_p) (\\sigma{1}{K} r_i + K - \\frac{1}{2}) $\n7. 需要在已知条件下求 H 的最小值，其中 S_K 和 S_0 恒定，可以换算为同等已知条件 $ \\prod\\limits_{1}^K r_i = (S_k / S_0) = C $\n8. 也就是希望在 $ \\prod\\limits_{1}^K r_i = (S_k / S_0) = C $ 的情况下求 $ \\sigma{1}{K} r_i $ 的最小值。\n9. 通过求偏导，得到 $ 0 = 1 - \\frac{1}{r_j} * C * \\prod\\limits_{1}^{K-1} r_j^{-1}.  然后求的每个 r_j 等于 $ C * \\prod\\limits_{1}^{K-1} r_j^{-1} $ 或者 $ C^{\\frac{1}/{K}} $ 情况下求的最小值。\n9. 在 LSM-Tree 中，相邻层然后把条件放宽（也就是不固定最大层的大小），每一层是上一层的 r 倍，由于正常情况下 r 会比较大，因此最大层会占据所有数据的大头（S_K ~~ S），那么固定整体大小 S 和 固定 S_K 就近似（上面的推导过程）\n\n> 其中通过求偏导得到最小值的过程，自己推导的结果与论文中有差异，如果有人知道，恳请告知，自己推导的结果是 $ 0 = -\\frac{1}{r_j} * C * \\prod\\limits_{1}^{K-1} r_j^{-1} $ 不是论文中的 $ 0 = 1 - \\frac{1}{r_j} * C * \\prod\\limits_{1}^{K-1} r_j^{-1} $。\n\n根据已知条件与上述证明可得\n- $ S = S_0 + r * S_0 + r^2 * S_0 + ... + r^K * S_0 $\n- $ H = (2R / S_p)*(K * (1 + r) - 1/ 2) -- 其中 R 是插入速度，S_p 是页大小，K 是磁盘上的层数，r 是相邻层的比值大小\n\n也就是 R 和 S_K 均保持不变的情况下，H 于 S_0 负相关（内存大小），与 r （相邻层的大小比例）正相关。\n\n\n可以使用两层 LSM-Tree 进行具体的推演\n```\n两层的 LSM-Tree 中\n- K = 1， r = S_1 / S_0\n- H  = \\frac{2R}{S_P}(K*(1+r) - \\frac{1}{2})\n- COST_tot = COST_m * S_0 + max(COST_d * S_1, COST_\\pi * H)\n- s = (COST_m * S_0) / (COST_d * S_1) -- cost of memory relative to storage cost for S_1 data\n- t = 2 ((R/S_p) / S_1) * (COST_\\pi /COST_d) * (COST_m / COST_d)\n- C = COST_tot / (COST_d * S_1)\n\n当 S_0 / S1 比较小的时候， C ~ s + max(1, t/s) \n```\n\n其中 C 是 t 和 s 的函数，其中 t 是应用的平均访问热度（the variable t is a kind of normalized temperature measuring the basic multi-page block I/O rate required by the application），s 表示使用的内存大小。\n\n最简单的来说，可以让 s = t, 这样 C  = s + 1，这样磁盘得到充分利用（I/O 的存储和访问量都打满）。\n\n> 个人理解这里是假定总存储量（磁盘所需空间）已知，且访问热度已知，也就是说 C 的最小值就是总成本的最小值。\n\n对于 t < 1 的情况，s = t 的成本是最小的，但是 t > 1 的情况下，C 在 s = t^{1/2} 的时候取得最小值，也就是 C = 2s = 2 t^{1/2}. 这个情况下 COST_tot = 2[(COST_m*S_1) * (2*COST_\\pi*R/S_p)]^{1/2}（通过 C = 2*t^{1/2} 以及 C = COST_tot / (COST_d * S_1) 然后换算得到），也就是说当 t > 1 的时候（两层的 LSM-Tree 最小代价如前所是），整体代价来源于两方面：1）内存的开销；2）I/O 访问的开销（由于 t 足够高，因此 I/O 开销比 I/O 存储代价更大）\n\n对于 t <= 1 的情况来说，C = s + 1 = t + 1 <= 2. 也就是说总在成本总是小于存储成本的两倍，因此通过存储需求来确定磁盘使用大小，然后利用所有的 I/O 能力来最小化内存使用。（尽可能打满对应存储所能提供的 I/O)\n\n### 具体例子计算 B-Tree 和 LSM-Tree 的成本分析\n上面对 LSM-Tree 和 B-Tree 做了定量分析，接下来使用具体例子计算 B-Tree 和 LSM-Tree 在具体场景下的成本对比。\n\n\n1 给定如下场景，计算 B-Tree 以及两层 LSM-Tree 的成本\n- R = 16000 byte（每个 entry 16 byte，也就是 1000 个 entry 每秒）\n- 总共 576 million entries（总存储空间 9.2Gbyte），每个 entry 的 ttl 是 20 days\n\n如果使用 B-Tree 的话，成本如下\n\n- 由于 I/O 访问是瓶颈，因此需要更多的磁盘存储空间才能满足对应的 I/O 访问（H = 2 * 1000 = 2000 随机访问），COST_P = 25$，那么随机访问的成本是 2000 * 25$ = 50,000$\n- 然后非叶子节点需要缓存，具体的缓存成本计算如下\n\t- 假设叶子节点 70% 满，也就是每个叶子节点有 0.7 * (4K / 16) = 180 个 entry，上层节点需要 576 million/180 = 3.2 million 数据，在加上部分前缀压缩的技术后，假设每个非叶子节点可以存储 200 条数据，也就是 3.2 million / 200 = 16000 个节点，每个 4KB，总共有 64MB 的内存存储空间\n\t- 64MB 的存储空间总成本是 64MB * 100$/MB  = 6400 $\n\t- 忽略其他一些细小的成本开销\n- B-Tree 的总成本 = 50000$ + 6400$ = 56400 $\n\n两层 LSM-Tree 的话，成本如下\n- 首先 C1 需要的总存储空间是 9.2Gbyte，总成本是 .1$/Mbyte * 92000Mbyte = 9200$\n- 根据 C1 的大小计算出打满情况下的 H  = 92000 / COST_\\pi = 9200 / 2.5 ~ 3700 page/s\n- 假设单 page 大小 4K 的情况下，根据 H 以及 H = (2*R/S_P)*(K*(1 + r) - 1/2) 计算得到 r ~ 460，可以得到 C_0 = C_1/460 = 9.2G / 460 = 20Mb\n- 20Mbyte C_0 的成本是 20MB * 100$/MB = 2000$，另外增加 2MB 用于 rolling merge 时使用，也就是 2000$ + 200$ = 2200$\n- 总成本是 9200 + 2200 = 11400$\n\n大致计算之后 LSM-Tree 比 B-Tree 的成本会低很多（11400 VS 56400)，相当于 B-Tree 的 1/5 左右\n\n2 如果 R 增加 10 倍，也就是 160000 byte/s，再计算 B-Tree，两层 LSM-Tree 以及三层 LSM-Tree 的成本\n- R = 160000 byte（单 entry 16 byte，也就是 10000 entry/s）\n- 576 million entries（总存储量 9.2GByte），每个 entry 的 ttl 是 20 days\n\nB-Tree 的情况下\n- 需要使用更多的磁盘来满足相应需求（主要是为了满足 I/O 的读写） 随机访问的总成本是 (2 * (160000 / 16)) * 25$ = 500,000$（相当于 500G 的存储，实际只需要 9.2G，也就是有 491G 的存储浪费）\n- buffer 非叶子节点的成本不变，也就是 6400$\n- 总成本 = 500,000$ + 6400$ = 506400$\n\n两层 LSM-Tree 的情况\n- 首先通过 t 的公式计算得到 t = 2*((R/S_p)/S_1)*(COST_\\pi/COST_d)*(COST_m/COST_d) ~ 2.2 > 1\n- 通过公式得到最低成本 = 2[(COST_m*S_1) * (2*COST_\\pi*R/S_p)]^{1/2} ~ 27129$，其中一半用于磁盘，一半用于内存开销，磁盘的总存储空间是 13.5G（27129/2/1 Mb），135M 的内存\n- 额外增加 2M 的内存用于 merge，200$ \n- 总成本 ~ 27329$\n\n对于三层 LSM-Tree 的情况\n- C_2 需要 9.2G 存储，总成本 9.2*1000*1$/Mb =9200$, 能提供的 I/O 访问频率 H  = 9.2 * 1000 / 2.5 ~ 3700\n- 根据 H  = (2R/S_p)*(K ( 1 + r) - 1/2) 计算得到 r ~ 23\n- C_0 = C_2 / r / r ~ 17MB，成本为 17 * 100$/Mb = 1700$\n- C_1 的成本是 C_2 的 1/r =  1/23 也就是 9200/23 * 1$/Mb = 400$ （由于是最大层成本的 1/23，因此在估算时也可以忽略）\n- 另外增加 4MB 用于 rolling merge，也就是 400$\n- 总成本 ~ 9200$ +  1700$ + 400$ + 400$ = 11700$\n\n对比可知 三层 LSM 的成本（11700$） < 两层 LSM 的成本（27329$） < B-Tree 的成本（506400$）\n\n## 4 未来可能的优化\n- 为了更好的平衡插入和查询性能，留取部分 I/O 供查询使用；另外在 rolling merge 的时候，可以适当保留部分上层数据（并不完全迁移）\n- 插入/合并的时候，CPU 做隔离，使用单独的 CPU 做合并，以及 LSM-Tree 结构的维护，这样可以在基本不增加延迟的情况下完成查找。\n\n\n# Ref\n[1] [The Log-Structured Merge-Tree (LSM-Tree)](https://www.cs.umb.edu/~poneil/lsmtree.pdf)  \n[2] [The Five Minute Rule](https://www.hpl.hp.com/techreports/tandem/TR-86.1.pdf)  \n[3] [Database Buffer and Disk Configuring and the Battle of the Bottlenecks]()  \n[4] [GPD Performance Evaluation Lab Database 2 Version 2 Utility Analysis, IBM Document Number GG09-1031-0, September 28, 1989]()  \n","slug":"lsm-tree-1-2023-05-17","published":1,"updated":"2024-05-06T02:52:12.101Z","_id":"clhsl7avl00042uv91n8t5gkt","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>文章内容基于原论文，结合自己的理解和思考，发现有错漏的地方，欢迎反馈探讨，感谢。</p>\n</blockquote>\n<p>LSM-Tree 拥有优异的性能出现在各种存储引擎中，本文希望对 LSM-Tree 进行一个最小全局认识，对其有个骨架结构认识，从 LSM-Tree 的原始论文开始，到现在的进展以及 LSM-Tree 中各种影响的因素。</p>\n<span id=\"more\"></span>\n<h1 id=\"起始\"><a href=\"#起始\" class=\"headerlink\" title=\"起始\"></a>起始</h1><h2 id=\"1-LSM-Tree-的缘起\"><a href=\"#1-LSM-Tree-的缘起\" class=\"headerlink\" title=\"1 LSM-Tree 的缘起\"></a>1 LSM-Tree 的缘起</h2><p>LSM-Tree 从论文[1] 中出生，在该论文中谈及了 LSM-Tree 诞生的原因，主要流程，优缺点，适合场景，以及决定性能的相关参数等。首先接下来重点介绍这篇 LSM-Tree 的原始论文。</p>\n<p>在论文[1] 之前的年代中，存储引擎主要使用 B-Tree 系列的数据结构，这种数据结构并不是 I/O 友好型的，随机 I/O 所带来的成本会比较高，尤其是写多读少的情况下，更新叶子节点会有两次随机 I/O（读+写），会有性能瓶颈。LSM-Tree 则以两个 batch 操作来优化 I/O 成本：1）首先写入 memory，然后 memory 的数据以 batch 形式写入磁盘；2）磁盘顺序读写，减少 seek 的成本（次数减少），均摊后单次成本更低。</p>\n<p>由论文[2] 中的结论可知，在一定范围内使用内存换 I/O 能减少整体成本。随着硬件的更新换代，内存和磁盘的成本关系也在变化，可根据具体使用的硬件进行对比。</p>\n<h2 id=\"2-LSM-Tree-的结构，以及主要流程\"><a href=\"#2-LSM-Tree-的结构，以及主要流程\" class=\"headerlink\" title=\"2 LSM-Tree 的结构，以及主要流程\"></a>2 LSM-Tree 的结构，以及主要流程</h2><p>LSM-Tree 是一个多层的数据结构，其中第一层（最上层）保持在内存中，除第一层外的其他层均在磁盘（部分频繁访问的数据会 cache 在内存）。最简单的 LSM-Tree 拥有两层：内存中一层，磁盘中一层。接下来首先以两层 LSM-Tree 介绍相关功能，后续在定量分析过程中，会详细介绍多层 LSM-Tree 结构。</p>\n<p>两层 LSM-Tree 的结构如下所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516141825.png\" alt=\"tow-component-lsm\"></p>\n<p>上图中 L0 与 L1 均是 tree-like 的数据结构，由于 L0 不需要特别考虑 tree high（都在内存，无 I/O），因此 B-Tree、AVL-Tree 以及 2-3-tree 等各种 tree like 数据结构读可以。 L1 保存在磁盘，需要考虑 tree high，使用 B-Tree。</p>\n<p>对 LSM-Tree 数据结构，首先看一下基本操作的流程(为了描述方便，L0 中的结构也以 B-Tree 为例）:</p>\n<ul>\n<li>insert：数据直接写入内存 L0 中。在 L0 大小达到一定阈值后，会进行 rolling merge 操作（后面详述），将数据从 L0 转移到 L1。</li>\n<li>get：读取数据的时候，首先从 L0 中进行查找，找到后直接返回（不管是否带 delete meta 信息的 key/value），否则继续从 L1 进行查找。</li>\n<li>delete：如果 L0 中没有 key/value 对，则在 L0 中增加一个 key/value 对，且 value 包括 delete 相关的 meta 信息；如果 L0 中有对应的 key/value，则将 value 更改为包括 delete meta 信息的值。rolling merge 的时候将带有 delete meta 信息的 key/value 从 L_i 写入到 L_(i+1) 删除 L_i &amp; L_(i + 1) 中的 key/value 对，然后在 L_(i+1) 插入一个带有 delete meta 信息的 key/value 对，当达到最底层的时候，将 key/value 对进行物理删除。同样 delete 的操作和 insert 一样，支持 batch 操作。</li>\n<li>update：update 可以看作是 delete&amp;insert 的组合</li>\n</ul>\n<p>LSM-Tree 为了保证更上层有空间接受插入的新数据，维护一个 rolling merge 的后台流程，该流程会从相邻两层中分别读取数据，写入到下层中，在 rolling merge 的过程中也可以进行部分逻辑处理：比如 ttl 的数据可以直接删除等。下图是一个 rolling merge 的示意图： </p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516141924.png\" alt=\"rolling-merge\"></p>\n<h2 id=\"3-LSM-Tree-相关的定量分析\"><a href=\"#3-LSM-Tree-相关的定量分析\" class=\"headerlink\" title=\"3 LSM-Tree 相关的定量分析\"></a>3 LSM-Tree 相关的定量分析</h2><p>上文介绍了 LSM-Tree 诞生的原因，以及基本的流程，下面着重进行性能相关的定量分析，包括双层 LSM-Tree 以及多层 LSM-Tree。</p>\n<h3 id=\"双层-LSM-Tree-的-IO-定量分析\"><a href=\"#双层-LSM-Tree-的-IO-定量分析\" class=\"headerlink\" title=\"双层 LSM-Tree 的 IO 定量分析\"></a>双层 LSM-Tree 的 IO 定量分析</h3><p>本节介绍双层 LSM-Tree 的 I/O 定量分析，以及和 B-Tree 的相关对比情况。</p>\n<p>以下对比内容基于 1995 年的硬件架构：</p>\n<ul>\n<li>1MByte 内存需要 100$</li>\n<li>1MByte 磁盘的存储需要 1$</li>\n<li>随机访问 I/O 成本是 25$</li>\n<li>顺序访问的 I/O 成本是 2.5$</li>\n</ul>\n<p>同时为了后面描述方便，定义变量如下:</p>\n<ul>\n<li>$COST_d$ 表示磁盘存储 1MByte 所需要的成本</li>\n<li>$COST_m $ 表示内存中存储 1MByte 所需要的成本</li>\n<li>$ COST_P $ 表示提供 1 page 每秒所需要的磁盘成本（随机访问）</li>\n<li>$ COST_\\pi $ 表示提供 1 page 每秒所需要的磁盘成本（顺序访问）</li>\n</ul>\n<p>内存的成本由存储空间决定，而磁盘的成本则由存储空间和访问频率的更大者决定。</p>\n<p>假设需要存储 S MByte 大小的数据，且每秒 H 的随机 I/O 访问（数据无缓存），则磁盘的开销是 $ COST_D = max(S <em> COST_d, H </em> COST_P $，其中 $ S<em>COST_d $ 表示存储所需成本，$ H </em> COST_P $ 则表示随机 I/O 访问的成本。</p>\n<p>当使用内存来缓存部分数据后，使得磁盘的瓶颈变为存储量后，则对应总成本是 $ COST-B = S <em> COST_m + S</em>COST_d $ 其中， $ S<em>COST_M $ 表示内存的成本，$ S</em>COST_d $ 表示磁盘的存储所需成本。</p>\n<p>综合上面两种情况可得，总共存储 S MByte 大小的数据，且每秒 H 随机访问的总成本公式如下所示：</p>\n<p>$ COST-TOT = min(max(S<em>COST_d, H</em>COST_P), S<em>COST_m + S</em>COST_d) $</p>\n<p>通过上述公式我们可以看到，整体的成本受总存储量，以及访问频率的影响，我们将 H/S（访问热度） 作为横轴，COST-TOT 作为纵轴画图得到如下曲线</p>\n<Graph-of-cost-of-access-per-MByte-vs-Temperature.jpg> \n\n<p>通过上图可知，总成本会随着访问热度的增长而增长，当达到一定程度后不在增长。上图中两个拐点将数据分为三段：cold，warm，hot。其中第一段的成本主要来源磁盘存储量，第二段则随着访问频率的增加而变多，第三段主要是内存与磁盘容量的成本。其中两个拐点则用如下公式定义</p>\n<ul>\n<li>$ T_f = COST_d / COST_P = 1 / 25 = 0.04 $ 表示 cold 和 warm data 之间的拐点</li>\n<li>$ T_b = COST_m / COST_P = 100 / 25 = 4 $ 表示 warm 和 hot data 之间的拐点</li>\n</ul>\n<blockquote>\n<p>对于连续 I/O 访问来说，也有类似上图的分析，而其中 warm 和 hot 的划分则是对 “The Five Minute Rule”[2] 的概括。</p>\n</blockquote>\n<p>根据论文[3] 中的说法，访问热度与实际的磁盘访问有关，而不是逻辑插入速度，LSM 也是通过减少实际的磁盘访问量来提效，LSM-Tree 有两个减少磁盘访问的点：1）先写内存，然后 batch 写磁盘；2）顺序访问磁盘。接下来接下下顺序 I/O 的收益。</p>\n<p>根据[4] 给的数据，随机读取一个磁盘页的耗时大概是 20ms（其中 10ms 用于磁道寻址，8.3ms 来源于旋转延迟，1.7ms 来源实际读取）。顺序读取 64 个磁盘页的耗时大概是 125ms（其中 10ms 来源于磁道寻址，8.3ms 来源于旋转延迟，106.9ms 来源于实际的数据读取），— 平均后大概只需要 2ms 读取一个磁盘页，是随机访问的 1/10。也就是 $ COST_{\\pi} / COST_P = \\frac{1}{10} $。通过前面计算也能直观感受到顺序 I/O 所带来的(均摊)具巨大性能收益。</p>\n<p>我们使用[3] 中的给的结论来计算 “五分钟规则” 的参考区间 —  $ \\tau $，规则指出“维持每秒 1 page 访问所需要的成本与保存它所需的内存成本一致”，我们得到如下公式</p>\n<ul>\n<li>$ \\frac{1}{ \\tau } <em> COST_P = pagesize </em> COST_m $  （I/O 速率 * 随机 I/O 的成本 = 内存存储的成本）</li>\n</ul>\n<p>那么 $ \\tau = (\\frac{1}{pagesize} <em> \\frac{COST_P}{COST_m}) = \\frac{1}{pagesize </em> T_b} $，如果每个 page 是 4k(0.004 Mb) 的话我们可以得到 <code>$\\tau = 1/(0.004 * 4) = 62.5 seconds/IO</code>。换句话说在访问间隔小于 62.5 seconds/IO 的时候，用内存换磁盘是合理的（现在需要根据硬件成本进行具体计算）。</p>\n<h3 id=\"B-Tree-和-LSM-Tree-的定量分析对比\"><a href=\"#B-Tree-和-LSM-Tree-的定量分析对比\" class=\"headerlink\" title=\"B-Tree 和 LSM-Tree 的定量分析对比\"></a>B-Tree 和 LSM-Tree 的定量分析对比</h3><p>在进行 B-Tree 和 LSM-Tree 的对比分析之前，先单独进行 B-Tree 和 LSM-Tree 的分析。主要对比 insert 的性能，同时忽略了 index 更新过程中所带来的微小 I/O 成本。</p>\n<h4 id=\"B-Tree-的定量分析\"><a href=\"#B-Tree-的定量分析\" class=\"headerlink\" title=\"B-Tree 的定量分析\"></a>B-Tree 的定量分析</h4><blockquote>\n<p>假设所有的 insert 是完全随机的，因此不会有叶子节点 buffer 在内存的情况。</p>\n</blockquote>\n<p>根据论文[5] 的结论，B-Tree 中的有效深度 - $D_e$ - 表示随机查找中，未在 buffer 中命中的平均 page 数目。在 B-Tree 的插入中，首先需要进行 $D_e$ 次 I/O 查找对应的叶子节点，更新改节点，然后将脏页写回（1 I/O），因此整个 I/O 的开销如下所示</p>\n<p>$ COST_{B-ins} = COST_P * (D_e + 1) $</p>\n<h4 id=\"LSM-的定量分析\"><a href=\"#LSM-的定量分析\" class=\"headerlink\" title=\"LSM 的定量分析\"></a>LSM 的定量分析</h4><p>由于 LSM 的单 entry insert 时直接写入内存，可能没有 I/O 开销，因此分析 LSM-Tree 的 insert I/O 开销时，使用均摊分析进行。</p>\n<p>首先定义一些变量如下</p>\n<ul>\n<li>$ S_e $ 表示 entry（index entry） 的大小（byte 为单位）</li>\n<li>$ S_p $ 表示 page size 的大小（byte 为单位）</li>\n<li>$ S_0 $ 表示 C0 中叶子节点的大小（MByte 为单位）</li>\n<li>$ S_1 $ 表示 C1 中叶子节点的大小（MByte 为单位）</li>\n<li>M 表示 rolling merge 的过程中平均有多少个 entry 插入到 <strong>每个</strong> C1 的叶子节点 (a given LSM-tree as the average number of entries in the C0 tree inserted into <strong>each</strong> single page leaf node of the C1 tree during the rolling merge)</li>\n</ul>\n<p>每个 page 中的 entry 数目大致为 $ S_p / S_e $，整个 LSM-tree 中在 C0 中的数据比例是 $ S_0 / (S_0 + S_1) $ )，因此 rolling merge 过程中会平均插入到每个 C1 叶子节点的 entry 数 M 可以通过其他公式计算得到 $ M = (S_p/S_e) * (S_0/(S_0 + S_1)) $。</p>\n<p>根据上述公式可以得到 LSM-Tree insert 的均摊开销为（将 C1 叶子节点读入和写出内存的开销均摊到 M 个 entry 上）</p>\n<p>$ COST_{LSM-ins} = 2 * COST_{\\pi} / M $ （读写一次 C1 的叶子节点，平均涉及到 M 个 entry）</p>\n<h4 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a>对比</h4><p>观察 B-Tree 和 LSM-Tree 的 insert I/O 开销我们可以得到如下的公式</p>\n<p>$ COST_{LSM-ins} / COST_{B-ins} = K1 <em> (COST_{\\pi}/COST_{P}) </em> (1 / M) $  </p>\n<p>其中 $ K1 ~ 2/(D_e + 1) $ 是一个常数</p>\n<p>上述公式对比展示出，LSM-Tree 比 B-Tree 的优势主要来自于两方面：1）$COST_{\\pi}/COST_{P}$ 也就是磁盘的连续访问相比随机访问所带来的优势；2）M 也就是 rolling merge 时批量写入到 C1 中单个叶子节点的平均 entry 数目（注意 M 并不是一定会大于 1）。</p>\n<p>在 B-Tree 作为索引的情况下，如果整体访问热度比较高的话，则可以使用上述公式进行粗略的估算，使用 LSM-Tree 之后大概会有多少收益。</p>\n<h3 id=\"多-component-LSM-Tree-的分析\"><a href=\"#多-component-LSM-Tree-的分析\" class=\"headerlink\" title=\"多 component LSM-Tree 的分析\"></a>多 component LSM-Tree 的分析</h3><p>上面所有关于 LSM-Tree 的讨论均假设 LSM-Tree 是两层的，在实际的生成中，LSM-Tree 则可能会有多层，具体的层数，以及相邻层之间的大小比例等可以通过分析得出，本节介绍多层 LSM-Tree 相关的分析。</p>\n<blockquote>\n<p>为了方便讨论，下面的描述中，假设 LSM-Tree 中的 entry 在插入后，仅在最底层进行删除。</p>\n</blockquote>\n<p>上面几节中的分析可以得到从 C0 写入到 C1 每个叶子节点的平均 entry 数目 M 并不一定大于 1，如果 M &lt;= 1 的话，则 LSM-Tree 两个优势中的一个：“批量更新” 就失效了，因此如果分析得知 $ M &lt; K1 * COST_{\\pi} / COSTP $ 的话则 B-Treee 比 LSM-Tree 会更好。另外一方面，为了更好的利用 LSM-Tree 的优势，则需要尽可能增大 M（也就是 C0 和 C1 的比值需要更大）；同时无限增大 C0  则会由于内存消耗更高造成成本过高，因此需要综合考虑计算一个总成本更小的参数值。</p>\n<p>为了保持 LSM-Tree 中上层有空间持续接受新数据，因此 rolling merge 从上层读取并删除的速度与 C0 接受到插入速度需要保持一致。</p>\n<p>在两层的 LSM-Tree 中，可以从 LSM-Tree 的总成本出发，寻找更合适的 C0 大小。首先从一个较大的 C0 开始，逐渐减小 C0 的大小（同时 I/O 开销会增加，I/O 的访问频率和存储成本会越来越小），直到达到一个平衡（此情况下再减少 C0 的大小会导致总成本增加）。另外的一个思路则是使用多层的 LSM-Tree 结构（这可以减少 C0 的大小，同时减少 I/O 的访问频率），同时没多一层会多部分 I/O 操作，因此需要综合考虑。</p>\n<p>下图是一个多层 LSM-Tree 的结构</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516142001.png\" alt=\"multi-component-lsm-tree\"></p>\n<p>对于 K+1 层的 LSM-Tree 来说，总共有 C0, C1, C2, … C_{K-1} 以及 C_K，并且每层的大小递增（C1 比 C0 大，C2 比 C1 大，依次类推，最小的层 C0 在内存，其他的所有均在磁盘），相邻层之间会有异步的 rolling merge 过程，将 C_{i - 1} 层的数据迁移到 C_i 层中。对于一个插入后从未删除的 entry 来说，会从最上层 C0 逐步迁移到最底层 C_K 中。</p>\n<p>接下来会通过定量的分析来说明多层 LSM-Tree 中不同参数对总成本的影响，并且推导得出一个总成本更低的参数组合。</p>\n<p>首先定义一些在定量分析中需要的参数与假设</p>\n<ul>\n<li>$ S(C_i) $ — 表示 LSM-Tree 第 i 层叶子层所有 entry 的总大小（单位是 byte）</li>\n<li>$ S_i $ — 表示 LSM-Tree 中第 i 层所有 entry 的总大小（单位是 byte），也就是 $S(C_i) = S_i$</li>\n<li>$ r_i = S_i / S_{i-1} $  — 表示相邻两层中的总大小比例</li>\n<li>S — 表示所有层中叶子节点的总大小，也就是 $S = \\sigma{1}{i} S_i$</li>\n<li>R — C0 接受到的插入速度（假设速度相对稳定），单位 byte/s</li>\n<li>每层的中数据量保持稳定，且接近该层的阈值</li>\n<li>每个 entry 只从 C0 插入，从 C_K 删除，中间层不删除 entry</li>\n<li>C_K 的大小保持相对恒定，删除与插入保持相对的平衡，C_K 层的删除，可以理解为不增加插入速度的情况下将 entry 从 C_0 删除</li>\n</ul>\n<p>假定 LSM-Tree 有 K + 1 层，其中 S_0 和 S_K 固定，S_0 接受到的插入速度 R 恒定<br>问题：求所有的 $ r_i $ 使得整个 LSM-Tree 的总 I/O  速度 H 最小。</p>\n<p>证明过程如下：</p>\n<ol>\n<li>由于假设每条数据从 C_0 插入后，一直到最底层 C_{K} 才会被删除，则所有相邻层 (C_{i-1}, C_{i}) 的 I/O 速度和 C_0 接受到的 I/O 速度一致，均是 C_0 接受的插入速度 R。</li>\n<li>如果 C_{i-1} 和 C_{i} 都在磁盘上，那么 C_{i-1} 层从磁盘上读取的 I/O 速度就是 $ R/S_P $（这部分数据会被移入到 $C_{i}$ 层，其中 $S_P$ 是单 page 的字节数大小，从 C_{i} 层会有 $r_i <em> R/S_P$ 的读取 I/O（一个 C_{i-1} 层平均对应 C_{i} 层 r_i 个 page），然后所有读取的数据会写入到 $C_i$ 层，其速度是 $ (r_i + 1) </em> R / S_p $ (从 C_{i-1] 与 C_{i} 读取的数据都会写入到 C_{i} 层中，不会中途删除)，因此整个 LSM-Tree 的总 I/O 速度 H 可以用公式计算如下： $ H = (R / S_P) <em> ((2 </em> r_1 + 1) + (2 <em> r_2 + 2) + … + (2</em>r_{K-1} + 2) + (2<em>r_K + 1)). 其中 $ (2 </em> r_i + k) $ 表示 rolling merge 过程中第 i 层的总 I/O 量，其中 $ r_i <em> R / S_p $ 表示从 C_{i-1} merge 到 C_{i} 中从第 i 层读取的 I/O 量，(r_i + 1)</em>R/S_P 表示从 C_{i-1} merge 到 C_{i』 层后写入到第 i 层的 I/O 量，R/S_P 表示从第 i 层 rolling merge 到第 i + 1 层时的读取 I/O （C_0 没有 I/O，C_K 不需要合并到更下一层，没有下一层对应的 I/O)</li>\n<li>简化 H 后得到 $ H + (R / S_P) <em> ((2 </em> r_1 + 2) + (2 <em> r_2 + 2) + … + (2</em>r_{K-1} + 1) + (2 * r_K + 1))  = (2R/S_p) (\\sigma{1}{K} r_i + K - \\frac{1}{2}) $</li>\n<li>需要在已知条件下求 H 的最小值，其中 S_K 和 S_0 恒定，可以换算为同等已知条件 $ \\prod\\limits_{1}^K r_i = (S_k / S_0) = C $</li>\n<li>也就是希望在 $ \\prod\\limits_{1}^K r_i = (S_k / S_0) = C $ 的情况下求 $ \\sigma{1}{K} r_i $ 的最小值。</li>\n<li>通过求偏导，得到 $ 0 = 1 - \\frac{1}{r_j} <em> C </em> \\prod\\limits_{1}^{K-1} r_j^{-1}.  然后求的每个 r_j 等于 $ C * \\prod\\limits_{1}^{K-1} r_j^{-1} $ 或者 $ C^{\\frac{1}/{K}} $ 情况下求的最小值。</li>\n<li>在 LSM-Tree 中，相邻层然后把条件放宽（也就是不固定最大层的大小），每一层是上一层的 r 倍，由于正常情况下 r 会比较大，因此最大层会占据所有数据的大头（S_K ~~ S），那么固定整体大小 S 和 固定 S_K 就近似（上面的推导过程）</li>\n</ol>\n<blockquote>\n<p>其中通过求偏导得到最小值的过程，自己推导的结果与论文中有差异，如果有人知道，恳请告知，自己推导的结果是 $ 0 = -\\frac{1}{r_j} <em> C </em> \\prod\\limits_{1}^{K-1} r_j^{-1} $ 不是论文中的 $ 0 = 1 - \\frac{1}{r_j} <em> C </em> \\prod\\limits_{1}^{K-1} r_j^{-1} $。</p>\n</blockquote>\n<p>根据已知条件与上述证明可得</p>\n<ul>\n<li>$ S = S_0 + r <em> S_0 + r^2 </em> S_0 + … + r^K * S_0 $</li>\n<li>$ H = (2R / S_p)<em>(K </em> (1 + r) - 1/ 2) — 其中 R 是插入速度，S_p 是页大小，K 是磁盘上的层数，r 是相邻层的比值大小</li>\n</ul>\n<p>也就是 R 和 S_K 均保持不变的情况下，H 于 S_0 负相关（内存大小），与 r （相邻层的大小比例）正相关。</p>\n<p>可以使用两层 LSM-Tree 进行具体的推演<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">两层的 LSM-Tree 中</span><br><span class=\"line\">- K = 1， r = S_1 / S_0</span><br><span class=\"line\">- H  = \\frac&#123;2R&#125;&#123;S_P&#125;(K*(1+r) - \\frac&#123;1&#125;&#123;2&#125;)</span><br><span class=\"line\">- COST_tot = COST_m * S_0 + max(COST_d * S_1, COST_\\pi * H)</span><br><span class=\"line\">- s = (COST_m * S_0) / (COST_d * S_1) -- cost of memory relative to storage cost for S_1 data</span><br><span class=\"line\">- t = 2 ((R/S_p) / S_1) * (COST_\\pi /COST_d) * (COST_m / COST_d)</span><br><span class=\"line\">- C = COST_tot / (COST_d * S_1)</span><br><span class=\"line\"></span><br><span class=\"line\">当 S_0 / S1 比较小的时候， C ~ s + max(1, t/s) </span><br></pre></td></tr></table></figure></p>\n<p>其中 C 是 t 和 s 的函数，其中 t 是应用的平均访问热度（the variable t is a kind of normalized temperature measuring the basic multi-page block I/O rate required by the application），s 表示使用的内存大小。</p>\n<p>最简单的来说，可以让 s = t, 这样 C  = s + 1，这样磁盘得到充分利用（I/O 的存储和访问量都打满）。</p>\n<blockquote>\n<p>个人理解这里是假定总存储量（磁盘所需空间）已知，且访问热度已知，也就是说 C 的最小值就是总成本的最小值。</p>\n</blockquote>\n<p>对于 t &lt; 1 的情况，s = t 的成本是最小的，但是 t &gt; 1 的情况下，C 在 s = t^{1/2} 的时候取得最小值，也就是 C = 2s = 2 t^{1/2}. 这个情况下 COST_tot = 2[(COST_m<em>S_1) </em> (2<em>COST_\\pi</em>R/S_p)]^{1/2}（通过 C = 2<em>t^{1/2} 以及 C = COST_tot / (COST_d </em> S_1) 然后换算得到），也就是说当 t &gt; 1 的时候（两层的 LSM-Tree 最小代价如前所是），整体代价来源于两方面：1）内存的开销；2）I/O 访问的开销（由于 t 足够高，因此 I/O 开销比 I/O 存储代价更大）</p>\n<p>对于 t &lt;= 1 的情况来说，C = s + 1 = t + 1 &lt;= 2. 也就是说总在成本总是小于存储成本的两倍，因此通过存储需求来确定磁盘使用大小，然后利用所有的 I/O 能力来最小化内存使用。（尽可能打满对应存储所能提供的 I/O)</p>\n<h3 id=\"具体例子计算-B-Tree-和-LSM-Tree-的成本分析\"><a href=\"#具体例子计算-B-Tree-和-LSM-Tree-的成本分析\" class=\"headerlink\" title=\"具体例子计算 B-Tree 和 LSM-Tree 的成本分析\"></a>具体例子计算 B-Tree 和 LSM-Tree 的成本分析</h3><p>上面对 LSM-Tree 和 B-Tree 做了定量分析，接下来使用具体例子计算 B-Tree 和 LSM-Tree 在具体场景下的成本对比。</p>\n<p>1 给定如下场景，计算 B-Tree 以及两层 LSM-Tree 的成本</p>\n<ul>\n<li>R = 16000 byte（每个 entry 16 byte，也就是 1000 个 entry 每秒）</li>\n<li>总共 576 million entries（总存储空间 9.2Gbyte），每个 entry 的 ttl 是 20 days</li>\n</ul>\n<p>如果使用 B-Tree 的话，成本如下</p>\n<ul>\n<li>由于 I/O 访问是瓶颈，因此需要更多的磁盘存储空间才能满足对应的 I/O 访问（H = 2 <em> 1000 = 2000 随机访问），COST_P = 25$，那么随机访问的成本是 2000 </em> 25$ = 50,000$</li>\n<li>然后非叶子节点需要缓存，具体的缓存成本计算如下<ul>\n<li>假设叶子节点 70% 满，也就是每个叶子节点有 0.7 * (4K / 16) = 180 个 entry，上层节点需要 576 million/180 = 3.2 million 数据，在加上部分前缀压缩的技术后，假设每个非叶子节点可以存储 200 条数据，也就是 3.2 million / 200 = 16000 个节点，每个 4KB，总共有 64MB 的内存存储空间</li>\n<li>64MB 的存储空间总成本是 64MB * 100$/MB  = 6400 $</li>\n<li>忽略其他一些细小的成本开销</li>\n</ul>\n</li>\n<li>B-Tree 的总成本 = 50000$ + 6400$ = 56400 $</li>\n</ul>\n<p>两层 LSM-Tree 的话，成本如下</p>\n<ul>\n<li>首先 C1 需要的总存储空间是 9.2Gbyte，总成本是 .1$/Mbyte * 92000Mbyte = 9200$</li>\n<li>根据 C1 的大小计算出打满情况下的 H  = 92000 / COST_\\pi = 9200 / 2.5 ~ 3700 page/s</li>\n<li>假设单 page 大小 4K 的情况下，根据 H 以及 H = (2<em>R/S_P)</em>(K*(1 + r) - 1/2) 计算得到 r ~ 460，可以得到 C_0 = C_1/460 = 9.2G / 460 = 20Mb</li>\n<li>20Mbyte C_0 的成本是 20MB * 100$/MB = 2000$，另外增加 2MB 用于 rolling merge 时使用，也就是 2000$ + 200$ = 2200$</li>\n<li>总成本是 9200 + 2200 = 11400$</li>\n</ul>\n<p>大致计算之后 LSM-Tree 比 B-Tree 的成本会低很多（11400 VS 56400)，相当于 B-Tree 的 1/5 左右</p>\n<p>2 如果 R 增加 10 倍，也就是 160000 byte/s，再计算 B-Tree，两层 LSM-Tree 以及三层 LSM-Tree 的成本</p>\n<ul>\n<li>R = 160000 byte（单 entry 16 byte，也就是 10000 entry/s）</li>\n<li>576 million entries（总存储量 9.2GByte），每个 entry 的 ttl 是 20 days</li>\n</ul>\n<p>B-Tree 的情况下</p>\n<ul>\n<li>需要使用更多的磁盘来满足相应需求（主要是为了满足 I/O 的读写） 随机访问的总成本是 (2 <em> (160000 / 16)) </em> 25$ = 500,000$（相当于 500G 的存储，实际只需要 9.2G，也就是有 491G 的存储浪费）</li>\n<li>buffer 非叶子节点的成本不变，也就是 6400$</li>\n<li>总成本 = 500,000$ + 6400$ = 506400$</li>\n</ul>\n<p>两层 LSM-Tree 的情况</p>\n<ul>\n<li>首先通过 t 的公式计算得到 t = 2<em>((R/S_p)/S_1)</em>(COST_\\pi/COST_d)*(COST_m/COST_d) ~ 2.2 &gt; 1</li>\n<li>通过公式得到最低成本 = 2[(COST_m<em>S_1) </em> (2<em>COST_\\pi</em>R/S_p)]^{1/2} ~ 27129$，其中一半用于磁盘，一半用于内存开销，磁盘的总存储空间是 13.5G（27129/2/1 Mb），135M 的内存</li>\n<li>额外增加 2M 的内存用于 merge，200$ </li>\n<li>总成本 ~ 27329$</li>\n</ul>\n<p>对于三层 LSM-Tree 的情况</p>\n<ul>\n<li>C_2 需要 9.2G 存储，总成本 9.2<em>1000</em>1$/Mb =9200$, 能提供的 I/O 访问频率 H  = 9.2 * 1000 / 2.5 ~ 3700</li>\n<li>根据 H  = (2R/S_p)*(K ( 1 + r) - 1/2) 计算得到 r ~ 23</li>\n<li>C_0 = C_2 / r / r ~ 17MB，成本为 17 * 100$/Mb = 1700$</li>\n<li>C_1 的成本是 C_2 的 1/r =  1/23 也就是 9200/23 * 1$/Mb = 400$ （由于是最大层成本的 1/23，因此在估算时也可以忽略）</li>\n<li>另外增加 4MB 用于 rolling merge，也就是 400$</li>\n<li>总成本 ~ 9200$ +  1700$ + 400$ + 400$ = 11700$</li>\n</ul>\n<p>对比可知 三层 LSM 的成本（11700$） &lt; 两层 LSM 的成本（27329$） &lt; B-Tree 的成本（506400$）</p>\n<h2 id=\"4-未来可能的优化\"><a href=\"#4-未来可能的优化\" class=\"headerlink\" title=\"4 未来可能的优化\"></a>4 未来可能的优化</h2><ul>\n<li>为了更好的平衡插入和查询性能，留取部分 I/O 供查询使用；另外在 rolling merge 的时候，可以适当保留部分上层数据（并不完全迁移）</li>\n<li>插入/合并的时候，CPU 做隔离，使用单独的 CPU 做合并，以及 LSM-Tree 结构的维护，这样可以在基本不增加延迟的情况下完成查找。</li>\n</ul>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] <a href=\"https://www.cs.umb.edu/~poneil/lsmtree.pdf\">The Log-Structured Merge-Tree (LSM-Tree)</a><br>[2] <a href=\"https://www.hpl.hp.com/techreports/tandem/TR-86.1.pdf\">The Five Minute Rule</a><br>[3] <a href=\"\">Database Buffer and Disk Configuring and the Battle of the Bottlenecks</a><br>[4] <a href=\"\">GPD Performance Evaluation Lab Database 2 Version 2 Utility Analysis, IBM Document Number GG09-1031-0, September 28, 1989</a>  </p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>文章内容基于原论文，结合自己的理解和思考，发现有错漏的地方，欢迎反馈探讨，感谢。</p>\n</blockquote>\n<p>LSM-Tree 拥有优异的性能出现在各种存储引擎中，本文希望对 LSM-Tree 进行一个最小全局认识，对其有个骨架结构认识，从 LSM-Tree 的原始论文开始，到现在的进展以及 LSM-Tree 中各种影响的因素。</p>","more":"<h1 id=\"起始\"><a href=\"#起始\" class=\"headerlink\" title=\"起始\"></a>起始</h1><h2 id=\"1-LSM-Tree-的缘起\"><a href=\"#1-LSM-Tree-的缘起\" class=\"headerlink\" title=\"1 LSM-Tree 的缘起\"></a>1 LSM-Tree 的缘起</h2><p>LSM-Tree 从论文[1] 中出生，在该论文中谈及了 LSM-Tree 诞生的原因，主要流程，优缺点，适合场景，以及决定性能的相关参数等。首先接下来重点介绍这篇 LSM-Tree 的原始论文。</p>\n<p>在论文[1] 之前的年代中，存储引擎主要使用 B-Tree 系列的数据结构，这种数据结构并不是 I/O 友好型的，随机 I/O 所带来的成本会比较高，尤其是写多读少的情况下，更新叶子节点会有两次随机 I/O（读+写），会有性能瓶颈。LSM-Tree 则以两个 batch 操作来优化 I/O 成本：1）首先写入 memory，然后 memory 的数据以 batch 形式写入磁盘；2）磁盘顺序读写，减少 seek 的成本（次数减少），均摊后单次成本更低。</p>\n<p>由论文[2] 中的结论可知，在一定范围内使用内存换 I/O 能减少整体成本。随着硬件的更新换代，内存和磁盘的成本关系也在变化，可根据具体使用的硬件进行对比。</p>\n<h2 id=\"2-LSM-Tree-的结构，以及主要流程\"><a href=\"#2-LSM-Tree-的结构，以及主要流程\" class=\"headerlink\" title=\"2 LSM-Tree 的结构，以及主要流程\"></a>2 LSM-Tree 的结构，以及主要流程</h2><p>LSM-Tree 是一个多层的数据结构，其中第一层（最上层）保持在内存中，除第一层外的其他层均在磁盘（部分频繁访问的数据会 cache 在内存）。最简单的 LSM-Tree 拥有两层：内存中一层，磁盘中一层。接下来首先以两层 LSM-Tree 介绍相关功能，后续在定量分析过程中，会详细介绍多层 LSM-Tree 结构。</p>\n<p>两层 LSM-Tree 的结构如下所示：</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516141825.png\" alt=\"tow-component-lsm\"></p>\n<p>上图中 L0 与 L1 均是 tree-like 的数据结构，由于 L0 不需要特别考虑 tree high（都在内存，无 I/O），因此 B-Tree、AVL-Tree 以及 2-3-tree 等各种 tree like 数据结构读可以。 L1 保存在磁盘，需要考虑 tree high，使用 B-Tree。</p>\n<p>对 LSM-Tree 数据结构，首先看一下基本操作的流程(为了描述方便，L0 中的结构也以 B-Tree 为例）:</p>\n<ul>\n<li>insert：数据直接写入内存 L0 中。在 L0 大小达到一定阈值后，会进行 rolling merge 操作（后面详述），将数据从 L0 转移到 L1。</li>\n<li>get：读取数据的时候，首先从 L0 中进行查找，找到后直接返回（不管是否带 delete meta 信息的 key/value），否则继续从 L1 进行查找。</li>\n<li>delete：如果 L0 中没有 key/value 对，则在 L0 中增加一个 key/value 对，且 value 包括 delete 相关的 meta 信息；如果 L0 中有对应的 key/value，则将 value 更改为包括 delete meta 信息的值。rolling merge 的时候将带有 delete meta 信息的 key/value 从 L_i 写入到 L_(i+1) 删除 L_i &amp; L_(i + 1) 中的 key/value 对，然后在 L_(i+1) 插入一个带有 delete meta 信息的 key/value 对，当达到最底层的时候，将 key/value 对进行物理删除。同样 delete 的操作和 insert 一样，支持 batch 操作。</li>\n<li>update：update 可以看作是 delete&amp;insert 的组合</li>\n</ul>\n<p>LSM-Tree 为了保证更上层有空间接受插入的新数据，维护一个 rolling merge 的后台流程，该流程会从相邻两层中分别读取数据，写入到下层中，在 rolling merge 的过程中也可以进行部分逻辑处理：比如 ttl 的数据可以直接删除等。下图是一个 rolling merge 的示意图： </p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516141924.png\" alt=\"rolling-merge\"></p>\n<h2 id=\"3-LSM-Tree-相关的定量分析\"><a href=\"#3-LSM-Tree-相关的定量分析\" class=\"headerlink\" title=\"3 LSM-Tree 相关的定量分析\"></a>3 LSM-Tree 相关的定量分析</h2><p>上文介绍了 LSM-Tree 诞生的原因，以及基本的流程，下面着重进行性能相关的定量分析，包括双层 LSM-Tree 以及多层 LSM-Tree。</p>\n<h3 id=\"双层-LSM-Tree-的-IO-定量分析\"><a href=\"#双层-LSM-Tree-的-IO-定量分析\" class=\"headerlink\" title=\"双层 LSM-Tree 的 IO 定量分析\"></a>双层 LSM-Tree 的 IO 定量分析</h3><p>本节介绍双层 LSM-Tree 的 I/O 定量分析，以及和 B-Tree 的相关对比情况。</p>\n<p>以下对比内容基于 1995 年的硬件架构：</p>\n<ul>\n<li>1MByte 内存需要 100$</li>\n<li>1MByte 磁盘的存储需要 1$</li>\n<li>随机访问 I/O 成本是 25$</li>\n<li>顺序访问的 I/O 成本是 2.5$</li>\n</ul>\n<p>同时为了后面描述方便，定义变量如下:</p>\n<ul>\n<li>$COST_d$ 表示磁盘存储 1MByte 所需要的成本</li>\n<li>$COST_m $ 表示内存中存储 1MByte 所需要的成本</li>\n<li>$ COST_P $ 表示提供 1 page 每秒所需要的磁盘成本（随机访问）</li>\n<li>$ COST_\\pi $ 表示提供 1 page 每秒所需要的磁盘成本（顺序访问）</li>\n</ul>\n<p>内存的成本由存储空间决定，而磁盘的成本则由存储空间和访问频率的更大者决定。</p>\n<p>假设需要存储 S MByte 大小的数据，且每秒 H 的随机 I/O 访问（数据无缓存），则磁盘的开销是 $ COST_D = max(S <em> COST_d, H </em> COST_P $，其中 $ S<em>COST_d $ 表示存储所需成本，$ H </em> COST_P $ 则表示随机 I/O 访问的成本。</p>\n<p>当使用内存来缓存部分数据后，使得磁盘的瓶颈变为存储量后，则对应总成本是 $ COST-B = S <em> COST_m + S</em>COST_d $ 其中， $ S<em>COST_M $ 表示内存的成本，$ S</em>COST_d $ 表示磁盘的存储所需成本。</p>\n<p>综合上面两种情况可得，总共存储 S MByte 大小的数据，且每秒 H 随机访问的总成本公式如下所示：</p>\n<p>$ COST-TOT = min(max(S<em>COST_d, H</em>COST_P), S<em>COST_m + S</em>COST_d) $</p>\n<p>通过上述公式我们可以看到，整体的成本受总存储量，以及访问频率的影响，我们将 H/S（访问热度） 作为横轴，COST-TOT 作为纵轴画图得到如下曲线</p>\n<Graph-of-cost-of-access-per-MByte-vs-Temperature.jpg> \n\n<p>通过上图可知，总成本会随着访问热度的增长而增长，当达到一定程度后不在增长。上图中两个拐点将数据分为三段：cold，warm，hot。其中第一段的成本主要来源磁盘存储量，第二段则随着访问频率的增加而变多，第三段主要是内存与磁盘容量的成本。其中两个拐点则用如下公式定义</p>\n<ul>\n<li>$ T_f = COST_d / COST_P = 1 / 25 = 0.04 $ 表示 cold 和 warm data 之间的拐点</li>\n<li>$ T_b = COST_m / COST_P = 100 / 25 = 4 $ 表示 warm 和 hot data 之间的拐点</li>\n</ul>\n<blockquote>\n<p>对于连续 I/O 访问来说，也有类似上图的分析，而其中 warm 和 hot 的划分则是对 “The Five Minute Rule”[2] 的概括。</p>\n</blockquote>\n<p>根据论文[3] 中的说法，访问热度与实际的磁盘访问有关，而不是逻辑插入速度，LSM 也是通过减少实际的磁盘访问量来提效，LSM-Tree 有两个减少磁盘访问的点：1）先写内存，然后 batch 写磁盘；2）顺序访问磁盘。接下来接下下顺序 I/O 的收益。</p>\n<p>根据[4] 给的数据，随机读取一个磁盘页的耗时大概是 20ms（其中 10ms 用于磁道寻址，8.3ms 来源于旋转延迟，1.7ms 来源实际读取）。顺序读取 64 个磁盘页的耗时大概是 125ms（其中 10ms 来源于磁道寻址，8.3ms 来源于旋转延迟，106.9ms 来源于实际的数据读取），— 平均后大概只需要 2ms 读取一个磁盘页，是随机访问的 1/10。也就是 $ COST_{\\pi} / COST_P = \\frac{1}{10} $。通过前面计算也能直观感受到顺序 I/O 所带来的(均摊)具巨大性能收益。</p>\n<p>我们使用[3] 中的给的结论来计算 “五分钟规则” 的参考区间 —  $ \\tau $，规则指出“维持每秒 1 page 访问所需要的成本与保存它所需的内存成本一致”，我们得到如下公式</p>\n<ul>\n<li>$ \\frac{1}{ \\tau } <em> COST_P = pagesize </em> COST_m $  （I/O 速率 * 随机 I/O 的成本 = 内存存储的成本）</li>\n</ul>\n<p>那么 $ \\tau = (\\frac{1}{pagesize} <em> \\frac{COST_P}{COST_m}) = \\frac{1}{pagesize </em> T_b} $，如果每个 page 是 4k(0.004 Mb) 的话我们可以得到 <code>$\\tau = 1/(0.004 * 4) = 62.5 seconds/IO</code>。换句话说在访问间隔小于 62.5 seconds/IO 的时候，用内存换磁盘是合理的（现在需要根据硬件成本进行具体计算）。</p>\n<h3 id=\"B-Tree-和-LSM-Tree-的定量分析对比\"><a href=\"#B-Tree-和-LSM-Tree-的定量分析对比\" class=\"headerlink\" title=\"B-Tree 和 LSM-Tree 的定量分析对比\"></a>B-Tree 和 LSM-Tree 的定量分析对比</h3><p>在进行 B-Tree 和 LSM-Tree 的对比分析之前，先单独进行 B-Tree 和 LSM-Tree 的分析。主要对比 insert 的性能，同时忽略了 index 更新过程中所带来的微小 I/O 成本。</p>\n<h4 id=\"B-Tree-的定量分析\"><a href=\"#B-Tree-的定量分析\" class=\"headerlink\" title=\"B-Tree 的定量分析\"></a>B-Tree 的定量分析</h4><blockquote>\n<p>假设所有的 insert 是完全随机的，因此不会有叶子节点 buffer 在内存的情况。</p>\n</blockquote>\n<p>根据论文[5] 的结论，B-Tree 中的有效深度 - $D_e$ - 表示随机查找中，未在 buffer 中命中的平均 page 数目。在 B-Tree 的插入中，首先需要进行 $D_e$ 次 I/O 查找对应的叶子节点，更新改节点，然后将脏页写回（1 I/O），因此整个 I/O 的开销如下所示</p>\n<p>$ COST_{B-ins} = COST_P * (D_e + 1) $</p>\n<h4 id=\"LSM-的定量分析\"><a href=\"#LSM-的定量分析\" class=\"headerlink\" title=\"LSM 的定量分析\"></a>LSM 的定量分析</h4><p>由于 LSM 的单 entry insert 时直接写入内存，可能没有 I/O 开销，因此分析 LSM-Tree 的 insert I/O 开销时，使用均摊分析进行。</p>\n<p>首先定义一些变量如下</p>\n<ul>\n<li>$ S_e $ 表示 entry（index entry） 的大小（byte 为单位）</li>\n<li>$ S_p $ 表示 page size 的大小（byte 为单位）</li>\n<li>$ S_0 $ 表示 C0 中叶子节点的大小（MByte 为单位）</li>\n<li>$ S_1 $ 表示 C1 中叶子节点的大小（MByte 为单位）</li>\n<li>M 表示 rolling merge 的过程中平均有多少个 entry 插入到 <strong>每个</strong> C1 的叶子节点 (a given LSM-tree as the average number of entries in the C0 tree inserted into <strong>each</strong> single page leaf node of the C1 tree during the rolling merge)</li>\n</ul>\n<p>每个 page 中的 entry 数目大致为 $ S_p / S_e $，整个 LSM-tree 中在 C0 中的数据比例是 $ S_0 / (S_0 + S_1) $ )，因此 rolling merge 过程中会平均插入到每个 C1 叶子节点的 entry 数 M 可以通过其他公式计算得到 $ M = (S_p/S_e) * (S_0/(S_0 + S_1)) $。</p>\n<p>根据上述公式可以得到 LSM-Tree insert 的均摊开销为（将 C1 叶子节点读入和写出内存的开销均摊到 M 个 entry 上）</p>\n<p>$ COST_{LSM-ins} = 2 * COST_{\\pi} / M $ （读写一次 C1 的叶子节点，平均涉及到 M 个 entry）</p>\n<h4 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a>对比</h4><p>观察 B-Tree 和 LSM-Tree 的 insert I/O 开销我们可以得到如下的公式</p>\n<p>$ COST_{LSM-ins} / COST_{B-ins} = K1 <em> (COST_{\\pi}/COST_{P}) </em> (1 / M) $  </p>\n<p>其中 $ K1 ~ 2/(D_e + 1) $ 是一个常数</p>\n<p>上述公式对比展示出，LSM-Tree 比 B-Tree 的优势主要来自于两方面：1）$COST_{\\pi}/COST_{P}$ 也就是磁盘的连续访问相比随机访问所带来的优势；2）M 也就是 rolling merge 时批量写入到 C1 中单个叶子节点的平均 entry 数目（注意 M 并不是一定会大于 1）。</p>\n<p>在 B-Tree 作为索引的情况下，如果整体访问热度比较高的话，则可以使用上述公式进行粗略的估算，使用 LSM-Tree 之后大概会有多少收益。</p>\n<h3 id=\"多-component-LSM-Tree-的分析\"><a href=\"#多-component-LSM-Tree-的分析\" class=\"headerlink\" title=\"多 component LSM-Tree 的分析\"></a>多 component LSM-Tree 的分析</h3><p>上面所有关于 LSM-Tree 的讨论均假设 LSM-Tree 是两层的，在实际的生成中，LSM-Tree 则可能会有多层，具体的层数，以及相邻层之间的大小比例等可以通过分析得出，本节介绍多层 LSM-Tree 相关的分析。</p>\n<blockquote>\n<p>为了方便讨论，下面的描述中，假设 LSM-Tree 中的 entry 在插入后，仅在最底层进行删除。</p>\n</blockquote>\n<p>上面几节中的分析可以得到从 C0 写入到 C1 每个叶子节点的平均 entry 数目 M 并不一定大于 1，如果 M &lt;= 1 的话，则 LSM-Tree 两个优势中的一个：“批量更新” 就失效了，因此如果分析得知 $ M &lt; K1 * COST_{\\pi} / COSTP $ 的话则 B-Treee 比 LSM-Tree 会更好。另外一方面，为了更好的利用 LSM-Tree 的优势，则需要尽可能增大 M（也就是 C0 和 C1 的比值需要更大）；同时无限增大 C0  则会由于内存消耗更高造成成本过高，因此需要综合考虑计算一个总成本更小的参数值。</p>\n<p>为了保持 LSM-Tree 中上层有空间持续接受新数据，因此 rolling merge 从上层读取并删除的速度与 C0 接受到插入速度需要保持一致。</p>\n<p>在两层的 LSM-Tree 中，可以从 LSM-Tree 的总成本出发，寻找更合适的 C0 大小。首先从一个较大的 C0 开始，逐渐减小 C0 的大小（同时 I/O 开销会增加，I/O 的访问频率和存储成本会越来越小），直到达到一个平衡（此情况下再减少 C0 的大小会导致总成本增加）。另外的一个思路则是使用多层的 LSM-Tree 结构（这可以减少 C0 的大小，同时减少 I/O 的访问频率），同时没多一层会多部分 I/O 操作，因此需要综合考虑。</p>\n<p>下图是一个多层 LSM-Tree 的结构</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20230516142001.png\" alt=\"multi-component-lsm-tree\"></p>\n<p>对于 K+1 层的 LSM-Tree 来说，总共有 C0, C1, C2, … C_{K-1} 以及 C_K，并且每层的大小递增（C1 比 C0 大，C2 比 C1 大，依次类推，最小的层 C0 在内存，其他的所有均在磁盘），相邻层之间会有异步的 rolling merge 过程，将 C_{i - 1} 层的数据迁移到 C_i 层中。对于一个插入后从未删除的 entry 来说，会从最上层 C0 逐步迁移到最底层 C_K 中。</p>\n<p>接下来会通过定量的分析来说明多层 LSM-Tree 中不同参数对总成本的影响，并且推导得出一个总成本更低的参数组合。</p>\n<p>首先定义一些在定量分析中需要的参数与假设</p>\n<ul>\n<li>$ S(C_i) $ — 表示 LSM-Tree 第 i 层叶子层所有 entry 的总大小（单位是 byte）</li>\n<li>$ S_i $ — 表示 LSM-Tree 中第 i 层所有 entry 的总大小（单位是 byte），也就是 $S(C_i) = S_i$</li>\n<li>$ r_i = S_i / S_{i-1} $  — 表示相邻两层中的总大小比例</li>\n<li>S — 表示所有层中叶子节点的总大小，也就是 $S = \\sigma{1}{i} S_i$</li>\n<li>R — C0 接受到的插入速度（假设速度相对稳定），单位 byte/s</li>\n<li>每层的中数据量保持稳定，且接近该层的阈值</li>\n<li>每个 entry 只从 C0 插入，从 C_K 删除，中间层不删除 entry</li>\n<li>C_K 的大小保持相对恒定，删除与插入保持相对的平衡，C_K 层的删除，可以理解为不增加插入速度的情况下将 entry 从 C_0 删除</li>\n</ul>\n<p>假定 LSM-Tree 有 K + 1 层，其中 S_0 和 S_K 固定，S_0 接受到的插入速度 R 恒定<br>问题：求所有的 $ r_i $ 使得整个 LSM-Tree 的总 I/O  速度 H 最小。</p>\n<p>证明过程如下：</p>\n<ol>\n<li>由于假设每条数据从 C_0 插入后，一直到最底层 C_{K} 才会被删除，则所有相邻层 (C_{i-1}, C_{i}) 的 I/O 速度和 C_0 接受到的 I/O 速度一致，均是 C_0 接受的插入速度 R。</li>\n<li>如果 C_{i-1} 和 C_{i} 都在磁盘上，那么 C_{i-1} 层从磁盘上读取的 I/O 速度就是 $ R/S_P $（这部分数据会被移入到 $C_{i}$ 层，其中 $S_P$ 是单 page 的字节数大小，从 C_{i} 层会有 $r_i <em> R/S_P$ 的读取 I/O（一个 C_{i-1} 层平均对应 C_{i} 层 r_i 个 page），然后所有读取的数据会写入到 $C_i$ 层，其速度是 $ (r_i + 1) </em> R / S_p $ (从 C_{i-1] 与 C_{i} 读取的数据都会写入到 C_{i} 层中，不会中途删除)，因此整个 LSM-Tree 的总 I/O 速度 H 可以用公式计算如下： $ H = (R / S_P) <em> ((2 </em> r_1 + 1) + (2 <em> r_2 + 2) + … + (2</em>r_{K-1} + 2) + (2<em>r_K + 1)). 其中 $ (2 </em> r_i + k) $ 表示 rolling merge 过程中第 i 层的总 I/O 量，其中 $ r_i <em> R / S_p $ 表示从 C_{i-1} merge 到 C_{i} 中从第 i 层读取的 I/O 量，(r_i + 1)</em>R/S_P 表示从 C_{i-1} merge 到 C_{i』 层后写入到第 i 层的 I/O 量，R/S_P 表示从第 i 层 rolling merge 到第 i + 1 层时的读取 I/O （C_0 没有 I/O，C_K 不需要合并到更下一层，没有下一层对应的 I/O)</li>\n<li>简化 H 后得到 $ H + (R / S_P) <em> ((2 </em> r_1 + 2) + (2 <em> r_2 + 2) + … + (2</em>r_{K-1} + 1) + (2 * r_K + 1))  = (2R/S_p) (\\sigma{1}{K} r_i + K - \\frac{1}{2}) $</li>\n<li>需要在已知条件下求 H 的最小值，其中 S_K 和 S_0 恒定，可以换算为同等已知条件 $ \\prod\\limits_{1}^K r_i = (S_k / S_0) = C $</li>\n<li>也就是希望在 $ \\prod\\limits_{1}^K r_i = (S_k / S_0) = C $ 的情况下求 $ \\sigma{1}{K} r_i $ 的最小值。</li>\n<li>通过求偏导，得到 $ 0 = 1 - \\frac{1}{r_j} <em> C </em> \\prod\\limits_{1}^{K-1} r_j^{-1}.  然后求的每个 r_j 等于 $ C * \\prod\\limits_{1}^{K-1} r_j^{-1} $ 或者 $ C^{\\frac{1}/{K}} $ 情况下求的最小值。</li>\n<li>在 LSM-Tree 中，相邻层然后把条件放宽（也就是不固定最大层的大小），每一层是上一层的 r 倍，由于正常情况下 r 会比较大，因此最大层会占据所有数据的大头（S_K ~~ S），那么固定整体大小 S 和 固定 S_K 就近似（上面的推导过程）</li>\n</ol>\n<blockquote>\n<p>其中通过求偏导得到最小值的过程，自己推导的结果与论文中有差异，如果有人知道，恳请告知，自己推导的结果是 $ 0 = -\\frac{1}{r_j} <em> C </em> \\prod\\limits_{1}^{K-1} r_j^{-1} $ 不是论文中的 $ 0 = 1 - \\frac{1}{r_j} <em> C </em> \\prod\\limits_{1}^{K-1} r_j^{-1} $。</p>\n</blockquote>\n<p>根据已知条件与上述证明可得</p>\n<ul>\n<li>$ S = S_0 + r <em> S_0 + r^2 </em> S_0 + … + r^K * S_0 $</li>\n<li>$ H = (2R / S_p)<em>(K </em> (1 + r) - 1/ 2) — 其中 R 是插入速度，S_p 是页大小，K 是磁盘上的层数，r 是相邻层的比值大小</li>\n</ul>\n<p>也就是 R 和 S_K 均保持不变的情况下，H 于 S_0 负相关（内存大小），与 r （相邻层的大小比例）正相关。</p>\n<p>可以使用两层 LSM-Tree 进行具体的推演<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">两层的 LSM-Tree 中</span><br><span class=\"line\">- K = 1， r = S_1 / S_0</span><br><span class=\"line\">- H  = \\frac&#123;2R&#125;&#123;S_P&#125;(K*(1+r) - \\frac&#123;1&#125;&#123;2&#125;)</span><br><span class=\"line\">- COST_tot = COST_m * S_0 + max(COST_d * S_1, COST_\\pi * H)</span><br><span class=\"line\">- s = (COST_m * S_0) / (COST_d * S_1) -- cost of memory relative to storage cost for S_1 data</span><br><span class=\"line\">- t = 2 ((R/S_p) / S_1) * (COST_\\pi /COST_d) * (COST_m / COST_d)</span><br><span class=\"line\">- C = COST_tot / (COST_d * S_1)</span><br><span class=\"line\"></span><br><span class=\"line\">当 S_0 / S1 比较小的时候， C ~ s + max(1, t/s) </span><br></pre></td></tr></table></figure></p>\n<p>其中 C 是 t 和 s 的函数，其中 t 是应用的平均访问热度（the variable t is a kind of normalized temperature measuring the basic multi-page block I/O rate required by the application），s 表示使用的内存大小。</p>\n<p>最简单的来说，可以让 s = t, 这样 C  = s + 1，这样磁盘得到充分利用（I/O 的存储和访问量都打满）。</p>\n<blockquote>\n<p>个人理解这里是假定总存储量（磁盘所需空间）已知，且访问热度已知，也就是说 C 的最小值就是总成本的最小值。</p>\n</blockquote>\n<p>对于 t &lt; 1 的情况，s = t 的成本是最小的，但是 t &gt; 1 的情况下，C 在 s = t^{1/2} 的时候取得最小值，也就是 C = 2s = 2 t^{1/2}. 这个情况下 COST_tot = 2[(COST_m<em>S_1) </em> (2<em>COST_\\pi</em>R/S_p)]^{1/2}（通过 C = 2<em>t^{1/2} 以及 C = COST_tot / (COST_d </em> S_1) 然后换算得到），也就是说当 t &gt; 1 的时候（两层的 LSM-Tree 最小代价如前所是），整体代价来源于两方面：1）内存的开销；2）I/O 访问的开销（由于 t 足够高，因此 I/O 开销比 I/O 存储代价更大）</p>\n<p>对于 t &lt;= 1 的情况来说，C = s + 1 = t + 1 &lt;= 2. 也就是说总在成本总是小于存储成本的两倍，因此通过存储需求来确定磁盘使用大小，然后利用所有的 I/O 能力来最小化内存使用。（尽可能打满对应存储所能提供的 I/O)</p>\n<h3 id=\"具体例子计算-B-Tree-和-LSM-Tree-的成本分析\"><a href=\"#具体例子计算-B-Tree-和-LSM-Tree-的成本分析\" class=\"headerlink\" title=\"具体例子计算 B-Tree 和 LSM-Tree 的成本分析\"></a>具体例子计算 B-Tree 和 LSM-Tree 的成本分析</h3><p>上面对 LSM-Tree 和 B-Tree 做了定量分析，接下来使用具体例子计算 B-Tree 和 LSM-Tree 在具体场景下的成本对比。</p>\n<p>1 给定如下场景，计算 B-Tree 以及两层 LSM-Tree 的成本</p>\n<ul>\n<li>R = 16000 byte（每个 entry 16 byte，也就是 1000 个 entry 每秒）</li>\n<li>总共 576 million entries（总存储空间 9.2Gbyte），每个 entry 的 ttl 是 20 days</li>\n</ul>\n<p>如果使用 B-Tree 的话，成本如下</p>\n<ul>\n<li>由于 I/O 访问是瓶颈，因此需要更多的磁盘存储空间才能满足对应的 I/O 访问（H = 2 <em> 1000 = 2000 随机访问），COST_P = 25$，那么随机访问的成本是 2000 </em> 25$ = 50,000$</li>\n<li>然后非叶子节点需要缓存，具体的缓存成本计算如下<ul>\n<li>假设叶子节点 70% 满，也就是每个叶子节点有 0.7 * (4K / 16) = 180 个 entry，上层节点需要 576 million/180 = 3.2 million 数据，在加上部分前缀压缩的技术后，假设每个非叶子节点可以存储 200 条数据，也就是 3.2 million / 200 = 16000 个节点，每个 4KB，总共有 64MB 的内存存储空间</li>\n<li>64MB 的存储空间总成本是 64MB * 100$/MB  = 6400 $</li>\n<li>忽略其他一些细小的成本开销</li>\n</ul>\n</li>\n<li>B-Tree 的总成本 = 50000$ + 6400$ = 56400 $</li>\n</ul>\n<p>两层 LSM-Tree 的话，成本如下</p>\n<ul>\n<li>首先 C1 需要的总存储空间是 9.2Gbyte，总成本是 .1$/Mbyte * 92000Mbyte = 9200$</li>\n<li>根据 C1 的大小计算出打满情况下的 H  = 92000 / COST_\\pi = 9200 / 2.5 ~ 3700 page/s</li>\n<li>假设单 page 大小 4K 的情况下，根据 H 以及 H = (2<em>R/S_P)</em>(K*(1 + r) - 1/2) 计算得到 r ~ 460，可以得到 C_0 = C_1/460 = 9.2G / 460 = 20Mb</li>\n<li>20Mbyte C_0 的成本是 20MB * 100$/MB = 2000$，另外增加 2MB 用于 rolling merge 时使用，也就是 2000$ + 200$ = 2200$</li>\n<li>总成本是 9200 + 2200 = 11400$</li>\n</ul>\n<p>大致计算之后 LSM-Tree 比 B-Tree 的成本会低很多（11400 VS 56400)，相当于 B-Tree 的 1/5 左右</p>\n<p>2 如果 R 增加 10 倍，也就是 160000 byte/s，再计算 B-Tree，两层 LSM-Tree 以及三层 LSM-Tree 的成本</p>\n<ul>\n<li>R = 160000 byte（单 entry 16 byte，也就是 10000 entry/s）</li>\n<li>576 million entries（总存储量 9.2GByte），每个 entry 的 ttl 是 20 days</li>\n</ul>\n<p>B-Tree 的情况下</p>\n<ul>\n<li>需要使用更多的磁盘来满足相应需求（主要是为了满足 I/O 的读写） 随机访问的总成本是 (2 <em> (160000 / 16)) </em> 25$ = 500,000$（相当于 500G 的存储，实际只需要 9.2G，也就是有 491G 的存储浪费）</li>\n<li>buffer 非叶子节点的成本不变，也就是 6400$</li>\n<li>总成本 = 500,000$ + 6400$ = 506400$</li>\n</ul>\n<p>两层 LSM-Tree 的情况</p>\n<ul>\n<li>首先通过 t 的公式计算得到 t = 2<em>((R/S_p)/S_1)</em>(COST_\\pi/COST_d)*(COST_m/COST_d) ~ 2.2 &gt; 1</li>\n<li>通过公式得到最低成本 = 2[(COST_m<em>S_1) </em> (2<em>COST_\\pi</em>R/S_p)]^{1/2} ~ 27129$，其中一半用于磁盘，一半用于内存开销，磁盘的总存储空间是 13.5G（27129/2/1 Mb），135M 的内存</li>\n<li>额外增加 2M 的内存用于 merge，200$ </li>\n<li>总成本 ~ 27329$</li>\n</ul>\n<p>对于三层 LSM-Tree 的情况</p>\n<ul>\n<li>C_2 需要 9.2G 存储，总成本 9.2<em>1000</em>1$/Mb =9200$, 能提供的 I/O 访问频率 H  = 9.2 * 1000 / 2.5 ~ 3700</li>\n<li>根据 H  = (2R/S_p)*(K ( 1 + r) - 1/2) 计算得到 r ~ 23</li>\n<li>C_0 = C_2 / r / r ~ 17MB，成本为 17 * 100$/Mb = 1700$</li>\n<li>C_1 的成本是 C_2 的 1/r =  1/23 也就是 9200/23 * 1$/Mb = 400$ （由于是最大层成本的 1/23，因此在估算时也可以忽略）</li>\n<li>另外增加 4MB 用于 rolling merge，也就是 400$</li>\n<li>总成本 ~ 9200$ +  1700$ + 400$ + 400$ = 11700$</li>\n</ul>\n<p>对比可知 三层 LSM 的成本（11700$） &lt; 两层 LSM 的成本（27329$） &lt; B-Tree 的成本（506400$）</p>\n<h2 id=\"4-未来可能的优化\"><a href=\"#4-未来可能的优化\" class=\"headerlink\" title=\"4 未来可能的优化\"></a>4 未来可能的优化</h2><ul>\n<li>为了更好的平衡插入和查询性能，留取部分 I/O 供查询使用；另外在 rolling merge 的时候，可以适当保留部分上层数据（并不完全迁移）</li>\n<li>插入/合并的时候，CPU 做隔离，使用单独的 CPU 做合并，以及 LSM-Tree 结构的维护，这样可以在基本不增加延迟的情况下完成查找。</li>\n</ul>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] <a href=\"https://www.cs.umb.edu/~poneil/lsmtree.pdf\">The Log-Structured Merge-Tree (LSM-Tree)</a><br>[2] <a href=\"https://www.hpl.hp.com/techreports/tandem/TR-86.1.pdf\">The Five Minute Rule</a><br>[3] <a href=\"\">Database Buffer and Disk Configuring and the Battle of the Bottlenecks</a><br>[4] <a href=\"\">GPD Performance Evaluation Lab Database 2 Version 2 Utility Analysis, IBM Document Number GG09-1031-0, September 28, 1989</a>  </p>"},{"title":"big_data_paper_big_picture","date":"2022-04-16T04:40:34.000Z","_content":"\n\n# 大数据全局认识：回到过去，展望未来\n\n\n大数据发展至今，各种技术层出不穷，需求也越来越多，在整个发展的历史河流中，有一些关键的 人/论文/系统，本系列文章则希望对对这些关键知识一窥究竟，从而在面对茫茫多的技术中能够更从容的做出更好的决策。\n\n全局认识的数据集以及\n论文主要来自于各大顶级会议[1]，系统则主要来自于开源系统，人则是论文的主要作者或者系统的核心成员。其中论文的分析主要有两种：1）使用系统分析（参考下图）；2）人肉阅读摘要进行分析；\n插入一张自动分析得到的图片\n\n人肉阅读一定会有偏见，同时大量阅读的时候一些共性现象也会明显的显现出来。比如 XML 数据库曾经红极一时，现在基本很难看到，现在很多流行的技术也都能在之前的论文中看到对应的\n\n阅读论文摘要的过程，有几个特别深刻\n\n论文主要从 如下一些会议选择选自如下会议[1]，系统主要从开源社区选择\n\n\n\n[1] 会议列表：VLDB、SOSP、ICDE、HPCA、SIGMOD、FAST、NSDI, OSDI（可能会有变化）","source":"_drafts/big-data-paper-big-picture.md","raw":"---\ntitle: big_data_paper_big_picture\ndate: 2022-04-16 12:40:34\ntags: 大数据, 全局认识, 偏见, 论文, 系统\n---\n\n\n# 大数据全局认识：回到过去，展望未来\n\n\n大数据发展至今，各种技术层出不穷，需求也越来越多，在整个发展的历史河流中，有一些关键的 人/论文/系统，本系列文章则希望对对这些关键知识一窥究竟，从而在面对茫茫多的技术中能够更从容的做出更好的决策。\n\n全局认识的数据集以及\n论文主要来自于各大顶级会议[1]，系统则主要来自于开源系统，人则是论文的主要作者或者系统的核心成员。其中论文的分析主要有两种：1）使用系统分析（参考下图）；2）人肉阅读摘要进行分析；\n插入一张自动分析得到的图片\n\n人肉阅读一定会有偏见，同时大量阅读的时候一些共性现象也会明显的显现出来。比如 XML 数据库曾经红极一时，现在基本很难看到，现在很多流行的技术也都能在之前的论文中看到对应的\n\n阅读论文摘要的过程，有几个特别深刻\n\n论文主要从 如下一些会议选择选自如下会议[1]，系统主要从开源社区选择\n\n\n\n[1] 会议列表：VLDB、SOSP、ICDE、HPCA、SIGMOD、FAST、NSDI, OSDI（可能会有变化）","slug":"big-data-paper-big-picture","published":0,"updated":"2025-01-02T08:20:49.866Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm5f2gbxw0000y8mk40oneky3","content":"<h1 id=\"大数据全局认识：回到过去，展望未来\"><a href=\"#大数据全局认识：回到过去，展望未来\" class=\"headerlink\" title=\"大数据全局认识：回到过去，展望未来\"></a>大数据全局认识：回到过去，展望未来</h1><p>大数据发展至今，各种技术层出不穷，需求也越来越多，在整个发展的历史河流中，有一些关键的 人/论文/系统，本系列文章则希望对对这些关键知识一窥究竟，从而在面对茫茫多的技术中能够更从容的做出更好的决策。</p>\n<p>全局认识的数据集以及<br>论文主要来自于各大顶级会议[1]，系统则主要来自于开源系统，人则是论文的主要作者或者系统的核心成员。其中论文的分析主要有两种：1）使用系统分析（参考下图）；2）人肉阅读摘要进行分析；<br>插入一张自动分析得到的图片</p>\n<p>人肉阅读一定会有偏见，同时大量阅读的时候一些共性现象也会明显的显现出来。比如 XML 数据库曾经红极一时，现在基本很难看到，现在很多流行的技术也都能在之前的论文中看到对应的</p>\n<p>阅读论文摘要的过程，有几个特别深刻</p>\n<p>论文主要从 如下一些会议选择选自如下会议[1]，系统主要从开源社区选择</p>\n<p>[1] 会议列表：VLDB、SOSP、ICDE、HPCA、SIGMOD、FAST、NSDI, OSDI（可能会有变化）</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"大数据全局认识：回到过去，展望未来\"><a href=\"#大数据全局认识：回到过去，展望未来\" class=\"headerlink\" title=\"大数据全局认识：回到过去，展望未来\"></a>大数据全局认识：回到过去，展望未来</h1><p>大数据发展至今，各种技术层出不穷，需求也越来越多，在整个发展的历史河流中，有一些关键的 人/论文/系统，本系列文章则希望对对这些关键知识一窥究竟，从而在面对茫茫多的技术中能够更从容的做出更好的决策。</p>\n<p>全局认识的数据集以及<br>论文主要来自于各大顶级会议[1]，系统则主要来自于开源系统，人则是论文的主要作者或者系统的核心成员。其中论文的分析主要有两种：1）使用系统分析（参考下图）；2）人肉阅读摘要进行分析；<br>插入一张自动分析得到的图片</p>\n<p>人肉阅读一定会有偏见，同时大量阅读的时候一些共性现象也会明显的显现出来。比如 XML 数据库曾经红极一时，现在基本很难看到，现在很多流行的技术也都能在之前的论文中看到对应的</p>\n<p>阅读论文摘要的过程，有几个特别深刻</p>\n<p>论文主要从 如下一些会议选择选自如下会议[1]，系统主要从开源社区选择</p>\n<p>[1] 会议列表：VLDB、SOSP、ICDE、HPCA、SIGMOD、FAST、NSDI, OSDI（可能会有变化）</p>\n"},{"title":"maotai-basic","toc":true,"_content":"\n> 本文尝试记录一些茅台公司的基本情况，便于对公司的深入了解。\n\n茅台的香型有三种典型体 -- 酱香，窖底香，醇香。茅台酒命名为酱香型。[1]\n- 酱香体：具有酱香味，且味感优雅细腻\n- 窖底香：用窖底酒醅酿烤、放香好，但酒味冲辣者定位窖底香。\n- 醇甜体：含有大量多种香气成分，味醇甜者定为醇甜体。\n\n<!-- more -->\n\n茅台酒有多个独特的作法：\n- 茅台酒生产从投料到丢糟直至结束，需要一年时间，也正好是一年一个生产周期\n- 茅台酒全年生产用料--高粱，要在两个月内两次投完。\n- 茅台酒的陈酿的时间，最短也要四年以上。这就是茅台酒显得优雅细腻的重要原因之一。\n- 茅台酒制曲需要经过数十天的高温发酵，时间之长，温度之高，在白酒生产中可以说是首屈一指。五月端午前后开始踩曲，曲香特别浓郁，用曲量大，是形成茅台酒酱香突出的重要原因。\n- 成熟了的曲药要经过 6 个月以上的贮存才能使用。\n- 茅台酒对同一种原料药反复 7 次取酒，由于每一轮酒醅的基础不一样，气候条件不一样，所以每一轮次酒都有其特点，再经勾兑，相互取长补短，酒体显得协调，丰满。\n- 同一批原料要经过 8 次摊凉，8 次加曲，8次堆积，8次入窖发酵，每一次入窖前都要喷洒一次“尾酒”，这种回沙技术是非常独特和科学的。\n- 生产季节性强，九月重阳投料，这个季节性生产的特点，是和气候密切相关联的。\n\n\n茅台酒的独特酿造工艺：高温制曲、高温堆积、高温流酒、两次投料、七次蒸馏、八次发酵、九次蒸煮、长期陈酿，精心勾兑。由于茅台酒生产受产地的地质、水源、气候、温度、湿度、风向等自然条件影响，形成了有利于茅台酒的微生物群，使茅台酒酱香突出，风格独异，他处难于仿制。\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202502081749302.png)\n\n\n因为刚酿烤出来的酒，具有爆辣、冲鼻，刺激性大的缺点。经过一定的陈酿期后，新酒变成陈酒，新酒具备的缺点就基本消失了。这个过程，经过氧化还原等一系列化学变化和物理变化，有效地排除了酒的低沸点物质，如醇类、硫化物等。除去了新酒的不愉快气味，乙醇缩合，辛辣味减少，增加了酒的芳香。随着酒的贮存时间的延长，增加爱了水分子和酒精分子的结合，减少了刺激，增加了香味。\n\n陈酿的工艺：新酒入库以后，经检验品尝鉴定定香型后，装入容量为几百公斤的大酒坛内，酒坛上贴标签，注明该坛酒的生产时间，哪一班，哪一轮次酿制，属哪一类香型。存放一年后，将此酒“盘勾”。盘勾两年后，共经过三年的陈酿期，酒已基本老熟，进入了小型勾兑和大型勾兑的“精心勾兑”阶段。精心勾兑后的茅台酒，还要在酒库里继续陈酿。一年以后，通过检查，如果符合或超过茅台酒的质量标准，即可送包装车间包装出厂。\n\n茅台是固态发酵，和洋酒的液态发酵不一样，液态发酵需要将原料经过粉碎后，在水溶液里添加酵母进行发酵。酵母相对比较单一，发酵力非常强，发酵速度一般比较快，比较充分，耗粮率比较低。但它带来的结果就是，里边的大分子物质比较多，香味成分少。大分子多的结果就是喝多了会上头。而我们国内的这些名白酒很细腻，喝太多不会上头，这是非常大的一个差别。\n\n堆积发酵是茅台酒独特的操作工艺，既网罗、筛选繁殖了微生物，又弥补了大曲微生物品种和数量的不足，同时生成 大量的香味物质和香味的前驱物质，在茅台酒传统的工艺中，占用重要的位置。\n\n茅台酒生产所需的原料是红高粱和小麦。每公斤酒用粮 5 公斤左右，红高粱和小麦大体上各占一半。据 1956 年的历史资料记载，有 4 个红高粱品种最适合于酿造茅台酒：矮子高粱、中心高粱、麻鸡婆高粱和红缨子高粱。\n\n制曲是酿酒的第一套工序，由于曲中有益微生物数量和品种较多，香味物质也较多，因此，它是关系到酒的质量高低的一个重要环节。茅台酒采用优质小麦制造高温大曲，与其他酒的大曲相比，有三个独特之处：\n- 生产季节性强，要求“伏天踩曲”，每年端午节前后开始踩曲，重阳节结束。这段时间内气温高、湿度大，空气中微生物的种类和数量多，且活跃。\n- 制曲需要优质小麦，不加任何辅料。小麦粘着力强，营养丰富，适宜于菌种的生长，也符合前人总结酿酒经验中之处的“得自然之曲，乃称第一品”的要求。\n- 制曲温度高在 60 摄氏度以上，俗称高温大曲。\n在踩曲过程中，高度、湿度、水分比例，母曲投放比例等均有独特的要求和严密的工艺。\n\n白酒中的主要成分包括醇类物质，酸、酯、醛、酮，酚等。酒中包含的物质含量、比例等不一样均会影响最终的口感，茅台酒通过不同香型、不同轮次，不同酒度，不同年龄的茅台酒相互勾兑，形成最终用户拿到的茅台酒。\n\n茅台酒的勾兑工序如下：茅台酒陈酿期满三年后，先勾兑基础酒，再调香，调味，先是小型勾兑，再大型勾兑。小型勾兑后，将样品摇匀，放置一个月，与标准酒样对照，如质量没有发生变化，即按照小型勾兑的比例进行大型勾兑。然后将大型勾兑后的酒密封贮存，一年后，将此酒样送厂评委检验，如果此酒达到或超过出厂酒的标准，即可包装出厂。\n\n制酒工艺的整体流程可以如下所示，假设第 X 年开始制曲和酿酒，那么在第 X + 5 年开始可以售卖成酒。\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20250218203542.png)\n\n- 第一年开始制曲和酿酒（假设是第 X 年），这个流程完成之后，会有基酒（此处是第 X + 1年）\n- 由于基酒不好喝，因此需要陈酿。\n  - 基酒首先存放一年，然后继续盘勾（这是第 X + 2 年）\n  - 盘勾两年后，酒基本老熟，可以进行进行勾兑（这个过程完成是在第 X + 4 年）\n- 精心勾兑是在第 X + 4 年完成，然后精心勾兑的酒需要再存放一年（这个过程完成是在第 X + 5 年），然后酒品达标酒装车包装出厂。\n\n\n茅台酒有两道工序需要冷却：一是蒸馏取酒，二是蒸馏后酒糟的摊凉。现在使用锡制水冷却器，天锅改用甑盖，蒸汽通过甑盖，顶部 2 米长的天桥管道，进入冷却器冷却，聚成酒接入酒坛，取酒手段大大进步，酒甑体积增大，增加了容量。\n\n茅台公司认为的核心竞争力如下：环境、工法、品质、品牌，文化，并拥有独一无二的原产地保护，不可复制的微生物菌落群、传承千年的独特酿造工艺，长期贮存的基酒资源组成的“四个核心势能”。\n\n\n系列酒\n- 2014 年 12 月，茅台酱香酒营销有限公司正式成立，系列酒开始独立运行，不再作为茅台的附属品存在。\n- 2015 年，推出赖茅、王茅、华茅和贵州大曲四个新平台。王茅和华茅很快就失败了，相继停产，到 2018 年又重新启动。\n- 系列酒包括：1935、一曲、三茅、四酱，以及大单品 1935\n\n\n公司的经营模式：采购原料 -- 生产产品-- 销售产品。\n原料采购模式为：茅台酒用高粱采取“公司+地方政府+供应商+合作社或农户”的模式；小麦采取“公司+供应商+合作社或农场”的模式，其他原辅料及包装材料采购主要根据公司生产和销售计划，通过集中采购方式向市场采购；\n产品生产工艺流程为：制曲 -- 制酒 -- 贮存 -- 勾兑 -- 包装\n销售模式为：公司产品通过直销和批发代理渠道进行销售。直销渠道指自营和“i 茅台”等数字营销平台渠道，批发代理渠道指社会经销商、商超、电商等渠道。\n\n# Ref\n[1] https://www.rh.gov.cn/yxrh/rhjj/mswh/202405/t20240508_84599090.html\n","source":"_posts/maotai-basic-2025-02-08.md","raw":"---\ntitle: maotai-basic\ntags: \n    - stock\n    - maotai\n    - company-analysis\n    - wine\ntoc: true\n---\n\n> 本文尝试记录一些茅台公司的基本情况，便于对公司的深入了解。\n\n茅台的香型有三种典型体 -- 酱香，窖底香，醇香。茅台酒命名为酱香型。[1]\n- 酱香体：具有酱香味，且味感优雅细腻\n- 窖底香：用窖底酒醅酿烤、放香好，但酒味冲辣者定位窖底香。\n- 醇甜体：含有大量多种香气成分，味醇甜者定为醇甜体。\n\n<!-- more -->\n\n茅台酒有多个独特的作法：\n- 茅台酒生产从投料到丢糟直至结束，需要一年时间，也正好是一年一个生产周期\n- 茅台酒全年生产用料--高粱，要在两个月内两次投完。\n- 茅台酒的陈酿的时间，最短也要四年以上。这就是茅台酒显得优雅细腻的重要原因之一。\n- 茅台酒制曲需要经过数十天的高温发酵，时间之长，温度之高，在白酒生产中可以说是首屈一指。五月端午前后开始踩曲，曲香特别浓郁，用曲量大，是形成茅台酒酱香突出的重要原因。\n- 成熟了的曲药要经过 6 个月以上的贮存才能使用。\n- 茅台酒对同一种原料药反复 7 次取酒，由于每一轮酒醅的基础不一样，气候条件不一样，所以每一轮次酒都有其特点，再经勾兑，相互取长补短，酒体显得协调，丰满。\n- 同一批原料要经过 8 次摊凉，8 次加曲，8次堆积，8次入窖发酵，每一次入窖前都要喷洒一次“尾酒”，这种回沙技术是非常独特和科学的。\n- 生产季节性强，九月重阳投料，这个季节性生产的特点，是和气候密切相关联的。\n\n\n茅台酒的独特酿造工艺：高温制曲、高温堆积、高温流酒、两次投料、七次蒸馏、八次发酵、九次蒸煮、长期陈酿，精心勾兑。由于茅台酒生产受产地的地质、水源、气候、温度、湿度、风向等自然条件影响，形成了有利于茅台酒的微生物群，使茅台酒酱香突出，风格独异，他处难于仿制。\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202502081749302.png)\n\n\n因为刚酿烤出来的酒，具有爆辣、冲鼻，刺激性大的缺点。经过一定的陈酿期后，新酒变成陈酒，新酒具备的缺点就基本消失了。这个过程，经过氧化还原等一系列化学变化和物理变化，有效地排除了酒的低沸点物质，如醇类、硫化物等。除去了新酒的不愉快气味，乙醇缩合，辛辣味减少，增加了酒的芳香。随着酒的贮存时间的延长，增加爱了水分子和酒精分子的结合，减少了刺激，增加了香味。\n\n陈酿的工艺：新酒入库以后，经检验品尝鉴定定香型后，装入容量为几百公斤的大酒坛内，酒坛上贴标签，注明该坛酒的生产时间，哪一班，哪一轮次酿制，属哪一类香型。存放一年后，将此酒“盘勾”。盘勾两年后，共经过三年的陈酿期，酒已基本老熟，进入了小型勾兑和大型勾兑的“精心勾兑”阶段。精心勾兑后的茅台酒，还要在酒库里继续陈酿。一年以后，通过检查，如果符合或超过茅台酒的质量标准，即可送包装车间包装出厂。\n\n茅台是固态发酵，和洋酒的液态发酵不一样，液态发酵需要将原料经过粉碎后，在水溶液里添加酵母进行发酵。酵母相对比较单一，发酵力非常强，发酵速度一般比较快，比较充分，耗粮率比较低。但它带来的结果就是，里边的大分子物质比较多，香味成分少。大分子多的结果就是喝多了会上头。而我们国内的这些名白酒很细腻，喝太多不会上头，这是非常大的一个差别。\n\n堆积发酵是茅台酒独特的操作工艺，既网罗、筛选繁殖了微生物，又弥补了大曲微生物品种和数量的不足，同时生成 大量的香味物质和香味的前驱物质，在茅台酒传统的工艺中，占用重要的位置。\n\n茅台酒生产所需的原料是红高粱和小麦。每公斤酒用粮 5 公斤左右，红高粱和小麦大体上各占一半。据 1956 年的历史资料记载，有 4 个红高粱品种最适合于酿造茅台酒：矮子高粱、中心高粱、麻鸡婆高粱和红缨子高粱。\n\n制曲是酿酒的第一套工序，由于曲中有益微生物数量和品种较多，香味物质也较多，因此，它是关系到酒的质量高低的一个重要环节。茅台酒采用优质小麦制造高温大曲，与其他酒的大曲相比，有三个独特之处：\n- 生产季节性强，要求“伏天踩曲”，每年端午节前后开始踩曲，重阳节结束。这段时间内气温高、湿度大，空气中微生物的种类和数量多，且活跃。\n- 制曲需要优质小麦，不加任何辅料。小麦粘着力强，营养丰富，适宜于菌种的生长，也符合前人总结酿酒经验中之处的“得自然之曲，乃称第一品”的要求。\n- 制曲温度高在 60 摄氏度以上，俗称高温大曲。\n在踩曲过程中，高度、湿度、水分比例，母曲投放比例等均有独特的要求和严密的工艺。\n\n白酒中的主要成分包括醇类物质，酸、酯、醛、酮，酚等。酒中包含的物质含量、比例等不一样均会影响最终的口感，茅台酒通过不同香型、不同轮次，不同酒度，不同年龄的茅台酒相互勾兑，形成最终用户拿到的茅台酒。\n\n茅台酒的勾兑工序如下：茅台酒陈酿期满三年后，先勾兑基础酒，再调香，调味，先是小型勾兑，再大型勾兑。小型勾兑后，将样品摇匀，放置一个月，与标准酒样对照，如质量没有发生变化，即按照小型勾兑的比例进行大型勾兑。然后将大型勾兑后的酒密封贮存，一年后，将此酒样送厂评委检验，如果此酒达到或超过出厂酒的标准，即可包装出厂。\n\n制酒工艺的整体流程可以如下所示，假设第 X 年开始制曲和酿酒，那么在第 X + 5 年开始可以售卖成酒。\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20250218203542.png)\n\n- 第一年开始制曲和酿酒（假设是第 X 年），这个流程完成之后，会有基酒（此处是第 X + 1年）\n- 由于基酒不好喝，因此需要陈酿。\n  - 基酒首先存放一年，然后继续盘勾（这是第 X + 2 年）\n  - 盘勾两年后，酒基本老熟，可以进行进行勾兑（这个过程完成是在第 X + 4 年）\n- 精心勾兑是在第 X + 4 年完成，然后精心勾兑的酒需要再存放一年（这个过程完成是在第 X + 5 年），然后酒品达标酒装车包装出厂。\n\n\n茅台酒有两道工序需要冷却：一是蒸馏取酒，二是蒸馏后酒糟的摊凉。现在使用锡制水冷却器，天锅改用甑盖，蒸汽通过甑盖，顶部 2 米长的天桥管道，进入冷却器冷却，聚成酒接入酒坛，取酒手段大大进步，酒甑体积增大，增加了容量。\n\n茅台公司认为的核心竞争力如下：环境、工法、品质、品牌，文化，并拥有独一无二的原产地保护，不可复制的微生物菌落群、传承千年的独特酿造工艺，长期贮存的基酒资源组成的“四个核心势能”。\n\n\n系列酒\n- 2014 年 12 月，茅台酱香酒营销有限公司正式成立，系列酒开始独立运行，不再作为茅台的附属品存在。\n- 2015 年，推出赖茅、王茅、华茅和贵州大曲四个新平台。王茅和华茅很快就失败了，相继停产，到 2018 年又重新启动。\n- 系列酒包括：1935、一曲、三茅、四酱，以及大单品 1935\n\n\n公司的经营模式：采购原料 -- 生产产品-- 销售产品。\n原料采购模式为：茅台酒用高粱采取“公司+地方政府+供应商+合作社或农户”的模式；小麦采取“公司+供应商+合作社或农场”的模式，其他原辅料及包装材料采购主要根据公司生产和销售计划，通过集中采购方式向市场采购；\n产品生产工艺流程为：制曲 -- 制酒 -- 贮存 -- 勾兑 -- 包装\n销售模式为：公司产品通过直销和批发代理渠道进行销售。直销渠道指自营和“i 茅台”等数字营销平台渠道，批发代理渠道指社会经销商、商超、电商等渠道。\n\n# Ref\n[1] https://www.rh.gov.cn/yxrh/rhjj/mswh/202405/t20240508_84599090.html\n","slug":"maotai-basic-2025-02-08","published":1,"date":"2025-02-22T08:33:34.889Z","updated":"2025-02-22T08:33:34.890Z","_id":"cm7esg5hw0000dhjo0zq785ir","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>本文尝试记录一些茅台公司的基本情况，便于对公司的深入了解。</p>\n</blockquote>\n<p>茅台的香型有三种典型体 — 酱香，窖底香，醇香。茅台酒命名为酱香型。[1]</p>\n<ul>\n<li>酱香体：具有酱香味，且味感优雅细腻</li>\n<li>窖底香：用窖底酒醅酿烤、放香好，但酒味冲辣者定位窖底香。</li>\n<li>醇甜体：含有大量多种香气成分，味醇甜者定为醇甜体。</li>\n</ul>\n<span id=\"more\"></span>\n<p>茅台酒有多个独特的作法：</p>\n<ul>\n<li>茅台酒生产从投料到丢糟直至结束，需要一年时间，也正好是一年一个生产周期</li>\n<li>茅台酒全年生产用料—高粱，要在两个月内两次投完。</li>\n<li>茅台酒的陈酿的时间，最短也要四年以上。这就是茅台酒显得优雅细腻的重要原因之一。</li>\n<li>茅台酒制曲需要经过数十天的高温发酵，时间之长，温度之高，在白酒生产中可以说是首屈一指。五月端午前后开始踩曲，曲香特别浓郁，用曲量大，是形成茅台酒酱香突出的重要原因。</li>\n<li>成熟了的曲药要经过 6 个月以上的贮存才能使用。</li>\n<li>茅台酒对同一种原料药反复 7 次取酒，由于每一轮酒醅的基础不一样，气候条件不一样，所以每一轮次酒都有其特点，再经勾兑，相互取长补短，酒体显得协调，丰满。</li>\n<li>同一批原料要经过 8 次摊凉，8 次加曲，8次堆积，8次入窖发酵，每一次入窖前都要喷洒一次“尾酒”，这种回沙技术是非常独特和科学的。</li>\n<li>生产季节性强，九月重阳投料，这个季节性生产的特点，是和气候密切相关联的。</li>\n</ul>\n<p>茅台酒的独特酿造工艺：高温制曲、高温堆积、高温流酒、两次投料、七次蒸馏、八次发酵、九次蒸煮、长期陈酿，精心勾兑。由于茅台酒生产受产地的地质、水源、气候、温度、湿度、风向等自然条件影响，形成了有利于茅台酒的微生物群，使茅台酒酱香突出，风格独异，他处难于仿制。</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202502081749302.png\" alt=\"\"></p>\n<p>因为刚酿烤出来的酒，具有爆辣、冲鼻，刺激性大的缺点。经过一定的陈酿期后，新酒变成陈酒，新酒具备的缺点就基本消失了。这个过程，经过氧化还原等一系列化学变化和物理变化，有效地排除了酒的低沸点物质，如醇类、硫化物等。除去了新酒的不愉快气味，乙醇缩合，辛辣味减少，增加了酒的芳香。随着酒的贮存时间的延长，增加爱了水分子和酒精分子的结合，减少了刺激，增加了香味。</p>\n<p>陈酿的工艺：新酒入库以后，经检验品尝鉴定定香型后，装入容量为几百公斤的大酒坛内，酒坛上贴标签，注明该坛酒的生产时间，哪一班，哪一轮次酿制，属哪一类香型。存放一年后，将此酒“盘勾”。盘勾两年后，共经过三年的陈酿期，酒已基本老熟，进入了小型勾兑和大型勾兑的“精心勾兑”阶段。精心勾兑后的茅台酒，还要在酒库里继续陈酿。一年以后，通过检查，如果符合或超过茅台酒的质量标准，即可送包装车间包装出厂。</p>\n<p>茅台是固态发酵，和洋酒的液态发酵不一样，液态发酵需要将原料经过粉碎后，在水溶液里添加酵母进行发酵。酵母相对比较单一，发酵力非常强，发酵速度一般比较快，比较充分，耗粮率比较低。但它带来的结果就是，里边的大分子物质比较多，香味成分少。大分子多的结果就是喝多了会上头。而我们国内的这些名白酒很细腻，喝太多不会上头，这是非常大的一个差别。</p>\n<p>堆积发酵是茅台酒独特的操作工艺，既网罗、筛选繁殖了微生物，又弥补了大曲微生物品种和数量的不足，同时生成 大量的香味物质和香味的前驱物质，在茅台酒传统的工艺中，占用重要的位置。</p>\n<p>茅台酒生产所需的原料是红高粱和小麦。每公斤酒用粮 5 公斤左右，红高粱和小麦大体上各占一半。据 1956 年的历史资料记载，有 4 个红高粱品种最适合于酿造茅台酒：矮子高粱、中心高粱、麻鸡婆高粱和红缨子高粱。</p>\n<p>制曲是酿酒的第一套工序，由于曲中有益微生物数量和品种较多，香味物质也较多，因此，它是关系到酒的质量高低的一个重要环节。茅台酒采用优质小麦制造高温大曲，与其他酒的大曲相比，有三个独特之处：</p>\n<ul>\n<li>生产季节性强，要求“伏天踩曲”，每年端午节前后开始踩曲，重阳节结束。这段时间内气温高、湿度大，空气中微生物的种类和数量多，且活跃。</li>\n<li>制曲需要优质小麦，不加任何辅料。小麦粘着力强，营养丰富，适宜于菌种的生长，也符合前人总结酿酒经验中之处的“得自然之曲，乃称第一品”的要求。</li>\n<li>制曲温度高在 60 摄氏度以上，俗称高温大曲。<br>在踩曲过程中，高度、湿度、水分比例，母曲投放比例等均有独特的要求和严密的工艺。</li>\n</ul>\n<p>白酒中的主要成分包括醇类物质，酸、酯、醛、酮，酚等。酒中包含的物质含量、比例等不一样均会影响最终的口感，茅台酒通过不同香型、不同轮次，不同酒度，不同年龄的茅台酒相互勾兑，形成最终用户拿到的茅台酒。</p>\n<p>茅台酒的勾兑工序如下：茅台酒陈酿期满三年后，先勾兑基础酒，再调香，调味，先是小型勾兑，再大型勾兑。小型勾兑后，将样品摇匀，放置一个月，与标准酒样对照，如质量没有发生变化，即按照小型勾兑的比例进行大型勾兑。然后将大型勾兑后的酒密封贮存，一年后，将此酒样送厂评委检验，如果此酒达到或超过出厂酒的标准，即可包装出厂。</p>\n<p>制酒工艺的整体流程可以如下所示，假设第 X 年开始制曲和酿酒，那么在第 X + 5 年开始可以售卖成酒。<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20250218203542.png\" alt=\"\"></p>\n<ul>\n<li>第一年开始制曲和酿酒（假设是第 X 年），这个流程完成之后，会有基酒（此处是第 X + 1年）</li>\n<li>由于基酒不好喝，因此需要陈酿。<ul>\n<li>基酒首先存放一年，然后继续盘勾（这是第 X + 2 年）</li>\n<li>盘勾两年后，酒基本老熟，可以进行进行勾兑（这个过程完成是在第 X + 4 年）</li>\n</ul>\n</li>\n<li>精心勾兑是在第 X + 4 年完成，然后精心勾兑的酒需要再存放一年（这个过程完成是在第 X + 5 年），然后酒品达标酒装车包装出厂。</li>\n</ul>\n<p>茅台酒有两道工序需要冷却：一是蒸馏取酒，二是蒸馏后酒糟的摊凉。现在使用锡制水冷却器，天锅改用甑盖，蒸汽通过甑盖，顶部 2 米长的天桥管道，进入冷却器冷却，聚成酒接入酒坛，取酒手段大大进步，酒甑体积增大，增加了容量。</p>\n<p>茅台公司认为的核心竞争力如下：环境、工法、品质、品牌，文化，并拥有独一无二的原产地保护，不可复制的微生物菌落群、传承千年的独特酿造工艺，长期贮存的基酒资源组成的“四个核心势能”。</p>\n<p>系列酒</p>\n<ul>\n<li>2014 年 12 月，茅台酱香酒营销有限公司正式成立，系列酒开始独立运行，不再作为茅台的附属品存在。</li>\n<li>2015 年，推出赖茅、王茅、华茅和贵州大曲四个新平台。王茅和华茅很快就失败了，相继停产，到 2018 年又重新启动。</li>\n<li>系列酒包括：1935、一曲、三茅、四酱，以及大单品 1935</li>\n</ul>\n<p>公司的经营模式：采购原料 — 生产产品— 销售产品。<br>原料采购模式为：茅台酒用高粱采取“公司+地方政府+供应商+合作社或农户”的模式；小麦采取“公司+供应商+合作社或农场”的模式，其他原辅料及包装材料采购主要根据公司生产和销售计划，通过集中采购方式向市场采购；<br>产品生产工艺流程为：制曲 — 制酒 — 贮存 — 勾兑 — 包装<br>销售模式为：公司产品通过直销和批发代理渠道进行销售。直销渠道指自营和“i 茅台”等数字营销平台渠道，批发代理渠道指社会经销商、商超、电商等渠道。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] <a href=\"https://www.rh.gov.cn/yxrh/rhjj/mswh/202405/t20240508_84599090.html\">https://www.rh.gov.cn/yxrh/rhjj/mswh/202405/t20240508_84599090.html</a></p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文尝试记录一些茅台公司的基本情况，便于对公司的深入了解。</p>\n</blockquote>\n<p>茅台的香型有三种典型体 — 酱香，窖底香，醇香。茅台酒命名为酱香型。[1]</p>\n<ul>\n<li>酱香体：具有酱香味，且味感优雅细腻</li>\n<li>窖底香：用窖底酒醅酿烤、放香好，但酒味冲辣者定位窖底香。</li>\n<li>醇甜体：含有大量多种香气成分，味醇甜者定为醇甜体。</li>\n</ul>","more":"<p>茅台酒有多个独特的作法：</p>\n<ul>\n<li>茅台酒生产从投料到丢糟直至结束，需要一年时间，也正好是一年一个生产周期</li>\n<li>茅台酒全年生产用料—高粱，要在两个月内两次投完。</li>\n<li>茅台酒的陈酿的时间，最短也要四年以上。这就是茅台酒显得优雅细腻的重要原因之一。</li>\n<li>茅台酒制曲需要经过数十天的高温发酵，时间之长，温度之高，在白酒生产中可以说是首屈一指。五月端午前后开始踩曲，曲香特别浓郁，用曲量大，是形成茅台酒酱香突出的重要原因。</li>\n<li>成熟了的曲药要经过 6 个月以上的贮存才能使用。</li>\n<li>茅台酒对同一种原料药反复 7 次取酒，由于每一轮酒醅的基础不一样，气候条件不一样，所以每一轮次酒都有其特点，再经勾兑，相互取长补短，酒体显得协调，丰满。</li>\n<li>同一批原料要经过 8 次摊凉，8 次加曲，8次堆积，8次入窖发酵，每一次入窖前都要喷洒一次“尾酒”，这种回沙技术是非常独特和科学的。</li>\n<li>生产季节性强，九月重阳投料，这个季节性生产的特点，是和气候密切相关联的。</li>\n</ul>\n<p>茅台酒的独特酿造工艺：高温制曲、高温堆积、高温流酒、两次投料、七次蒸馏、八次发酵、九次蒸煮、长期陈酿，精心勾兑。由于茅台酒生产受产地的地质、水源、气候、温度、湿度、风向等自然条件影响，形成了有利于茅台酒的微生物群，使茅台酒酱香突出，风格独异，他处难于仿制。</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202502081749302.png\" alt=\"\"></p>\n<p>因为刚酿烤出来的酒，具有爆辣、冲鼻，刺激性大的缺点。经过一定的陈酿期后，新酒变成陈酒，新酒具备的缺点就基本消失了。这个过程，经过氧化还原等一系列化学变化和物理变化，有效地排除了酒的低沸点物质，如醇类、硫化物等。除去了新酒的不愉快气味，乙醇缩合，辛辣味减少，增加了酒的芳香。随着酒的贮存时间的延长，增加爱了水分子和酒精分子的结合，减少了刺激，增加了香味。</p>\n<p>陈酿的工艺：新酒入库以后，经检验品尝鉴定定香型后，装入容量为几百公斤的大酒坛内，酒坛上贴标签，注明该坛酒的生产时间，哪一班，哪一轮次酿制，属哪一类香型。存放一年后，将此酒“盘勾”。盘勾两年后，共经过三年的陈酿期，酒已基本老熟，进入了小型勾兑和大型勾兑的“精心勾兑”阶段。精心勾兑后的茅台酒，还要在酒库里继续陈酿。一年以后，通过检查，如果符合或超过茅台酒的质量标准，即可送包装车间包装出厂。</p>\n<p>茅台是固态发酵，和洋酒的液态发酵不一样，液态发酵需要将原料经过粉碎后，在水溶液里添加酵母进行发酵。酵母相对比较单一，发酵力非常强，发酵速度一般比较快，比较充分，耗粮率比较低。但它带来的结果就是，里边的大分子物质比较多，香味成分少。大分子多的结果就是喝多了会上头。而我们国内的这些名白酒很细腻，喝太多不会上头，这是非常大的一个差别。</p>\n<p>堆积发酵是茅台酒独特的操作工艺，既网罗、筛选繁殖了微生物，又弥补了大曲微生物品种和数量的不足，同时生成 大量的香味物质和香味的前驱物质，在茅台酒传统的工艺中，占用重要的位置。</p>\n<p>茅台酒生产所需的原料是红高粱和小麦。每公斤酒用粮 5 公斤左右，红高粱和小麦大体上各占一半。据 1956 年的历史资料记载，有 4 个红高粱品种最适合于酿造茅台酒：矮子高粱、中心高粱、麻鸡婆高粱和红缨子高粱。</p>\n<p>制曲是酿酒的第一套工序，由于曲中有益微生物数量和品种较多，香味物质也较多，因此，它是关系到酒的质量高低的一个重要环节。茅台酒采用优质小麦制造高温大曲，与其他酒的大曲相比，有三个独特之处：</p>\n<ul>\n<li>生产季节性强，要求“伏天踩曲”，每年端午节前后开始踩曲，重阳节结束。这段时间内气温高、湿度大，空气中微生物的种类和数量多，且活跃。</li>\n<li>制曲需要优质小麦，不加任何辅料。小麦粘着力强，营养丰富，适宜于菌种的生长，也符合前人总结酿酒经验中之处的“得自然之曲，乃称第一品”的要求。</li>\n<li>制曲温度高在 60 摄氏度以上，俗称高温大曲。<br>在踩曲过程中，高度、湿度、水分比例，母曲投放比例等均有独特的要求和严密的工艺。</li>\n</ul>\n<p>白酒中的主要成分包括醇类物质，酸、酯、醛、酮，酚等。酒中包含的物质含量、比例等不一样均会影响最终的口感，茅台酒通过不同香型、不同轮次，不同酒度，不同年龄的茅台酒相互勾兑，形成最终用户拿到的茅台酒。</p>\n<p>茅台酒的勾兑工序如下：茅台酒陈酿期满三年后，先勾兑基础酒，再调香，调味，先是小型勾兑，再大型勾兑。小型勾兑后，将样品摇匀，放置一个月，与标准酒样对照，如质量没有发生变化，即按照小型勾兑的比例进行大型勾兑。然后将大型勾兑后的酒密封贮存，一年后，将此酒样送厂评委检验，如果此酒达到或超过出厂酒的标准，即可包装出厂。</p>\n<p>制酒工艺的整体流程可以如下所示，假设第 X 年开始制曲和酿酒，那么在第 X + 5 年开始可以售卖成酒。<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20250218203542.png\" alt=\"\"></p>\n<ul>\n<li>第一年开始制曲和酿酒（假设是第 X 年），这个流程完成之后，会有基酒（此处是第 X + 1年）</li>\n<li>由于基酒不好喝，因此需要陈酿。<ul>\n<li>基酒首先存放一年，然后继续盘勾（这是第 X + 2 年）</li>\n<li>盘勾两年后，酒基本老熟，可以进行进行勾兑（这个过程完成是在第 X + 4 年）</li>\n</ul>\n</li>\n<li>精心勾兑是在第 X + 4 年完成，然后精心勾兑的酒需要再存放一年（这个过程完成是在第 X + 5 年），然后酒品达标酒装车包装出厂。</li>\n</ul>\n<p>茅台酒有两道工序需要冷却：一是蒸馏取酒，二是蒸馏后酒糟的摊凉。现在使用锡制水冷却器，天锅改用甑盖，蒸汽通过甑盖，顶部 2 米长的天桥管道，进入冷却器冷却，聚成酒接入酒坛，取酒手段大大进步，酒甑体积增大，增加了容量。</p>\n<p>茅台公司认为的核心竞争力如下：环境、工法、品质、品牌，文化，并拥有独一无二的原产地保护，不可复制的微生物菌落群、传承千年的独特酿造工艺，长期贮存的基酒资源组成的“四个核心势能”。</p>\n<p>系列酒</p>\n<ul>\n<li>2014 年 12 月，茅台酱香酒营销有限公司正式成立，系列酒开始独立运行，不再作为茅台的附属品存在。</li>\n<li>2015 年，推出赖茅、王茅、华茅和贵州大曲四个新平台。王茅和华茅很快就失败了，相继停产，到 2018 年又重新启动。</li>\n<li>系列酒包括：1935、一曲、三茅、四酱，以及大单品 1935</li>\n</ul>\n<p>公司的经营模式：采购原料 — 生产产品— 销售产品。<br>原料采购模式为：茅台酒用高粱采取“公司+地方政府+供应商+合作社或农户”的模式；小麦采取“公司+供应商+合作社或农场”的模式，其他原辅料及包装材料采购主要根据公司生产和销售计划，通过集中采购方式向市场采购；<br>产品生产工艺流程为：制曲 — 制酒 — 贮存 — 勾兑 — 包装<br>销售模式为：公司产品通过直销和批发代理渠道进行销售。直销渠道指自营和“i 茅台”等数字营销平台渠道，批发代理渠道指社会经销商、商超、电商等渠道。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] <a href=\"https://www.rh.gov.cn/yxrh/rhjj/mswh/202405/t20240508_84599090.html\">https://www.rh.gov.cn/yxrh/rhjj/mswh/202405/t20240508_84599090.html</a></p>"},{"_content":"主要描述 dblog 和 flinkcdc 中的实现。\n\n怎么从 db 中无锁同步数据（无锁主要是不需要锁整个表）\n\n","source":"_drafts/sync-data-without-lock.md","raw":"主要描述 dblog 和 flinkcdc 中的实现。\n\n怎么从 db 中无锁同步数据（无锁主要是不需要锁整个表）\n\n","slug":"sync-data-without-lock","published":0,"date":"2025-03-16T07:09:23.093Z","updated":"2025-03-16T07:09:23.094Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cm8l8efli0000cjjl48dyc4fz","content":"<p>主要描述 dblog 和 flinkcdc 中的实现。</p>\n<p>怎么从 db 中无锁同步数据（无锁主要是不需要锁整个表）</p>\n","site":{"data":{}},"excerpt":"","more":"<p>主要描述 dblog 和 flinkcdc 中的实现。</p>\n<p>怎么从 db 中无锁同步数据（无锁主要是不需要锁整个表）</p>\n"},{"title":"40 questions to ask yourself every year","toc":true,"_content":"\n尝试从 2025 开始每年回答一下 40 个问题[1]，作为一年的回顾\n\n<!-- more -->\n\n# What did you do this year that you’d never done before?\n# Did you keep your new year’s resolutions?\n# Did anyone close to you give birth?\n\n# Did anyone close to you die?\n没有\n\n# What cities/states/countries did you visit?\n在北京周边（河北），去了一趟泰山\n\n# What would you like to have next year that you lacked this year?\n\n# What date(s) from this year will remain etched upon your memory, and why?\n# What was your biggest achievement of the year?\n- 职业相关的（title 变成副总监，成为 Apache Amoro PPMC member）\n- 陪家人的时间更多了一些\n# What was your biggest failure?\n- \n# What other hardships did you face?\n- 还是不够自由\n\n# Did you suffer illness or injury?\n身体暂时还行\n\n# What was the best thing you bought?\n# Whose behavior merited celebration?\n# Whose behavior made you appalled?\n# Where did most of your money go?\n- 投资（这个是消费还是？）\n\n# What did you get really, really, really excited about?\n- 对投资的理解上了一个台阶\n\n# What song will always remind you of this year?\n# Compared to this time last year, are you: happier or sadder? Thinner or fatter? Richer or poorer?\n- happier / fatter / richer\n\n# What do you wish you’d done more of?\n- 锻炼\n- 陪家人\n- 商业理解\n\n# What do you wish you’d done less of?\n# How are you spending the holidays?\n# Did you fall in love this year?\n\n# Do you hate anyone now that you didn’t hate this time last year?\n- 有不喜欢的，但不至于 hate\n\n# What was your favorite show?\n# What was the best book you read?\n- 段永平 投资相关的数据。让我了解了一部分商业模式：差异化 = 用户需要但是提供商暂未提供的\n\n# What was your greatest musical discovery of the year?\n# What was your favorite film?\n# What was your favorite meal?\n# What did you want and get?\n# What did you want and not get?\n# What did you do on your birthday?\n# What one thing would have made your year immeasurably more satisfying?\n# How would you describe your personal fashion this year?\n# What kept you sane?\n# Which celebrity/public figure did you admire the most?\n# What political issue stirred you the most?\n# Who did you miss?\n# Who was the best new person you met?\n# What valuable life lesson did you learn this year?\n# What is a quote that sums up your year?\n\n# Ref\n[1] https://stephango.com/40-questions\n","source":"_drafts/40-questions-2024.md","raw":"---\ntitle: 40 questions to ask yourself every year\ntags:\n    - review\n    - question\ntoc: true\n---\n\n尝试从 2025 开始每年回答一下 40 个问题[1]，作为一年的回顾\n\n<!-- more -->\n\n# What did you do this year that you’d never done before?\n# Did you keep your new year’s resolutions?\n# Did anyone close to you give birth?\n\n# Did anyone close to you die?\n没有\n\n# What cities/states/countries did you visit?\n在北京周边（河北），去了一趟泰山\n\n# What would you like to have next year that you lacked this year?\n\n# What date(s) from this year will remain etched upon your memory, and why?\n# What was your biggest achievement of the year?\n- 职业相关的（title 变成副总监，成为 Apache Amoro PPMC member）\n- 陪家人的时间更多了一些\n# What was your biggest failure?\n- \n# What other hardships did you face?\n- 还是不够自由\n\n# Did you suffer illness or injury?\n身体暂时还行\n\n# What was the best thing you bought?\n# Whose behavior merited celebration?\n# Whose behavior made you appalled?\n# Where did most of your money go?\n- 投资（这个是消费还是？）\n\n# What did you get really, really, really excited about?\n- 对投资的理解上了一个台阶\n\n# What song will always remind you of this year?\n# Compared to this time last year, are you: happier or sadder? Thinner or fatter? Richer or poorer?\n- happier / fatter / richer\n\n# What do you wish you’d done more of?\n- 锻炼\n- 陪家人\n- 商业理解\n\n# What do you wish you’d done less of?\n# How are you spending the holidays?\n# Did you fall in love this year?\n\n# Do you hate anyone now that you didn’t hate this time last year?\n- 有不喜欢的，但不至于 hate\n\n# What was your favorite show?\n# What was the best book you read?\n- 段永平 投资相关的数据。让我了解了一部分商业模式：差异化 = 用户需要但是提供商暂未提供的\n\n# What was your greatest musical discovery of the year?\n# What was your favorite film?\n# What was your favorite meal?\n# What did you want and get?\n# What did you want and not get?\n# What did you do on your birthday?\n# What one thing would have made your year immeasurably more satisfying?\n# How would you describe your personal fashion this year?\n# What kept you sane?\n# Which celebrity/public figure did you admire the most?\n# What political issue stirred you the most?\n# Who did you miss?\n# Who was the best new person you met?\n# What valuable life lesson did you learn this year?\n# What is a quote that sums up your year?\n\n# Ref\n[1] https://stephango.com/40-questions\n","slug":"40-questions-2024","published":0,"date":"2025-03-13T11:00:05.294Z","updated":"2025-03-13T11:00:05.295Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cm8l8eflp0001cjjl80sl72n6","content":"<p>尝试从 2025 开始每年回答一下 40 个问题[1]，作为一年的回顾</p>\n<span id=\"more\"></span>\n<h1 id=\"What-did-you-do-this-year-that-you’d-never-done-before\"><a href=\"#What-did-you-do-this-year-that-you’d-never-done-before\" class=\"headerlink\" title=\"What did you do this year that you’d never done before?\"></a>What did you do this year that you’d never done before?</h1><h1 id=\"Did-you-keep-your-new-year’s-resolutions\"><a href=\"#Did-you-keep-your-new-year’s-resolutions\" class=\"headerlink\" title=\"Did you keep your new year’s resolutions?\"></a>Did you keep your new year’s resolutions?</h1><h1 id=\"Did-anyone-close-to-you-give-birth\"><a href=\"#Did-anyone-close-to-you-give-birth\" class=\"headerlink\" title=\"Did anyone close to you give birth?\"></a>Did anyone close to you give birth?</h1><h1 id=\"Did-anyone-close-to-you-die\"><a href=\"#Did-anyone-close-to-you-die\" class=\"headerlink\" title=\"Did anyone close to you die?\"></a>Did anyone close to you die?</h1><p>没有</p>\n<h1 id=\"What-cities-states-countries-did-you-visit\"><a href=\"#What-cities-states-countries-did-you-visit\" class=\"headerlink\" title=\"What cities/states/countries did you visit?\"></a>What cities/states/countries did you visit?</h1><p>在北京周边（河北），去了一趟泰山</p>\n<h1 id=\"What-would-you-like-to-have-next-year-that-you-lacked-this-year\"><a href=\"#What-would-you-like-to-have-next-year-that-you-lacked-this-year\" class=\"headerlink\" title=\"What would you like to have next year that you lacked this year?\"></a>What would you like to have next year that you lacked this year?</h1><h1 id=\"What-date-s-from-this-year-will-remain-etched-upon-your-memory-and-why\"><a href=\"#What-date-s-from-this-year-will-remain-etched-upon-your-memory-and-why\" class=\"headerlink\" title=\"What date(s) from this year will remain etched upon your memory, and why?\"></a>What date(s) from this year will remain etched upon your memory, and why?</h1><h1 id=\"What-was-your-biggest-achievement-of-the-year\"><a href=\"#What-was-your-biggest-achievement-of-the-year\" class=\"headerlink\" title=\"What was your biggest achievement of the year?\"></a>What was your biggest achievement of the year?</h1><ul>\n<li>职业相关的（title 变成副总监，成为 Apache Amoro PPMC member）</li>\n<li>陪家人的时间更多了一些<h1 id=\"What-was-your-biggest-failure\"><a href=\"#What-was-your-biggest-failure\" class=\"headerlink\" title=\"What was your biggest failure?\"></a>What was your biggest failure?</h1></li>\n<li><h1 id=\"What-other-hardships-did-you-face\"><a href=\"#What-other-hardships-did-you-face\" class=\"headerlink\" title=\"What other hardships did you face?\"></a>What other hardships did you face?</h1></li>\n<li>还是不够自由</li>\n</ul>\n<h1 id=\"Did-you-suffer-illness-or-injury\"><a href=\"#Did-you-suffer-illness-or-injury\" class=\"headerlink\" title=\"Did you suffer illness or injury?\"></a>Did you suffer illness or injury?</h1><p>身体暂时还行</p>\n<h1 id=\"What-was-the-best-thing-you-bought\"><a href=\"#What-was-the-best-thing-you-bought\" class=\"headerlink\" title=\"What was the best thing you bought?\"></a>What was the best thing you bought?</h1><h1 id=\"Whose-behavior-merited-celebration\"><a href=\"#Whose-behavior-merited-celebration\" class=\"headerlink\" title=\"Whose behavior merited celebration?\"></a>Whose behavior merited celebration?</h1><h1 id=\"Whose-behavior-made-you-appalled\"><a href=\"#Whose-behavior-made-you-appalled\" class=\"headerlink\" title=\"Whose behavior made you appalled?\"></a>Whose behavior made you appalled?</h1><h1 id=\"Where-did-most-of-your-money-go\"><a href=\"#Where-did-most-of-your-money-go\" class=\"headerlink\" title=\"Where did most of your money go?\"></a>Where did most of your money go?</h1><ul>\n<li>投资（这个是消费还是？）</li>\n</ul>\n<h1 id=\"What-did-you-get-really-really-really-excited-about\"><a href=\"#What-did-you-get-really-really-really-excited-about\" class=\"headerlink\" title=\"What did you get really, really, really excited about?\"></a>What did you get really, really, really excited about?</h1><ul>\n<li>对投资的理解上了一个台阶</li>\n</ul>\n<h1 id=\"What-song-will-always-remind-you-of-this-year\"><a href=\"#What-song-will-always-remind-you-of-this-year\" class=\"headerlink\" title=\"What song will always remind you of this year?\"></a>What song will always remind you of this year?</h1><h1 id=\"Compared-to-this-time-last-year-are-you-happier-or-sadder-Thinner-or-fatter-Richer-or-poorer\"><a href=\"#Compared-to-this-time-last-year-are-you-happier-or-sadder-Thinner-or-fatter-Richer-or-poorer\" class=\"headerlink\" title=\"Compared to this time last year, are you: happier or sadder? Thinner or fatter? Richer or poorer?\"></a>Compared to this time last year, are you: happier or sadder? Thinner or fatter? Richer or poorer?</h1><ul>\n<li>happier / fatter / richer</li>\n</ul>\n<h1 id=\"What-do-you-wish-you’d-done-more-of\"><a href=\"#What-do-you-wish-you’d-done-more-of\" class=\"headerlink\" title=\"What do you wish you’d done more of?\"></a>What do you wish you’d done more of?</h1><ul>\n<li>锻炼</li>\n<li>陪家人</li>\n<li>商业理解</li>\n</ul>\n<h1 id=\"What-do-you-wish-you’d-done-less-of\"><a href=\"#What-do-you-wish-you’d-done-less-of\" class=\"headerlink\" title=\"What do you wish you’d done less of?\"></a>What do you wish you’d done less of?</h1><h1 id=\"How-are-you-spending-the-holidays\"><a href=\"#How-are-you-spending-the-holidays\" class=\"headerlink\" title=\"How are you spending the holidays?\"></a>How are you spending the holidays?</h1><h1 id=\"Did-you-fall-in-love-this-year\"><a href=\"#Did-you-fall-in-love-this-year\" class=\"headerlink\" title=\"Did you fall in love this year?\"></a>Did you fall in love this year?</h1><h1 id=\"Do-you-hate-anyone-now-that-you-didn’t-hate-this-time-last-year\"><a href=\"#Do-you-hate-anyone-now-that-you-didn’t-hate-this-time-last-year\" class=\"headerlink\" title=\"Do you hate anyone now that you didn’t hate this time last year?\"></a>Do you hate anyone now that you didn’t hate this time last year?</h1><ul>\n<li>有不喜欢的，但不至于 hate</li>\n</ul>\n<h1 id=\"What-was-your-favorite-show\"><a href=\"#What-was-your-favorite-show\" class=\"headerlink\" title=\"What was your favorite show?\"></a>What was your favorite show?</h1><h1 id=\"What-was-the-best-book-you-read\"><a href=\"#What-was-the-best-book-you-read\" class=\"headerlink\" title=\"What was the best book you read?\"></a>What was the best book you read?</h1><ul>\n<li>段永平 投资相关的数据。让我了解了一部分商业模式：差异化 = 用户需要但是提供商暂未提供的</li>\n</ul>\n<h1 id=\"What-was-your-greatest-musical-discovery-of-the-year\"><a href=\"#What-was-your-greatest-musical-discovery-of-the-year\" class=\"headerlink\" title=\"What was your greatest musical discovery of the year?\"></a>What was your greatest musical discovery of the year?</h1><h1 id=\"What-was-your-favorite-film\"><a href=\"#What-was-your-favorite-film\" class=\"headerlink\" title=\"What was your favorite film?\"></a>What was your favorite film?</h1><h1 id=\"What-was-your-favorite-meal\"><a href=\"#What-was-your-favorite-meal\" class=\"headerlink\" title=\"What was your favorite meal?\"></a>What was your favorite meal?</h1><h1 id=\"What-did-you-want-and-get\"><a href=\"#What-did-you-want-and-get\" class=\"headerlink\" title=\"What did you want and get?\"></a>What did you want and get?</h1><h1 id=\"What-did-you-want-and-not-get\"><a href=\"#What-did-you-want-and-not-get\" class=\"headerlink\" title=\"What did you want and not get?\"></a>What did you want and not get?</h1><h1 id=\"What-did-you-do-on-your-birthday\"><a href=\"#What-did-you-do-on-your-birthday\" class=\"headerlink\" title=\"What did you do on your birthday?\"></a>What did you do on your birthday?</h1><h1 id=\"What-one-thing-would-have-made-your-year-immeasurably-more-satisfying\"><a href=\"#What-one-thing-would-have-made-your-year-immeasurably-more-satisfying\" class=\"headerlink\" title=\"What one thing would have made your year immeasurably more satisfying?\"></a>What one thing would have made your year immeasurably more satisfying?</h1><h1 id=\"How-would-you-describe-your-personal-fashion-this-year\"><a href=\"#How-would-you-describe-your-personal-fashion-this-year\" class=\"headerlink\" title=\"How would you describe your personal fashion this year?\"></a>How would you describe your personal fashion this year?</h1><h1 id=\"What-kept-you-sane\"><a href=\"#What-kept-you-sane\" class=\"headerlink\" title=\"What kept you sane?\"></a>What kept you sane?</h1><h1 id=\"Which-celebrity-public-figure-did-you-admire-the-most\"><a href=\"#Which-celebrity-public-figure-did-you-admire-the-most\" class=\"headerlink\" title=\"Which celebrity/public figure did you admire the most?\"></a>Which celebrity/public figure did you admire the most?</h1><h1 id=\"What-political-issue-stirred-you-the-most\"><a href=\"#What-political-issue-stirred-you-the-most\" class=\"headerlink\" title=\"What political issue stirred you the most?\"></a>What political issue stirred you the most?</h1><h1 id=\"Who-did-you-miss\"><a href=\"#Who-did-you-miss\" class=\"headerlink\" title=\"Who did you miss?\"></a>Who did you miss?</h1><h1 id=\"Who-was-the-best-new-person-you-met\"><a href=\"#Who-was-the-best-new-person-you-met\" class=\"headerlink\" title=\"Who was the best new person you met?\"></a>Who was the best new person you met?</h1><h1 id=\"What-valuable-life-lesson-did-you-learn-this-year\"><a href=\"#What-valuable-life-lesson-did-you-learn-this-year\" class=\"headerlink\" title=\"What valuable life lesson did you learn this year?\"></a>What valuable life lesson did you learn this year?</h1><h1 id=\"What-is-a-quote-that-sums-up-your-year\"><a href=\"#What-is-a-quote-that-sums-up-your-year\" class=\"headerlink\" title=\"What is a quote that sums up your year?\"></a>What is a quote that sums up your year?</h1><h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] <a href=\"https://stephango.com/40-questions\">https://stephango.com/40-questions</a></p>\n","site":{"data":{}},"excerpt":"<p>尝试从 2025 开始每年回答一下 40 个问题[1]，作为一年的回顾</p>","more":"<h1 id=\"What-did-you-do-this-year-that-you’d-never-done-before\"><a href=\"#What-did-you-do-this-year-that-you’d-never-done-before\" class=\"headerlink\" title=\"What did you do this year that you’d never done before?\"></a>What did you do this year that you’d never done before?</h1><h1 id=\"Did-you-keep-your-new-year’s-resolutions\"><a href=\"#Did-you-keep-your-new-year’s-resolutions\" class=\"headerlink\" title=\"Did you keep your new year’s resolutions?\"></a>Did you keep your new year’s resolutions?</h1><h1 id=\"Did-anyone-close-to-you-give-birth\"><a href=\"#Did-anyone-close-to-you-give-birth\" class=\"headerlink\" title=\"Did anyone close to you give birth?\"></a>Did anyone close to you give birth?</h1><h1 id=\"Did-anyone-close-to-you-die\"><a href=\"#Did-anyone-close-to-you-die\" class=\"headerlink\" title=\"Did anyone close to you die?\"></a>Did anyone close to you die?</h1><p>没有</p>\n<h1 id=\"What-cities-states-countries-did-you-visit\"><a href=\"#What-cities-states-countries-did-you-visit\" class=\"headerlink\" title=\"What cities/states/countries did you visit?\"></a>What cities/states/countries did you visit?</h1><p>在北京周边（河北），去了一趟泰山</p>\n<h1 id=\"What-would-you-like-to-have-next-year-that-you-lacked-this-year\"><a href=\"#What-would-you-like-to-have-next-year-that-you-lacked-this-year\" class=\"headerlink\" title=\"What would you like to have next year that you lacked this year?\"></a>What would you like to have next year that you lacked this year?</h1><h1 id=\"What-date-s-from-this-year-will-remain-etched-upon-your-memory-and-why\"><a href=\"#What-date-s-from-this-year-will-remain-etched-upon-your-memory-and-why\" class=\"headerlink\" title=\"What date(s) from this year will remain etched upon your memory, and why?\"></a>What date(s) from this year will remain etched upon your memory, and why?</h1><h1 id=\"What-was-your-biggest-achievement-of-the-year\"><a href=\"#What-was-your-biggest-achievement-of-the-year\" class=\"headerlink\" title=\"What was your biggest achievement of the year?\"></a>What was your biggest achievement of the year?</h1><ul>\n<li>职业相关的（title 变成副总监，成为 Apache Amoro PPMC member）</li>\n<li>陪家人的时间更多了一些<h1 id=\"What-was-your-biggest-failure\"><a href=\"#What-was-your-biggest-failure\" class=\"headerlink\" title=\"What was your biggest failure?\"></a>What was your biggest failure?</h1></li>\n<li><h1 id=\"What-other-hardships-did-you-face\"><a href=\"#What-other-hardships-did-you-face\" class=\"headerlink\" title=\"What other hardships did you face?\"></a>What other hardships did you face?</h1></li>\n<li>还是不够自由</li>\n</ul>\n<h1 id=\"Did-you-suffer-illness-or-injury\"><a href=\"#Did-you-suffer-illness-or-injury\" class=\"headerlink\" title=\"Did you suffer illness or injury?\"></a>Did you suffer illness or injury?</h1><p>身体暂时还行</p>\n<h1 id=\"What-was-the-best-thing-you-bought\"><a href=\"#What-was-the-best-thing-you-bought\" class=\"headerlink\" title=\"What was the best thing you bought?\"></a>What was the best thing you bought?</h1><h1 id=\"Whose-behavior-merited-celebration\"><a href=\"#Whose-behavior-merited-celebration\" class=\"headerlink\" title=\"Whose behavior merited celebration?\"></a>Whose behavior merited celebration?</h1><h1 id=\"Whose-behavior-made-you-appalled\"><a href=\"#Whose-behavior-made-you-appalled\" class=\"headerlink\" title=\"Whose behavior made you appalled?\"></a>Whose behavior made you appalled?</h1><h1 id=\"Where-did-most-of-your-money-go\"><a href=\"#Where-did-most-of-your-money-go\" class=\"headerlink\" title=\"Where did most of your money go?\"></a>Where did most of your money go?</h1><ul>\n<li>投资（这个是消费还是？）</li>\n</ul>\n<h1 id=\"What-did-you-get-really-really-really-excited-about\"><a href=\"#What-did-you-get-really-really-really-excited-about\" class=\"headerlink\" title=\"What did you get really, really, really excited about?\"></a>What did you get really, really, really excited about?</h1><ul>\n<li>对投资的理解上了一个台阶</li>\n</ul>\n<h1 id=\"What-song-will-always-remind-you-of-this-year\"><a href=\"#What-song-will-always-remind-you-of-this-year\" class=\"headerlink\" title=\"What song will always remind you of this year?\"></a>What song will always remind you of this year?</h1><h1 id=\"Compared-to-this-time-last-year-are-you-happier-or-sadder-Thinner-or-fatter-Richer-or-poorer\"><a href=\"#Compared-to-this-time-last-year-are-you-happier-or-sadder-Thinner-or-fatter-Richer-or-poorer\" class=\"headerlink\" title=\"Compared to this time last year, are you: happier or sadder? Thinner or fatter? Richer or poorer?\"></a>Compared to this time last year, are you: happier or sadder? Thinner or fatter? Richer or poorer?</h1><ul>\n<li>happier / fatter / richer</li>\n</ul>\n<h1 id=\"What-do-you-wish-you’d-done-more-of\"><a href=\"#What-do-you-wish-you’d-done-more-of\" class=\"headerlink\" title=\"What do you wish you’d done more of?\"></a>What do you wish you’d done more of?</h1><ul>\n<li>锻炼</li>\n<li>陪家人</li>\n<li>商业理解</li>\n</ul>\n<h1 id=\"What-do-you-wish-you’d-done-less-of\"><a href=\"#What-do-you-wish-you’d-done-less-of\" class=\"headerlink\" title=\"What do you wish you’d done less of?\"></a>What do you wish you’d done less of?</h1><h1 id=\"How-are-you-spending-the-holidays\"><a href=\"#How-are-you-spending-the-holidays\" class=\"headerlink\" title=\"How are you spending the holidays?\"></a>How are you spending the holidays?</h1><h1 id=\"Did-you-fall-in-love-this-year\"><a href=\"#Did-you-fall-in-love-this-year\" class=\"headerlink\" title=\"Did you fall in love this year?\"></a>Did you fall in love this year?</h1><h1 id=\"Do-you-hate-anyone-now-that-you-didn’t-hate-this-time-last-year\"><a href=\"#Do-you-hate-anyone-now-that-you-didn’t-hate-this-time-last-year\" class=\"headerlink\" title=\"Do you hate anyone now that you didn’t hate this time last year?\"></a>Do you hate anyone now that you didn’t hate this time last year?</h1><ul>\n<li>有不喜欢的，但不至于 hate</li>\n</ul>\n<h1 id=\"What-was-your-favorite-show\"><a href=\"#What-was-your-favorite-show\" class=\"headerlink\" title=\"What was your favorite show?\"></a>What was your favorite show?</h1><h1 id=\"What-was-the-best-book-you-read\"><a href=\"#What-was-the-best-book-you-read\" class=\"headerlink\" title=\"What was the best book you read?\"></a>What was the best book you read?</h1><ul>\n<li>段永平 投资相关的数据。让我了解了一部分商业模式：差异化 = 用户需要但是提供商暂未提供的</li>\n</ul>\n<h1 id=\"What-was-your-greatest-musical-discovery-of-the-year\"><a href=\"#What-was-your-greatest-musical-discovery-of-the-year\" class=\"headerlink\" title=\"What was your greatest musical discovery of the year?\"></a>What was your greatest musical discovery of the year?</h1><h1 id=\"What-was-your-favorite-film\"><a href=\"#What-was-your-favorite-film\" class=\"headerlink\" title=\"What was your favorite film?\"></a>What was your favorite film?</h1><h1 id=\"What-was-your-favorite-meal\"><a href=\"#What-was-your-favorite-meal\" class=\"headerlink\" title=\"What was your favorite meal?\"></a>What was your favorite meal?</h1><h1 id=\"What-did-you-want-and-get\"><a href=\"#What-did-you-want-and-get\" class=\"headerlink\" title=\"What did you want and get?\"></a>What did you want and get?</h1><h1 id=\"What-did-you-want-and-not-get\"><a href=\"#What-did-you-want-and-not-get\" class=\"headerlink\" title=\"What did you want and not get?\"></a>What did you want and not get?</h1><h1 id=\"What-did-you-do-on-your-birthday\"><a href=\"#What-did-you-do-on-your-birthday\" class=\"headerlink\" title=\"What did you do on your birthday?\"></a>What did you do on your birthday?</h1><h1 id=\"What-one-thing-would-have-made-your-year-immeasurably-more-satisfying\"><a href=\"#What-one-thing-would-have-made-your-year-immeasurably-more-satisfying\" class=\"headerlink\" title=\"What one thing would have made your year immeasurably more satisfying?\"></a>What one thing would have made your year immeasurably more satisfying?</h1><h1 id=\"How-would-you-describe-your-personal-fashion-this-year\"><a href=\"#How-would-you-describe-your-personal-fashion-this-year\" class=\"headerlink\" title=\"How would you describe your personal fashion this year?\"></a>How would you describe your personal fashion this year?</h1><h1 id=\"What-kept-you-sane\"><a href=\"#What-kept-you-sane\" class=\"headerlink\" title=\"What kept you sane?\"></a>What kept you sane?</h1><h1 id=\"Which-celebrity-public-figure-did-you-admire-the-most\"><a href=\"#Which-celebrity-public-figure-did-you-admire-the-most\" class=\"headerlink\" title=\"Which celebrity/public figure did you admire the most?\"></a>Which celebrity/public figure did you admire the most?</h1><h1 id=\"What-political-issue-stirred-you-the-most\"><a href=\"#What-political-issue-stirred-you-the-most\" class=\"headerlink\" title=\"What political issue stirred you the most?\"></a>What political issue stirred you the most?</h1><h1 id=\"Who-did-you-miss\"><a href=\"#Who-did-you-miss\" class=\"headerlink\" title=\"Who did you miss?\"></a>Who did you miss?</h1><h1 id=\"Who-was-the-best-new-person-you-met\"><a href=\"#Who-was-the-best-new-person-you-met\" class=\"headerlink\" title=\"Who was the best new person you met?\"></a>Who was the best new person you met?</h1><h1 id=\"What-valuable-life-lesson-did-you-learn-this-year\"><a href=\"#What-valuable-life-lesson-did-you-learn-this-year\" class=\"headerlink\" title=\"What valuable life lesson did you learn this year?\"></a>What valuable life lesson did you learn this year?</h1><h1 id=\"What-is-a-quote-that-sums-up-your-year\"><a href=\"#What-is-a-quote-that-sums-up-your-year\" class=\"headerlink\" title=\"What is a quote that sums up your year?\"></a>What is a quote that sums up your year?</h1><h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] <a href=\"https://stephango.com/40-questions\">https://stephango.com/40-questions</a></p>"},{"title":"maotai-input-output","date":"2025-03-16T08:53:32.000Z","toc":true,"_content":"\n本文尝试更详细的分析茅台以及所在行业的一些指标信息，希望对茅台是否赚钱，以及赚钱后是否能够归属小股东等有一个大体的认识，也希望能够更好的了解应该关注公司哪些指标以及信息。\n\n<!--more-->\n\n对于股东来说，主要关注一个公司两点\n1. 公司业务是否赚钱\n2. 公司业务赚钱之后，是否都归属于股份有限公司（股东所有)\n\n# 茅台的业务\n\n茅台的业务主要是卖酒，在茅台酒的整条链路中，大致如下所示\n\n[原材料提供商] --原材料--> [茅台股份有限公司]  --酒--> [直销/经销商] (--酒--> [终端销售]) --酒--> [终端客户]\n\n其中 [终端销售] 这一环节可能没有，比如在直销或者电商等渠道\n\n国信证券梳理[2]的销售渠道以及相关价格如下所示（2023 年出厂价涨价前）\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231410651.png)\n\n涨价后，大致修改如下所示\n- 原材料提供商\n  - 茅台股份有限公司\n    - [直销] i茅台/数字营销平台  <-- 零售指导价 1499\n    - 茅台销售公司\n      - [经销] 一级经销商  <-- 拿酒成本是 出厂价 1199\n        - 终端销售  <-- 一批价 按照[2] 大概 2300\n          - 客户    <-- 实际购买价  散装大概 2600[3]，会持续有变动\n    - 商超  <--  1399 参考国信证券数据[2]\n    - 电商  <--  1399 参考国信证券数据[2]\n    - 团购  <-- 零售指导价 1499\n\n其中出厂价是固定的(1199)，零售指导价是固定的(1499)，批价和终端价会随着市场需求的变动而变化。如果终端需求多，终端价会增加，从而会提高批价，反之则会导致终端价和批价下降。\n\n其中出厂价/建议零售价/商超/电商/团购的 基本固定（变动周期较长），经销商相关的的销售链路，其中 [终端价] 和 [批价] 的差异为终端销售的利润，[批价] 和 [出厂价] 的差异则是经销商的利润。如果这两个利润过低甚至变负，则会影响整条链路上的整体酒销售。\n\n下图展示了经销商在过去几年中的利润空间变化（其中灰色的区域是渠道利润，红色是出厂价，蓝色是批价）[2]\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202504021431926.png)\n\n# 茅台是否赚钱\n茅台的整体业务比较简单，主要是卖酒，然后还有部分金融业务。\n\n首先看下最近几年的营收和成本，如下图所示\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231446109.png)\n\n上图中可以看出几点\n- 利润主要来自于营业收入 -- 也就是卖酒。\n- 营业收入最近几年逐年增加\n- 营业成本的增长率和营业收入的增长率差不多\n\n其中营业收入拆开来看的情况如下图所示\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231417076.png)\n\n从图中可以看到\n- 最多的成本是税及附加 -- 由于税率固定，这部分是卖的越多，税越多\n- 营业成本逐年增加，但是增加的没有税多\n- 管理费用/销售费用 逐年增加，但是增加不是很多，整体占比也不是很多\n\n另外从不同角度查看营业收入的情况。\n\n茅台酒和系列酒的情况（单位：百万）\n\n| 年份 | 茅台酒(占比/较上年涨幅) | 系列酒(占比/较上年涨幅) |\n| -- | -- | -- |\n| 2023 | 126589(85.9%/17.6%) | 20629(14.1%/29.4%) |\n| 2022 | 107833(87.1%/15.3%) | 15938(12.9%/26.5%) |\n| 2021 | 93464(88.1%/10.1%) | 12594(11.9%/26%) |\n| 2020 | 84830(89.4%/11.9%) | 9991(10.6%/4.7%) |\n| 2019 | 75802(88.8%/15.7%) | 9542(11.2%/18.2%) |\n\n经销和直销的收入情况（单位：百万）\n\n| 年份 | 经销（占比/较上年涨幅) | 直销（占比/较上年涨幅）|\n| -- | -- | -- |\n| 2023 | 7998611.94(54.33%/7.5%) | 6723287.69(45.67%/36.15%) |\n| 2022 | 7439359.47(60.10%/-9.4%) | 4937873.77(39.9%/105%) |\n| 2021 | 8202992(77.34%/0.5%) | 2402936(22.66%/81.48%) |\n| 2020 | 8158164.26(86.03%/377%) | 1324035.65(13.97%/82.6%) |\n| 2019 | 7809590.86(91.5%/-) | 724865.97(8.5%/-) |\n\n经销和直销的酒量情况（单位：吨）\n\n| 年份 | 经销（占比/较上年涨幅) | 直销（占比/较上年涨幅）|\n| -- | -- | -- |\n| 2023 | 57639.09(78.66%/1.1%) | 15634.95(21.34%/39.76%) |\n| 2022 | 56989.75(83.59%/-6.1%) | 11186.57(16.41%/95.04%) |\n| 2021 | 60702.99(91.36%/0.9%) | 5735.70(8.64%/45.85%) |\n| 2020 | 60123.8(93.86%/-3.01%)  | 3932.08(6.14%/48.32%) |\n| 2019 | 61993.46(95.89%/-) | 2651.84(4.11%/-) |\n\n从上面的数据可以看到，经销的量基本没有太大变化，总收入稍微有些增长；直销的量和收入均有比较大的增长。\n\n国内和国外销售情况（单位：百万），暂时国内销售占主要比例\n\n| 年份 | 国内（占比/较上年涨幅) | 国外（占比/较上年涨幅）|\n| -- | -- | -- |\n| 2023 | 142868(97%/19.5%) | 4350(3%/2.6%) |\n| 2022 | 119532(96.5%/15.5%) | 4239(3.5%/61.9%) |\n| 2021 | 103440(97.5%/11.9%) | 2618(2.5%/7.6%) |\n| 2020 | 92389(97.4%/12%) | 2432(2.6%/-16.8%) |\n| 2019 | 82424(96.5%/16.6%) | 2920(3.5%/0.9%) |\n\n接下来查看预收账款（单位：百万）相关的情况 -- 经销售需要预打款才能买到货（这个也变相的说明茅台不愁销量 -- 这里的销量和终端销售公司的销量不完全是一个概念），可以每年有百亿级别的预收账款\n\n| 年份 | 预售款（增长） |\n| -- | -- |\n| 2023 | 14,125(-8.7%) |\n| 2022 | 15,471(21.64%) |\n| 2021 | 12,718(4.5%) | \n| 2020 | 13,321(-3.0% |\n| 2019 | 13,740(-) |\n\n\n然后再看下不同类型酒的销售额（单位：十亿），以及涨幅如下。从数据可以看出来，白酒持续在增长，但是其他类型酒的销售额则有不同类型的波动。\n\n| 年份 | 白酒（涨幅) | 啤酒（涨幅）| 葡萄酒（涨幅）|黄酒（涨幅）|\n| -- | -- | -- | -- | -- |\n| 2023 | 756(19.5%) | 186.3(8.6%) | 9(4.8%) | 21(2.1%) |\n| 2022 | 662(9.64%) | 175.1(10.1%) | 9.1(-2.91%) | 1.2(-24.3%)|\n| 2021 | 603(18.6%) | 158.4(7.91%) | 9(-9.79%) | 12.7(-5.24%) |\n| 2020 | 583(4.61%) | 146.8(-6.12%) | 10(-29.82%) | 13.4(-20.18%) |\n| 2019 | 561(8.2%) | 158(4.8%) | 14.5(17.5%) | 17.3(2.7%) |\n\n然后查看茅台酒和系列酒占整个白酒的销售收入情况如下（单位十亿），可以看出茅台酒和系列酒的收入在缓慢上升。\n\n| 年份 | 白酒（较上年涨幅) | 茅台酒（占比）| 系列酒（占比）|\n| -- | -- | -- | -- | -- |\n| 2023 | 756(19.5%) | 126.5(16.7%) | 20.6(2.7%) |\n| 2022 | 662(9.64%) | 107.8(16.2%) | 15.9(2.4%) |\n| 2021 | 603(18.6%) | 93.4(15.4%) | 12.5(2.0%) |\n| 2020 | 583(4.61%) | 84.8(14.5%) | 9.9(1.6%) |\n| 2019 | 561(8.2%) | 75.8(13.5%) | 9.5(1.6%) |\n\n另外由中酒协披露 2023 年酒业数据[4] 可知，白酒销量在减少，但整体实现营收不断上升，白酒整体逐步迈向高端化。\n\n# 收益归属\n\n接下来查看相关归属情况\n\n我们看下以茅台股份有限公司为中心视角的一些公司情况\n\n- 中国贵州茅台酒厂（集团）有限责任公司  54.07%\n- 香港中央结算有限公司  6.45%\n- 贵州国有资本运营有限责任公司  4.64%\n- 贵州茅台酒厂（集团）技术开发有限公司 2.22%\n- 中国工商银行-上证50交易型开放式指数证券投资基金 1.01%\n- 中国工商银行股份有限公司-华泰柏瑞沪深300交易型开放式指数证券投资基金 0.91%\n- 中央汇金资产管理有限公司 0.83%\n- 中国证券金融股份有限责任公司 0.64%\n- 中国建设银行股份有限公司-易方达沪深300交易型开放式指数发起式证券投资基金 0.61%\n- 中国人寿保险股份有限公司-传统-普通保险产品-005L-CT001沪 0.44%\n  - 贵州茅台酒股份有限公司\n    - 贵州茅台酱香酒营销有限公司 100%\n    - 贵州茅台酒销售有限公司 95%\n    - 北京友谊使者商贸有限公司 70%\n    - 国酒茅台定制营销（贵州）有限公司 70%\n    - 贵州茅台酒进出口有限责任公司 70%\n    - 贵州茅台集团财务有限公司 51%\n    - 贵州赖茅酒业有限公司 43%\n    - 贵州金石（贵州）产业发展基金合伙企业（有限公司）\n    - 茅台招华（贵州）产业发展基金合伙企业（有限合伙）\n\n其中「茅台股份有限责任公司」的收益是所有股东共享的，也就是说该公司的利润普通股东是有份的。\n\n如果有部分利益从「贵州茅台酒股份有限公司」移到其他地方，则会有损小股东的权益，比如 2009 年成立的 茅台销售公司成立是大家所担心的那样 --  后来茅台股份公司回应统一按照出厂价较会议，不影响股份有限公司的收。\n\n那么另外有一个问题，这部分归属于小股东的权益，怎么保证实实在在会给到小股东呢？是否有可能造成大股东替小股东决策，然后导致大股东占小股东便宜的事情呢，这个在后续加上分红相关的一起描述。\n\n# 总结\n从本文我们可以看出，作为茅台股份有限公司的股东来说，主要关心的一些点\n- 茅台酒的利润情况：这个和酒的质量、销量、价格等有关\n- 茅台酒的利润归属：是否有相关收益从股份公司移到了其他公司，归属在茅台股份公司的利益是否都分给所有股东了 -- 主要是小股东\n\n第一点来说主要有公司的商业模式决定，茅台酒（白酒）的商业模式好，不愁卖（有很多预收款），对上下游均有定价权，且进入门槛/口味等拥有一定的差异化，因此在可预见的未来。在之前的文章 [茅台是一个好的投资标的吗] 以及[茅台的成本分析] 中也有一些相关分析。\n\n第二点主要从历史以及公司的透明度等情况来进行分析，另外后面会尝试从分红等角度来进行一些分析。\n\n\n# 其他\nQ: 茅台的销量能持续吗？未来很多年轻人可能不喝白酒了？酒是有害物品\nA: 关于这个问题，大致思考是这样的：整体白酒的销量不太确定，但是茅台的销量暂时看不太会受影响\n1. 人不仅仅是为了健康（比如吸烟），还会考虑快乐 \n2. 通过和一些常喝酒的人沟通，酒会有用户粘性（至少到类似香型），不会因为稍微涨价而喝其他的。另外茅台在整体白酒中占比也还较低\n3. 茅台有一定的送礼/面子 属性在里面，这属于文化的一种，只要相关文化不变，就需要一种载体，茅台现在充当这个载体，载体是一个群体共识，共识的改变会比较难。\n\n\n\n[1] https://echarts.apache.org/examples/en/editor.html?c=bar-negative\n[2] https://pdf.dfcfw.com/pdf/H3_AP202407301638468976_1.pdf\n[3] https://m.cls.cn/detail/712100\n[4] https://jljcscyxs.mofcom.gov.cn/efile/html/yjbg/2024/3/1711437584739419.html\n","source":"_posts/maotai-input-output.md","raw":"---\ntitle: maotai-input-output\ndate: 2025-03-16 16:53:32\ntags:\n    - stock\n    - maotai\n    - profit\n    - cost\ntoc: true\n---\n\n本文尝试更详细的分析茅台以及所在行业的一些指标信息，希望对茅台是否赚钱，以及赚钱后是否能够归属小股东等有一个大体的认识，也希望能够更好的了解应该关注公司哪些指标以及信息。\n\n<!--more-->\n\n对于股东来说，主要关注一个公司两点\n1. 公司业务是否赚钱\n2. 公司业务赚钱之后，是否都归属于股份有限公司（股东所有)\n\n# 茅台的业务\n\n茅台的业务主要是卖酒，在茅台酒的整条链路中，大致如下所示\n\n[原材料提供商] --原材料--> [茅台股份有限公司]  --酒--> [直销/经销商] (--酒--> [终端销售]) --酒--> [终端客户]\n\n其中 [终端销售] 这一环节可能没有，比如在直销或者电商等渠道\n\n国信证券梳理[2]的销售渠道以及相关价格如下所示（2023 年出厂价涨价前）\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231410651.png)\n\n涨价后，大致修改如下所示\n- 原材料提供商\n  - 茅台股份有限公司\n    - [直销] i茅台/数字营销平台  <-- 零售指导价 1499\n    - 茅台销售公司\n      - [经销] 一级经销商  <-- 拿酒成本是 出厂价 1199\n        - 终端销售  <-- 一批价 按照[2] 大概 2300\n          - 客户    <-- 实际购买价  散装大概 2600[3]，会持续有变动\n    - 商超  <--  1399 参考国信证券数据[2]\n    - 电商  <--  1399 参考国信证券数据[2]\n    - 团购  <-- 零售指导价 1499\n\n其中出厂价是固定的(1199)，零售指导价是固定的(1499)，批价和终端价会随着市场需求的变动而变化。如果终端需求多，终端价会增加，从而会提高批价，反之则会导致终端价和批价下降。\n\n其中出厂价/建议零售价/商超/电商/团购的 基本固定（变动周期较长），经销商相关的的销售链路，其中 [终端价] 和 [批价] 的差异为终端销售的利润，[批价] 和 [出厂价] 的差异则是经销商的利润。如果这两个利润过低甚至变负，则会影响整条链路上的整体酒销售。\n\n下图展示了经销商在过去几年中的利润空间变化（其中灰色的区域是渠道利润，红色是出厂价，蓝色是批价）[2]\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202504021431926.png)\n\n# 茅台是否赚钱\n茅台的整体业务比较简单，主要是卖酒，然后还有部分金融业务。\n\n首先看下最近几年的营收和成本，如下图所示\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231446109.png)\n\n上图中可以看出几点\n- 利润主要来自于营业收入 -- 也就是卖酒。\n- 营业收入最近几年逐年增加\n- 营业成本的增长率和营业收入的增长率差不多\n\n其中营业收入拆开来看的情况如下图所示\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231417076.png)\n\n从图中可以看到\n- 最多的成本是税及附加 -- 由于税率固定，这部分是卖的越多，税越多\n- 营业成本逐年增加，但是增加的没有税多\n- 管理费用/销售费用 逐年增加，但是增加不是很多，整体占比也不是很多\n\n另外从不同角度查看营业收入的情况。\n\n茅台酒和系列酒的情况（单位：百万）\n\n| 年份 | 茅台酒(占比/较上年涨幅) | 系列酒(占比/较上年涨幅) |\n| -- | -- | -- |\n| 2023 | 126589(85.9%/17.6%) | 20629(14.1%/29.4%) |\n| 2022 | 107833(87.1%/15.3%) | 15938(12.9%/26.5%) |\n| 2021 | 93464(88.1%/10.1%) | 12594(11.9%/26%) |\n| 2020 | 84830(89.4%/11.9%) | 9991(10.6%/4.7%) |\n| 2019 | 75802(88.8%/15.7%) | 9542(11.2%/18.2%) |\n\n经销和直销的收入情况（单位：百万）\n\n| 年份 | 经销（占比/较上年涨幅) | 直销（占比/较上年涨幅）|\n| -- | -- | -- |\n| 2023 | 7998611.94(54.33%/7.5%) | 6723287.69(45.67%/36.15%) |\n| 2022 | 7439359.47(60.10%/-9.4%) | 4937873.77(39.9%/105%) |\n| 2021 | 8202992(77.34%/0.5%) | 2402936(22.66%/81.48%) |\n| 2020 | 8158164.26(86.03%/377%) | 1324035.65(13.97%/82.6%) |\n| 2019 | 7809590.86(91.5%/-) | 724865.97(8.5%/-) |\n\n经销和直销的酒量情况（单位：吨）\n\n| 年份 | 经销（占比/较上年涨幅) | 直销（占比/较上年涨幅）|\n| -- | -- | -- |\n| 2023 | 57639.09(78.66%/1.1%) | 15634.95(21.34%/39.76%) |\n| 2022 | 56989.75(83.59%/-6.1%) | 11186.57(16.41%/95.04%) |\n| 2021 | 60702.99(91.36%/0.9%) | 5735.70(8.64%/45.85%) |\n| 2020 | 60123.8(93.86%/-3.01%)  | 3932.08(6.14%/48.32%) |\n| 2019 | 61993.46(95.89%/-) | 2651.84(4.11%/-) |\n\n从上面的数据可以看到，经销的量基本没有太大变化，总收入稍微有些增长；直销的量和收入均有比较大的增长。\n\n国内和国外销售情况（单位：百万），暂时国内销售占主要比例\n\n| 年份 | 国内（占比/较上年涨幅) | 国外（占比/较上年涨幅）|\n| -- | -- | -- |\n| 2023 | 142868(97%/19.5%) | 4350(3%/2.6%) |\n| 2022 | 119532(96.5%/15.5%) | 4239(3.5%/61.9%) |\n| 2021 | 103440(97.5%/11.9%) | 2618(2.5%/7.6%) |\n| 2020 | 92389(97.4%/12%) | 2432(2.6%/-16.8%) |\n| 2019 | 82424(96.5%/16.6%) | 2920(3.5%/0.9%) |\n\n接下来查看预收账款（单位：百万）相关的情况 -- 经销售需要预打款才能买到货（这个也变相的说明茅台不愁销量 -- 这里的销量和终端销售公司的销量不完全是一个概念），可以每年有百亿级别的预收账款\n\n| 年份 | 预售款（增长） |\n| -- | -- |\n| 2023 | 14,125(-8.7%) |\n| 2022 | 15,471(21.64%) |\n| 2021 | 12,718(4.5%) | \n| 2020 | 13,321(-3.0% |\n| 2019 | 13,740(-) |\n\n\n然后再看下不同类型酒的销售额（单位：十亿），以及涨幅如下。从数据可以看出来，白酒持续在增长，但是其他类型酒的销售额则有不同类型的波动。\n\n| 年份 | 白酒（涨幅) | 啤酒（涨幅）| 葡萄酒（涨幅）|黄酒（涨幅）|\n| -- | -- | -- | -- | -- |\n| 2023 | 756(19.5%) | 186.3(8.6%) | 9(4.8%) | 21(2.1%) |\n| 2022 | 662(9.64%) | 175.1(10.1%) | 9.1(-2.91%) | 1.2(-24.3%)|\n| 2021 | 603(18.6%) | 158.4(7.91%) | 9(-9.79%) | 12.7(-5.24%) |\n| 2020 | 583(4.61%) | 146.8(-6.12%) | 10(-29.82%) | 13.4(-20.18%) |\n| 2019 | 561(8.2%) | 158(4.8%) | 14.5(17.5%) | 17.3(2.7%) |\n\n然后查看茅台酒和系列酒占整个白酒的销售收入情况如下（单位十亿），可以看出茅台酒和系列酒的收入在缓慢上升。\n\n| 年份 | 白酒（较上年涨幅) | 茅台酒（占比）| 系列酒（占比）|\n| -- | -- | -- | -- | -- |\n| 2023 | 756(19.5%) | 126.5(16.7%) | 20.6(2.7%) |\n| 2022 | 662(9.64%) | 107.8(16.2%) | 15.9(2.4%) |\n| 2021 | 603(18.6%) | 93.4(15.4%) | 12.5(2.0%) |\n| 2020 | 583(4.61%) | 84.8(14.5%) | 9.9(1.6%) |\n| 2019 | 561(8.2%) | 75.8(13.5%) | 9.5(1.6%) |\n\n另外由中酒协披露 2023 年酒业数据[4] 可知，白酒销量在减少，但整体实现营收不断上升，白酒整体逐步迈向高端化。\n\n# 收益归属\n\n接下来查看相关归属情况\n\n我们看下以茅台股份有限公司为中心视角的一些公司情况\n\n- 中国贵州茅台酒厂（集团）有限责任公司  54.07%\n- 香港中央结算有限公司  6.45%\n- 贵州国有资本运营有限责任公司  4.64%\n- 贵州茅台酒厂（集团）技术开发有限公司 2.22%\n- 中国工商银行-上证50交易型开放式指数证券投资基金 1.01%\n- 中国工商银行股份有限公司-华泰柏瑞沪深300交易型开放式指数证券投资基金 0.91%\n- 中央汇金资产管理有限公司 0.83%\n- 中国证券金融股份有限责任公司 0.64%\n- 中国建设银行股份有限公司-易方达沪深300交易型开放式指数发起式证券投资基金 0.61%\n- 中国人寿保险股份有限公司-传统-普通保险产品-005L-CT001沪 0.44%\n  - 贵州茅台酒股份有限公司\n    - 贵州茅台酱香酒营销有限公司 100%\n    - 贵州茅台酒销售有限公司 95%\n    - 北京友谊使者商贸有限公司 70%\n    - 国酒茅台定制营销（贵州）有限公司 70%\n    - 贵州茅台酒进出口有限责任公司 70%\n    - 贵州茅台集团财务有限公司 51%\n    - 贵州赖茅酒业有限公司 43%\n    - 贵州金石（贵州）产业发展基金合伙企业（有限公司）\n    - 茅台招华（贵州）产业发展基金合伙企业（有限合伙）\n\n其中「茅台股份有限责任公司」的收益是所有股东共享的，也就是说该公司的利润普通股东是有份的。\n\n如果有部分利益从「贵州茅台酒股份有限公司」移到其他地方，则会有损小股东的权益，比如 2009 年成立的 茅台销售公司成立是大家所担心的那样 --  后来茅台股份公司回应统一按照出厂价较会议，不影响股份有限公司的收。\n\n那么另外有一个问题，这部分归属于小股东的权益，怎么保证实实在在会给到小股东呢？是否有可能造成大股东替小股东决策，然后导致大股东占小股东便宜的事情呢，这个在后续加上分红相关的一起描述。\n\n# 总结\n从本文我们可以看出，作为茅台股份有限公司的股东来说，主要关心的一些点\n- 茅台酒的利润情况：这个和酒的质量、销量、价格等有关\n- 茅台酒的利润归属：是否有相关收益从股份公司移到了其他公司，归属在茅台股份公司的利益是否都分给所有股东了 -- 主要是小股东\n\n第一点来说主要有公司的商业模式决定，茅台酒（白酒）的商业模式好，不愁卖（有很多预收款），对上下游均有定价权，且进入门槛/口味等拥有一定的差异化，因此在可预见的未来。在之前的文章 [茅台是一个好的投资标的吗] 以及[茅台的成本分析] 中也有一些相关分析。\n\n第二点主要从历史以及公司的透明度等情况来进行分析，另外后面会尝试从分红等角度来进行一些分析。\n\n\n# 其他\nQ: 茅台的销量能持续吗？未来很多年轻人可能不喝白酒了？酒是有害物品\nA: 关于这个问题，大致思考是这样的：整体白酒的销量不太确定，但是茅台的销量暂时看不太会受影响\n1. 人不仅仅是为了健康（比如吸烟），还会考虑快乐 \n2. 通过和一些常喝酒的人沟通，酒会有用户粘性（至少到类似香型），不会因为稍微涨价而喝其他的。另外茅台在整体白酒中占比也还较低\n3. 茅台有一定的送礼/面子 属性在里面，这属于文化的一种，只要相关文化不变，就需要一种载体，茅台现在充当这个载体，载体是一个群体共识，共识的改变会比较难。\n\n\n\n[1] https://echarts.apache.org/examples/en/editor.html?c=bar-negative\n[2] https://pdf.dfcfw.com/pdf/H3_AP202407301638468976_1.pdf\n[3] https://m.cls.cn/detail/712100\n[4] https://jljcscyxs.mofcom.gov.cn/efile/html/yjbg/2024/3/1711437584739419.html\n","slug":"maotai-input-output","published":1,"updated":"2025-04-03T01:18:09.647Z","_id":"cm8zliwkd000atkmk0i722o2i","comments":1,"layout":"post","photos":[],"link":"","content":"<p>本文尝试更详细的分析茅台以及所在行业的一些指标信息，希望对茅台是否赚钱，以及赚钱后是否能够归属小股东等有一个大体的认识，也希望能够更好的了解应该关注公司哪些指标以及信息。</p>\n<span id=\"more\"></span>\n<p>对于股东来说，主要关注一个公司两点</p>\n<ol>\n<li>公司业务是否赚钱</li>\n<li>公司业务赚钱之后，是否都归属于股份有限公司（股东所有)</li>\n</ol>\n<h1 id=\"茅台的业务\"><a href=\"#茅台的业务\" class=\"headerlink\" title=\"茅台的业务\"></a>茅台的业务</h1><p>茅台的业务主要是卖酒，在茅台酒的整条链路中，大致如下所示</p>\n<p>[原材料提供商] —原材料—&gt; [茅台股份有限公司]  —酒—&gt; [直销/经销商] (—酒—&gt; [终端销售]) —酒—&gt; [终端客户]</p>\n<p>其中 [终端销售] 这一环节可能没有，比如在直销或者电商等渠道</p>\n<p>国信证券梳理[2]的销售渠道以及相关价格如下所示（2023 年出厂价涨价前）</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231410651.png\" alt=\"\"></p>\n<p>涨价后，大致修改如下所示</p>\n<ul>\n<li>原材料提供商<ul>\n<li>茅台股份有限公司<ul>\n<li>[直销] i茅台/数字营销平台  &lt;— 零售指导价 1499</li>\n<li>茅台销售公司<ul>\n<li>[经销] 一级经销商  &lt;— 拿酒成本是 出厂价 1199<ul>\n<li>终端销售  &lt;— 一批价 按照[2] 大概 2300<ul>\n<li>客户    &lt;— 实际购买价  散装大概 2600[3]，会持续有变动</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>商超  &lt;—  1399 参考国信证券数据[2]</li>\n<li>电商  &lt;—  1399 参考国信证券数据[2]</li>\n<li>团购  &lt;— 零售指导价 1499</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>其中出厂价是固定的(1199)，零售指导价是固定的(1499)，批价和终端价会随着市场需求的变动而变化。如果终端需求多，终端价会增加，从而会提高批价，反之则会导致终端价和批价下降。</p>\n<p>其中出厂价/建议零售价/商超/电商/团购的 基本固定（变动周期较长），经销商相关的的销售链路，其中 [终端价] 和 [批价] 的差异为终端销售的利润，[批价] 和 [出厂价] 的差异则是经销商的利润。如果这两个利润过低甚至变负，则会影响整条链路上的整体酒销售。</p>\n<p>下图展示了经销商在过去几年中的利润空间变化（其中灰色的区域是渠道利润，红色是出厂价，蓝色是批价）[2]</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202504021431926.png\" alt=\"\"></p>\n<h1 id=\"茅台是否赚钱\"><a href=\"#茅台是否赚钱\" class=\"headerlink\" title=\"茅台是否赚钱\"></a>茅台是否赚钱</h1><p>茅台的整体业务比较简单，主要是卖酒，然后还有部分金融业务。</p>\n<p>首先看下最近几年的营收和成本，如下图所示<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231446109.png\" alt=\"\"></p>\n<p>上图中可以看出几点</p>\n<ul>\n<li>利润主要来自于营业收入 — 也就是卖酒。</li>\n<li>营业收入最近几年逐年增加</li>\n<li>营业成本的增长率和营业收入的增长率差不多</li>\n</ul>\n<p>其中营业收入拆开来看的情况如下图所示<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231417076.png\" alt=\"\"></p>\n<p>从图中可以看到</p>\n<ul>\n<li>最多的成本是税及附加 — 由于税率固定，这部分是卖的越多，税越多</li>\n<li>营业成本逐年增加，但是增加的没有税多</li>\n<li>管理费用/销售费用 逐年增加，但是增加不是很多，整体占比也不是很多</li>\n</ul>\n<p>另外从不同角度查看营业收入的情况。</p>\n<p>茅台酒和系列酒的情况（单位：百万）</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>茅台酒(占比/较上年涨幅)</th>\n<th>系列酒(占比/较上年涨幅)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>126589(85.9%/17.6%)</td>\n<td>20629(14.1%/29.4%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>107833(87.1%/15.3%)</td>\n<td>15938(12.9%/26.5%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>93464(88.1%/10.1%)</td>\n<td>12594(11.9%/26%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>84830(89.4%/11.9%)</td>\n<td>9991(10.6%/4.7%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>75802(88.8%/15.7%)</td>\n<td>9542(11.2%/18.2%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>经销和直销的收入情况（单位：百万）</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>经销（占比/较上年涨幅)</th>\n<th>直销（占比/较上年涨幅）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>7998611.94(54.33%/7.5%)</td>\n<td>6723287.69(45.67%/36.15%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>7439359.47(60.10%/-9.4%)</td>\n<td>4937873.77(39.9%/105%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>8202992(77.34%/0.5%)</td>\n<td>2402936(22.66%/81.48%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>8158164.26(86.03%/377%)</td>\n<td>1324035.65(13.97%/82.6%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>7809590.86(91.5%/-)</td>\n<td>724865.97(8.5%/-)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>经销和直销的酒量情况（单位：吨）</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>经销（占比/较上年涨幅)</th>\n<th>直销（占比/较上年涨幅）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>57639.09(78.66%/1.1%)</td>\n<td>15634.95(21.34%/39.76%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>56989.75(83.59%/-6.1%)</td>\n<td>11186.57(16.41%/95.04%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>60702.99(91.36%/0.9%)</td>\n<td>5735.70(8.64%/45.85%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>60123.8(93.86%/-3.01%)</td>\n<td>3932.08(6.14%/48.32%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>61993.46(95.89%/-)</td>\n<td>2651.84(4.11%/-)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>从上面的数据可以看到，经销的量基本没有太大变化，总收入稍微有些增长；直销的量和收入均有比较大的增长。</p>\n<p>国内和国外销售情况（单位：百万），暂时国内销售占主要比例</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>国内（占比/较上年涨幅)</th>\n<th>国外（占比/较上年涨幅）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>142868(97%/19.5%)</td>\n<td>4350(3%/2.6%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>119532(96.5%/15.5%)</td>\n<td>4239(3.5%/61.9%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>103440(97.5%/11.9%)</td>\n<td>2618(2.5%/7.6%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>92389(97.4%/12%)</td>\n<td>2432(2.6%/-16.8%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>82424(96.5%/16.6%)</td>\n<td>2920(3.5%/0.9%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>接下来查看预收账款（单位：百万）相关的情况 — 经销售需要预打款才能买到货（这个也变相的说明茅台不愁销量 — 这里的销量和终端销售公司的销量不完全是一个概念），可以每年有百亿级别的预收账款</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>预售款（增长）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>14,125(-8.7%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>15,471(21.64%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>12,718(4.5%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>13,321(-3.0%</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>13,740(-)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>然后再看下不同类型酒的销售额（单位：十亿），以及涨幅如下。从数据可以看出来，白酒持续在增长，但是其他类型酒的销售额则有不同类型的波动。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>白酒（涨幅)</th>\n<th>啤酒（涨幅）</th>\n<th>葡萄酒（涨幅）</th>\n<th>黄酒（涨幅）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>756(19.5%)</td>\n<td>186.3(8.6%)</td>\n<td>9(4.8%)</td>\n<td>21(2.1%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>662(9.64%)</td>\n<td>175.1(10.1%)</td>\n<td>9.1(-2.91%)</td>\n<td>1.2(-24.3%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>603(18.6%)</td>\n<td>158.4(7.91%)</td>\n<td>9(-9.79%)</td>\n<td>12.7(-5.24%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>583(4.61%)</td>\n<td>146.8(-6.12%)</td>\n<td>10(-29.82%)</td>\n<td>13.4(-20.18%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>561(8.2%)</td>\n<td>158(4.8%)</td>\n<td>14.5(17.5%)</td>\n<td>17.3(2.7%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>然后查看茅台酒和系列酒占整个白酒的销售收入情况如下（单位十亿），可以看出茅台酒和系列酒的收入在缓慢上升。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>白酒（较上年涨幅)</th>\n<th>茅台酒（占比）</th>\n<th>系列酒（占比）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>756(19.5%)</td>\n<td>126.5(16.7%)</td>\n<td>20.6(2.7%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>662(9.64%)</td>\n<td>107.8(16.2%)</td>\n<td>15.9(2.4%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>603(18.6%)</td>\n<td>93.4(15.4%)</td>\n<td>12.5(2.0%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>583(4.61%)</td>\n<td>84.8(14.5%)</td>\n<td>9.9(1.6%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>561(8.2%)</td>\n<td>75.8(13.5%)</td>\n<td>9.5(1.6%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>另外由中酒协披露 2023 年酒业数据[4] 可知，白酒销量在减少，但整体实现营收不断上升，白酒整体逐步迈向高端化。</p>\n<h1 id=\"收益归属\"><a href=\"#收益归属\" class=\"headerlink\" title=\"收益归属\"></a>收益归属</h1><p>接下来查看相关归属情况</p>\n<p>我们看下以茅台股份有限公司为中心视角的一些公司情况</p>\n<ul>\n<li>中国贵州茅台酒厂（集团）有限责任公司  54.07%</li>\n<li>香港中央结算有限公司  6.45%</li>\n<li>贵州国有资本运营有限责任公司  4.64%</li>\n<li>贵州茅台酒厂（集团）技术开发有限公司 2.22%</li>\n<li>中国工商银行-上证50交易型开放式指数证券投资基金 1.01%</li>\n<li>中国工商银行股份有限公司-华泰柏瑞沪深300交易型开放式指数证券投资基金 0.91%</li>\n<li>中央汇金资产管理有限公司 0.83%</li>\n<li>中国证券金融股份有限责任公司 0.64%</li>\n<li>中国建设银行股份有限公司-易方达沪深300交易型开放式指数发起式证券投资基金 0.61%</li>\n<li>中国人寿保险股份有限公司-传统-普通保险产品-005L-CT001沪 0.44%<ul>\n<li>贵州茅台酒股份有限公司<ul>\n<li>贵州茅台酱香酒营销有限公司 100%</li>\n<li>贵州茅台酒销售有限公司 95%</li>\n<li>北京友谊使者商贸有限公司 70%</li>\n<li>国酒茅台定制营销（贵州）有限公司 70%</li>\n<li>贵州茅台酒进出口有限责任公司 70%</li>\n<li>贵州茅台集团财务有限公司 51%</li>\n<li>贵州赖茅酒业有限公司 43%</li>\n<li>贵州金石（贵州）产业发展基金合伙企业（有限公司）</li>\n<li>茅台招华（贵州）产业发展基金合伙企业（有限合伙）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>其中「茅台股份有限责任公司」的收益是所有股东共享的，也就是说该公司的利润普通股东是有份的。</p>\n<p>如果有部分利益从「贵州茅台酒股份有限公司」移到其他地方，则会有损小股东的权益，比如 2009 年成立的 茅台销售公司成立是大家所担心的那样 —  后来茅台股份公司回应统一按照出厂价较会议，不影响股份有限公司的收。</p>\n<p>那么另外有一个问题，这部分归属于小股东的权益，怎么保证实实在在会给到小股东呢？是否有可能造成大股东替小股东决策，然后导致大股东占小股东便宜的事情呢，这个在后续加上分红相关的一起描述。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>从本文我们可以看出，作为茅台股份有限公司的股东来说，主要关心的一些点</p>\n<ul>\n<li>茅台酒的利润情况：这个和酒的质量、销量、价格等有关</li>\n<li>茅台酒的利润归属：是否有相关收益从股份公司移到了其他公司，归属在茅台股份公司的利益是否都分给所有股东了 — 主要是小股东</li>\n</ul>\n<p>第一点来说主要有公司的商业模式决定，茅台酒（白酒）的商业模式好，不愁卖（有很多预收款），对上下游均有定价权，且进入门槛/口味等拥有一定的差异化，因此在可预见的未来。在之前的文章 [茅台是一个好的投资标的吗] 以及[茅台的成本分析] 中也有一些相关分析。</p>\n<p>第二点主要从历史以及公司的透明度等情况来进行分析，另外后面会尝试从分红等角度来进行一些分析。</p>\n<h1 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h1><p>Q: 茅台的销量能持续吗？未来很多年轻人可能不喝白酒了？酒是有害物品<br>A: 关于这个问题，大致思考是这样的：整体白酒的销量不太确定，但是茅台的销量暂时看不太会受影响</p>\n<ol>\n<li>人不仅仅是为了健康（比如吸烟），还会考虑快乐 </li>\n<li>通过和一些常喝酒的人沟通，酒会有用户粘性（至少到类似香型），不会因为稍微涨价而喝其他的。另外茅台在整体白酒中占比也还较低</li>\n<li>茅台有一定的送礼/面子 属性在里面，这属于文化的一种，只要相关文化不变，就需要一种载体，茅台现在充当这个载体，载体是一个群体共识，共识的改变会比较难。</li>\n</ol>\n<p>[1] <a href=\"https://echarts.apache.org/examples/en/editor.html?c=bar-negative\">https://echarts.apache.org/examples/en/editor.html?c=bar-negative</a><br>[2] <a href=\"https://pdf.dfcfw.com/pdf/H3_AP202407301638468976_1.pdf\">https://pdf.dfcfw.com/pdf/H3_AP202407301638468976_1.pdf</a><br>[3] <a href=\"https://m.cls.cn/detail/712100\">https://m.cls.cn/detail/712100</a><br>[4] <a href=\"https://jljcscyxs.mofcom.gov.cn/efile/html/yjbg/2024/3/1711437584739419.html\">https://jljcscyxs.mofcom.gov.cn/efile/html/yjbg/2024/3/1711437584739419.html</a></p>\n","site":{"data":{}},"excerpt":"<p>本文尝试更详细的分析茅台以及所在行业的一些指标信息，希望对茅台是否赚钱，以及赚钱后是否能够归属小股东等有一个大体的认识，也希望能够更好的了解应该关注公司哪些指标以及信息。</p>","more":"<p>对于股东来说，主要关注一个公司两点</p>\n<ol>\n<li>公司业务是否赚钱</li>\n<li>公司业务赚钱之后，是否都归属于股份有限公司（股东所有)</li>\n</ol>\n<h1 id=\"茅台的业务\"><a href=\"#茅台的业务\" class=\"headerlink\" title=\"茅台的业务\"></a>茅台的业务</h1><p>茅台的业务主要是卖酒，在茅台酒的整条链路中，大致如下所示</p>\n<p>[原材料提供商] —原材料—&gt; [茅台股份有限公司]  —酒—&gt; [直销/经销商] (—酒—&gt; [终端销售]) —酒—&gt; [终端客户]</p>\n<p>其中 [终端销售] 这一环节可能没有，比如在直销或者电商等渠道</p>\n<p>国信证券梳理[2]的销售渠道以及相关价格如下所示（2023 年出厂价涨价前）</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231410651.png\" alt=\"\"></p>\n<p>涨价后，大致修改如下所示</p>\n<ul>\n<li>原材料提供商<ul>\n<li>茅台股份有限公司<ul>\n<li>[直销] i茅台/数字营销平台  &lt;— 零售指导价 1499</li>\n<li>茅台销售公司<ul>\n<li>[经销] 一级经销商  &lt;— 拿酒成本是 出厂价 1199<ul>\n<li>终端销售  &lt;— 一批价 按照[2] 大概 2300<ul>\n<li>客户    &lt;— 实际购买价  散装大概 2600[3]，会持续有变动</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>商超  &lt;—  1399 参考国信证券数据[2]</li>\n<li>电商  &lt;—  1399 参考国信证券数据[2]</li>\n<li>团购  &lt;— 零售指导价 1499</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>其中出厂价是固定的(1199)，零售指导价是固定的(1499)，批价和终端价会随着市场需求的变动而变化。如果终端需求多，终端价会增加，从而会提高批价，反之则会导致终端价和批价下降。</p>\n<p>其中出厂价/建议零售价/商超/电商/团购的 基本固定（变动周期较长），经销商相关的的销售链路，其中 [终端价] 和 [批价] 的差异为终端销售的利润，[批价] 和 [出厂价] 的差异则是经销商的利润。如果这两个利润过低甚至变负，则会影响整条链路上的整体酒销售。</p>\n<p>下图展示了经销商在过去几年中的利润空间变化（其中灰色的区域是渠道利润，红色是出厂价，蓝色是批价）[2]</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202504021431926.png\" alt=\"\"></p>\n<h1 id=\"茅台是否赚钱\"><a href=\"#茅台是否赚钱\" class=\"headerlink\" title=\"茅台是否赚钱\"></a>茅台是否赚钱</h1><p>茅台的整体业务比较简单，主要是卖酒，然后还有部分金融业务。</p>\n<p>首先看下最近几年的营收和成本，如下图所示<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231446109.png\" alt=\"\"></p>\n<p>上图中可以看出几点</p>\n<ul>\n<li>利润主要来自于营业收入 — 也就是卖酒。</li>\n<li>营业收入最近几年逐年增加</li>\n<li>营业成本的增长率和营业收入的增长率差不多</li>\n</ul>\n<p>其中营业收入拆开来看的情况如下图所示<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202503231417076.png\" alt=\"\"></p>\n<p>从图中可以看到</p>\n<ul>\n<li>最多的成本是税及附加 — 由于税率固定，这部分是卖的越多，税越多</li>\n<li>营业成本逐年增加，但是增加的没有税多</li>\n<li>管理费用/销售费用 逐年增加，但是增加不是很多，整体占比也不是很多</li>\n</ul>\n<p>另外从不同角度查看营业收入的情况。</p>\n<p>茅台酒和系列酒的情况（单位：百万）</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>茅台酒(占比/较上年涨幅)</th>\n<th>系列酒(占比/较上年涨幅)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>126589(85.9%/17.6%)</td>\n<td>20629(14.1%/29.4%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>107833(87.1%/15.3%)</td>\n<td>15938(12.9%/26.5%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>93464(88.1%/10.1%)</td>\n<td>12594(11.9%/26%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>84830(89.4%/11.9%)</td>\n<td>9991(10.6%/4.7%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>75802(88.8%/15.7%)</td>\n<td>9542(11.2%/18.2%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>经销和直销的收入情况（单位：百万）</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>经销（占比/较上年涨幅)</th>\n<th>直销（占比/较上年涨幅）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>7998611.94(54.33%/7.5%)</td>\n<td>6723287.69(45.67%/36.15%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>7439359.47(60.10%/-9.4%)</td>\n<td>4937873.77(39.9%/105%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>8202992(77.34%/0.5%)</td>\n<td>2402936(22.66%/81.48%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>8158164.26(86.03%/377%)</td>\n<td>1324035.65(13.97%/82.6%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>7809590.86(91.5%/-)</td>\n<td>724865.97(8.5%/-)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>经销和直销的酒量情况（单位：吨）</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>经销（占比/较上年涨幅)</th>\n<th>直销（占比/较上年涨幅）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>57639.09(78.66%/1.1%)</td>\n<td>15634.95(21.34%/39.76%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>56989.75(83.59%/-6.1%)</td>\n<td>11186.57(16.41%/95.04%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>60702.99(91.36%/0.9%)</td>\n<td>5735.70(8.64%/45.85%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>60123.8(93.86%/-3.01%)</td>\n<td>3932.08(6.14%/48.32%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>61993.46(95.89%/-)</td>\n<td>2651.84(4.11%/-)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>从上面的数据可以看到，经销的量基本没有太大变化，总收入稍微有些增长；直销的量和收入均有比较大的增长。</p>\n<p>国内和国外销售情况（单位：百万），暂时国内销售占主要比例</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>国内（占比/较上年涨幅)</th>\n<th>国外（占比/较上年涨幅）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>142868(97%/19.5%)</td>\n<td>4350(3%/2.6%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>119532(96.5%/15.5%)</td>\n<td>4239(3.5%/61.9%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>103440(97.5%/11.9%)</td>\n<td>2618(2.5%/7.6%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>92389(97.4%/12%)</td>\n<td>2432(2.6%/-16.8%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>82424(96.5%/16.6%)</td>\n<td>2920(3.5%/0.9%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>接下来查看预收账款（单位：百万）相关的情况 — 经销售需要预打款才能买到货（这个也变相的说明茅台不愁销量 — 这里的销量和终端销售公司的销量不完全是一个概念），可以每年有百亿级别的预收账款</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>预售款（增长）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>14,125(-8.7%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>15,471(21.64%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>12,718(4.5%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>13,321(-3.0%</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>13,740(-)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>然后再看下不同类型酒的销售额（单位：十亿），以及涨幅如下。从数据可以看出来，白酒持续在增长，但是其他类型酒的销售额则有不同类型的波动。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>白酒（涨幅)</th>\n<th>啤酒（涨幅）</th>\n<th>葡萄酒（涨幅）</th>\n<th>黄酒（涨幅）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>756(19.5%)</td>\n<td>186.3(8.6%)</td>\n<td>9(4.8%)</td>\n<td>21(2.1%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>662(9.64%)</td>\n<td>175.1(10.1%)</td>\n<td>9.1(-2.91%)</td>\n<td>1.2(-24.3%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>603(18.6%)</td>\n<td>158.4(7.91%)</td>\n<td>9(-9.79%)</td>\n<td>12.7(-5.24%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>583(4.61%)</td>\n<td>146.8(-6.12%)</td>\n<td>10(-29.82%)</td>\n<td>13.4(-20.18%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>561(8.2%)</td>\n<td>158(4.8%)</td>\n<td>14.5(17.5%)</td>\n<td>17.3(2.7%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>然后查看茅台酒和系列酒占整个白酒的销售收入情况如下（单位十亿），可以看出茅台酒和系列酒的收入在缓慢上升。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>白酒（较上年涨幅)</th>\n<th>茅台酒（占比）</th>\n<th>系列酒（占比）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2023</td>\n<td>756(19.5%)</td>\n<td>126.5(16.7%)</td>\n<td>20.6(2.7%)</td>\n</tr>\n<tr>\n<td>2022</td>\n<td>662(9.64%)</td>\n<td>107.8(16.2%)</td>\n<td>15.9(2.4%)</td>\n</tr>\n<tr>\n<td>2021</td>\n<td>603(18.6%)</td>\n<td>93.4(15.4%)</td>\n<td>12.5(2.0%)</td>\n</tr>\n<tr>\n<td>2020</td>\n<td>583(4.61%)</td>\n<td>84.8(14.5%)</td>\n<td>9.9(1.6%)</td>\n</tr>\n<tr>\n<td>2019</td>\n<td>561(8.2%)</td>\n<td>75.8(13.5%)</td>\n<td>9.5(1.6%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>另外由中酒协披露 2023 年酒业数据[4] 可知，白酒销量在减少，但整体实现营收不断上升，白酒整体逐步迈向高端化。</p>\n<h1 id=\"收益归属\"><a href=\"#收益归属\" class=\"headerlink\" title=\"收益归属\"></a>收益归属</h1><p>接下来查看相关归属情况</p>\n<p>我们看下以茅台股份有限公司为中心视角的一些公司情况</p>\n<ul>\n<li>中国贵州茅台酒厂（集团）有限责任公司  54.07%</li>\n<li>香港中央结算有限公司  6.45%</li>\n<li>贵州国有资本运营有限责任公司  4.64%</li>\n<li>贵州茅台酒厂（集团）技术开发有限公司 2.22%</li>\n<li>中国工商银行-上证50交易型开放式指数证券投资基金 1.01%</li>\n<li>中国工商银行股份有限公司-华泰柏瑞沪深300交易型开放式指数证券投资基金 0.91%</li>\n<li>中央汇金资产管理有限公司 0.83%</li>\n<li>中国证券金融股份有限责任公司 0.64%</li>\n<li>中国建设银行股份有限公司-易方达沪深300交易型开放式指数发起式证券投资基金 0.61%</li>\n<li>中国人寿保险股份有限公司-传统-普通保险产品-005L-CT001沪 0.44%<ul>\n<li>贵州茅台酒股份有限公司<ul>\n<li>贵州茅台酱香酒营销有限公司 100%</li>\n<li>贵州茅台酒销售有限公司 95%</li>\n<li>北京友谊使者商贸有限公司 70%</li>\n<li>国酒茅台定制营销（贵州）有限公司 70%</li>\n<li>贵州茅台酒进出口有限责任公司 70%</li>\n<li>贵州茅台集团财务有限公司 51%</li>\n<li>贵州赖茅酒业有限公司 43%</li>\n<li>贵州金石（贵州）产业发展基金合伙企业（有限公司）</li>\n<li>茅台招华（贵州）产业发展基金合伙企业（有限合伙）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>其中「茅台股份有限责任公司」的收益是所有股东共享的，也就是说该公司的利润普通股东是有份的。</p>\n<p>如果有部分利益从「贵州茅台酒股份有限公司」移到其他地方，则会有损小股东的权益，比如 2009 年成立的 茅台销售公司成立是大家所担心的那样 —  后来茅台股份公司回应统一按照出厂价较会议，不影响股份有限公司的收。</p>\n<p>那么另外有一个问题，这部分归属于小股东的权益，怎么保证实实在在会给到小股东呢？是否有可能造成大股东替小股东决策，然后导致大股东占小股东便宜的事情呢，这个在后续加上分红相关的一起描述。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>从本文我们可以看出，作为茅台股份有限公司的股东来说，主要关心的一些点</p>\n<ul>\n<li>茅台酒的利润情况：这个和酒的质量、销量、价格等有关</li>\n<li>茅台酒的利润归属：是否有相关收益从股份公司移到了其他公司，归属在茅台股份公司的利益是否都分给所有股东了 — 主要是小股东</li>\n</ul>\n<p>第一点来说主要有公司的商业模式决定，茅台酒（白酒）的商业模式好，不愁卖（有很多预收款），对上下游均有定价权，且进入门槛/口味等拥有一定的差异化，因此在可预见的未来。在之前的文章 [茅台是一个好的投资标的吗] 以及[茅台的成本分析] 中也有一些相关分析。</p>\n<p>第二点主要从历史以及公司的透明度等情况来进行分析，另外后面会尝试从分红等角度来进行一些分析。</p>\n<h1 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h1><p>Q: 茅台的销量能持续吗？未来很多年轻人可能不喝白酒了？酒是有害物品<br>A: 关于这个问题，大致思考是这样的：整体白酒的销量不太确定，但是茅台的销量暂时看不太会受影响</p>\n<ol>\n<li>人不仅仅是为了健康（比如吸烟），还会考虑快乐 </li>\n<li>通过和一些常喝酒的人沟通，酒会有用户粘性（至少到类似香型），不会因为稍微涨价而喝其他的。另外茅台在整体白酒中占比也还较低</li>\n<li>茅台有一定的送礼/面子 属性在里面，这属于文化的一种，只要相关文化不变，就需要一种载体，茅台现在充当这个载体，载体是一个群体共识，共识的改变会比较难。</li>\n</ol>\n<p>[1] <a href=\"https://echarts.apache.org/examples/en/editor.html?c=bar-negative\">https://echarts.apache.org/examples/en/editor.html?c=bar-negative</a><br>[2] <a href=\"https://pdf.dfcfw.com/pdf/H3_AP202407301638468976_1.pdf\">https://pdf.dfcfw.com/pdf/H3_AP202407301638468976_1.pdf</a><br>[3] <a href=\"https://m.cls.cn/detail/712100\">https://m.cls.cn/detail/712100</a><br>[4] <a href=\"https://jljcscyxs.mofcom.gov.cn/efile/html/yjbg/2024/3/1711437584739419.html\">https://jljcscyxs.mofcom.gov.cn/efile/html/yjbg/2024/3/1711437584739419.html</a></p>"},{"title":"分红以及投资复利-以茅台为例","date":"2025-04-09T08:53:32.000Z","toc":true,"_content":"\n> 本文尝试对上市公司分红以及投资复利进行一些分析，希望能够更好的了解投资的选择标准，以及操作标准。\n\n在 [赚钱机器茅台](https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA) 一文中，我们有提到分红相关的事情，这里我们仍旧以茅台为例分析下分红相关的内容。\n\n<!-- more -->\n\n# 股本位\n\n现在的生活中大家会以拥有 *本币本位/纸币本位* 的视角，也就是所有的价值/价格体系等都会锚定到本国法币的价值，同时也有一个 *金本位*，表示所有的价值都体现在包含多少黄金。\n\n那么对于股市投资是不是可以有一种“股本位”的视角，那么所有的目的都是以 *股数* 作为衡量，我们的目的也将变成获取更多的 *股数*。\n\n# 分红以及投资收益\n接下来我们以茅台上市后股东收益来阐述分红，复利，收益等。\n\n## 分析情况说明\n首先描述下本文会使用到的一些情况\n1. 本文假设股票可以零散买入，也就是没有最低股数要求，甚至可以买入小于 1 股（比如 0.01 股）\n2. 对于茅台整个上市历史的收益，起点为上市是购入 1 元茅台股（为了计算方便，不影响整体收益比例）\n3. 对于比较中最近十年的收益情况，起点为 2015 年选择一个市值高点，以市价买入 1 元茅台股票\n\n原始数据整理如下，数据来源[1]，股数计算公式参考图片中左上角的公式，市值是 股数 * 股价。\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121251913.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121253102.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121254827.png)\n\n## 收益和股数\n\n通过整体茅台的数据，绘制如下几张图，下图中展示了不同纬度情况下茅台股票的收益（总市值和总股数），其中\n\n- ValueFromInit 表示从上市开始投入 1 元，然后分股继续持有，分红再买入后的总市值\n- CountFromInit 表示从上市开始投入 1 元，然后分股继续持有，分红再买入后的总股数\n- ValueFrom2015 表示从 20150526 开始投入 1 元，然后分股继续持有，分红再买入后的总市值\n- CountFrom2015 表示从 20150526 开始投入 1 元，然后分股继续持有，分红再买入后的总股数\n\n> 选择 20150526 是因为当天市值是当年一个高值\n> 下图中的每条线可以点击标题控制是否显示\n\n{% echarts 85% 400 %}\n{\n  legend: {\n    data: ['ValueFromInit', 'CountFromInit', 'ValueFrom2015', 'CountFrom2015']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: ['20020725', '20030714', '20040701', '20050804', '20060519', '20060524', '20070713', '20080613', '20090701', '20100705', '20110701', '20120705', '20130607', '20140625', '20150717', '20160701', '20170707', '20180615', '20190628', '20200624', '20210625', '20220628', '20221226', '20230629', '20231219', '20240618', '20241219']\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n    {\n      name: 'stock-count',\n      type: 'value'\n    }\n  ],\n  series: [\n    {\n      name: 'ValueFromInit',\n      data: [1.15, 0.93, 1.38, 3.47, 4.97, 5.05, 14.69, 19.29, 18.94, 16.52, 27.98, 37.33, 30.06, 24.64, 44.26, 56.68, 89.67, 157.71, 203.64, 305.67, 442.03, 433.51, 376.70, 376.17, 371.87, 344.64, 356.74],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'ValueFrom2015',\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.88, 1.12, 1.78, 3.13, 4.05, 6.08, 8.79, 8.62, 7.49, 7.48, 7.40, 6.86, 7.10],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'CountFromInit',\n      data: [0.0356, 0.0394, 0.0517, 0.0626, 0.1257, 0.1275, 0.1283, 0.1290, 0.1301, 0.1313, 0.1460, 0.1483, 0.1532, 0.1732, 0.1938, 0.1980, 0.2010, 0.2039, 0.2069, 0.2093, 0.2112, 0.2135, 0.2162, 0.2190, 0.2220, 0.2265, 0.23],\n      type: 'line',\n      yAxisIndex: 1\n    },\n    {\n      name: 'CountFrom2015',\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.00344, 0.00385, 0.00394, 0.0040, 0.00405, 0.00411, 0.00416, 0.0042, 0.00425, 0.0043, 0.00436, 0.00441, 0.0045, 0.00457],\n      type: 'line',\n      yAxisIndex: 1\n    }\n  ]\n}\n{% endecharts %}\n\n下面的图中，20140625 之前的表示从上市开始投入 1 元后，总市值和总股数的情况，20140625 以及以后的情况则表示在 20140625 买入 1 元后的总市值和总股数情况，其中\n\n- Value 表示对应时间的总市值\n- Count 表示对应时间的总股数\n\n> 下图中的每条线可以点击标题控制是否显示\n\n{% echarts 85% 400 %}\n{\n  legend: {\n    data: ['Value', 'Count']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: ['20020725', '20030714', '20040701', '20050804', '20060519', '20060524', '20070713', '20080613', '20090701', '20100705', '20110701', '20120705', '20130607', '20140625', '20150717', '20160701', '20170707', '20180615', '20190628', '20200624', '20210625', '20220628', '20221226', '20230629', '20231219', '20240618', '20241219']\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n    {\n      name: 'stock-count',\n      type: 'value'\n    }\n  ],\n  series: [\n    {\n      name: 'Value',\n      data: [1.15, 0.93, 1.38, 3.47, 4.97, 5.05, 14.69, 19.29, 18.94, 16.52, 27.98, 37.33, 30.06, 1, 0.88, 1.12, 1.78, 3.13, 4.05, 6.08, 8.79, 8.62, 7.49, 7.48, 7.40, 6.86, 7.10],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'Count',\n      data: [0.0356, 0.0394, 0.0517, 0.0626, 0.1257, 0.1275, 0.1283, 0.1290, 0.1301, 0.1313, 0.1460, 0.1483, 0.1532, 0.00344, 0.00385, 0.00394, 0.0040, 0.00405, 0.00411, 0.00416, 0.0042, 0.00425, 0.0043, 0.00436, 0.00441, 0.0045, 0.00457],\n      type: 'line',\n      yAxisIndex: 1\n    },\n  ]\n}\n{% endecharts %}\n\n## 简单分析\n上面的信息可以分为如下几组的对比\n\n- 不同阶段十年的对比：2001 年到 2010 年这十年，与 2015 年到 2024 年这十年对比\n- 十年和二十多年的对比：2001 年到 2012 年这 11 年，与 2001 年到 2014 年这 23 年对比\n- 二十多年前后段和后半段的对比：2001 年到 2012 年，与 2012 年到 2024 年进行对比\n- 对比分红再买入和分红不再买入的情况\n\n其中第一组可以发现 2001 年到 2010 年这十年总市值变为 **16.56**, 总股数是 **0.1313** 。也就是总市值变成了原来的 **16** 倍，股数变为原来的 **3.6** 倍左右；2015 年到 2024 年这十年总价值变成了 **7.1**，总股数变成了 **0.00457**, 总价值变成了原来的 **7** 倍左右，股数变成了原来的 **1.3** 倍。通过对比可以看出\n1. 后面这十年总收益比前面十年少\n2. 后面这十年总股数增加的不如前十年多\n3. 总股数前十年比后十年多更多。这里可能有多个原因：1）前十年有过送股；2）前十年股价更低，同样分红的钱能买更多的股数\n\n第二组可以看出来，总共 24 年总市值变为 **356.74**，总股数变为 **0.23**，总市值是原来的 **356** 倍，总股数是原来的 **6.4** 倍；前 11 年总市值变为 **37.33**，总股数变为 **0.1483**, 总市值变为原来的 **37** 倍，总股数变为原来的 **4** 倍。这里可以看出来，时间长一倍，总市值不仅仅是多一倍，二十将近 **10** 倍，从原来的 **37** 倍变成了 **356** 倍。总股数由于后面股价上涨了，则增长不多。\n\n第三组可以看出来，前面十二年总价值从 1 涨到 **37.33**，总股数从 **0.0356** 变为 **0.1483**；后面十二年，价值从 **37.33** 涨到 **356.74**,总股数从 **0.1483** 涨到 **0.23**。可以看出来\n1. 前面十二年总价值涨了 **37** 倍，后面十二年总价值涨了将近 **10** 倍\n2. 前面十二年总股数涨到原来 **4** 倍，后面十二年总股数涨到 **1.6** 倍\n可以大致认为，股数越多，总收益越多；股价更低的时候，股东总收益反而会更好。\n\n第四组 分红不再买入的情况下，总市值变为 **248.27**, 总股数变为 **0.16**。分红再买入的情况下，总市值变为 **356.74**，总股数变为 **0.23**。分红再投入的总收益会更高。从总收益来看差异还挺大，分红不再买入的情况下是 **248** 倍，分红再买入的情况下是 **356** 倍。\n\n## 整体结论\n1. 投资是有复利的，所以越早开始投资越好，投资的时间越长越好\n2. 对于好公司（上面的茅台），不管是否分红再投入，都能有不错的收益\n3. 对于好公司，分红应该再投入，收益会更多\n 3.1  分红可以理解为公司部分收益的处置权交给所有股东（而不是只有大股东），股东收到分红后至少有两个选择：1）继续买入；2）不买入该投资标的。那么这两种选择也会有不同的收益，如果不买入该投资标的的收益无法比过当前投资标的，则收益会变少 -- 当然如果有正当使用需要则另说。\n 3.2  另外可以从股本位的视角来考虑，分红再买入是再增加整体股数，长远来看收益也会更好。\n4. 市值 = 股数 * 单价。股数和股票单价上涨均能导致市值上涨。\n4.1. 市值短期受市场影响（市场内参与该股票交易所有人的预期），长期受公司内在价值影响。也就是说从长期来看公司股价会围绕公司价值波动。\n4.2. 不管股价是否增长，股数增长均会提高整体市值，但是股价增长，会导致同样资金能够买到的股数变少。\n4.3. 因此股价大幅增长对股东来说反而不是一个好事情:1）股价是否涨高，并不会影响公司的营业情况 -- 也就是盈利、分红等；2）股价涨高导致能买的股数变少（实际情况下甚至由于股价过高，分红没法购买 1 手）。\n\n# 其他\n1. 上面的所有分析，有一个前提：公司是一个好公司。\n2. 不是所有公司的收益率都如茅台，因此上述数据仅作参考。\n3. 我们可以多一个维度分析公司的收益情况。如果公司是好公司的情况下，整体收益可以由 <股数 * 股价> 决定，那么我们在用数据进行筛选公司的时候，可以考虑分红再买入后的情况。\n4. 既然上面说的分红再买入会更好，那是不是可以让公司不分红（变相的相当于再买入），分红的意义是啥呢？\n4.1. 分红会从利润中出，公司分红表示有利润，同时如果公式有分红比例的话，会变相的约束公司不虚报利润（只可能隐藏利润） -- 表明公司利润只会比表现出来的更好。也可以一定情看下监督公司一年经营情况\n4.2. 分红后的钱股东有自由取决权，可以再买入，可以用于其他途径（生活，或者投资其他地方）\n5. 分红的情况是将当年的收益分配给股东的一种形式，可以有三种：现价分红；派发新股；转增股本[2]，这里说的分红主要是是现价分红。\n\n另外建议结合 [股市是一个好的投资渠道吗](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ) 一起阅读（注意：里面茅台相关总收益/总股数计算有误，以本文为准），里面对不同投资标的进行一个分析\n\n# Ref\n[1] https://vip.stock.finance.sina.com.cn/corp/go.php/vISSUE_ShareBonus/stockid/600519.phtml\n[2] https://www.morganstanleysecurities.com.cn/investor/education-dividendpolicy.html\n","source":"_posts/invest-compond.md","raw":"---\ntitle: 分红以及投资复利-以茅台为例\ndate: 2025-04-09 16:53:32\ntags:\n    - stock\n    - investment\n    - 分红\n    - compond\ntoc: true\n---\n\n> 本文尝试对上市公司分红以及投资复利进行一些分析，希望能够更好的了解投资的选择标准，以及操作标准。\n\n在 [赚钱机器茅台](https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA) 一文中，我们有提到分红相关的事情，这里我们仍旧以茅台为例分析下分红相关的内容。\n\n<!-- more -->\n\n# 股本位\n\n现在的生活中大家会以拥有 *本币本位/纸币本位* 的视角，也就是所有的价值/价格体系等都会锚定到本国法币的价值，同时也有一个 *金本位*，表示所有的价值都体现在包含多少黄金。\n\n那么对于股市投资是不是可以有一种“股本位”的视角，那么所有的目的都是以 *股数* 作为衡量，我们的目的也将变成获取更多的 *股数*。\n\n# 分红以及投资收益\n接下来我们以茅台上市后股东收益来阐述分红，复利，收益等。\n\n## 分析情况说明\n首先描述下本文会使用到的一些情况\n1. 本文假设股票可以零散买入，也就是没有最低股数要求，甚至可以买入小于 1 股（比如 0.01 股）\n2. 对于茅台整个上市历史的收益，起点为上市是购入 1 元茅台股（为了计算方便，不影响整体收益比例）\n3. 对于比较中最近十年的收益情况，起点为 2015 年选择一个市值高点，以市价买入 1 元茅台股票\n\n原始数据整理如下，数据来源[1]，股数计算公式参考图片中左上角的公式，市值是 股数 * 股价。\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121251913.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121253102.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121254827.png)\n\n## 收益和股数\n\n通过整体茅台的数据，绘制如下几张图，下图中展示了不同纬度情况下茅台股票的收益（总市值和总股数），其中\n\n- ValueFromInit 表示从上市开始投入 1 元，然后分股继续持有，分红再买入后的总市值\n- CountFromInit 表示从上市开始投入 1 元，然后分股继续持有，分红再买入后的总股数\n- ValueFrom2015 表示从 20150526 开始投入 1 元，然后分股继续持有，分红再买入后的总市值\n- CountFrom2015 表示从 20150526 开始投入 1 元，然后分股继续持有，分红再买入后的总股数\n\n> 选择 20150526 是因为当天市值是当年一个高值\n> 下图中的每条线可以点击标题控制是否显示\n\n{% echarts 85% 400 %}\n{\n  legend: {\n    data: ['ValueFromInit', 'CountFromInit', 'ValueFrom2015', 'CountFrom2015']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: ['20020725', '20030714', '20040701', '20050804', '20060519', '20060524', '20070713', '20080613', '20090701', '20100705', '20110701', '20120705', '20130607', '20140625', '20150717', '20160701', '20170707', '20180615', '20190628', '20200624', '20210625', '20220628', '20221226', '20230629', '20231219', '20240618', '20241219']\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n    {\n      name: 'stock-count',\n      type: 'value'\n    }\n  ],\n  series: [\n    {\n      name: 'ValueFromInit',\n      data: [1.15, 0.93, 1.38, 3.47, 4.97, 5.05, 14.69, 19.29, 18.94, 16.52, 27.98, 37.33, 30.06, 24.64, 44.26, 56.68, 89.67, 157.71, 203.64, 305.67, 442.03, 433.51, 376.70, 376.17, 371.87, 344.64, 356.74],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'ValueFrom2015',\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.88, 1.12, 1.78, 3.13, 4.05, 6.08, 8.79, 8.62, 7.49, 7.48, 7.40, 6.86, 7.10],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'CountFromInit',\n      data: [0.0356, 0.0394, 0.0517, 0.0626, 0.1257, 0.1275, 0.1283, 0.1290, 0.1301, 0.1313, 0.1460, 0.1483, 0.1532, 0.1732, 0.1938, 0.1980, 0.2010, 0.2039, 0.2069, 0.2093, 0.2112, 0.2135, 0.2162, 0.2190, 0.2220, 0.2265, 0.23],\n      type: 'line',\n      yAxisIndex: 1\n    },\n    {\n      name: 'CountFrom2015',\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.00344, 0.00385, 0.00394, 0.0040, 0.00405, 0.00411, 0.00416, 0.0042, 0.00425, 0.0043, 0.00436, 0.00441, 0.0045, 0.00457],\n      type: 'line',\n      yAxisIndex: 1\n    }\n  ]\n}\n{% endecharts %}\n\n下面的图中，20140625 之前的表示从上市开始投入 1 元后，总市值和总股数的情况，20140625 以及以后的情况则表示在 20140625 买入 1 元后的总市值和总股数情况，其中\n\n- Value 表示对应时间的总市值\n- Count 表示对应时间的总股数\n\n> 下图中的每条线可以点击标题控制是否显示\n\n{% echarts 85% 400 %}\n{\n  legend: {\n    data: ['Value', 'Count']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: ['20020725', '20030714', '20040701', '20050804', '20060519', '20060524', '20070713', '20080613', '20090701', '20100705', '20110701', '20120705', '20130607', '20140625', '20150717', '20160701', '20170707', '20180615', '20190628', '20200624', '20210625', '20220628', '20221226', '20230629', '20231219', '20240618', '20241219']\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n    {\n      name: 'stock-count',\n      type: 'value'\n    }\n  ],\n  series: [\n    {\n      name: 'Value',\n      data: [1.15, 0.93, 1.38, 3.47, 4.97, 5.05, 14.69, 19.29, 18.94, 16.52, 27.98, 37.33, 30.06, 1, 0.88, 1.12, 1.78, 3.13, 4.05, 6.08, 8.79, 8.62, 7.49, 7.48, 7.40, 6.86, 7.10],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'Count',\n      data: [0.0356, 0.0394, 0.0517, 0.0626, 0.1257, 0.1275, 0.1283, 0.1290, 0.1301, 0.1313, 0.1460, 0.1483, 0.1532, 0.00344, 0.00385, 0.00394, 0.0040, 0.00405, 0.00411, 0.00416, 0.0042, 0.00425, 0.0043, 0.00436, 0.00441, 0.0045, 0.00457],\n      type: 'line',\n      yAxisIndex: 1\n    },\n  ]\n}\n{% endecharts %}\n\n## 简单分析\n上面的信息可以分为如下几组的对比\n\n- 不同阶段十年的对比：2001 年到 2010 年这十年，与 2015 年到 2024 年这十年对比\n- 十年和二十多年的对比：2001 年到 2012 年这 11 年，与 2001 年到 2014 年这 23 年对比\n- 二十多年前后段和后半段的对比：2001 年到 2012 年，与 2012 年到 2024 年进行对比\n- 对比分红再买入和分红不再买入的情况\n\n其中第一组可以发现 2001 年到 2010 年这十年总市值变为 **16.56**, 总股数是 **0.1313** 。也就是总市值变成了原来的 **16** 倍，股数变为原来的 **3.6** 倍左右；2015 年到 2024 年这十年总价值变成了 **7.1**，总股数变成了 **0.00457**, 总价值变成了原来的 **7** 倍左右，股数变成了原来的 **1.3** 倍。通过对比可以看出\n1. 后面这十年总收益比前面十年少\n2. 后面这十年总股数增加的不如前十年多\n3. 总股数前十年比后十年多更多。这里可能有多个原因：1）前十年有过送股；2）前十年股价更低，同样分红的钱能买更多的股数\n\n第二组可以看出来，总共 24 年总市值变为 **356.74**，总股数变为 **0.23**，总市值是原来的 **356** 倍，总股数是原来的 **6.4** 倍；前 11 年总市值变为 **37.33**，总股数变为 **0.1483**, 总市值变为原来的 **37** 倍，总股数变为原来的 **4** 倍。这里可以看出来，时间长一倍，总市值不仅仅是多一倍，二十将近 **10** 倍，从原来的 **37** 倍变成了 **356** 倍。总股数由于后面股价上涨了，则增长不多。\n\n第三组可以看出来，前面十二年总价值从 1 涨到 **37.33**，总股数从 **0.0356** 变为 **0.1483**；后面十二年，价值从 **37.33** 涨到 **356.74**,总股数从 **0.1483** 涨到 **0.23**。可以看出来\n1. 前面十二年总价值涨了 **37** 倍，后面十二年总价值涨了将近 **10** 倍\n2. 前面十二年总股数涨到原来 **4** 倍，后面十二年总股数涨到 **1.6** 倍\n可以大致认为，股数越多，总收益越多；股价更低的时候，股东总收益反而会更好。\n\n第四组 分红不再买入的情况下，总市值变为 **248.27**, 总股数变为 **0.16**。分红再买入的情况下，总市值变为 **356.74**，总股数变为 **0.23**。分红再投入的总收益会更高。从总收益来看差异还挺大，分红不再买入的情况下是 **248** 倍，分红再买入的情况下是 **356** 倍。\n\n## 整体结论\n1. 投资是有复利的，所以越早开始投资越好，投资的时间越长越好\n2. 对于好公司（上面的茅台），不管是否分红再投入，都能有不错的收益\n3. 对于好公司，分红应该再投入，收益会更多\n 3.1  分红可以理解为公司部分收益的处置权交给所有股东（而不是只有大股东），股东收到分红后至少有两个选择：1）继续买入；2）不买入该投资标的。那么这两种选择也会有不同的收益，如果不买入该投资标的的收益无法比过当前投资标的，则收益会变少 -- 当然如果有正当使用需要则另说。\n 3.2  另外可以从股本位的视角来考虑，分红再买入是再增加整体股数，长远来看收益也会更好。\n4. 市值 = 股数 * 单价。股数和股票单价上涨均能导致市值上涨。\n4.1. 市值短期受市场影响（市场内参与该股票交易所有人的预期），长期受公司内在价值影响。也就是说从长期来看公司股价会围绕公司价值波动。\n4.2. 不管股价是否增长，股数增长均会提高整体市值，但是股价增长，会导致同样资金能够买到的股数变少。\n4.3. 因此股价大幅增长对股东来说反而不是一个好事情:1）股价是否涨高，并不会影响公司的营业情况 -- 也就是盈利、分红等；2）股价涨高导致能买的股数变少（实际情况下甚至由于股价过高，分红没法购买 1 手）。\n\n# 其他\n1. 上面的所有分析，有一个前提：公司是一个好公司。\n2. 不是所有公司的收益率都如茅台，因此上述数据仅作参考。\n3. 我们可以多一个维度分析公司的收益情况。如果公司是好公司的情况下，整体收益可以由 <股数 * 股价> 决定，那么我们在用数据进行筛选公司的时候，可以考虑分红再买入后的情况。\n4. 既然上面说的分红再买入会更好，那是不是可以让公司不分红（变相的相当于再买入），分红的意义是啥呢？\n4.1. 分红会从利润中出，公司分红表示有利润，同时如果公式有分红比例的话，会变相的约束公司不虚报利润（只可能隐藏利润） -- 表明公司利润只会比表现出来的更好。也可以一定情看下监督公司一年经营情况\n4.2. 分红后的钱股东有自由取决权，可以再买入，可以用于其他途径（生活，或者投资其他地方）\n5. 分红的情况是将当年的收益分配给股东的一种形式，可以有三种：现价分红；派发新股；转增股本[2]，这里说的分红主要是是现价分红。\n\n另外建议结合 [股市是一个好的投资渠道吗](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ) 一起阅读（注意：里面茅台相关总收益/总股数计算有误，以本文为准），里面对不同投资标的进行一个分析\n\n# Ref\n[1] https://vip.stock.finance.sina.com.cn/corp/go.php/vISSUE_ShareBonus/stockid/600519.phtml\n[2] https://www.morganstanleysecurities.com.cn/investor/education-dividendpolicy.html\n","slug":"invest-compond","published":1,"updated":"2025-04-12T10:25:58.542Z","_id":"cm99qn2hc00001nmk2xf74mbp","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>本文尝试对上市公司分红以及投资复利进行一些分析，希望能够更好的了解投资的选择标准，以及操作标准。</p>\n</blockquote>\n<p>在 <a href=\"https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA\">赚钱机器茅台</a> 一文中，我们有提到分红相关的事情，这里我们仍旧以茅台为例分析下分红相关的内容。</p>\n<span id=\"more\"></span>\n<h1 id=\"股本位\"><a href=\"#股本位\" class=\"headerlink\" title=\"股本位\"></a>股本位</h1><p>现在的生活中大家会以拥有 <em>本币本位/纸币本位</em> 的视角，也就是所有的价值/价格体系等都会锚定到本国法币的价值，同时也有一个 <em>金本位</em>，表示所有的价值都体现在包含多少黄金。</p>\n<p>那么对于股市投资是不是可以有一种“股本位”的视角，那么所有的目的都是以 <em>股数</em> 作为衡量，我们的目的也将变成获取更多的 <em>股数</em>。</p>\n<h1 id=\"分红以及投资收益\"><a href=\"#分红以及投资收益\" class=\"headerlink\" title=\"分红以及投资收益\"></a>分红以及投资收益</h1><p>接下来我们以茅台上市后股东收益来阐述分红，复利，收益等。</p>\n<h2 id=\"分析情况说明\"><a href=\"#分析情况说明\" class=\"headerlink\" title=\"分析情况说明\"></a>分析情况说明</h2><p>首先描述下本文会使用到的一些情况</p>\n<ol>\n<li>本文假设股票可以零散买入，也就是没有最低股数要求，甚至可以买入小于 1 股（比如 0.01 股）</li>\n<li>对于茅台整个上市历史的收益，起点为上市是购入 1 元茅台股（为了计算方便，不影响整体收益比例）</li>\n<li>对于比较中最近十年的收益情况，起点为 2015 年选择一个市值高点，以市价买入 1 元茅台股票</li>\n</ol>\n<p>原始数据整理如下，数据来源[1]，股数计算公式参考图片中左上角的公式，市值是 股数 * 股价。</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121251913.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121253102.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121254827.png\" alt=\"\"></p>\n<h2 id=\"收益和股数\"><a href=\"#收益和股数\" class=\"headerlink\" title=\"收益和股数\"></a>收益和股数</h2><p>通过整体茅台的数据，绘制如下几张图，下图中展示了不同纬度情况下茅台股票的收益（总市值和总股数），其中</p>\n<ul>\n<li>ValueFromInit 表示从上市开始投入 1 元，然后分股继续持有，分红再买入后的总市值</li>\n<li>CountFromInit 表示从上市开始投入 1 元，然后分股继续持有，分红再买入后的总股数</li>\n<li>ValueFrom2015 表示从 20150526 开始投入 1 元，然后分股继续持有，分红再买入后的总市值</li>\n<li>CountFrom2015 表示从 20150526 开始投入 1 元，然后分股继续持有，分红再买入后的总股数</li>\n</ul>\n<blockquote>\n<p>选择 20150526 是因为当天市值是当年一个高值<br>下图中的每条线可以点击标题控制是否显示</p>\n</blockquote>\n\n<div id=\"echarts7404\" style=\"width: 85%;height:400px;margin: 0 auto\"></div>\n<script src=\"https://unpkg.com/echarts@5.6.0/dist/echarts.min.js\" ></script>\n<script >\n  if (window.eChartecharts7404ResizeHandler) {\n    window.removeEventListener(\"resize\", eChartecharts7404ResizeHandler);\n  }\n  var optionecharts7404 = {\n  legend: {\n    data: ['ValueFromInit', 'CountFromInit', 'ValueFrom2015', 'CountFrom2015']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: ['20020725', '20030714', '20040701', '20050804', '20060519', '20060524', '20070713', '20080613', '20090701', '20100705', '20110701', '20120705', '20130607', '20140625', '20150717', '20160701', '20170707', '20180615', '20190628', '20200624', '20210625', '20220628', '20221226', '20230629', '20231219', '20240618', '20241219']\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n    {\n      name: 'stock-count',\n      type: 'value'\n    }\n  ],\n  series: [\n    {\n      name: 'ValueFromInit',\n      data: [1.15, 0.93, 1.38, 3.47, 4.97, 5.05, 14.69, 19.29, 18.94, 16.52, 27.98, 37.33, 30.06, 24.64, 44.26, 56.68, 89.67, 157.71, 203.64, 305.67, 442.03, 433.51, 376.70, 376.17, 371.87, 344.64, 356.74],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'ValueFrom2015',\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.88, 1.12, 1.78, 3.13, 4.05, 6.08, 8.79, 8.62, 7.49, 7.48, 7.40, 6.86, 7.10],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'CountFromInit',\n      data: [0.0356, 0.0394, 0.0517, 0.0626, 0.1257, 0.1275, 0.1283, 0.1290, 0.1301, 0.1313, 0.1460, 0.1483, 0.1532, 0.1732, 0.1938, 0.1980, 0.2010, 0.2039, 0.2069, 0.2093, 0.2112, 0.2135, 0.2162, 0.2190, 0.2220, 0.2265, 0.23],\n      type: 'line',\n      yAxisIndex: 1\n    },\n    {\n      name: 'CountFrom2015',\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.00344, 0.00385, 0.00394, 0.0040, 0.00405, 0.00411, 0.00416, 0.0042, 0.00425, 0.0043, 0.00436, 0.00441, 0.0045, 0.00457],\n      type: 'line',\n      yAxisIndex: 1\n    }\n  ]\n};\n  if (window.echarts !== undefined) {\n    var eChartecharts7404 = echarts.init(document.getElementById('echarts7404'));\n    eChartecharts7404.setOption(optionecharts7404);\n    var eChartecharts7404ResizeHandler = function() {\n      eChartecharts7404.resize();\n    };\n    window.addEventListener(\"resize\", eChartecharts7404ResizeHandler);\n  }\n</script>\n<p>下面的图中，20140625 之前的表示从上市开始投入 1 元后，总市值和总股数的情况，20140625 以及以后的情况则表示在 20140625 买入 1 元后的总市值和总股数情况，其中</p>\n<ul>\n<li>Value 表示对应时间的总市值</li>\n<li>Count 表示对应时间的总股数</li>\n</ul>\n<blockquote>\n<p>下图中的每条线可以点击标题控制是否显示</p>\n</blockquote>\n\n<div id=\"echarts9375\" style=\"width: 85%;height:400px;margin: 0 auto\"></div>\n<script src=\"https://unpkg.com/echarts@5.6.0/dist/echarts.min.js\" ></script>\n<script >\n  if (window.eChartecharts9375ResizeHandler) {\n    window.removeEventListener(\"resize\", eChartecharts9375ResizeHandler);\n  }\n  var optionecharts9375 = {\n  legend: {\n    data: ['Value', 'Count']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: ['20020725', '20030714', '20040701', '20050804', '20060519', '20060524', '20070713', '20080613', '20090701', '20100705', '20110701', '20120705', '20130607', '20140625', '20150717', '20160701', '20170707', '20180615', '20190628', '20200624', '20210625', '20220628', '20221226', '20230629', '20231219', '20240618', '20241219']\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n    {\n      name: 'stock-count',\n      type: 'value'\n    }\n  ],\n  series: [\n    {\n      name: 'Value',\n      data: [1.15, 0.93, 1.38, 3.47, 4.97, 5.05, 14.69, 19.29, 18.94, 16.52, 27.98, 37.33, 30.06, 1, 0.88, 1.12, 1.78, 3.13, 4.05, 6.08, 8.79, 8.62, 7.49, 7.48, 7.40, 6.86, 7.10],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'Count',\n      data: [0.0356, 0.0394, 0.0517, 0.0626, 0.1257, 0.1275, 0.1283, 0.1290, 0.1301, 0.1313, 0.1460, 0.1483, 0.1532, 0.00344, 0.00385, 0.00394, 0.0040, 0.00405, 0.00411, 0.00416, 0.0042, 0.00425, 0.0043, 0.00436, 0.00441, 0.0045, 0.00457],\n      type: 'line',\n      yAxisIndex: 1\n    },\n  ]\n};\n  if (window.echarts !== undefined) {\n    var eChartecharts9375 = echarts.init(document.getElementById('echarts9375'));\n    eChartecharts9375.setOption(optionecharts9375);\n    var eChartecharts9375ResizeHandler = function() {\n      eChartecharts9375.resize();\n    };\n    window.addEventListener(\"resize\", eChartecharts9375ResizeHandler);\n  }\n</script>\n<h2 id=\"简单分析\"><a href=\"#简单分析\" class=\"headerlink\" title=\"简单分析\"></a>简单分析</h2><p>上面的信息可以分为如下几组的对比</p>\n<ul>\n<li>不同阶段十年的对比：2001 年到 2010 年这十年，与 2015 年到 2024 年这十年对比</li>\n<li>十年和二十多年的对比：2001 年到 2012 年这 11 年，与 2001 年到 2014 年这 23 年对比</li>\n<li>二十多年前后段和后半段的对比：2001 年到 2012 年，与 2012 年到 2024 年进行对比</li>\n<li>对比分红再买入和分红不再买入的情况</li>\n</ul>\n<p>其中第一组可以发现 2001 年到 2010 年这十年总市值变为 <strong>16.56</strong>, 总股数是 <strong>0.1313</strong> 。也就是总市值变成了原来的 <strong>16</strong> 倍，股数变为原来的 <strong>3.6</strong> 倍左右；2015 年到 2024 年这十年总价值变成了 <strong>7.1</strong>，总股数变成了 <strong>0.00457</strong>, 总价值变成了原来的 <strong>7</strong> 倍左右，股数变成了原来的 <strong>1.3</strong> 倍。通过对比可以看出</p>\n<ol>\n<li>后面这十年总收益比前面十年少</li>\n<li>后面这十年总股数增加的不如前十年多</li>\n<li>总股数前十年比后十年多更多。这里可能有多个原因：1）前十年有过送股；2）前十年股价更低，同样分红的钱能买更多的股数</li>\n</ol>\n<p>第二组可以看出来，总共 24 年总市值变为 <strong>356.74</strong>，总股数变为 <strong>0.23</strong>，总市值是原来的 <strong>356</strong> 倍，总股数是原来的 <strong>6.4</strong> 倍；前 11 年总市值变为 <strong>37.33</strong>，总股数变为 <strong>0.1483</strong>, 总市值变为原来的 <strong>37</strong> 倍，总股数变为原来的 <strong>4</strong> 倍。这里可以看出来，时间长一倍，总市值不仅仅是多一倍，二十将近 <strong>10</strong> 倍，从原来的 <strong>37</strong> 倍变成了 <strong>356</strong> 倍。总股数由于后面股价上涨了，则增长不多。</p>\n<p>第三组可以看出来，前面十二年总价值从 1 涨到 <strong>37.33</strong>，总股数从 <strong>0.0356</strong> 变为 <strong>0.1483</strong>；后面十二年，价值从 <strong>37.33</strong> 涨到 <strong>356.74</strong>,总股数从 <strong>0.1483</strong> 涨到 <strong>0.23</strong>。可以看出来</p>\n<ol>\n<li>前面十二年总价值涨了 <strong>37</strong> 倍，后面十二年总价值涨了将近 <strong>10</strong> 倍</li>\n<li>前面十二年总股数涨到原来 <strong>4</strong> 倍，后面十二年总股数涨到 <strong>1.6</strong> 倍<br>可以大致认为，股数越多，总收益越多；股价更低的时候，股东总收益反而会更好。</li>\n</ol>\n<p>第四组 分红不再买入的情况下，总市值变为 <strong>248.27</strong>, 总股数变为 <strong>0.16</strong>。分红再买入的情况下，总市值变为 <strong>356.74</strong>，总股数变为 <strong>0.23</strong>。分红再投入的总收益会更高。从总收益来看差异还挺大，分红不再买入的情况下是 <strong>248</strong> 倍，分红再买入的情况下是 <strong>356</strong> 倍。</p>\n<h2 id=\"整体结论\"><a href=\"#整体结论\" class=\"headerlink\" title=\"整体结论\"></a>整体结论</h2><ol>\n<li>投资是有复利的，所以越早开始投资越好，投资的时间越长越好</li>\n<li>对于好公司（上面的茅台），不管是否分红再投入，都能有不错的收益</li>\n<li>对于好公司，分红应该再投入，收益会更多<br>3.1  分红可以理解为公司部分收益的处置权交给所有股东（而不是只有大股东），股东收到分红后至少有两个选择：1）继续买入；2）不买入该投资标的。那么这两种选择也会有不同的收益，如果不买入该投资标的的收益无法比过当前投资标的，则收益会变少 — 当然如果有正当使用需要则另说。<br>3.2  另外可以从股本位的视角来考虑，分红再买入是再增加整体股数，长远来看收益也会更好。</li>\n<li>市值 = 股数 * 单价。股数和股票单价上涨均能导致市值上涨。<br>4.1. 市值短期受市场影响（市场内参与该股票交易所有人的预期），长期受公司内在价值影响。也就是说从长期来看公司股价会围绕公司价值波动。<br>4.2. 不管股价是否增长，股数增长均会提高整体市值，但是股价增长，会导致同样资金能够买到的股数变少。<br>4.3. 因此股价大幅增长对股东来说反而不是一个好事情:1）股价是否涨高，并不会影响公司的营业情况 — 也就是盈利、分红等；2）股价涨高导致能买的股数变少（实际情况下甚至由于股价过高，分红没法购买 1 手）。</li>\n</ol>\n<h1 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h1><ol>\n<li>上面的所有分析，有一个前提：公司是一个好公司。</li>\n<li>不是所有公司的收益率都如茅台，因此上述数据仅作参考。</li>\n<li>我们可以多一个维度分析公司的收益情况。如果公司是好公司的情况下，整体收益可以由 &lt;股数 * 股价&gt; 决定，那么我们在用数据进行筛选公司的时候，可以考虑分红再买入后的情况。</li>\n<li>既然上面说的分红再买入会更好，那是不是可以让公司不分红（变相的相当于再买入），分红的意义是啥呢？<br>4.1. 分红会从利润中出，公司分红表示有利润，同时如果公式有分红比例的话，会变相的约束公司不虚报利润（只可能隐藏利润） — 表明公司利润只会比表现出来的更好。也可以一定情看下监督公司一年经营情况<br>4.2. 分红后的钱股东有自由取决权，可以再买入，可以用于其他途径（生活，或者投资其他地方）</li>\n<li>分红的情况是将当年的收益分配给股东的一种形式，可以有三种：现价分红；派发新股；转增股本[2]，这里说的分红主要是是现价分红。</li>\n</ol>\n<p>另外建议结合 <a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">股市是一个好的投资渠道吗</a> 一起阅读（注意：里面茅台相关总收益/总股数计算有误，以本文为准），里面对不同投资标的进行一个分析</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] <a href=\"https://vip.stock.finance.sina.com.cn/corp/go.php/vISSUE_ShareBonus/stockid/600519.phtml\">https://vip.stock.finance.sina.com.cn/corp/go.php/vISSUE_ShareBonus/stockid/600519.phtml</a><br>[2] <a href=\"https://www.morganstanleysecurities.com.cn/investor/education-dividendpolicy.html\">https://www.morganstanleysecurities.com.cn/investor/education-dividendpolicy.html</a></p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文尝试对上市公司分红以及投资复利进行一些分析，希望能够更好的了解投资的选择标准，以及操作标准。</p>\n</blockquote>\n<p>在 <a href=\"https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA\">赚钱机器茅台</a> 一文中，我们有提到分红相关的事情，这里我们仍旧以茅台为例分析下分红相关的内容。</p>","more":"<h1 id=\"股本位\"><a href=\"#股本位\" class=\"headerlink\" title=\"股本位\"></a>股本位</h1><p>现在的生活中大家会以拥有 <em>本币本位/纸币本位</em> 的视角，也就是所有的价值/价格体系等都会锚定到本国法币的价值，同时也有一个 <em>金本位</em>，表示所有的价值都体现在包含多少黄金。</p>\n<p>那么对于股市投资是不是可以有一种“股本位”的视角，那么所有的目的都是以 <em>股数</em> 作为衡量，我们的目的也将变成获取更多的 <em>股数</em>。</p>\n<h1 id=\"分红以及投资收益\"><a href=\"#分红以及投资收益\" class=\"headerlink\" title=\"分红以及投资收益\"></a>分红以及投资收益</h1><p>接下来我们以茅台上市后股东收益来阐述分红，复利，收益等。</p>\n<h2 id=\"分析情况说明\"><a href=\"#分析情况说明\" class=\"headerlink\" title=\"分析情况说明\"></a>分析情况说明</h2><p>首先描述下本文会使用到的一些情况</p>\n<ol>\n<li>本文假设股票可以零散买入，也就是没有最低股数要求，甚至可以买入小于 1 股（比如 0.01 股）</li>\n<li>对于茅台整个上市历史的收益，起点为上市是购入 1 元茅台股（为了计算方便，不影响整体收益比例）</li>\n<li>对于比较中最近十年的收益情况，起点为 2015 年选择一个市值高点，以市价买入 1 元茅台股票</li>\n</ol>\n<p>原始数据整理如下，数据来源[1]，股数计算公式参考图片中左上角的公式，市值是 股数 * 股价。</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121251913.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121253102.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202504121254827.png\" alt=\"\"></p>\n<h2 id=\"收益和股数\"><a href=\"#收益和股数\" class=\"headerlink\" title=\"收益和股数\"></a>收益和股数</h2><p>通过整体茅台的数据，绘制如下几张图，下图中展示了不同纬度情况下茅台股票的收益（总市值和总股数），其中</p>\n<ul>\n<li>ValueFromInit 表示从上市开始投入 1 元，然后分股继续持有，分红再买入后的总市值</li>\n<li>CountFromInit 表示从上市开始投入 1 元，然后分股继续持有，分红再买入后的总股数</li>\n<li>ValueFrom2015 表示从 20150526 开始投入 1 元，然后分股继续持有，分红再买入后的总市值</li>\n<li>CountFrom2015 表示从 20150526 开始投入 1 元，然后分股继续持有，分红再买入后的总股数</li>\n</ul>\n<blockquote>\n<p>选择 20150526 是因为当天市值是当年一个高值<br>下图中的每条线可以点击标题控制是否显示</p>\n</blockquote>\n\n<div id=\"echarts7404\" style=\"width: 85%;height:400px;margin: 0 auto\"></div>\n<script src=\"https://unpkg.com/echarts@5.6.0/dist/echarts.min.js\" ></script>\n<script >\n  if (window.eChartecharts7404ResizeHandler) {\n    window.removeEventListener(\"resize\", eChartecharts7404ResizeHandler);\n  }\n  var optionecharts7404 = {\n  legend: {\n    data: ['ValueFromInit', 'CountFromInit', 'ValueFrom2015', 'CountFrom2015']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: ['20020725', '20030714', '20040701', '20050804', '20060519', '20060524', '20070713', '20080613', '20090701', '20100705', '20110701', '20120705', '20130607', '20140625', '20150717', '20160701', '20170707', '20180615', '20190628', '20200624', '20210625', '20220628', '20221226', '20230629', '20231219', '20240618', '20241219']\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n    {\n      name: 'stock-count',\n      type: 'value'\n    }\n  ],\n  series: [\n    {\n      name: 'ValueFromInit',\n      data: [1.15, 0.93, 1.38, 3.47, 4.97, 5.05, 14.69, 19.29, 18.94, 16.52, 27.98, 37.33, 30.06, 24.64, 44.26, 56.68, 89.67, 157.71, 203.64, 305.67, 442.03, 433.51, 376.70, 376.17, 371.87, 344.64, 356.74],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'ValueFrom2015',\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.88, 1.12, 1.78, 3.13, 4.05, 6.08, 8.79, 8.62, 7.49, 7.48, 7.40, 6.86, 7.10],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'CountFromInit',\n      data: [0.0356, 0.0394, 0.0517, 0.0626, 0.1257, 0.1275, 0.1283, 0.1290, 0.1301, 0.1313, 0.1460, 0.1483, 0.1532, 0.1732, 0.1938, 0.1980, 0.2010, 0.2039, 0.2069, 0.2093, 0.2112, 0.2135, 0.2162, 0.2190, 0.2220, 0.2265, 0.23],\n      type: 'line',\n      yAxisIndex: 1\n    },\n    {\n      name: 'CountFrom2015',\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.00344, 0.00385, 0.00394, 0.0040, 0.00405, 0.00411, 0.00416, 0.0042, 0.00425, 0.0043, 0.00436, 0.00441, 0.0045, 0.00457],\n      type: 'line',\n      yAxisIndex: 1\n    }\n  ]\n};\n  if (window.echarts !== undefined) {\n    var eChartecharts7404 = echarts.init(document.getElementById('echarts7404'));\n    eChartecharts7404.setOption(optionecharts7404);\n    var eChartecharts7404ResizeHandler = function() {\n      eChartecharts7404.resize();\n    };\n    window.addEventListener(\"resize\", eChartecharts7404ResizeHandler);\n  }\n</script>\n<p>下面的图中，20140625 之前的表示从上市开始投入 1 元后，总市值和总股数的情况，20140625 以及以后的情况则表示在 20140625 买入 1 元后的总市值和总股数情况，其中</p>\n<ul>\n<li>Value 表示对应时间的总市值</li>\n<li>Count 表示对应时间的总股数</li>\n</ul>\n<blockquote>\n<p>下图中的每条线可以点击标题控制是否显示</p>\n</blockquote>\n\n<div id=\"echarts9375\" style=\"width: 85%;height:400px;margin: 0 auto\"></div>\n<script src=\"https://unpkg.com/echarts@5.6.0/dist/echarts.min.js\" ></script>\n<script >\n  if (window.eChartecharts9375ResizeHandler) {\n    window.removeEventListener(\"resize\", eChartecharts9375ResizeHandler);\n  }\n  var optionecharts9375 = {\n  legend: {\n    data: ['Value', 'Count']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: ['20020725', '20030714', '20040701', '20050804', '20060519', '20060524', '20070713', '20080613', '20090701', '20100705', '20110701', '20120705', '20130607', '20140625', '20150717', '20160701', '20170707', '20180615', '20190628', '20200624', '20210625', '20220628', '20221226', '20230629', '20231219', '20240618', '20241219']\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n    {\n      name: 'stock-count',\n      type: 'value'\n    }\n  ],\n  series: [\n    {\n      name: 'Value',\n      data: [1.15, 0.93, 1.38, 3.47, 4.97, 5.05, 14.69, 19.29, 18.94, 16.52, 27.98, 37.33, 30.06, 1, 0.88, 1.12, 1.78, 3.13, 4.05, 6.08, 8.79, 8.62, 7.49, 7.48, 7.40, 6.86, 7.10],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: 'Count',\n      data: [0.0356, 0.0394, 0.0517, 0.0626, 0.1257, 0.1275, 0.1283, 0.1290, 0.1301, 0.1313, 0.1460, 0.1483, 0.1532, 0.00344, 0.00385, 0.00394, 0.0040, 0.00405, 0.00411, 0.00416, 0.0042, 0.00425, 0.0043, 0.00436, 0.00441, 0.0045, 0.00457],\n      type: 'line',\n      yAxisIndex: 1\n    },\n  ]\n};\n  if (window.echarts !== undefined) {\n    var eChartecharts9375 = echarts.init(document.getElementById('echarts9375'));\n    eChartecharts9375.setOption(optionecharts9375);\n    var eChartecharts9375ResizeHandler = function() {\n      eChartecharts9375.resize();\n    };\n    window.addEventListener(\"resize\", eChartecharts9375ResizeHandler);\n  }\n</script>\n<h2 id=\"简单分析\"><a href=\"#简单分析\" class=\"headerlink\" title=\"简单分析\"></a>简单分析</h2><p>上面的信息可以分为如下几组的对比</p>\n<ul>\n<li>不同阶段十年的对比：2001 年到 2010 年这十年，与 2015 年到 2024 年这十年对比</li>\n<li>十年和二十多年的对比：2001 年到 2012 年这 11 年，与 2001 年到 2014 年这 23 年对比</li>\n<li>二十多年前后段和后半段的对比：2001 年到 2012 年，与 2012 年到 2024 年进行对比</li>\n<li>对比分红再买入和分红不再买入的情况</li>\n</ul>\n<p>其中第一组可以发现 2001 年到 2010 年这十年总市值变为 <strong>16.56</strong>, 总股数是 <strong>0.1313</strong> 。也就是总市值变成了原来的 <strong>16</strong> 倍，股数变为原来的 <strong>3.6</strong> 倍左右；2015 年到 2024 年这十年总价值变成了 <strong>7.1</strong>，总股数变成了 <strong>0.00457</strong>, 总价值变成了原来的 <strong>7</strong> 倍左右，股数变成了原来的 <strong>1.3</strong> 倍。通过对比可以看出</p>\n<ol>\n<li>后面这十年总收益比前面十年少</li>\n<li>后面这十年总股数增加的不如前十年多</li>\n<li>总股数前十年比后十年多更多。这里可能有多个原因：1）前十年有过送股；2）前十年股价更低，同样分红的钱能买更多的股数</li>\n</ol>\n<p>第二组可以看出来，总共 24 年总市值变为 <strong>356.74</strong>，总股数变为 <strong>0.23</strong>，总市值是原来的 <strong>356</strong> 倍，总股数是原来的 <strong>6.4</strong> 倍；前 11 年总市值变为 <strong>37.33</strong>，总股数变为 <strong>0.1483</strong>, 总市值变为原来的 <strong>37</strong> 倍，总股数变为原来的 <strong>4</strong> 倍。这里可以看出来，时间长一倍，总市值不仅仅是多一倍，二十将近 <strong>10</strong> 倍，从原来的 <strong>37</strong> 倍变成了 <strong>356</strong> 倍。总股数由于后面股价上涨了，则增长不多。</p>\n<p>第三组可以看出来，前面十二年总价值从 1 涨到 <strong>37.33</strong>，总股数从 <strong>0.0356</strong> 变为 <strong>0.1483</strong>；后面十二年，价值从 <strong>37.33</strong> 涨到 <strong>356.74</strong>,总股数从 <strong>0.1483</strong> 涨到 <strong>0.23</strong>。可以看出来</p>\n<ol>\n<li>前面十二年总价值涨了 <strong>37</strong> 倍，后面十二年总价值涨了将近 <strong>10</strong> 倍</li>\n<li>前面十二年总股数涨到原来 <strong>4</strong> 倍，后面十二年总股数涨到 <strong>1.6</strong> 倍<br>可以大致认为，股数越多，总收益越多；股价更低的时候，股东总收益反而会更好。</li>\n</ol>\n<p>第四组 分红不再买入的情况下，总市值变为 <strong>248.27</strong>, 总股数变为 <strong>0.16</strong>。分红再买入的情况下，总市值变为 <strong>356.74</strong>，总股数变为 <strong>0.23</strong>。分红再投入的总收益会更高。从总收益来看差异还挺大，分红不再买入的情况下是 <strong>248</strong> 倍，分红再买入的情况下是 <strong>356</strong> 倍。</p>\n<h2 id=\"整体结论\"><a href=\"#整体结论\" class=\"headerlink\" title=\"整体结论\"></a>整体结论</h2><ol>\n<li>投资是有复利的，所以越早开始投资越好，投资的时间越长越好</li>\n<li>对于好公司（上面的茅台），不管是否分红再投入，都能有不错的收益</li>\n<li>对于好公司，分红应该再投入，收益会更多<br>3.1  分红可以理解为公司部分收益的处置权交给所有股东（而不是只有大股东），股东收到分红后至少有两个选择：1）继续买入；2）不买入该投资标的。那么这两种选择也会有不同的收益，如果不买入该投资标的的收益无法比过当前投资标的，则收益会变少 — 当然如果有正当使用需要则另说。<br>3.2  另外可以从股本位的视角来考虑，分红再买入是再增加整体股数，长远来看收益也会更好。</li>\n<li>市值 = 股数 * 单价。股数和股票单价上涨均能导致市值上涨。<br>4.1. 市值短期受市场影响（市场内参与该股票交易所有人的预期），长期受公司内在价值影响。也就是说从长期来看公司股价会围绕公司价值波动。<br>4.2. 不管股价是否增长，股数增长均会提高整体市值，但是股价增长，会导致同样资金能够买到的股数变少。<br>4.3. 因此股价大幅增长对股东来说反而不是一个好事情:1）股价是否涨高，并不会影响公司的营业情况 — 也就是盈利、分红等；2）股价涨高导致能买的股数变少（实际情况下甚至由于股价过高，分红没法购买 1 手）。</li>\n</ol>\n<h1 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h1><ol>\n<li>上面的所有分析，有一个前提：公司是一个好公司。</li>\n<li>不是所有公司的收益率都如茅台，因此上述数据仅作参考。</li>\n<li>我们可以多一个维度分析公司的收益情况。如果公司是好公司的情况下，整体收益可以由 &lt;股数 * 股价&gt; 决定，那么我们在用数据进行筛选公司的时候，可以考虑分红再买入后的情况。</li>\n<li>既然上面说的分红再买入会更好，那是不是可以让公司不分红（变相的相当于再买入），分红的意义是啥呢？<br>4.1. 分红会从利润中出，公司分红表示有利润，同时如果公式有分红比例的话，会变相的约束公司不虚报利润（只可能隐藏利润） — 表明公司利润只会比表现出来的更好。也可以一定情看下监督公司一年经营情况<br>4.2. 分红后的钱股东有自由取决权，可以再买入，可以用于其他途径（生活，或者投资其他地方）</li>\n<li>分红的情况是将当年的收益分配给股东的一种形式，可以有三种：现价分红；派发新股；转增股本[2]，这里说的分红主要是是现价分红。</li>\n</ol>\n<p>另外建议结合 <a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">股市是一个好的投资渠道吗</a> 一起阅读（注意：里面茅台相关总收益/总股数计算有误，以本文为准），里面对不同投资标的进行一个分析</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] <a href=\"https://vip.stock.finance.sina.com.cn/corp/go.php/vISSUE_ShareBonus/stockid/600519.phtml\">https://vip.stock.finance.sina.com.cn/corp/go.php/vISSUE_ShareBonus/stockid/600519.phtml</a><br>[2] <a href=\"https://www.morganstanleysecurities.com.cn/investor/education-dividendpolicy.html\">https://www.morganstanleysecurities.com.cn/investor/education-dividendpolicy.html</a></p>"},{"title":"比较，机会成本以及迭代速度","date":"2025-04-17T08:53:32.000Z","toc":true,"_content":"> 本文希望能够通过对一些例子，梳理一些基本/常用的事项。\n\n在 [分红及投资复利-以茅台为例](https://mp.weixin.qq.com/s/7T22TF60g_FQV10xfzZBZw) 一文中主要阐述了投资中复利的力量，从相关数据可以看出，复利能够让我们的得到更好的结果，复利中结果和利率也会相关。\n\n本文尝试对利率(本文中的迭代速度)，比较以及机会成本进行相关阐述，希望能对这些有一个更深的认识。部分想法受《雪球特别版-段永平投资问答录》启发。 \n\n<!-- more -->\n\n# 迭代速度\n\n复利中有两个因为比较重要：时间，和增长率。时间我们在之前的文章中有大致描述。增长率/迭代速度 会在这里进行描述。\n\n迭代速度大致分为三类：负数，零 和正数。其中负数表示往反方向发展，零表示不发展，正数表示往正方向发展。\n\n下面的图形中展示了不同情况下 20 年后的总收益\n- 迭代速度分别是 2%，5%，8%，10%，15%，20%，30%，-2%，-5%，-8%，-10% 的总收益\n- 迭代速度是 8%，15% 的情况下，每过两年会有 -2% 的增长的情况\n\n> 这些数字的选择，大概是，每年 CPI 涨幅 2% 左右，GDP 涨幅 5% 左右，CPI + GDP 大概 8%，具体可以参考 [股市是一个好的投资渠道吗](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ)\n> 时间跨度选择的是 20 年\n\n> 下图中通过点击标题，可以展示/隐藏不同情况下的曲线\n\n{% echarts 85% 400 %}\n{\n  legend: {\n    data: ['2', '5', '8', '8(-2)', '10', '15', '15(-2)', '20', '25', '-2', '-5', '-8', '-10']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n  ],\n  series: [\n    {\n      name: '2',\n      data: [1, 1.02, 1.0404, 1.061208, 1.08243216, 1.1040808032, 1.126162419264, 1.14868566764928, 1.1716593810022657, 1.195092568622311, 1.2189944199947573, 1.2433743083946525, 1.2682417945625455, 1.2936066304537963, 1.3194787630628724, 1.3458683383241299, 1.3727857050906125, 1.4002414191924248, 1.4282462475762734, 1.4568111725277988, 1.485947395978355],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '5',\n      data: [1, 1.05, 1.1025, 1.1576250000000001, 1.2155062500000002, 1.2762815625000004, 1.3400956406250004, 1.4071004226562505, 1.477455443789063, 1.5513282159785162, 1.628894626777442, 1.7103393581163142, 1.79585632602213, 1.8856491423232367, 1.9799315994393987, 2.0789281794113688, 2.1828745883819374, 2.2920183178010345, 2.406619233691086, 2.5269501953756404, 2.6532977051444226],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '8',\n      data: [1, 1.08, 1.1664, 1.2597120000000002, 1.3604889600000003, 1.4693280768000003, 1.5868743229440005, 1.7138242687795207, 1.8509302102818825, 1.9990046271044333, 2.158924997272788, 2.331638997054611, 2.5181701168189803, 2.719623726164499, 2.937193624257659, 3.172169114198272, 3.425942643334134, 3.7000180548008648, 3.9960194991849343, 4.315701059119729, 4.660957143849308],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '8(-2)',\n      data: [1, 1.08, 1.1664, 1.143072, 1.2345177600000001, 1.3332791808000002, 1.306613597184, 1.41114268495872, 1.5240340997554178, 1.4935534177603094, 1.6130376911811342, 1.742080706475625, 1.7072390923461125, 1.8438182197338016, 1.9913236773125058, 1.9514972037662557, 2.107616980067556, 2.2762263384729606, 2.2307018117035016, 2.409157956639782, 2.601890593170965],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '10',\n      data: [1, 1.1, 1.2100000000000002, 1.3310000000000004, 1.4641000000000006, 1.6105100000000008, 1.771561000000001, 1.9487171000000014, 2.1435888100000016, 2.357947691000002, 2.5937424601000023, 2.853116706110003, 3.1384283767210035, 3.4522712143931042, 3.797498335832415, 4.177248169415656, 4.594972986357222, 5.054470284992944, 5.559917313492239, 6.115909044841463, 6.72749994932561],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '15',\n      data: [1, 1.15, 1.3224999999999998, 1.5208749999999995, 1.7490062499999994, 2.0113571874999994, 2.313060765624999, 2.6600198804687487, 3.0590228625390607, 3.5178762919199196, 4.0455577357079076, 4.652391396064093, 5.350250105473707, 6.152787621294762, 7.075705764488976, 8.137061629162321, 9.35762087353667, 10.761264004567169, 12.375453605252243, 14.231771646040078, 16.36653739294609],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '15(-2)',\n      data: [1, 1.15, 1.3224999999999998, 1.2960499999999997, 1.4904574999999995, 1.7140261249999993, 1.6797456024999993, 1.931707442874999, 2.221463559306249, 2.1770342881201237, 2.503589431338142, 2.879127846038863, 2.8215452891180854, 3.244777082485798, 3.7314936448586677, 3.6568637719614943, 4.205393337755718, 4.836202338419076, 4.739478291650695, 5.450400035398299, 6.267960040708043],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '20',\n      data: [1, 1.2, 1.44, 1.728, 2.0736, 2.48832, 2.9859839999999997, 3.5831807999999996, 4.299816959999999, 5.159780351999999, 6.191736422399999, 7.430083706879999, 8.916100448255998, 10.699320537907196, 12.839184645488634, 15.407021574586361, 18.48842588950363, 22.186111067404358, 26.62333328088523, 31.947999937062274, 38.33759992447473],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '25',\n      data: [1, 1.25, 1.5625, 1.953125, 2.44140625, 3.0517578125, 3.814697265625, 4.76837158203125, 5.9604644775390625, 7.450580596923828, 9.313225746154785, 11.641532182693481, 14.551915228366852, 18.189894035458565, 22.737367544323206, 28.421709430404007, 35.52713678800501, 44.40892098500626, 55.51115123125783, 69.38893903907228, 86.73617379884035],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-2',\n      data: [1, 0.98, 0.9603999999999999, 0.9411919999999999, 0.9223681599999999, 0.9039207967999998, 0.8858423808639998, 0.8681255332467198, 0.8507630225817854, 0.8337477621301497, 0.8170728068875467, 0.8007313507497957, 0.7847167237347998, 0.7690223892601038, 0.7536419414749017, 0.7385691026454037, 0.7237977205924956, 0.7093217661806457, 0.6951353308570327, 0.6812326242398921, 0.6676079717550942],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-5',\n      data: [1, 0.95, 0.9025, 0.8573749999999999, 0.8145062499999999, 0.7737809374999999, 0.7350918906249998, 0.6983372960937497, 0.6634204312890623, 0.6302494097246091, 0.5987369392383786, 0.5688000922764596, 0.5403600876626365, 0.5133420832795047, 0.48767497911552943, 0.46329123015975293, 0.44012666865176525, 0.41812033521917696, 0.3972143184582181, 0.37735360253530714, 0.35848592240854177],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-8',\n      data: [1, 0.92, 0.8464, 0.778688, 0.7163929600000001, 0.6590815232000001, 0.6063550013440001, 0.5578466012364801, 0.5132188731375618, 0.47216136328655683, 0.4343884542236323, 0.3996373778857418, 0.36766638765488246, 0.3382530766424919, 0.31119283051109253, 0.28629740407020515, 0.26339361174458875, 0.24232212280502166, 0.22293635298061995, 0.20510144474217037, 0.18869332916279674],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-10',\n      data: [1, 0.9, 0.81, 0.7290000000000001, 0.6561000000000001, 0.5904900000000002, 0.5314410000000002, 0.47829690000000014, 0.43046721000000016, 0.38742048900000015, 0.34867844010000015, 0.31381059609000017, 0.28242953648100017, 0.25418658283290013, 0.22876792454961012, 0.2058911320946491, 0.1853020188851842, 0.16677181699666577, 0.1500946352969992, 0.13508517176729928, 0.12157665459056936],\n      type: 'line',\n      yAxisIndex: 0\n    }\n  ]\n}\n{% endecharts %}\n\n\n我们可以大致对比几组上面的情况：\n- 不同迭代速度下 10/20 年后的情况\n- 同一迭代速度前 10 年和后 10 年的情况\n- 同一利率下有回撤与无回撤的情况对比\n- 负利率情况下的情况\n\n我们可以看到 5%，10%，15%，20% 迭代速度下\n- 10 年后，分别的总收益是 1.62, 2.59，4.04, 6.19, 可以看出不同迭代速度下，总收益差距还是不少的，但是好像也并没有那么大（从 5% 增长到 10%，增长了没有 1 倍，从 10% 增长到 20% 的情况下，总收益增长了 1 倍多一点）；\n- 20 年后，分别的总收益是 2.65, 6.72, 16.36, 38.33. 拉长时间后，如果迭代速度增加越大，整体收益会越高，而且迭代速度每增长 5%，整体收益增长 2-3 倍的样子。\n\n\n在不同迭代速度下（5%，10%，15%，20%），前 10 年和后 10 年的增长分别如下\n\n| 迭代速度 | 10 年收益| 20 年总收益 |\n| -- | -- | -- |\n| 5% | 1.62 | 2.65 |\n| 10% | 2.59 | 6.72 |\n| 15% | 4.04 | 16.36 |\n| 20% | 6.19 | 38.33 |\n\n可以看出如果迭代速度越大，那么 20 年和 10 年总收益差距越大（但是前 10 年的增长率和后十年的增长率实际是一样的，因为都是 (1 + r) ^ 10), 整体差距来自于基数的差异，由于迭代速度越大，第 10 年的时候整体收益越大，因此第 20 年的时候总收益会越好（基于第 10 年的总收益）\n\n\n接下来对比下，每两年有 2% 回撤的增长情况：增长率分别为 8% 和 15%，然后另外在当前迭代速度下，每 3 年有 2% 的回撤\n- 在第 10 年的时候，8%，8% + 每 3 年回撤 2%，15%， 15% + 每 3年回撤 2% 的总收益分别是：2.15，1.61, 4.04, 2.5 ，可以看到每 3 年回撤 2% 对整体收益影响就挺大：总收益将近少了一半。\n- 第 20 年的时候，8%，8% + 每 3 年回撤 2%，15%， 15% + 每 3年回撤 2% 的总收益分>别是：4.6, 2.6, 16.3, 6.2。可以看出年限越长，有回撤的和无回撤的差距更大。\n\n\n接下来再看看负迭代速度的情况，-2%，-5%，-8%，-10% 迭代速度的情况下\n10 年的情况下，总收益分别为 0.81, 0.59, 0.43, 0.34， 在 20 年的时候总收益分别为 0.66, 0.35, 0.18, 0.12。不管负迭代速度是多少，时间久了之后，整体收益会比较明显，如果迭代速度达到 -10% 的情况下，10 年就已经不剩一半了，20 年就只剩 1 成了。\n\n\n另外由于股市是非固定收益，因此不卖出的情况下，可以不算回撤（但是股价能否涨上去是另外一回事），股市更好的计算比例需要看长期的复合年化收益。如果自己不好计算，可以找一个 App 帮助计算。\n\n# 比较和机会成本\n\n投资中决策是非常重要的一点，决策会涉及到比较，在日常生活中也会经常有比较, 这里主要阐述一些常见的比较情况。\n\n有两个假设前提\n1 同一时刻只能做一件事情\n2 时间是不可逆的，过去了就没有了\n\n比较的时候可能会涉及多个维度，或者对比的维度不统一，而在做决策的时候更好的是能够对一个或多个选项进行同样维度的比较。比如下面的一些比较问题：\n- 投资中，某个投资标的数据发生变化，那么是否实际影响投资决策（比如茅台的预收账款变少）\n- 低价促销的东西，到底要不要买，不买感觉亏了，买好像又不是特别需要\n- 某类投资方式能大概率变富，但是时间比较长，比如 20 年，这种要不要投呢\n\n下面尝试对每一个问题进行详细的阐述\n\n## 投资数据变化的影响\n之前文章中我们说过，买股票就是买公司，那么公司的指标就会影响公司的情况，到底哪些指标的变化，变化成啥样会影响公司呢\n\n这里以一个预收款减少的情况作为例子，比如某公司某年的预售款比之前少了，可能不少人会觉得，这是公司变差的一个信号，甚至说已经不是一个可以继续投资的信号了。\n\n回到投资的本质来说，我们希望将钱放到某些投资标的中，从而获取更好的收益，就像 [股市是一个好的投资渠道吗](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ) 描述的那样。那么我们应该比较的是：1）当前公司因为预收款等实际影响公司的营收；2）其他公司的情况怎么样 -- 因为如果我们不投资到当前公司，就需要投资到其他地方。\n\n然后我们可能发现，大部分公司实际上是没有预收款的，反而是有不少应收账款。那么预收款减少也就是说还有，还有就表示相对下游还有定价权（比较抢手，下游希望通过提前交钱来预订）。那么就要看这个预收款减少是否有影响公司未来的盈利能力。\n\n## 促销商品购买\n商品经常会使用类似降价的方式来进行促销，比如原价 A 售卖的，现在通过降价 30% 售卖，而且降价只有最后 3 天。\n\n那么这种情况下我们的购买策略应该比较的是：[购买] VS [不购买] 是否影响自己的生活情况。而不是 [原价] 和 [降价了 30%] 进行对比。将是否需要和价格情况进行组合将得到如下的情况\n\n|  | 需要 | 不需要 |\n| -- | -- | -- |\n| 原价 | (1) | (2) |\n| 降价 | (3) | (4) | \n\n也就是对应的优先级应该是 (3) > (1) >> (4) > (2)。也就是说在我们应该在需要的情况下再考虑价格，如果不需要的情况下，就算降价购买，那也是一种浪费。\n\n## 长期和短期\n在价值投资中，往往需要比较长时间才能有好的结果，比如 10 年 5 倍，20 年 15 倍（复合年化 15% 已经很不错了），但是可能有人看到后会说，自己希望是短期就能变富，10 年 20 年太久了，另外看上去 10 年 20 年后这个收益好像也不是很高。\n\n这个可以这样比较：[选择这种投资方式，复合年化 15%] VS [其他投资渠道]。然后比较两种投资渠道哪个更能满足自己的需求\n- 投资时间的情况（短期还是长期）\n- 变富\n\n其中短期和长期来说，不同的投资市场会影响投资决策，如果是短期投资，不一定适合投资非固定收益的标的（比如股市），因为股市短期的涨跌太难预测，但是长期来说，股价围绕公司价值波动，那么股价就更好预测一些。\n\n另外变富是人人都想要的，但是具体到投资来说，就会有复合年化收益来衡量。对于不同收益率在不同年限中的总收益情况可以参考前文的情况。然后我们应该考虑的是 [选择该方式] 和 [选择其他方式] 哪个更能够让自己变的更富有，而不是单纯的觉得某个收益率太高或者太低。\n\n## 机会成本\n比较会进一步促进决策（不行动也是一种决策），由于没法同时做两件事，因此部分只能进行假设的比较，因此选择的成本实际是我们选择了 A 之后，剩下的所有选项中最好结果来决定的，这也就是我们的机会成本 -- 因为当前决策导致我们丧失了一次机会。\n\n投资是一个称重游戏，那么我们需要做的是，在较长的时间内，比较多个投资标的，哪个会增长的更多，所有投资的机会成本是自己能获得的稳定收益的最高值，这个对大部分人来说是长期无风险国债，具体的利率可以参考 [股市是一个好的投资渠道吗](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ)。然后对于未来现金流折线来说，折现率我们也可以使用机会成本来进行计算。\n\n# 总结\n本文尝试描述迭代速度/增长比率，比较以及机会成本，这些不仅仅在投资中重要，在平时生活中也有不小影响，有复利的情况下都能套用迭代速度，然后比较和机会成本也会影响我们的每次决策，从而影响我们的生活。\n\n但是需要注意的一点是 决策的质量 和 决策后的结果好坏并不完全相关，它们会有如下四种情况\n\n|  | 好决策 | 差决策 |\n| -- | -- | -- |\n| 好结果 | 1 | 2 |\n| 坏结果 | 3 | 4 |\n\n其中 1 和 4 是我们很容易了解并接受的，但是实际生活中还会有 2 和 3 的存在，如果在对过去决策进行复盘的时候，我们需要考虑到这些情况的存在，另外每次决策的时候也应该记录更多的上下文信息，这样在后续复盘的时候能够知道当时的决策是否好，而不仅仅是通过结果来进行判断。\n","source":"_posts/compare-opportunity-cost-and-ratio.md","raw":"---\ntitle: 比较，机会成本以及迭代速度\ndate: 2025-04-17 16:53:32\ntags:\n    - compare\n    - opportunity-cost\n    - iterative velocity\ntoc: true\n---\n> 本文希望能够通过对一些例子，梳理一些基本/常用的事项。\n\n在 [分红及投资复利-以茅台为例](https://mp.weixin.qq.com/s/7T22TF60g_FQV10xfzZBZw) 一文中主要阐述了投资中复利的力量，从相关数据可以看出，复利能够让我们的得到更好的结果，复利中结果和利率也会相关。\n\n本文尝试对利率(本文中的迭代速度)，比较以及机会成本进行相关阐述，希望能对这些有一个更深的认识。部分想法受《雪球特别版-段永平投资问答录》启发。 \n\n<!-- more -->\n\n# 迭代速度\n\n复利中有两个因为比较重要：时间，和增长率。时间我们在之前的文章中有大致描述。增长率/迭代速度 会在这里进行描述。\n\n迭代速度大致分为三类：负数，零 和正数。其中负数表示往反方向发展，零表示不发展，正数表示往正方向发展。\n\n下面的图形中展示了不同情况下 20 年后的总收益\n- 迭代速度分别是 2%，5%，8%，10%，15%，20%，30%，-2%，-5%，-8%，-10% 的总收益\n- 迭代速度是 8%，15% 的情况下，每过两年会有 -2% 的增长的情况\n\n> 这些数字的选择，大概是，每年 CPI 涨幅 2% 左右，GDP 涨幅 5% 左右，CPI + GDP 大概 8%，具体可以参考 [股市是一个好的投资渠道吗](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ)\n> 时间跨度选择的是 20 年\n\n> 下图中通过点击标题，可以展示/隐藏不同情况下的曲线\n\n{% echarts 85% 400 %}\n{\n  legend: {\n    data: ['2', '5', '8', '8(-2)', '10', '15', '15(-2)', '20', '25', '-2', '-5', '-8', '-10']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n  ],\n  series: [\n    {\n      name: '2',\n      data: [1, 1.02, 1.0404, 1.061208, 1.08243216, 1.1040808032, 1.126162419264, 1.14868566764928, 1.1716593810022657, 1.195092568622311, 1.2189944199947573, 1.2433743083946525, 1.2682417945625455, 1.2936066304537963, 1.3194787630628724, 1.3458683383241299, 1.3727857050906125, 1.4002414191924248, 1.4282462475762734, 1.4568111725277988, 1.485947395978355],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '5',\n      data: [1, 1.05, 1.1025, 1.1576250000000001, 1.2155062500000002, 1.2762815625000004, 1.3400956406250004, 1.4071004226562505, 1.477455443789063, 1.5513282159785162, 1.628894626777442, 1.7103393581163142, 1.79585632602213, 1.8856491423232367, 1.9799315994393987, 2.0789281794113688, 2.1828745883819374, 2.2920183178010345, 2.406619233691086, 2.5269501953756404, 2.6532977051444226],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '8',\n      data: [1, 1.08, 1.1664, 1.2597120000000002, 1.3604889600000003, 1.4693280768000003, 1.5868743229440005, 1.7138242687795207, 1.8509302102818825, 1.9990046271044333, 2.158924997272788, 2.331638997054611, 2.5181701168189803, 2.719623726164499, 2.937193624257659, 3.172169114198272, 3.425942643334134, 3.7000180548008648, 3.9960194991849343, 4.315701059119729, 4.660957143849308],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '8(-2)',\n      data: [1, 1.08, 1.1664, 1.143072, 1.2345177600000001, 1.3332791808000002, 1.306613597184, 1.41114268495872, 1.5240340997554178, 1.4935534177603094, 1.6130376911811342, 1.742080706475625, 1.7072390923461125, 1.8438182197338016, 1.9913236773125058, 1.9514972037662557, 2.107616980067556, 2.2762263384729606, 2.2307018117035016, 2.409157956639782, 2.601890593170965],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '10',\n      data: [1, 1.1, 1.2100000000000002, 1.3310000000000004, 1.4641000000000006, 1.6105100000000008, 1.771561000000001, 1.9487171000000014, 2.1435888100000016, 2.357947691000002, 2.5937424601000023, 2.853116706110003, 3.1384283767210035, 3.4522712143931042, 3.797498335832415, 4.177248169415656, 4.594972986357222, 5.054470284992944, 5.559917313492239, 6.115909044841463, 6.72749994932561],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '15',\n      data: [1, 1.15, 1.3224999999999998, 1.5208749999999995, 1.7490062499999994, 2.0113571874999994, 2.313060765624999, 2.6600198804687487, 3.0590228625390607, 3.5178762919199196, 4.0455577357079076, 4.652391396064093, 5.350250105473707, 6.152787621294762, 7.075705764488976, 8.137061629162321, 9.35762087353667, 10.761264004567169, 12.375453605252243, 14.231771646040078, 16.36653739294609],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '15(-2)',\n      data: [1, 1.15, 1.3224999999999998, 1.2960499999999997, 1.4904574999999995, 1.7140261249999993, 1.6797456024999993, 1.931707442874999, 2.221463559306249, 2.1770342881201237, 2.503589431338142, 2.879127846038863, 2.8215452891180854, 3.244777082485798, 3.7314936448586677, 3.6568637719614943, 4.205393337755718, 4.836202338419076, 4.739478291650695, 5.450400035398299, 6.267960040708043],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '20',\n      data: [1, 1.2, 1.44, 1.728, 2.0736, 2.48832, 2.9859839999999997, 3.5831807999999996, 4.299816959999999, 5.159780351999999, 6.191736422399999, 7.430083706879999, 8.916100448255998, 10.699320537907196, 12.839184645488634, 15.407021574586361, 18.48842588950363, 22.186111067404358, 26.62333328088523, 31.947999937062274, 38.33759992447473],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '25',\n      data: [1, 1.25, 1.5625, 1.953125, 2.44140625, 3.0517578125, 3.814697265625, 4.76837158203125, 5.9604644775390625, 7.450580596923828, 9.313225746154785, 11.641532182693481, 14.551915228366852, 18.189894035458565, 22.737367544323206, 28.421709430404007, 35.52713678800501, 44.40892098500626, 55.51115123125783, 69.38893903907228, 86.73617379884035],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-2',\n      data: [1, 0.98, 0.9603999999999999, 0.9411919999999999, 0.9223681599999999, 0.9039207967999998, 0.8858423808639998, 0.8681255332467198, 0.8507630225817854, 0.8337477621301497, 0.8170728068875467, 0.8007313507497957, 0.7847167237347998, 0.7690223892601038, 0.7536419414749017, 0.7385691026454037, 0.7237977205924956, 0.7093217661806457, 0.6951353308570327, 0.6812326242398921, 0.6676079717550942],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-5',\n      data: [1, 0.95, 0.9025, 0.8573749999999999, 0.8145062499999999, 0.7737809374999999, 0.7350918906249998, 0.6983372960937497, 0.6634204312890623, 0.6302494097246091, 0.5987369392383786, 0.5688000922764596, 0.5403600876626365, 0.5133420832795047, 0.48767497911552943, 0.46329123015975293, 0.44012666865176525, 0.41812033521917696, 0.3972143184582181, 0.37735360253530714, 0.35848592240854177],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-8',\n      data: [1, 0.92, 0.8464, 0.778688, 0.7163929600000001, 0.6590815232000001, 0.6063550013440001, 0.5578466012364801, 0.5132188731375618, 0.47216136328655683, 0.4343884542236323, 0.3996373778857418, 0.36766638765488246, 0.3382530766424919, 0.31119283051109253, 0.28629740407020515, 0.26339361174458875, 0.24232212280502166, 0.22293635298061995, 0.20510144474217037, 0.18869332916279674],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-10',\n      data: [1, 0.9, 0.81, 0.7290000000000001, 0.6561000000000001, 0.5904900000000002, 0.5314410000000002, 0.47829690000000014, 0.43046721000000016, 0.38742048900000015, 0.34867844010000015, 0.31381059609000017, 0.28242953648100017, 0.25418658283290013, 0.22876792454961012, 0.2058911320946491, 0.1853020188851842, 0.16677181699666577, 0.1500946352969992, 0.13508517176729928, 0.12157665459056936],\n      type: 'line',\n      yAxisIndex: 0\n    }\n  ]\n}\n{% endecharts %}\n\n\n我们可以大致对比几组上面的情况：\n- 不同迭代速度下 10/20 年后的情况\n- 同一迭代速度前 10 年和后 10 年的情况\n- 同一利率下有回撤与无回撤的情况对比\n- 负利率情况下的情况\n\n我们可以看到 5%，10%，15%，20% 迭代速度下\n- 10 年后，分别的总收益是 1.62, 2.59，4.04, 6.19, 可以看出不同迭代速度下，总收益差距还是不少的，但是好像也并没有那么大（从 5% 增长到 10%，增长了没有 1 倍，从 10% 增长到 20% 的情况下，总收益增长了 1 倍多一点）；\n- 20 年后，分别的总收益是 2.65, 6.72, 16.36, 38.33. 拉长时间后，如果迭代速度增加越大，整体收益会越高，而且迭代速度每增长 5%，整体收益增长 2-3 倍的样子。\n\n\n在不同迭代速度下（5%，10%，15%，20%），前 10 年和后 10 年的增长分别如下\n\n| 迭代速度 | 10 年收益| 20 年总收益 |\n| -- | -- | -- |\n| 5% | 1.62 | 2.65 |\n| 10% | 2.59 | 6.72 |\n| 15% | 4.04 | 16.36 |\n| 20% | 6.19 | 38.33 |\n\n可以看出如果迭代速度越大，那么 20 年和 10 年总收益差距越大（但是前 10 年的增长率和后十年的增长率实际是一样的，因为都是 (1 + r) ^ 10), 整体差距来自于基数的差异，由于迭代速度越大，第 10 年的时候整体收益越大，因此第 20 年的时候总收益会越好（基于第 10 年的总收益）\n\n\n接下来对比下，每两年有 2% 回撤的增长情况：增长率分别为 8% 和 15%，然后另外在当前迭代速度下，每 3 年有 2% 的回撤\n- 在第 10 年的时候，8%，8% + 每 3 年回撤 2%，15%， 15% + 每 3年回撤 2% 的总收益分别是：2.15，1.61, 4.04, 2.5 ，可以看到每 3 年回撤 2% 对整体收益影响就挺大：总收益将近少了一半。\n- 第 20 年的时候，8%，8% + 每 3 年回撤 2%，15%， 15% + 每 3年回撤 2% 的总收益分>别是：4.6, 2.6, 16.3, 6.2。可以看出年限越长，有回撤的和无回撤的差距更大。\n\n\n接下来再看看负迭代速度的情况，-2%，-5%，-8%，-10% 迭代速度的情况下\n10 年的情况下，总收益分别为 0.81, 0.59, 0.43, 0.34， 在 20 年的时候总收益分别为 0.66, 0.35, 0.18, 0.12。不管负迭代速度是多少，时间久了之后，整体收益会比较明显，如果迭代速度达到 -10% 的情况下，10 年就已经不剩一半了，20 年就只剩 1 成了。\n\n\n另外由于股市是非固定收益，因此不卖出的情况下，可以不算回撤（但是股价能否涨上去是另外一回事），股市更好的计算比例需要看长期的复合年化收益。如果自己不好计算，可以找一个 App 帮助计算。\n\n# 比较和机会成本\n\n投资中决策是非常重要的一点，决策会涉及到比较，在日常生活中也会经常有比较, 这里主要阐述一些常见的比较情况。\n\n有两个假设前提\n1 同一时刻只能做一件事情\n2 时间是不可逆的，过去了就没有了\n\n比较的时候可能会涉及多个维度，或者对比的维度不统一，而在做决策的时候更好的是能够对一个或多个选项进行同样维度的比较。比如下面的一些比较问题：\n- 投资中，某个投资标的数据发生变化，那么是否实际影响投资决策（比如茅台的预收账款变少）\n- 低价促销的东西，到底要不要买，不买感觉亏了，买好像又不是特别需要\n- 某类投资方式能大概率变富，但是时间比较长，比如 20 年，这种要不要投呢\n\n下面尝试对每一个问题进行详细的阐述\n\n## 投资数据变化的影响\n之前文章中我们说过，买股票就是买公司，那么公司的指标就会影响公司的情况，到底哪些指标的变化，变化成啥样会影响公司呢\n\n这里以一个预收款减少的情况作为例子，比如某公司某年的预售款比之前少了，可能不少人会觉得，这是公司变差的一个信号，甚至说已经不是一个可以继续投资的信号了。\n\n回到投资的本质来说，我们希望将钱放到某些投资标的中，从而获取更好的收益，就像 [股市是一个好的投资渠道吗](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ) 描述的那样。那么我们应该比较的是：1）当前公司因为预收款等实际影响公司的营收；2）其他公司的情况怎么样 -- 因为如果我们不投资到当前公司，就需要投资到其他地方。\n\n然后我们可能发现，大部分公司实际上是没有预收款的，反而是有不少应收账款。那么预收款减少也就是说还有，还有就表示相对下游还有定价权（比较抢手，下游希望通过提前交钱来预订）。那么就要看这个预收款减少是否有影响公司未来的盈利能力。\n\n## 促销商品购买\n商品经常会使用类似降价的方式来进行促销，比如原价 A 售卖的，现在通过降价 30% 售卖，而且降价只有最后 3 天。\n\n那么这种情况下我们的购买策略应该比较的是：[购买] VS [不购买] 是否影响自己的生活情况。而不是 [原价] 和 [降价了 30%] 进行对比。将是否需要和价格情况进行组合将得到如下的情况\n\n|  | 需要 | 不需要 |\n| -- | -- | -- |\n| 原价 | (1) | (2) |\n| 降价 | (3) | (4) | \n\n也就是对应的优先级应该是 (3) > (1) >> (4) > (2)。也就是说在我们应该在需要的情况下再考虑价格，如果不需要的情况下，就算降价购买，那也是一种浪费。\n\n## 长期和短期\n在价值投资中，往往需要比较长时间才能有好的结果，比如 10 年 5 倍，20 年 15 倍（复合年化 15% 已经很不错了），但是可能有人看到后会说，自己希望是短期就能变富，10 年 20 年太久了，另外看上去 10 年 20 年后这个收益好像也不是很高。\n\n这个可以这样比较：[选择这种投资方式，复合年化 15%] VS [其他投资渠道]。然后比较两种投资渠道哪个更能满足自己的需求\n- 投资时间的情况（短期还是长期）\n- 变富\n\n其中短期和长期来说，不同的投资市场会影响投资决策，如果是短期投资，不一定适合投资非固定收益的标的（比如股市），因为股市短期的涨跌太难预测，但是长期来说，股价围绕公司价值波动，那么股价就更好预测一些。\n\n另外变富是人人都想要的，但是具体到投资来说，就会有复合年化收益来衡量。对于不同收益率在不同年限中的总收益情况可以参考前文的情况。然后我们应该考虑的是 [选择该方式] 和 [选择其他方式] 哪个更能够让自己变的更富有，而不是单纯的觉得某个收益率太高或者太低。\n\n## 机会成本\n比较会进一步促进决策（不行动也是一种决策），由于没法同时做两件事，因此部分只能进行假设的比较，因此选择的成本实际是我们选择了 A 之后，剩下的所有选项中最好结果来决定的，这也就是我们的机会成本 -- 因为当前决策导致我们丧失了一次机会。\n\n投资是一个称重游戏，那么我们需要做的是，在较长的时间内，比较多个投资标的，哪个会增长的更多，所有投资的机会成本是自己能获得的稳定收益的最高值，这个对大部分人来说是长期无风险国债，具体的利率可以参考 [股市是一个好的投资渠道吗](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ)。然后对于未来现金流折线来说，折现率我们也可以使用机会成本来进行计算。\n\n# 总结\n本文尝试描述迭代速度/增长比率，比较以及机会成本，这些不仅仅在投资中重要，在平时生活中也有不小影响，有复利的情况下都能套用迭代速度，然后比较和机会成本也会影响我们的每次决策，从而影响我们的生活。\n\n但是需要注意的一点是 决策的质量 和 决策后的结果好坏并不完全相关，它们会有如下四种情况\n\n|  | 好决策 | 差决策 |\n| -- | -- | -- |\n| 好结果 | 1 | 2 |\n| 坏结果 | 3 | 4 |\n\n其中 1 和 4 是我们很容易了解并接受的，但是实际生活中还会有 2 和 3 的存在，如果在对过去决策进行复盘的时候，我们需要考虑到这些情况的存在，另外每次决策的时候也应该记录更多的上下文信息，这样在后续复盘的时候能够知道当时的决策是否好，而不仅仅是通过结果来进行判断。\n","slug":"compare-opportunity-cost-and-ratio","published":1,"updated":"2025-04-19T14:39:45.796Z","_id":"cm9oaybst001j2umkhf4721ax","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>本文希望能够通过对一些例子，梳理一些基本/常用的事项。</p>\n</blockquote>\n<p>在 <a href=\"https://mp.weixin.qq.com/s/7T22TF60g_FQV10xfzZBZw\">分红及投资复利-以茅台为例</a> 一文中主要阐述了投资中复利的力量，从相关数据可以看出，复利能够让我们的得到更好的结果，复利中结果和利率也会相关。</p>\n<p>本文尝试对利率(本文中的迭代速度)，比较以及机会成本进行相关阐述，希望能对这些有一个更深的认识。部分想法受《雪球特别版-段永平投资问答录》启发。 </p>\n<span id=\"more\"></span>\n<h1 id=\"迭代速度\"><a href=\"#迭代速度\" class=\"headerlink\" title=\"迭代速度\"></a>迭代速度</h1><p>复利中有两个因为比较重要：时间，和增长率。时间我们在之前的文章中有大致描述。增长率/迭代速度 会在这里进行描述。</p>\n<p>迭代速度大致分为三类：负数，零 和正数。其中负数表示往反方向发展，零表示不发展，正数表示往正方向发展。</p>\n<p>下面的图形中展示了不同情况下 20 年后的总收益</p>\n<ul>\n<li>迭代速度分别是 2%，5%，8%，10%，15%，20%，30%，-2%，-5%，-8%，-10% 的总收益</li>\n<li>迭代速度是 8%，15% 的情况下，每过两年会有 -2% 的增长的情况</li>\n</ul>\n<blockquote>\n<p>这些数字的选择，大概是，每年 CPI 涨幅 2% 左右，GDP 涨幅 5% 左右，CPI + GDP 大概 8%，具体可以参考 <a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">股市是一个好的投资渠道吗</a><br>时间跨度选择的是 20 年</p>\n<p>下图中通过点击标题，可以展示/隐藏不同情况下的曲线</p>\n</blockquote>\n\n<div id=\"echarts4680\" style=\"width: 85%;height:400px;margin: 0 auto\"></div>\n<script src=\"https://unpkg.com/echarts@5.6.0/dist/echarts.min.js\" ></script>\n<script >\n  if (window.eChartecharts4680ResizeHandler) {\n    window.removeEventListener(\"resize\", eChartecharts4680ResizeHandler);\n  }\n  var optionecharts4680 = {\n  legend: {\n    data: ['2', '5', '8', '8(-2)', '10', '15', '15(-2)', '20', '25', '-2', '-5', '-8', '-10']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n  ],\n  series: [\n    {\n      name: '2',\n      data: [1, 1.02, 1.0404, 1.061208, 1.08243216, 1.1040808032, 1.126162419264, 1.14868566764928, 1.1716593810022657, 1.195092568622311, 1.2189944199947573, 1.2433743083946525, 1.2682417945625455, 1.2936066304537963, 1.3194787630628724, 1.3458683383241299, 1.3727857050906125, 1.4002414191924248, 1.4282462475762734, 1.4568111725277988, 1.485947395978355],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '5',\n      data: [1, 1.05, 1.1025, 1.1576250000000001, 1.2155062500000002, 1.2762815625000004, 1.3400956406250004, 1.4071004226562505, 1.477455443789063, 1.5513282159785162, 1.628894626777442, 1.7103393581163142, 1.79585632602213, 1.8856491423232367, 1.9799315994393987, 2.0789281794113688, 2.1828745883819374, 2.2920183178010345, 2.406619233691086, 2.5269501953756404, 2.6532977051444226],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '8',\n      data: [1, 1.08, 1.1664, 1.2597120000000002, 1.3604889600000003, 1.4693280768000003, 1.5868743229440005, 1.7138242687795207, 1.8509302102818825, 1.9990046271044333, 2.158924997272788, 2.331638997054611, 2.5181701168189803, 2.719623726164499, 2.937193624257659, 3.172169114198272, 3.425942643334134, 3.7000180548008648, 3.9960194991849343, 4.315701059119729, 4.660957143849308],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '8(-2)',\n      data: [1, 1.08, 1.1664, 1.143072, 1.2345177600000001, 1.3332791808000002, 1.306613597184, 1.41114268495872, 1.5240340997554178, 1.4935534177603094, 1.6130376911811342, 1.742080706475625, 1.7072390923461125, 1.8438182197338016, 1.9913236773125058, 1.9514972037662557, 2.107616980067556, 2.2762263384729606, 2.2307018117035016, 2.409157956639782, 2.601890593170965],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '10',\n      data: [1, 1.1, 1.2100000000000002, 1.3310000000000004, 1.4641000000000006, 1.6105100000000008, 1.771561000000001, 1.9487171000000014, 2.1435888100000016, 2.357947691000002, 2.5937424601000023, 2.853116706110003, 3.1384283767210035, 3.4522712143931042, 3.797498335832415, 4.177248169415656, 4.594972986357222, 5.054470284992944, 5.559917313492239, 6.115909044841463, 6.72749994932561],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '15',\n      data: [1, 1.15, 1.3224999999999998, 1.5208749999999995, 1.7490062499999994, 2.0113571874999994, 2.313060765624999, 2.6600198804687487, 3.0590228625390607, 3.5178762919199196, 4.0455577357079076, 4.652391396064093, 5.350250105473707, 6.152787621294762, 7.075705764488976, 8.137061629162321, 9.35762087353667, 10.761264004567169, 12.375453605252243, 14.231771646040078, 16.36653739294609],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '15(-2)',\n      data: [1, 1.15, 1.3224999999999998, 1.2960499999999997, 1.4904574999999995, 1.7140261249999993, 1.6797456024999993, 1.931707442874999, 2.221463559306249, 2.1770342881201237, 2.503589431338142, 2.879127846038863, 2.8215452891180854, 3.244777082485798, 3.7314936448586677, 3.6568637719614943, 4.205393337755718, 4.836202338419076, 4.739478291650695, 5.450400035398299, 6.267960040708043],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '20',\n      data: [1, 1.2, 1.44, 1.728, 2.0736, 2.48832, 2.9859839999999997, 3.5831807999999996, 4.299816959999999, 5.159780351999999, 6.191736422399999, 7.430083706879999, 8.916100448255998, 10.699320537907196, 12.839184645488634, 15.407021574586361, 18.48842588950363, 22.186111067404358, 26.62333328088523, 31.947999937062274, 38.33759992447473],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '25',\n      data: [1, 1.25, 1.5625, 1.953125, 2.44140625, 3.0517578125, 3.814697265625, 4.76837158203125, 5.9604644775390625, 7.450580596923828, 9.313225746154785, 11.641532182693481, 14.551915228366852, 18.189894035458565, 22.737367544323206, 28.421709430404007, 35.52713678800501, 44.40892098500626, 55.51115123125783, 69.38893903907228, 86.73617379884035],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-2',\n      data: [1, 0.98, 0.9603999999999999, 0.9411919999999999, 0.9223681599999999, 0.9039207967999998, 0.8858423808639998, 0.8681255332467198, 0.8507630225817854, 0.8337477621301497, 0.8170728068875467, 0.8007313507497957, 0.7847167237347998, 0.7690223892601038, 0.7536419414749017, 0.7385691026454037, 0.7237977205924956, 0.7093217661806457, 0.6951353308570327, 0.6812326242398921, 0.6676079717550942],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-5',\n      data: [1, 0.95, 0.9025, 0.8573749999999999, 0.8145062499999999, 0.7737809374999999, 0.7350918906249998, 0.6983372960937497, 0.6634204312890623, 0.6302494097246091, 0.5987369392383786, 0.5688000922764596, 0.5403600876626365, 0.5133420832795047, 0.48767497911552943, 0.46329123015975293, 0.44012666865176525, 0.41812033521917696, 0.3972143184582181, 0.37735360253530714, 0.35848592240854177],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-8',\n      data: [1, 0.92, 0.8464, 0.778688, 0.7163929600000001, 0.6590815232000001, 0.6063550013440001, 0.5578466012364801, 0.5132188731375618, 0.47216136328655683, 0.4343884542236323, 0.3996373778857418, 0.36766638765488246, 0.3382530766424919, 0.31119283051109253, 0.28629740407020515, 0.26339361174458875, 0.24232212280502166, 0.22293635298061995, 0.20510144474217037, 0.18869332916279674],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-10',\n      data: [1, 0.9, 0.81, 0.7290000000000001, 0.6561000000000001, 0.5904900000000002, 0.5314410000000002, 0.47829690000000014, 0.43046721000000016, 0.38742048900000015, 0.34867844010000015, 0.31381059609000017, 0.28242953648100017, 0.25418658283290013, 0.22876792454961012, 0.2058911320946491, 0.1853020188851842, 0.16677181699666577, 0.1500946352969992, 0.13508517176729928, 0.12157665459056936],\n      type: 'line',\n      yAxisIndex: 0\n    }\n  ]\n};\n  if (window.echarts !== undefined) {\n    var eChartecharts4680 = echarts.init(document.getElementById('echarts4680'));\n    eChartecharts4680.setOption(optionecharts4680);\n    var eChartecharts4680ResizeHandler = function() {\n      eChartecharts4680.resize();\n    };\n    window.addEventListener(\"resize\", eChartecharts4680ResizeHandler);\n  }\n</script>\n<p>我们可以大致对比几组上面的情况：</p>\n<ul>\n<li>不同迭代速度下 10/20 年后的情况</li>\n<li>同一迭代速度前 10 年和后 10 年的情况</li>\n<li>同一利率下有回撤与无回撤的情况对比</li>\n<li>负利率情况下的情况</li>\n</ul>\n<p>我们可以看到 5%，10%，15%，20% 迭代速度下</p>\n<ul>\n<li>10 年后，分别的总收益是 1.62, 2.59，4.04, 6.19, 可以看出不同迭代速度下，总收益差距还是不少的，但是好像也并没有那么大（从 5% 增长到 10%，增长了没有 1 倍，从 10% 增长到 20% 的情况下，总收益增长了 1 倍多一点）；</li>\n<li>20 年后，分别的总收益是 2.65, 6.72, 16.36, 38.33. 拉长时间后，如果迭代速度增加越大，整体收益会越高，而且迭代速度每增长 5%，整体收益增长 2-3 倍的样子。</li>\n</ul>\n<p>在不同迭代速度下（5%，10%，15%，20%），前 10 年和后 10 年的增长分别如下</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>迭代速度</th>\n<th>10 年收益</th>\n<th>20 年总收益</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>5%</td>\n<td>1.62</td>\n<td>2.65</td>\n</tr>\n<tr>\n<td>10%</td>\n<td>2.59</td>\n<td>6.72</td>\n</tr>\n<tr>\n<td>15%</td>\n<td>4.04</td>\n<td>16.36</td>\n</tr>\n<tr>\n<td>20%</td>\n<td>6.19</td>\n<td>38.33</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看出如果迭代速度越大，那么 20 年和 10 年总收益差距越大（但是前 10 年的增长率和后十年的增长率实际是一样的，因为都是 (1 + r) ^ 10), 整体差距来自于基数的差异，由于迭代速度越大，第 10 年的时候整体收益越大，因此第 20 年的时候总收益会越好（基于第 10 年的总收益）</p>\n<p>接下来对比下，每两年有 2% 回撤的增长情况：增长率分别为 8% 和 15%，然后另外在当前迭代速度下，每 3 年有 2% 的回撤</p>\n<ul>\n<li>在第 10 年的时候，8%，8% + 每 3 年回撤 2%，15%， 15% + 每 3年回撤 2% 的总收益分别是：2.15，1.61, 4.04, 2.5 ，可以看到每 3 年回撤 2% 对整体收益影响就挺大：总收益将近少了一半。</li>\n<li>第 20 年的时候，8%，8% + 每 3 年回撤 2%，15%， 15% + 每 3年回撤 2% 的总收益分&gt;别是：4.6, 2.6, 16.3, 6.2。可以看出年限越长，有回撤的和无回撤的差距更大。</li>\n</ul>\n<p>接下来再看看负迭代速度的情况，-2%，-5%，-8%，-10% 迭代速度的情况下<br>10 年的情况下，总收益分别为 0.81, 0.59, 0.43, 0.34， 在 20 年的时候总收益分别为 0.66, 0.35, 0.18, 0.12。不管负迭代速度是多少，时间久了之后，整体收益会比较明显，如果迭代速度达到 -10% 的情况下，10 年就已经不剩一半了，20 年就只剩 1 成了。</p>\n<p>另外由于股市是非固定收益，因此不卖出的情况下，可以不算回撤（但是股价能否涨上去是另外一回事），股市更好的计算比例需要看长期的复合年化收益。如果自己不好计算，可以找一个 App 帮助计算。</p>\n<h1 id=\"比较和机会成本\"><a href=\"#比较和机会成本\" class=\"headerlink\" title=\"比较和机会成本\"></a>比较和机会成本</h1><p>投资中决策是非常重要的一点，决策会涉及到比较，在日常生活中也会经常有比较, 这里主要阐述一些常见的比较情况。</p>\n<p>有两个假设前提<br>1 同一时刻只能做一件事情<br>2 时间是不可逆的，过去了就没有了</p>\n<p>比较的时候可能会涉及多个维度，或者对比的维度不统一，而在做决策的时候更好的是能够对一个或多个选项进行同样维度的比较。比如下面的一些比较问题：</p>\n<ul>\n<li>投资中，某个投资标的数据发生变化，那么是否实际影响投资决策（比如茅台的预收账款变少）</li>\n<li>低价促销的东西，到底要不要买，不买感觉亏了，买好像又不是特别需要</li>\n<li>某类投资方式能大概率变富，但是时间比较长，比如 20 年，这种要不要投呢</li>\n</ul>\n<p>下面尝试对每一个问题进行详细的阐述</p>\n<h2 id=\"投资数据变化的影响\"><a href=\"#投资数据变化的影响\" class=\"headerlink\" title=\"投资数据变化的影响\"></a>投资数据变化的影响</h2><p>之前文章中我们说过，买股票就是买公司，那么公司的指标就会影响公司的情况，到底哪些指标的变化，变化成啥样会影响公司呢</p>\n<p>这里以一个预收款减少的情况作为例子，比如某公司某年的预售款比之前少了，可能不少人会觉得，这是公司变差的一个信号，甚至说已经不是一个可以继续投资的信号了。</p>\n<p>回到投资的本质来说，我们希望将钱放到某些投资标的中，从而获取更好的收益，就像 <a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">股市是一个好的投资渠道吗</a> 描述的那样。那么我们应该比较的是：1）当前公司因为预收款等实际影响公司的营收；2）其他公司的情况怎么样 — 因为如果我们不投资到当前公司，就需要投资到其他地方。</p>\n<p>然后我们可能发现，大部分公司实际上是没有预收款的，反而是有不少应收账款。那么预收款减少也就是说还有，还有就表示相对下游还有定价权（比较抢手，下游希望通过提前交钱来预订）。那么就要看这个预收款减少是否有影响公司未来的盈利能力。</p>\n<h2 id=\"促销商品购买\"><a href=\"#促销商品购买\" class=\"headerlink\" title=\"促销商品购买\"></a>促销商品购买</h2><p>商品经常会使用类似降价的方式来进行促销，比如原价 A 售卖的，现在通过降价 30% 售卖，而且降价只有最后 3 天。</p>\n<p>那么这种情况下我们的购买策略应该比较的是：[购买] VS [不购买] 是否影响自己的生活情况。而不是 [原价] 和 [降价了 30%] 进行对比。将是否需要和价格情况进行组合将得到如下的情况</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>需要</th>\n<th>不需要</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>原价</td>\n<td>(1)</td>\n<td>(2)</td>\n</tr>\n<tr>\n<td>降价</td>\n<td>(3)</td>\n<td>(4)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>也就是对应的优先级应该是 (3) &gt; (1) &gt;&gt; (4) &gt; (2)。也就是说在我们应该在需要的情况下再考虑价格，如果不需要的情况下，就算降价购买，那也是一种浪费。</p>\n<h2 id=\"长期和短期\"><a href=\"#长期和短期\" class=\"headerlink\" title=\"长期和短期\"></a>长期和短期</h2><p>在价值投资中，往往需要比较长时间才能有好的结果，比如 10 年 5 倍，20 年 15 倍（复合年化 15% 已经很不错了），但是可能有人看到后会说，自己希望是短期就能变富，10 年 20 年太久了，另外看上去 10 年 20 年后这个收益好像也不是很高。</p>\n<p>这个可以这样比较：[选择这种投资方式，复合年化 15%] VS [其他投资渠道]。然后比较两种投资渠道哪个更能满足自己的需求</p>\n<ul>\n<li>投资时间的情况（短期还是长期）</li>\n<li>变富</li>\n</ul>\n<p>其中短期和长期来说，不同的投资市场会影响投资决策，如果是短期投资，不一定适合投资非固定收益的标的（比如股市），因为股市短期的涨跌太难预测，但是长期来说，股价围绕公司价值波动，那么股价就更好预测一些。</p>\n<p>另外变富是人人都想要的，但是具体到投资来说，就会有复合年化收益来衡量。对于不同收益率在不同年限中的总收益情况可以参考前文的情况。然后我们应该考虑的是 [选择该方式] 和 [选择其他方式] 哪个更能够让自己变的更富有，而不是单纯的觉得某个收益率太高或者太低。</p>\n<h2 id=\"机会成本\"><a href=\"#机会成本\" class=\"headerlink\" title=\"机会成本\"></a>机会成本</h2><p>比较会进一步促进决策（不行动也是一种决策），由于没法同时做两件事，因此部分只能进行假设的比较，因此选择的成本实际是我们选择了 A 之后，剩下的所有选项中最好结果来决定的，这也就是我们的机会成本 — 因为当前决策导致我们丧失了一次机会。</p>\n<p>投资是一个称重游戏，那么我们需要做的是，在较长的时间内，比较多个投资标的，哪个会增长的更多，所有投资的机会成本是自己能获得的稳定收益的最高值，这个对大部分人来说是长期无风险国债，具体的利率可以参考 <a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">股市是一个好的投资渠道吗</a>。然后对于未来现金流折线来说，折现率我们也可以使用机会成本来进行计算。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>本文尝试描述迭代速度/增长比率，比较以及机会成本，这些不仅仅在投资中重要，在平时生活中也有不小影响，有复利的情况下都能套用迭代速度，然后比较和机会成本也会影响我们的每次决策，从而影响我们的生活。</p>\n<p>但是需要注意的一点是 决策的质量 和 决策后的结果好坏并不完全相关，它们会有如下四种情况</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>好决策</th>\n<th>差决策</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>好结果</td>\n<td>1</td>\n<td>2</td>\n</tr>\n<tr>\n<td>坏结果</td>\n<td>3</td>\n<td>4</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>其中 1 和 4 是我们很容易了解并接受的，但是实际生活中还会有 2 和 3 的存在，如果在对过去决策进行复盘的时候，我们需要考虑到这些情况的存在，另外每次决策的时候也应该记录更多的上下文信息，这样在后续复盘的时候能够知道当时的决策是否好，而不仅仅是通过结果来进行判断。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文希望能够通过对一些例子，梳理一些基本/常用的事项。</p>\n</blockquote>\n<p>在 <a href=\"https://mp.weixin.qq.com/s/7T22TF60g_FQV10xfzZBZw\">分红及投资复利-以茅台为例</a> 一文中主要阐述了投资中复利的力量，从相关数据可以看出，复利能够让我们的得到更好的结果，复利中结果和利率也会相关。</p>\n<p>本文尝试对利率(本文中的迭代速度)，比较以及机会成本进行相关阐述，希望能对这些有一个更深的认识。部分想法受《雪球特别版-段永平投资问答录》启发。 </p>","more":"<h1 id=\"迭代速度\"><a href=\"#迭代速度\" class=\"headerlink\" title=\"迭代速度\"></a>迭代速度</h1><p>复利中有两个因为比较重要：时间，和增长率。时间我们在之前的文章中有大致描述。增长率/迭代速度 会在这里进行描述。</p>\n<p>迭代速度大致分为三类：负数，零 和正数。其中负数表示往反方向发展，零表示不发展，正数表示往正方向发展。</p>\n<p>下面的图形中展示了不同情况下 20 年后的总收益</p>\n<ul>\n<li>迭代速度分别是 2%，5%，8%，10%，15%，20%，30%，-2%，-5%，-8%，-10% 的总收益</li>\n<li>迭代速度是 8%，15% 的情况下，每过两年会有 -2% 的增长的情况</li>\n</ul>\n<blockquote>\n<p>这些数字的选择，大概是，每年 CPI 涨幅 2% 左右，GDP 涨幅 5% 左右，CPI + GDP 大概 8%，具体可以参考 <a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">股市是一个好的投资渠道吗</a><br>时间跨度选择的是 20 年</p>\n<p>下图中通过点击标题，可以展示/隐藏不同情况下的曲线</p>\n</blockquote>\n\n<div id=\"echarts4680\" style=\"width: 85%;height:400px;margin: 0 auto\"></div>\n<script src=\"https://unpkg.com/echarts@5.6.0/dist/echarts.min.js\" ></script>\n<script >\n  if (window.eChartecharts4680ResizeHandler) {\n    window.removeEventListener(\"resize\", eChartecharts4680ResizeHandler);\n  }\n  var optionecharts4680 = {\n  legend: {\n    data: ['2', '5', '8', '8(-2)', '10', '15', '15(-2)', '20', '25', '-2', '-5', '-8', '-10']\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  xAxis: {\n    type: 'category',\n    data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n  },\n  yAxis: [\n    {\n      name: 'total-value',\n      type: 'value'\n    },\n  ],\n  series: [\n    {\n      name: '2',\n      data: [1, 1.02, 1.0404, 1.061208, 1.08243216, 1.1040808032, 1.126162419264, 1.14868566764928, 1.1716593810022657, 1.195092568622311, 1.2189944199947573, 1.2433743083946525, 1.2682417945625455, 1.2936066304537963, 1.3194787630628724, 1.3458683383241299, 1.3727857050906125, 1.4002414191924248, 1.4282462475762734, 1.4568111725277988, 1.485947395978355],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '5',\n      data: [1, 1.05, 1.1025, 1.1576250000000001, 1.2155062500000002, 1.2762815625000004, 1.3400956406250004, 1.4071004226562505, 1.477455443789063, 1.5513282159785162, 1.628894626777442, 1.7103393581163142, 1.79585632602213, 1.8856491423232367, 1.9799315994393987, 2.0789281794113688, 2.1828745883819374, 2.2920183178010345, 2.406619233691086, 2.5269501953756404, 2.6532977051444226],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '8',\n      data: [1, 1.08, 1.1664, 1.2597120000000002, 1.3604889600000003, 1.4693280768000003, 1.5868743229440005, 1.7138242687795207, 1.8509302102818825, 1.9990046271044333, 2.158924997272788, 2.331638997054611, 2.5181701168189803, 2.719623726164499, 2.937193624257659, 3.172169114198272, 3.425942643334134, 3.7000180548008648, 3.9960194991849343, 4.315701059119729, 4.660957143849308],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '8(-2)',\n      data: [1, 1.08, 1.1664, 1.143072, 1.2345177600000001, 1.3332791808000002, 1.306613597184, 1.41114268495872, 1.5240340997554178, 1.4935534177603094, 1.6130376911811342, 1.742080706475625, 1.7072390923461125, 1.8438182197338016, 1.9913236773125058, 1.9514972037662557, 2.107616980067556, 2.2762263384729606, 2.2307018117035016, 2.409157956639782, 2.601890593170965],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '10',\n      data: [1, 1.1, 1.2100000000000002, 1.3310000000000004, 1.4641000000000006, 1.6105100000000008, 1.771561000000001, 1.9487171000000014, 2.1435888100000016, 2.357947691000002, 2.5937424601000023, 2.853116706110003, 3.1384283767210035, 3.4522712143931042, 3.797498335832415, 4.177248169415656, 4.594972986357222, 5.054470284992944, 5.559917313492239, 6.115909044841463, 6.72749994932561],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '15',\n      data: [1, 1.15, 1.3224999999999998, 1.5208749999999995, 1.7490062499999994, 2.0113571874999994, 2.313060765624999, 2.6600198804687487, 3.0590228625390607, 3.5178762919199196, 4.0455577357079076, 4.652391396064093, 5.350250105473707, 6.152787621294762, 7.075705764488976, 8.137061629162321, 9.35762087353667, 10.761264004567169, 12.375453605252243, 14.231771646040078, 16.36653739294609],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '15(-2)',\n      data: [1, 1.15, 1.3224999999999998, 1.2960499999999997, 1.4904574999999995, 1.7140261249999993, 1.6797456024999993, 1.931707442874999, 2.221463559306249, 2.1770342881201237, 2.503589431338142, 2.879127846038863, 2.8215452891180854, 3.244777082485798, 3.7314936448586677, 3.6568637719614943, 4.205393337755718, 4.836202338419076, 4.739478291650695, 5.450400035398299, 6.267960040708043],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '20',\n      data: [1, 1.2, 1.44, 1.728, 2.0736, 2.48832, 2.9859839999999997, 3.5831807999999996, 4.299816959999999, 5.159780351999999, 6.191736422399999, 7.430083706879999, 8.916100448255998, 10.699320537907196, 12.839184645488634, 15.407021574586361, 18.48842588950363, 22.186111067404358, 26.62333328088523, 31.947999937062274, 38.33759992447473],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '25',\n      data: [1, 1.25, 1.5625, 1.953125, 2.44140625, 3.0517578125, 3.814697265625, 4.76837158203125, 5.9604644775390625, 7.450580596923828, 9.313225746154785, 11.641532182693481, 14.551915228366852, 18.189894035458565, 22.737367544323206, 28.421709430404007, 35.52713678800501, 44.40892098500626, 55.51115123125783, 69.38893903907228, 86.73617379884035],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-2',\n      data: [1, 0.98, 0.9603999999999999, 0.9411919999999999, 0.9223681599999999, 0.9039207967999998, 0.8858423808639998, 0.8681255332467198, 0.8507630225817854, 0.8337477621301497, 0.8170728068875467, 0.8007313507497957, 0.7847167237347998, 0.7690223892601038, 0.7536419414749017, 0.7385691026454037, 0.7237977205924956, 0.7093217661806457, 0.6951353308570327, 0.6812326242398921, 0.6676079717550942],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-5',\n      data: [1, 0.95, 0.9025, 0.8573749999999999, 0.8145062499999999, 0.7737809374999999, 0.7350918906249998, 0.6983372960937497, 0.6634204312890623, 0.6302494097246091, 0.5987369392383786, 0.5688000922764596, 0.5403600876626365, 0.5133420832795047, 0.48767497911552943, 0.46329123015975293, 0.44012666865176525, 0.41812033521917696, 0.3972143184582181, 0.37735360253530714, 0.35848592240854177],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-8',\n      data: [1, 0.92, 0.8464, 0.778688, 0.7163929600000001, 0.6590815232000001, 0.6063550013440001, 0.5578466012364801, 0.5132188731375618, 0.47216136328655683, 0.4343884542236323, 0.3996373778857418, 0.36766638765488246, 0.3382530766424919, 0.31119283051109253, 0.28629740407020515, 0.26339361174458875, 0.24232212280502166, 0.22293635298061995, 0.20510144474217037, 0.18869332916279674],\n      type: 'line',\n      yAxisIndex: 0\n    },\n    {\n      name: '-10',\n      data: [1, 0.9, 0.81, 0.7290000000000001, 0.6561000000000001, 0.5904900000000002, 0.5314410000000002, 0.47829690000000014, 0.43046721000000016, 0.38742048900000015, 0.34867844010000015, 0.31381059609000017, 0.28242953648100017, 0.25418658283290013, 0.22876792454961012, 0.2058911320946491, 0.1853020188851842, 0.16677181699666577, 0.1500946352969992, 0.13508517176729928, 0.12157665459056936],\n      type: 'line',\n      yAxisIndex: 0\n    }\n  ]\n};\n  if (window.echarts !== undefined) {\n    var eChartecharts4680 = echarts.init(document.getElementById('echarts4680'));\n    eChartecharts4680.setOption(optionecharts4680);\n    var eChartecharts4680ResizeHandler = function() {\n      eChartecharts4680.resize();\n    };\n    window.addEventListener(\"resize\", eChartecharts4680ResizeHandler);\n  }\n</script>\n<p>我们可以大致对比几组上面的情况：</p>\n<ul>\n<li>不同迭代速度下 10/20 年后的情况</li>\n<li>同一迭代速度前 10 年和后 10 年的情况</li>\n<li>同一利率下有回撤与无回撤的情况对比</li>\n<li>负利率情况下的情况</li>\n</ul>\n<p>我们可以看到 5%，10%，15%，20% 迭代速度下</p>\n<ul>\n<li>10 年后，分别的总收益是 1.62, 2.59，4.04, 6.19, 可以看出不同迭代速度下，总收益差距还是不少的，但是好像也并没有那么大（从 5% 增长到 10%，增长了没有 1 倍，从 10% 增长到 20% 的情况下，总收益增长了 1 倍多一点）；</li>\n<li>20 年后，分别的总收益是 2.65, 6.72, 16.36, 38.33. 拉长时间后，如果迭代速度增加越大，整体收益会越高，而且迭代速度每增长 5%，整体收益增长 2-3 倍的样子。</li>\n</ul>\n<p>在不同迭代速度下（5%，10%，15%，20%），前 10 年和后 10 年的增长分别如下</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>迭代速度</th>\n<th>10 年收益</th>\n<th>20 年总收益</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>5%</td>\n<td>1.62</td>\n<td>2.65</td>\n</tr>\n<tr>\n<td>10%</td>\n<td>2.59</td>\n<td>6.72</td>\n</tr>\n<tr>\n<td>15%</td>\n<td>4.04</td>\n<td>16.36</td>\n</tr>\n<tr>\n<td>20%</td>\n<td>6.19</td>\n<td>38.33</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看出如果迭代速度越大，那么 20 年和 10 年总收益差距越大（但是前 10 年的增长率和后十年的增长率实际是一样的，因为都是 (1 + r) ^ 10), 整体差距来自于基数的差异，由于迭代速度越大，第 10 年的时候整体收益越大，因此第 20 年的时候总收益会越好（基于第 10 年的总收益）</p>\n<p>接下来对比下，每两年有 2% 回撤的增长情况：增长率分别为 8% 和 15%，然后另外在当前迭代速度下，每 3 年有 2% 的回撤</p>\n<ul>\n<li>在第 10 年的时候，8%，8% + 每 3 年回撤 2%，15%， 15% + 每 3年回撤 2% 的总收益分别是：2.15，1.61, 4.04, 2.5 ，可以看到每 3 年回撤 2% 对整体收益影响就挺大：总收益将近少了一半。</li>\n<li>第 20 年的时候，8%，8% + 每 3 年回撤 2%，15%， 15% + 每 3年回撤 2% 的总收益分&gt;别是：4.6, 2.6, 16.3, 6.2。可以看出年限越长，有回撤的和无回撤的差距更大。</li>\n</ul>\n<p>接下来再看看负迭代速度的情况，-2%，-5%，-8%，-10% 迭代速度的情况下<br>10 年的情况下，总收益分别为 0.81, 0.59, 0.43, 0.34， 在 20 年的时候总收益分别为 0.66, 0.35, 0.18, 0.12。不管负迭代速度是多少，时间久了之后，整体收益会比较明显，如果迭代速度达到 -10% 的情况下，10 年就已经不剩一半了，20 年就只剩 1 成了。</p>\n<p>另外由于股市是非固定收益，因此不卖出的情况下，可以不算回撤（但是股价能否涨上去是另外一回事），股市更好的计算比例需要看长期的复合年化收益。如果自己不好计算，可以找一个 App 帮助计算。</p>\n<h1 id=\"比较和机会成本\"><a href=\"#比较和机会成本\" class=\"headerlink\" title=\"比较和机会成本\"></a>比较和机会成本</h1><p>投资中决策是非常重要的一点，决策会涉及到比较，在日常生活中也会经常有比较, 这里主要阐述一些常见的比较情况。</p>\n<p>有两个假设前提<br>1 同一时刻只能做一件事情<br>2 时间是不可逆的，过去了就没有了</p>\n<p>比较的时候可能会涉及多个维度，或者对比的维度不统一，而在做决策的时候更好的是能够对一个或多个选项进行同样维度的比较。比如下面的一些比较问题：</p>\n<ul>\n<li>投资中，某个投资标的数据发生变化，那么是否实际影响投资决策（比如茅台的预收账款变少）</li>\n<li>低价促销的东西，到底要不要买，不买感觉亏了，买好像又不是特别需要</li>\n<li>某类投资方式能大概率变富，但是时间比较长，比如 20 年，这种要不要投呢</li>\n</ul>\n<p>下面尝试对每一个问题进行详细的阐述</p>\n<h2 id=\"投资数据变化的影响\"><a href=\"#投资数据变化的影响\" class=\"headerlink\" title=\"投资数据变化的影响\"></a>投资数据变化的影响</h2><p>之前文章中我们说过，买股票就是买公司，那么公司的指标就会影响公司的情况，到底哪些指标的变化，变化成啥样会影响公司呢</p>\n<p>这里以一个预收款减少的情况作为例子，比如某公司某年的预售款比之前少了，可能不少人会觉得，这是公司变差的一个信号，甚至说已经不是一个可以继续投资的信号了。</p>\n<p>回到投资的本质来说，我们希望将钱放到某些投资标的中，从而获取更好的收益，就像 <a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">股市是一个好的投资渠道吗</a> 描述的那样。那么我们应该比较的是：1）当前公司因为预收款等实际影响公司的营收；2）其他公司的情况怎么样 — 因为如果我们不投资到当前公司，就需要投资到其他地方。</p>\n<p>然后我们可能发现，大部分公司实际上是没有预收款的，反而是有不少应收账款。那么预收款减少也就是说还有，还有就表示相对下游还有定价权（比较抢手，下游希望通过提前交钱来预订）。那么就要看这个预收款减少是否有影响公司未来的盈利能力。</p>\n<h2 id=\"促销商品购买\"><a href=\"#促销商品购买\" class=\"headerlink\" title=\"促销商品购买\"></a>促销商品购买</h2><p>商品经常会使用类似降价的方式来进行促销，比如原价 A 售卖的，现在通过降价 30% 售卖，而且降价只有最后 3 天。</p>\n<p>那么这种情况下我们的购买策略应该比较的是：[购买] VS [不购买] 是否影响自己的生活情况。而不是 [原价] 和 [降价了 30%] 进行对比。将是否需要和价格情况进行组合将得到如下的情况</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>需要</th>\n<th>不需要</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>原价</td>\n<td>(1)</td>\n<td>(2)</td>\n</tr>\n<tr>\n<td>降价</td>\n<td>(3)</td>\n<td>(4)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>也就是对应的优先级应该是 (3) &gt; (1) &gt;&gt; (4) &gt; (2)。也就是说在我们应该在需要的情况下再考虑价格，如果不需要的情况下，就算降价购买，那也是一种浪费。</p>\n<h2 id=\"长期和短期\"><a href=\"#长期和短期\" class=\"headerlink\" title=\"长期和短期\"></a>长期和短期</h2><p>在价值投资中，往往需要比较长时间才能有好的结果，比如 10 年 5 倍，20 年 15 倍（复合年化 15% 已经很不错了），但是可能有人看到后会说，自己希望是短期就能变富，10 年 20 年太久了，另外看上去 10 年 20 年后这个收益好像也不是很高。</p>\n<p>这个可以这样比较：[选择这种投资方式，复合年化 15%] VS [其他投资渠道]。然后比较两种投资渠道哪个更能满足自己的需求</p>\n<ul>\n<li>投资时间的情况（短期还是长期）</li>\n<li>变富</li>\n</ul>\n<p>其中短期和长期来说，不同的投资市场会影响投资决策，如果是短期投资，不一定适合投资非固定收益的标的（比如股市），因为股市短期的涨跌太难预测，但是长期来说，股价围绕公司价值波动，那么股价就更好预测一些。</p>\n<p>另外变富是人人都想要的，但是具体到投资来说，就会有复合年化收益来衡量。对于不同收益率在不同年限中的总收益情况可以参考前文的情况。然后我们应该考虑的是 [选择该方式] 和 [选择其他方式] 哪个更能够让自己变的更富有，而不是单纯的觉得某个收益率太高或者太低。</p>\n<h2 id=\"机会成本\"><a href=\"#机会成本\" class=\"headerlink\" title=\"机会成本\"></a>机会成本</h2><p>比较会进一步促进决策（不行动也是一种决策），由于没法同时做两件事，因此部分只能进行假设的比较，因此选择的成本实际是我们选择了 A 之后，剩下的所有选项中最好结果来决定的，这也就是我们的机会成本 — 因为当前决策导致我们丧失了一次机会。</p>\n<p>投资是一个称重游戏，那么我们需要做的是，在较长的时间内，比较多个投资标的，哪个会增长的更多，所有投资的机会成本是自己能获得的稳定收益的最高值，这个对大部分人来说是长期无风险国债，具体的利率可以参考 <a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">股市是一个好的投资渠道吗</a>。然后对于未来现金流折线来说，折现率我们也可以使用机会成本来进行计算。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>本文尝试描述迭代速度/增长比率，比较以及机会成本，这些不仅仅在投资中重要，在平时生活中也有不小影响，有复利的情况下都能套用迭代速度，然后比较和机会成本也会影响我们的每次决策，从而影响我们的生活。</p>\n<p>但是需要注意的一点是 决策的质量 和 决策后的结果好坏并不完全相关，它们会有如下四种情况</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>好决策</th>\n<th>差决策</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>好结果</td>\n<td>1</td>\n<td>2</td>\n</tr>\n<tr>\n<td>坏结果</td>\n<td>3</td>\n<td>4</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>其中 1 和 4 是我们很容易了解并接受的，但是实际生活中还会有 2 和 3 的存在，如果在对过去决策进行复盘的时候，我们需要考虑到这些情况的存在，另外每次决策的时候也应该记录更多的上下文信息，这样在后续复盘的时候能够知道当时的决策是否好，而不仅仅是通过结果来进行判断。</p>"},{"title":"差异化和公司文化","date":"2025-04-26T08:53:32.000Z","toc":true,"_content":"\n在商业世界中，公司靠持续提供有差异化的产品保持竞争力，公司的文化则在更长时间范围内保证可以提供差异化的产品。\n\n> 本文受《雪球特别版-段永平投资问答录》启发\n\n<!-- more -->\n\n# 差异化\n\n公司的提供某产品，是因为客户有需求，同一个需求可以有不同的满足方式，因此不同的公司会提供不同的产品。在市场上所有产品中，那些有差异化的产品能够更受客户欢迎。\n\n差异化可以理解为：客户想要但还未满足的需求。\n\n差异化并不是一个高高在上的概念，但是却需要非常实际了解客户的需求，了解那些实际需要但还未得到满足的需求，满足这些需求就提供价值，就有了差异化的竞争力。比如 hao123 的导航栏，比如苹果的产品，比如小商店的地理位置等都是差异化的一种体现。功能，性能，体验等\n\n## hao123 的故事\n\nhao123 是一个很好的体现差异化需求的事情。hao123 站长在网吧当网管期间，一个人设计和维护了 hao123 网帐。在最初的时候，由于上网的人比较难记住经常要访问的网址 -- 有一个导航的需求，而网吧是按时收费的，如果找不到地址则钱就白白浪费了。hao123 就在这种情况下诞生了，从解决客户的实际需求（需要能记录常用网站）开始，然后不断的维护网址导航。后来 2004 年 hao123 以 1190 万加 4 万股的价格卖给百度，可见其价值。\n\nhao123 从技术角度上看，没有太大的难度（后期量大之后还是有难度的），但是能够实实在在解决用户的需求 -- 网站导航。或者说成为当时互联网的入口。这是用户可观存在的需求，解决了用户的需求之后就能够获得对应的流量。\n\n\n## 苹果产品\n\n苹果从 iPhone4 出来之后，产品卖的非常好，产品拥有不错的差异化。这里以用户视角描述下苹果产品的差异化。\n\n苹果不仅提供了硬件，还包括了软件，服务等。其中 iPhone 提供了非常流畅的体验，iCloud 提供了一套帐号，云存储服务，整体体验不错。对于要求不是特别高的情况下，苹果自带的产品就能够满足基本的要求。\n\n比如 iNote 可以解决日常笔记问题，能够随手进行记录，可以自动同步到云存储，有基本的格式、分类功能; iBook 能够阅读 pdf/epub 等各种格式的书籍，在不同设备（iPhone/Mac/iPad) 上进行同步，还能够进行听书，算是看书的一种补充；「提醒事项」可以在特定时间点提醒自己，释放自己的记忆压力。换设备的体验也很好，登录 iCloud 帐号之后，所有的能够自动进行同步，基本感受不到设备的切换。而如果有更高的要求，也可以在 AppStore 上进行相关软件下载。\n\n不过苹果最近的品控感觉不如以前，最近遇到好几次问题，最后在客服人员的帮助下，进行解决。比较好的是，有专门的客服协助解决（售后），但是品控比起之前确实感受有下降。\n\n## 其他\n差异化不仅仅是功能，性能，也可能是地理位置，体验，感受等。比如小区的商店就比 3 公里外的商店更能满足自己的需求，喜欢咖啡/酒的人，习惯喝的饮品就是能满足自己体验，感受的；游戏也是类似。这些有差异化的产品，往往不会因为（部分）提价客户就进行转换，从公司角度这就是竞争力，就有一定的护城河。\n\n# 文化\n\n差异化是用户需要但还未被满足的需求，那用户需求被满足后，就会有新的需求，因此需要能够持续的提供差异化的产品，而保证能够持续的提供差异化的产品，就需要一套系统，或者说公司的文化。\n\n文化包括公司墙上宣传的，也包括大家内心认可的。也就是说分为明面上的规则，和潜规则。潜规则的影响往往也会很大。\n\n另外文化在没有经过验证之前，是不太靠谱的。只有面临真正的考验的时候，才能说是自己公司的文化，这也会影响后面非常多的情况。\n\n比如阿里 2011 年 B2B 事件[1]，这种会很大影响公司外对公司的看法和判断，同时也会影响公司内的后续决策上的取舍。当然好文化也需要持续保持，不然也会被稀释，或者变差。\n> 2011年2月21日下午消息，阿里巴巴B2B公司宣布，为维护公司“客户第一”的价值观及诚信原则，2010年公司清理了约0.8%逾千名涉嫌欺诈的“中国供应商”客户，公司CEO卫哲、COO李旭晖因此引咎辞职，原淘宝网CEO陆兆禧接任。阿里巴巴表示，公司绝不能仅仅变成一家赚钱的机器，让天下没有难做的生意才是其使命所在。\n\n另「外某电商平台自营」实际并不一定是自己经营的产品，这种如果出问题也无法找到该平台，这里的「自营」和平常的理解有差异，但是这种会一定程度降低客户的信任度。\n\n如果某些规章制度明显不合理，那么能否修改规章制度，还是随机执行，也能体现文化。比如公司园区内有很多地，车位不多，发现大家乱停车的时候，到底是宣传说不能乱停车，然后罚款，还是调研后增加车位，这些选择会影响公司的文化。\n\n文化也是一件件选择塑造的，每一次选择可能可以对公司的文化往更好的方向发展，不变，往更差的方向发展，我们应该选择那些长期来看往更好方向发展的。\n\n# 总结\n公司的产品是需要有差异化才能保证更好的卖给客户，更好的赚钱，这也就是生意模式。但是生意模式也许要有系统/文化来保持，从而持久的产生有差异化的产品。文化不仅仅是公司墙上的规章制度，也包括平时的选择。但是需要区分这两点：1）是做了错的事情；2）做对的事情过程中犯了错。其中第一点就会导致文化变差，但是第二点是无法避免的（所有人都可能会犯错）。\n\n另外对于个人来说，可以思考自己提供的什么产品/服务，自己的客户是谁，怎么提供差异化的产品/服务，然后怎么保持持续提供差异化的产品/服务，这样更能够将焦点聚焦在自己身上，而不是围绕工作转。\n\n# Ref\n[1] https://baike.baidu.com/item/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ceo%E5%8D%AB%E5%93%B2%E5%BC%95%E5%92%8E%E8%BE%9E%E8%81%8C%E4%BA%8B%E4%BB%B6/6317687\n","source":"_posts/differentiation.md","raw":"---\ntitle: 差异化和公司文化\ndate: 2025-04-26 16:53:32\ntags:\n    - differentiation\n    - strategy\ntoc: true\n---\n\n在商业世界中，公司靠持续提供有差异化的产品保持竞争力，公司的文化则在更长时间范围内保证可以提供差异化的产品。\n\n> 本文受《雪球特别版-段永平投资问答录》启发\n\n<!-- more -->\n\n# 差异化\n\n公司的提供某产品，是因为客户有需求，同一个需求可以有不同的满足方式，因此不同的公司会提供不同的产品。在市场上所有产品中，那些有差异化的产品能够更受客户欢迎。\n\n差异化可以理解为：客户想要但还未满足的需求。\n\n差异化并不是一个高高在上的概念，但是却需要非常实际了解客户的需求，了解那些实际需要但还未得到满足的需求，满足这些需求就提供价值，就有了差异化的竞争力。比如 hao123 的导航栏，比如苹果的产品，比如小商店的地理位置等都是差异化的一种体现。功能，性能，体验等\n\n## hao123 的故事\n\nhao123 是一个很好的体现差异化需求的事情。hao123 站长在网吧当网管期间，一个人设计和维护了 hao123 网帐。在最初的时候，由于上网的人比较难记住经常要访问的网址 -- 有一个导航的需求，而网吧是按时收费的，如果找不到地址则钱就白白浪费了。hao123 就在这种情况下诞生了，从解决客户的实际需求（需要能记录常用网站）开始，然后不断的维护网址导航。后来 2004 年 hao123 以 1190 万加 4 万股的价格卖给百度，可见其价值。\n\nhao123 从技术角度上看，没有太大的难度（后期量大之后还是有难度的），但是能够实实在在解决用户的需求 -- 网站导航。或者说成为当时互联网的入口。这是用户可观存在的需求，解决了用户的需求之后就能够获得对应的流量。\n\n\n## 苹果产品\n\n苹果从 iPhone4 出来之后，产品卖的非常好，产品拥有不错的差异化。这里以用户视角描述下苹果产品的差异化。\n\n苹果不仅提供了硬件，还包括了软件，服务等。其中 iPhone 提供了非常流畅的体验，iCloud 提供了一套帐号，云存储服务，整体体验不错。对于要求不是特别高的情况下，苹果自带的产品就能够满足基本的要求。\n\n比如 iNote 可以解决日常笔记问题，能够随手进行记录，可以自动同步到云存储，有基本的格式、分类功能; iBook 能够阅读 pdf/epub 等各种格式的书籍，在不同设备（iPhone/Mac/iPad) 上进行同步，还能够进行听书，算是看书的一种补充；「提醒事项」可以在特定时间点提醒自己，释放自己的记忆压力。换设备的体验也很好，登录 iCloud 帐号之后，所有的能够自动进行同步，基本感受不到设备的切换。而如果有更高的要求，也可以在 AppStore 上进行相关软件下载。\n\n不过苹果最近的品控感觉不如以前，最近遇到好几次问题，最后在客服人员的帮助下，进行解决。比较好的是，有专门的客服协助解决（售后），但是品控比起之前确实感受有下降。\n\n## 其他\n差异化不仅仅是功能，性能，也可能是地理位置，体验，感受等。比如小区的商店就比 3 公里外的商店更能满足自己的需求，喜欢咖啡/酒的人，习惯喝的饮品就是能满足自己体验，感受的；游戏也是类似。这些有差异化的产品，往往不会因为（部分）提价客户就进行转换，从公司角度这就是竞争力，就有一定的护城河。\n\n# 文化\n\n差异化是用户需要但还未被满足的需求，那用户需求被满足后，就会有新的需求，因此需要能够持续的提供差异化的产品，而保证能够持续的提供差异化的产品，就需要一套系统，或者说公司的文化。\n\n文化包括公司墙上宣传的，也包括大家内心认可的。也就是说分为明面上的规则，和潜规则。潜规则的影响往往也会很大。\n\n另外文化在没有经过验证之前，是不太靠谱的。只有面临真正的考验的时候，才能说是自己公司的文化，这也会影响后面非常多的情况。\n\n比如阿里 2011 年 B2B 事件[1]，这种会很大影响公司外对公司的看法和判断，同时也会影响公司内的后续决策上的取舍。当然好文化也需要持续保持，不然也会被稀释，或者变差。\n> 2011年2月21日下午消息，阿里巴巴B2B公司宣布，为维护公司“客户第一”的价值观及诚信原则，2010年公司清理了约0.8%逾千名涉嫌欺诈的“中国供应商”客户，公司CEO卫哲、COO李旭晖因此引咎辞职，原淘宝网CEO陆兆禧接任。阿里巴巴表示，公司绝不能仅仅变成一家赚钱的机器，让天下没有难做的生意才是其使命所在。\n\n另「外某电商平台自营」实际并不一定是自己经营的产品，这种如果出问题也无法找到该平台，这里的「自营」和平常的理解有差异，但是这种会一定程度降低客户的信任度。\n\n如果某些规章制度明显不合理，那么能否修改规章制度，还是随机执行，也能体现文化。比如公司园区内有很多地，车位不多，发现大家乱停车的时候，到底是宣传说不能乱停车，然后罚款，还是调研后增加车位，这些选择会影响公司的文化。\n\n文化也是一件件选择塑造的，每一次选择可能可以对公司的文化往更好的方向发展，不变，往更差的方向发展，我们应该选择那些长期来看往更好方向发展的。\n\n# 总结\n公司的产品是需要有差异化才能保证更好的卖给客户，更好的赚钱，这也就是生意模式。但是生意模式也许要有系统/文化来保持，从而持久的产生有差异化的产品。文化不仅仅是公司墙上的规章制度，也包括平时的选择。但是需要区分这两点：1）是做了错的事情；2）做对的事情过程中犯了错。其中第一点就会导致文化变差，但是第二点是无法避免的（所有人都可能会犯错）。\n\n另外对于个人来说，可以思考自己提供的什么产品/服务，自己的客户是谁，怎么提供差异化的产品/服务，然后怎么保持持续提供差异化的产品/服务，这样更能够将焦点聚焦在自己身上，而不是围绕工作转。\n\n# Ref\n[1] https://baike.baidu.com/item/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ceo%E5%8D%AB%E5%93%B2%E5%BC%95%E5%92%8E%E8%BE%9E%E8%81%8C%E4%BA%8B%E4%BB%B6/6317687\n","slug":"differentiation","published":1,"updated":"2025-04-26T12:22:52.848Z","_id":"cm9y6y65v00066kjn7bo51lpf","comments":1,"layout":"post","photos":[],"link":"","content":"<p>在商业世界中，公司靠持续提供有差异化的产品保持竞争力，公司的文化则在更长时间范围内保证可以提供差异化的产品。</p>\n<blockquote>\n<p>本文受《雪球特别版-段永平投资问答录》启发</p>\n</blockquote>\n<span id=\"more\"></span>\n<h1 id=\"差异化\"><a href=\"#差异化\" class=\"headerlink\" title=\"差异化\"></a>差异化</h1><p>公司的提供某产品，是因为客户有需求，同一个需求可以有不同的满足方式，因此不同的公司会提供不同的产品。在市场上所有产品中，那些有差异化的产品能够更受客户欢迎。</p>\n<p>差异化可以理解为：客户想要但还未满足的需求。</p>\n<p>差异化并不是一个高高在上的概念，但是却需要非常实际了解客户的需求，了解那些实际需要但还未得到满足的需求，满足这些需求就提供价值，就有了差异化的竞争力。比如 hao123 的导航栏，比如苹果的产品，比如小商店的地理位置等都是差异化的一种体现。功能，性能，体验等</p>\n<h2 id=\"hao123-的故事\"><a href=\"#hao123-的故事\" class=\"headerlink\" title=\"hao123 的故事\"></a>hao123 的故事</h2><p>hao123 是一个很好的体现差异化需求的事情。hao123 站长在网吧当网管期间，一个人设计和维护了 hao123 网帐。在最初的时候，由于上网的人比较难记住经常要访问的网址 — 有一个导航的需求，而网吧是按时收费的，如果找不到地址则钱就白白浪费了。hao123 就在这种情况下诞生了，从解决客户的实际需求（需要能记录常用网站）开始，然后不断的维护网址导航。后来 2004 年 hao123 以 1190 万加 4 万股的价格卖给百度，可见其价值。</p>\n<p>hao123 从技术角度上看，没有太大的难度（后期量大之后还是有难度的），但是能够实实在在解决用户的需求 — 网站导航。或者说成为当时互联网的入口。这是用户可观存在的需求，解决了用户的需求之后就能够获得对应的流量。</p>\n<h2 id=\"苹果产品\"><a href=\"#苹果产品\" class=\"headerlink\" title=\"苹果产品\"></a>苹果产品</h2><p>苹果从 iPhone4 出来之后，产品卖的非常好，产品拥有不错的差异化。这里以用户视角描述下苹果产品的差异化。</p>\n<p>苹果不仅提供了硬件，还包括了软件，服务等。其中 iPhone 提供了非常流畅的体验，iCloud 提供了一套帐号，云存储服务，整体体验不错。对于要求不是特别高的情况下，苹果自带的产品就能够满足基本的要求。</p>\n<p>比如 iNote 可以解决日常笔记问题，能够随手进行记录，可以自动同步到云存储，有基本的格式、分类功能; iBook 能够阅读 pdf/epub 等各种格式的书籍，在不同设备（iPhone/Mac/iPad) 上进行同步，还能够进行听书，算是看书的一种补充；「提醒事项」可以在特定时间点提醒自己，释放自己的记忆压力。换设备的体验也很好，登录 iCloud 帐号之后，所有的能够自动进行同步，基本感受不到设备的切换。而如果有更高的要求，也可以在 AppStore 上进行相关软件下载。</p>\n<p>不过苹果最近的品控感觉不如以前，最近遇到好几次问题，最后在客服人员的帮助下，进行解决。比较好的是，有专门的客服协助解决（售后），但是品控比起之前确实感受有下降。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><p>差异化不仅仅是功能，性能，也可能是地理位置，体验，感受等。比如小区的商店就比 3 公里外的商店更能满足自己的需求，喜欢咖啡/酒的人，习惯喝的饮品就是能满足自己体验，感受的；游戏也是类似。这些有差异化的产品，往往不会因为（部分）提价客户就进行转换，从公司角度这就是竞争力，就有一定的护城河。</p>\n<h1 id=\"文化\"><a href=\"#文化\" class=\"headerlink\" title=\"文化\"></a>文化</h1><p>差异化是用户需要但还未被满足的需求，那用户需求被满足后，就会有新的需求，因此需要能够持续的提供差异化的产品，而保证能够持续的提供差异化的产品，就需要一套系统，或者说公司的文化。</p>\n<p>文化包括公司墙上宣传的，也包括大家内心认可的。也就是说分为明面上的规则，和潜规则。潜规则的影响往往也会很大。</p>\n<p>另外文化在没有经过验证之前，是不太靠谱的。只有面临真正的考验的时候，才能说是自己公司的文化，这也会影响后面非常多的情况。</p>\n<p>比如阿里 2011 年 B2B 事件[1]，这种会很大影响公司外对公司的看法和判断，同时也会影响公司内的后续决策上的取舍。当然好文化也需要持续保持，不然也会被稀释，或者变差。</p>\n<blockquote>\n<p>2011年2月21日下午消息，阿里巴巴B2B公司宣布，为维护公司“客户第一”的价值观及诚信原则，2010年公司清理了约0.8%逾千名涉嫌欺诈的“中国供应商”客户，公司CEO卫哲、COO李旭晖因此引咎辞职，原淘宝网CEO陆兆禧接任。阿里巴巴表示，公司绝不能仅仅变成一家赚钱的机器，让天下没有难做的生意才是其使命所在。</p>\n</blockquote>\n<p>另「外某电商平台自营」实际并不一定是自己经营的产品，这种如果出问题也无法找到该平台，这里的「自营」和平常的理解有差异，但是这种会一定程度降低客户的信任度。</p>\n<p>如果某些规章制度明显不合理，那么能否修改规章制度，还是随机执行，也能体现文化。比如公司园区内有很多地，车位不多，发现大家乱停车的时候，到底是宣传说不能乱停车，然后罚款，还是调研后增加车位，这些选择会影响公司的文化。</p>\n<p>文化也是一件件选择塑造的，每一次选择可能可以对公司的文化往更好的方向发展，不变，往更差的方向发展，我们应该选择那些长期来看往更好方向发展的。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>公司的产品是需要有差异化才能保证更好的卖给客户，更好的赚钱，这也就是生意模式。但是生意模式也许要有系统/文化来保持，从而持久的产生有差异化的产品。文化不仅仅是公司墙上的规章制度，也包括平时的选择。但是需要区分这两点：1）是做了错的事情；2）做对的事情过程中犯了错。其中第一点就会导致文化变差，但是第二点是无法避免的（所有人都可能会犯错）。</p>\n<p>另外对于个人来说，可以思考自己提供的什么产品/服务，自己的客户是谁，怎么提供差异化的产品/服务，然后怎么保持持续提供差异化的产品/服务，这样更能够将焦点聚焦在自己身上，而不是围绕工作转。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] <a href=\"https://baike.baidu.com/item/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ceo%E5%8D%AB%E5%93%B2%E5%BC%95%E5%92%8E%E8%BE%9E%E8%81%8C%E4%BA%8B%E4%BB%B6/6317687\">https://baike.baidu.com/item/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ceo%E5%8D%AB%E5%93%B2%E5%BC%95%E5%92%8E%E8%BE%9E%E8%81%8C%E4%BA%8B%E4%BB%B6/6317687</a></p>\n","site":{"data":{}},"excerpt":"<p>在商业世界中，公司靠持续提供有差异化的产品保持竞争力，公司的文化则在更长时间范围内保证可以提供差异化的产品。</p>\n<blockquote>\n<p>本文受《雪球特别版-段永平投资问答录》启发</p>\n</blockquote>","more":"<h1 id=\"差异化\"><a href=\"#差异化\" class=\"headerlink\" title=\"差异化\"></a>差异化</h1><p>公司的提供某产品，是因为客户有需求，同一个需求可以有不同的满足方式，因此不同的公司会提供不同的产品。在市场上所有产品中，那些有差异化的产品能够更受客户欢迎。</p>\n<p>差异化可以理解为：客户想要但还未满足的需求。</p>\n<p>差异化并不是一个高高在上的概念，但是却需要非常实际了解客户的需求，了解那些实际需要但还未得到满足的需求，满足这些需求就提供价值，就有了差异化的竞争力。比如 hao123 的导航栏，比如苹果的产品，比如小商店的地理位置等都是差异化的一种体现。功能，性能，体验等</p>\n<h2 id=\"hao123-的故事\"><a href=\"#hao123-的故事\" class=\"headerlink\" title=\"hao123 的故事\"></a>hao123 的故事</h2><p>hao123 是一个很好的体现差异化需求的事情。hao123 站长在网吧当网管期间，一个人设计和维护了 hao123 网帐。在最初的时候，由于上网的人比较难记住经常要访问的网址 — 有一个导航的需求，而网吧是按时收费的，如果找不到地址则钱就白白浪费了。hao123 就在这种情况下诞生了，从解决客户的实际需求（需要能记录常用网站）开始，然后不断的维护网址导航。后来 2004 年 hao123 以 1190 万加 4 万股的价格卖给百度，可见其价值。</p>\n<p>hao123 从技术角度上看，没有太大的难度（后期量大之后还是有难度的），但是能够实实在在解决用户的需求 — 网站导航。或者说成为当时互联网的入口。这是用户可观存在的需求，解决了用户的需求之后就能够获得对应的流量。</p>\n<h2 id=\"苹果产品\"><a href=\"#苹果产品\" class=\"headerlink\" title=\"苹果产品\"></a>苹果产品</h2><p>苹果从 iPhone4 出来之后，产品卖的非常好，产品拥有不错的差异化。这里以用户视角描述下苹果产品的差异化。</p>\n<p>苹果不仅提供了硬件，还包括了软件，服务等。其中 iPhone 提供了非常流畅的体验，iCloud 提供了一套帐号，云存储服务，整体体验不错。对于要求不是特别高的情况下，苹果自带的产品就能够满足基本的要求。</p>\n<p>比如 iNote 可以解决日常笔记问题，能够随手进行记录，可以自动同步到云存储，有基本的格式、分类功能; iBook 能够阅读 pdf/epub 等各种格式的书籍，在不同设备（iPhone/Mac/iPad) 上进行同步，还能够进行听书，算是看书的一种补充；「提醒事项」可以在特定时间点提醒自己，释放自己的记忆压力。换设备的体验也很好，登录 iCloud 帐号之后，所有的能够自动进行同步，基本感受不到设备的切换。而如果有更高的要求，也可以在 AppStore 上进行相关软件下载。</p>\n<p>不过苹果最近的品控感觉不如以前，最近遇到好几次问题，最后在客服人员的帮助下，进行解决。比较好的是，有专门的客服协助解决（售后），但是品控比起之前确实感受有下降。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><p>差异化不仅仅是功能，性能，也可能是地理位置，体验，感受等。比如小区的商店就比 3 公里外的商店更能满足自己的需求，喜欢咖啡/酒的人，习惯喝的饮品就是能满足自己体验，感受的；游戏也是类似。这些有差异化的产品，往往不会因为（部分）提价客户就进行转换，从公司角度这就是竞争力，就有一定的护城河。</p>\n<h1 id=\"文化\"><a href=\"#文化\" class=\"headerlink\" title=\"文化\"></a>文化</h1><p>差异化是用户需要但还未被满足的需求，那用户需求被满足后，就会有新的需求，因此需要能够持续的提供差异化的产品，而保证能够持续的提供差异化的产品，就需要一套系统，或者说公司的文化。</p>\n<p>文化包括公司墙上宣传的，也包括大家内心认可的。也就是说分为明面上的规则，和潜规则。潜规则的影响往往也会很大。</p>\n<p>另外文化在没有经过验证之前，是不太靠谱的。只有面临真正的考验的时候，才能说是自己公司的文化，这也会影响后面非常多的情况。</p>\n<p>比如阿里 2011 年 B2B 事件[1]，这种会很大影响公司外对公司的看法和判断，同时也会影响公司内的后续决策上的取舍。当然好文化也需要持续保持，不然也会被稀释，或者变差。</p>\n<blockquote>\n<p>2011年2月21日下午消息，阿里巴巴B2B公司宣布，为维护公司“客户第一”的价值观及诚信原则，2010年公司清理了约0.8%逾千名涉嫌欺诈的“中国供应商”客户，公司CEO卫哲、COO李旭晖因此引咎辞职，原淘宝网CEO陆兆禧接任。阿里巴巴表示，公司绝不能仅仅变成一家赚钱的机器，让天下没有难做的生意才是其使命所在。</p>\n</blockquote>\n<p>另「外某电商平台自营」实际并不一定是自己经营的产品，这种如果出问题也无法找到该平台，这里的「自营」和平常的理解有差异，但是这种会一定程度降低客户的信任度。</p>\n<p>如果某些规章制度明显不合理，那么能否修改规章制度，还是随机执行，也能体现文化。比如公司园区内有很多地，车位不多，发现大家乱停车的时候，到底是宣传说不能乱停车，然后罚款，还是调研后增加车位，这些选择会影响公司的文化。</p>\n<p>文化也是一件件选择塑造的，每一次选择可能可以对公司的文化往更好的方向发展，不变，往更差的方向发展，我们应该选择那些长期来看往更好方向发展的。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>公司的产品是需要有差异化才能保证更好的卖给客户，更好的赚钱，这也就是生意模式。但是生意模式也许要有系统/文化来保持，从而持久的产生有差异化的产品。文化不仅仅是公司墙上的规章制度，也包括平时的选择。但是需要区分这两点：1）是做了错的事情；2）做对的事情过程中犯了错。其中第一点就会导致文化变差，但是第二点是无法避免的（所有人都可能会犯错）。</p>\n<p>另外对于个人来说，可以思考自己提供的什么产品/服务，自己的客户是谁，怎么提供差异化的产品/服务，然后怎么保持持续提供差异化的产品/服务，这样更能够将焦点聚焦在自己身上，而不是围绕工作转。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] <a href=\"https://baike.baidu.com/item/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ceo%E5%8D%AB%E5%93%B2%E5%BC%95%E5%92%8E%E8%BE%9E%E8%81%8C%E4%BA%8B%E4%BB%B6/6317687\">https://baike.baidu.com/item/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4ceo%E5%8D%AB%E5%93%B2%E5%BC%95%E5%92%8E%E8%BE%9E%E8%81%8C%E4%BA%8B%E4%BB%B6/6317687</a></p>"},{"title":"iceberg summit 2025 notes","date":"2025-05-20T08:03:32.000Z","author":"klion26","toc":true,"_content":"本次 Iceberg Summit 2025[0] 上行业内众多公司做了分享，包括 Iceberg 核心技术、使用案例，优化方案，未来走向等等。其中国内的腾讯（两个 talk），小米，小红书均有分享，整体内容不错，这里做一个总结，更详细的请参考原视频。\n\n<!--more-->\n\n# Beyound Iceberg's ongoing evolution\n\n首先是 Iceberg 的 PMC member Ryan Blue 的 talk[1], 这个 talk 整体介绍了 Iceberg 的过去，现在以及将来的一些事情。Iceberg 现在已经成为湖仓的事实标准，在各大公司被官方使用，在湖仓一体/流批一体等方案中作为共享存储存在，提供了 ACID，time travel，branch，tag 等各种功能，支持了众多查询引擎，整体生态非常繁荣。\n\n最近一年已经完成或者正在进行的一些重大特性包括\n- Geo type 的支持，更好的支持地图数据\n- Variant type 的支持，可以支持半结构化数据（这个另外一个 talk 单独有讲）\n- 全表加密（data 和 metadata）\n- deletion vector  -- 更好的 position deletes（有另外一个 talk 单独讲），在性能、文件数量以及维护成本做了一个均衡\n- row lineage，主要方便增量消费以及数据的校验等\n\n在 Iceberg 中增加新的数据类型可以带来：1）有标准，各引擎更方便交互；2）能够借用 Iceberg 的 Metadata/Index 等做查询优化。\n\n另外在广泛使用过程中，大家也有提出来一些有关 metadata 的痛点，比如\n- manifest 相关\n  - 文件可能会比较多：先生成 manifest 然后是 manifest list；manifest 会重写最后删除\n  - 现在对小表不太友好（实际中有很多小表）：scan 需要走 manifest list 然后顺序的访问每个 manifest 文件\n  - manifest 文件太多：导致 metadata 需要周期性合并\n- 故障恢复比较困难: file replication  不够恢复整张表；metadata 需要重写（主要是绝对路径）\n- 列信息是二进制的：对扩展类型不优化（比如 geo/variant 等)\n- plan 性能可以更好: 需要读取所有列信息（不在 filter 中的列信息也需要读取）\n- Metadata skipping 需要分区信息：数据倾斜处理不好；无法和 geo 数据很好的结合；容易过度分区\n\n针对这些问题，也有一些相应的规划，整体思路是 metadata 往 adaptive tree structure方向走，adaptive tree structure 加上 RestCatalog, 再加上 servcie 就更像 DB 了。\n\nadaptive tree structure 大致如下\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20250512145432.png)\n\n另外 Iceberg 也在如下一下方面有考虑\n- Relative paths：主要是为了容灾、故障恢复考虑\n- Columnar metadata: 更方便跳过不需要的 column stat；typed lower/upper bounds/alternative sort orders\n- Adaptive metadata & Unified manifests: 更好的 manifest 结构，主要适配多模态数据，优化小表，manifest 的维护性等。\n\n后文中会从如下几方面展开描述\n- Manifest/Index：表元数据相关\n- Catalog: Catalog 相关\n- Compute&Management(Optimiztion&Service): 表查询和管理相关\n- File format: file format 相关\n- Streaming: 流式入湖\n- Ecosystem(&usecase&migration): 生态以及迁移到 Iceberg\n\n# Matadata(manifest/Index)\nIceberg 的 metadata 是核心组件，包括了支持各种功能以及查询优化所必需的信息，这里介绍一些和 metadata 相关的演讲内容。更详细的可以查看原视频（下同）。\n\n本次 Summit 中有介绍 Iceberg （正在）支持多种类型：geo 类型[2]，variant 类型[3]，支持了 deletion vector[4] -- 更好的 position delete。\n\n也有尝试将 Iceberg 的 metadata 暴露成常规的 Iceberg 表方便分析的[5]，演讲中有介绍使用 PG 来承载 metadata 的分析，发现量大之后会遇到性能瓶颈，因此希望 Iceberg 原生支持将 metadata 暴露为标准表。\n\n其中增加新类型主要是定义标准以及优化查询，geo 主要是地图相关的数据（点、线，区域等），而 variant 则主要是支持半结构化的数据 -- 比如 json。variant 在 log/event 等数据类型中大量使用，IoT/Telemetry 数据非常多，variant 的支持还有一个就是增加 shredding 过程，用于进一步加速。\n\n在 position delete 的基础上演化出了 delete vector，出要出发点在于不管是 partition-level 还是 file-level 的 position delete 文件都有局限。因此演化成现在的 delete vector 方式，这样磁盘和内存中的数据结构统一，每条数据仅会被删除一次，文件数也大大减少。\n\n也有一些分享提了类似[29] first-row/last-row 的 merge option 等需求。\n\n# Catalog\nCatalog 主要负责表层面的元数据，包括最新的元数据，事物控制协调等。现在 Iceberg 提供了多种类型的 Catalog 供用户选择。\n\n本次 Summit 中有用户介绍使用 Catalog 的具体情况[6]，也有介绍 RestCatalog 的相关事情[7][8][9]。\n\n其中 Bloomberg 对不同的 catalog 有一些总结如下\n\n- Hive\n  - Easiest to utilize, as we were already using the ApacheHive Metastore\n  - Scale and performance challenges\n- AWS Glue\n  - managed service\n  - vendor lock-in\n  - access control limited through AWS primitives\n- JDBC\n  - Easy and familiar to manage and connect to a database\n  - access control limited through AWS or DB primitives\n- Rest\n  - Gave use the most flexibility to support the Iceberg Spec and additional custom features\n  - Flexible integration with different query engines\n  - Backed by a PostgreSQL database\n  - Provided the most flexibility on access control and multi-tenancy\n\n[7][8]分享了 RestCatalog 的由来。RestCatalog 从最初解决 HiveCatalog 的问题出发（锁粒度，以及事物控制等），分析了一个 Catalog 需要满足的条件：可靠性，低延迟提交；事物/冲突管理；客户端的兼容性；数据的权限等。Iceberg 的 RestCatalog 将部分客户端的职责移到 server 端，这样客户端更轻量级；更好的事物控制（DML/DDL 的协调，合并和实时写入的协调），多表事物控制；客户端更好实现（更轻量级，更方便多语言实现）。以及 Apache Polaris 的一些实际使用情况。\n\n[9] 分享了 Pinterest 使用 Gravtino 解决 Iceberg 过程中的一些实际问题，包括：partition list 很慢；性能分析；已经引擎相关的性能问题等。\n\n# Compute&Management\n数据存储后会被查询使用，为了查询效率高也需要对数据进行管理优化。\n\n[10] 主要分享了不同参数下 Iceberg 表的性能情况。主要在 file format 层面的调优，包括 `write.target-file-size-bytes` 和 `write.parquet.row-group-size-bytes` 的调优实践。一些具体的测试数据如下：\n\n| metric | 2mb row-group size(unsorted) | 128mb row group size(unsorted) | 2m row group size(sorted) | 128mb row group size(sorted) |\n| -- | -- | -- | -- | -- |\n| num_columns | 21 | 21 | 21 | 21 |\n| num_rows | 391844 | 391844 | 1794155 | 656682 |\n| num_row_groups | 33 | 1 | 150 | 1 |\n| serialized_size | 94736 | 4824 | 424318 | 4799 |\n\n并测试了不同引擎下的查询效率\n- unsorted 情况下 2MB vs 128MB row group size 性能可以提升 15%\n- sorted 的情况下 2MB vs 128MB row group size 性能可以提升 177%\n\n[11] 分享了 Impala 优化 Iceberg MOR 的流程，主要思路是避免无限重复读取 delete 文件，单独一个算子读取 delete 文件，然后使用 broadcast join 来进行数据的删除。\n\n[12] 分享了如果给 Iceberg 查询做 I/O 优化进行加速，主要思路是尽可能的进行 filter pushdown -- `filter pushdown is the gold standard of I/O optimizations`\n\n由于不是所有的 filter 都能够 pushdown，可以可能需要 rewrite SQL。现在 Iceberg 中 filter pushdown 会有如下约束\n- Filters are only useful if they eliminate entire partitions or data files\n- Limited set of statistics to evaluate with\n  - Lower and upper bounds\n  - Null, NAN, Value Counts\n  - Partition Values\n  - Not as useful for non-numberic cols\n- Complex filters contain compute functions\n  - Iceberg transforms are only a subset\n\n然后给出了一些 rewrite 的具体例子\n\n| Before | After(completely pushable) |\n| -- | -- |\n| coalese(date, TODAY) <= TODAY | date is null or date <= TODAY |\n| zip_code in (12345, 54321, 31524) | zip_code = 12345 or zip_code = 54321 or zip_code = 31524 |\n| size / 2.0 > PARAM | size > PARAM * 2.0 |\n| username LIKE 'bill%' | STARTSWITH(username, 'bill'); |\n| tag ILIKE 'A' | tag = 'A' or tag = 'a' |\n\n对于无法全部下推的，可以考虑部分下推，如下所示\n\n| original | runtime filter | file-level filter |\n| -- | -- | -- |\n| url like 'http://%.com% | startswith(url, 'http://') and contains(url, '.com') | startswith(url, 'http://')|\n| lower(name) = 'adam' (name ilike 'adam') | lower(name) = 'adam') | name = 'ADAM' and name ='adam'|\n| qyt INT > 100 | qty INT > 100 | qty is NOT null|\n\n在最后对 Iceberg Metadata 提出一些需求，希望未来有更多可用于 file pruning 的 metadata 信息。\n\n\n[13] 分享了 partition stats 的背景，当前情况等。主要是为了更好优化查询(CBO 过程)。\n\n现在 Iceberg 有 FileLevel/Manifest Level/Snapshot Level 的指标，希望有 partition level 的指标。由于实际场景中大部分是分区表，因此 partition level 指标在现实世界中有很多使用场景。\n- 避免读取所有的 manifest（有些表的 manifest 非常多）\n- 在 plan 的时候可以 autoscaling（根据 partition level 指标动态调整并发）\n- 动态调整 query plan（join reordering，IO operator）\n- 仅在最新 snapshot 中 partition 会影响查询时进行合并\n- 根据 partition 指标刷新数据写入链路（Two sigma 无法 expire snapshot 的例子）\n\n\n[14] 分享了 Iceberg 的跨集群复制以及灾难恢复，主要思路是基于 snapshot 的增量复制。\n\n[15] 腾讯(TEG) 分享了处理超宽表的一些线上生产经验，主要在 ML/DL 等场景下，会有上千列的情况。主要问题有：\n- 表太宽，单表上 P\n  - 单表上千万的文件数量，上千数量的 manifest 文件\n  - plan 性能瓶颈\n  - batch 写入消耗内存多，容易导致 OOM\n- 列管理困难\n  - 不是所有列的价值都一样\n  - 列的频繁增删\n\n整体的思路包括：减少不必要的元数据（比如指标）；通过 column stats 知道列的使用频率，然后进行调整；将 datafile 合并到 manifest file 中，减少文件数量；另外在合并的时候通过直接操作 parquet 来加速等一系列优化方案。更详细的可以查看对应视频。\n\n[16][17][18] 有讲表管理、优化相关的事情（和 Amoro 定位类似，Linkdin 开源了他们的  OpenHouse），这里面有比较多实际生产经验可以借鉴，包括合并策略、资源优化、扩展性、观测性（用户侧，服务侧）、告警等\n\n[22] 分享了腾讯云基于 Amoro 做的流批一体的湖仓系统，包括 MixedIceberg 承接实时数据，以及支持 partial update 等需求。\n\n# File format\n为了满足不同的场景（尤其是 ML&AI），有不同的 file format 出来(lance, vertox 等)，如何在 Iceberg 中结合新型 file format 的能力是一个社区正在做的事情。\n\n[19]分享了 fileformat 出现的一些原因，以及 Iceberg 正在做的事情 -- 抽象 FileReader/Writer 的接口等。\n\n- ML workload 的特点\n  - wide columns\n  - both scan & search\n  - grow horizontally(wide schema)\n- 新硬件的特点\n  - not just(or even primarily) run on CPUS\n  - Accelerators like GPU & FPGA are embarrassingly parallel\n  - Common bottlenecks: CPU, Copying to device memory\n  - IDEA: Load compressed data, decompress on-device\n\n新的 file-format 要求和特点如下所示\n- 要求\n  - Decompression via GPU SIMT\n  - Decompression via CPU SIMD\n  - Random access on compressed data\n- 特点\n  - workload diversity\n  - flexibility & interop\n  - accelerated computing\n\n[15] 中腾讯的分享是在 parquet 中做的一些工作。\n\n# Streaming\n随着大家对实时入湖的需求，以及 Iceberg 在实时入湖上的现状，大家在寻找时效性，湖仓治理的一个平衡点。\n\n不同公司也在尝试实时入湖的事情，如何做到时效性、管理成本等的平衡是一个难点。\n\n[20] 分享了 Snowflake 在 Iceberg 上做增量计算的一些事情，这个分享包括了增量计算的定义，以及在 snowflake 中实现的一些思路，思路大概是通过 row_id 来记录数据的演进（row_id 也可以当成 watermark），然后通过代数变换讲 join 等算子变换为增量计算的算子减少计算量。比较麻烦的是多表事物的处理 -- 需要有一个全局的时间。\n\n[21] 分享了实时入湖效率，以及后续湖仓内数据治理的一些实测数据，希望达到一个全局的最优，主要思路是在不影响 compaction 的情况下增大入湖效率（增大写入并发），然后通过类似 RestCatalog 的角色来协调 commit。另外会对一些错误配置等提前预判并通知。\n\n[26] 分享了如何实时入湖相关的事情，并给出了从 Snowflake 迁移到 Iceberg 的一些情况，并且基于实际情况提出了 Flink Dynamic Schama 的需求，在最新的 Sink 中有相关的工作正在进行中。\n\n# Ecosystem(&usecase &migration)\n\n[6] 有分享迁移到 Iceberg 前后的收益\n\n| Before Iceberg | After Iceberg |\n| -- | -- |\n| Full daily restatements of 7TB+  | Incremental daily revision between 5~10 GB(<1% of total table) |\n| High ingestion overhead | Streamlined ingestion and processing |\n| Slow processing and costly storage | Efficiency gains in storage and compute |\n| Hard to diagnose and debug data quality | Easier to diagnose and debug data quality | \n\n\n[17][25][27]分享了 Hive 迁移到 Iceberg 的一些事情，描述了 Hive 的一些限制：partition 支持不好；ACID 支持不好，性能，扩展性，多引擎支持等等，以及从 Hive 迁移到 Iceberg 的详细流程和 checklist，包括前期分析，迁移计划，具体执行，以及最后验证等，对于 Hive 迁移 Iceberg 的可以参考下。从 Hive 迁移到 Iceberg 后，整体减少了 70% 的资源，查询峰值时间降低了 95%，对于 streaming 入湖也更简单了。\n\n[9] 使用 Iceberg 做流批一体存储，链路大致如下 [upstream] -> kafka -> flink -> Iceberg -> [Flink/Spark]，使用了两张表来承接实时数据：其中一张表保留全量数据，一张表保留增量数据，增量数据周期性写入全量表（Amoro 中的 mixed-iceberg 思路类似）。\n\n[23] 分享了使用 Trino 做可扩展的湖仓，主要解决如下问题：扩展性；管理难度；查询性能慢；vendor lock-in 等。\n\n在扩展性方面遇到：metadata 增长；不同的 workload；查询性能的稳定；数据倾斜的处理以及限速等。\n\n基于生产经验总结了一些最佳实践：\n- 读方面：使用 NDV Status，filter pushdown， metadata/data cache，materialized view(trino），合适的线程池大小等\n- 写方面（主要是 trino 相关）：限制写入并发；数据合理分区，专用 plan/delete 的线程池等\n\n[23] 分享了使用 Iceberg 做统一存储后，避免在各系统之间进行数据的传输，计算等，减少了整体的计算和存储量。\n\n[24] 分享了构建基于 Iceberg(+StarRocks/BigQuery) 的大规模分析系统，并且在生产中实现了 blue/green 的常规流程。 使用 Iceberg 前后的对比如下所示（之前是 PG 和 BigQuery）\n\n| Before | After |\n| -- | -- |\n| 大查询经常超时 | 查询耗时大规模减少  P95 2.976s  Avg 1.65s |\n| increasing SSD costs to store ever increasing volumes of data |  数据可以 offload 到 object storage |\n| 存算一体（耦合）|  存算分离（可以单独扩展）|\n| Hourly and daily data loads frequently resulted in SLO misses |  存储只需要在一个地方就行 | \n| 无法很容易的换计算引擎 |  可以使用多引擎查询 |\n| 数据太大需要从 PG 切到 BigQuery，无法在 on-premise 环境 | 可以在 on-premise 环境使用 | \n\n\n\n[28] 则分享了 PG 支持 Iceberg 外表的一些情况，这样可以结合 PG 和 Iceberg 的能力。\n\n[30] 分享了 Redpanda 的 iceberg table，听起来和Automq 的 iceberg table 以及 fluss 有相似之处，可以将 MQ 的数据直接 compaction 到 datalake 中，这块或许一个完整的是，有轻量级 MQ + service 能力负责 offload 和 compaction，以及现在的 datalake。\n\n[31] 则分享了生产中实际情况，比如使用 storage partitioned join 来避免大量 shuffle 的场景。\n\n另外类似 Trino/StarRocks/BigQuery 等引擎均在大会上分享介绍如何结合 Iceberg 的，在语言方面，除了 Java 之外，现在 Python/Rust/C++ 等语言也在积极推动中。\n\n# Ref\n[0] https://www.icebergsummit2025.com/agenda/\n[1] V3 and Beyond Iceberg’s ongoing evolution\n[2] Decoupling Metadata: Leveraging Queryable Iceberg Tables for Scalable, Cross-Engine Innovation\n[3] Understanding Deletion Vectors in Apache Iceberg\n[4] Iceberg Geo Type: Transforming Geospatial Data Management at Scale\n[5] Decoupling Metadata: Leveraging Queryable Iceberg Tables for Scalable, Cross-Engine Innovation\n[6] Building Bloomberg’s First Incremental Alternative Data Product Using Apache Iceberg\n[7] Pioneering the Next Frontier: The REST Revolution in Apache Iceberg Metadata\n[8] Scalable Lakehouse Architecture with Iceberg & Polaris: A Battle-tested Playbook\n[9] Scaling Iceberg Adoption at Pinterest with Gravtino\n[10] Deep Dive into Iceberg Optimizations and Best Practices for a Scalable and Performant Lakehouse\n[11] Extending the One Trillion Row Challenge to Iceberg V2 Tables\n[12] Iceberg I/O Optimizations in Compute Engines\n[13] Supercharging Apache Iceberg Strategies for Harnessing Partition Stats\n[14] Iceberg Resilience: Building a DR Strategy for the Data Lake\n[15] Efficiently Managing Table With Thousands of Columns Using Iceberg In Tencent\n[16] Learning from running large-scale Apache Iceberg Table Management Service\n[17] Airbnb Icehouse: The Journey to Iceberg\n[18] Optimizing Iceberg Table Layouts at Scale: A Multi-Objective Approach\n[19] Turbocharge Queries on Iceberg with Next-Gen File Formats\n[20] CDC Implementations on Apache Iceberg and where are we headed\n[21] Unleashing the power of Iceberg ingestion 100GB/s and beyond\n[22] Building a Batch-Stream-Unified Lakehouse on Apache Iceberg in Tencent Cloud\n[23] Eliminating redundancies in ETL with Iceberg tables on Snowflake\n[24] From zero to one: Building a petabyte-scale data analytics platform with Apache Iceberg\n[25] Hive Tables to Apache Iceberg: A Step by step Migration Blueprint\n[26] Iceberg with Flink at DoorDash\n[27] Implement Iceberg for Improved Data Management at Autodesk\n[28] Postgres meets Iceberg\n[29] Supercharging wise data lake with apache iceberg\n[30] The ‘Streamhouse’: Extending Redpanda into a fully managed, Iceberg-backed realtime data lakehouse\n[31] Adopting Apache Iceberg at Slack: Challenges, Lessons, and Best Practices\n","source":"_posts/iceberg-summit-2025.md","raw":"---\ntitle: iceberg summit 2025 notes\ndate: 2025-05-20 16:03:32\nauthor: klion26\ntags:\n    - iceberg-summit\n    - notes\ntoc: true\n---\n本次 Iceberg Summit 2025[0] 上行业内众多公司做了分享，包括 Iceberg 核心技术、使用案例，优化方案，未来走向等等。其中国内的腾讯（两个 talk），小米，小红书均有分享，整体内容不错，这里做一个总结，更详细的请参考原视频。\n\n<!--more-->\n\n# Beyound Iceberg's ongoing evolution\n\n首先是 Iceberg 的 PMC member Ryan Blue 的 talk[1], 这个 talk 整体介绍了 Iceberg 的过去，现在以及将来的一些事情。Iceberg 现在已经成为湖仓的事实标准，在各大公司被官方使用，在湖仓一体/流批一体等方案中作为共享存储存在，提供了 ACID，time travel，branch，tag 等各种功能，支持了众多查询引擎，整体生态非常繁荣。\n\n最近一年已经完成或者正在进行的一些重大特性包括\n- Geo type 的支持，更好的支持地图数据\n- Variant type 的支持，可以支持半结构化数据（这个另外一个 talk 单独有讲）\n- 全表加密（data 和 metadata）\n- deletion vector  -- 更好的 position deletes（有另外一个 talk 单独讲），在性能、文件数量以及维护成本做了一个均衡\n- row lineage，主要方便增量消费以及数据的校验等\n\n在 Iceberg 中增加新的数据类型可以带来：1）有标准，各引擎更方便交互；2）能够借用 Iceberg 的 Metadata/Index 等做查询优化。\n\n另外在广泛使用过程中，大家也有提出来一些有关 metadata 的痛点，比如\n- manifest 相关\n  - 文件可能会比较多：先生成 manifest 然后是 manifest list；manifest 会重写最后删除\n  - 现在对小表不太友好（实际中有很多小表）：scan 需要走 manifest list 然后顺序的访问每个 manifest 文件\n  - manifest 文件太多：导致 metadata 需要周期性合并\n- 故障恢复比较困难: file replication  不够恢复整张表；metadata 需要重写（主要是绝对路径）\n- 列信息是二进制的：对扩展类型不优化（比如 geo/variant 等)\n- plan 性能可以更好: 需要读取所有列信息（不在 filter 中的列信息也需要读取）\n- Metadata skipping 需要分区信息：数据倾斜处理不好；无法和 geo 数据很好的结合；容易过度分区\n\n针对这些问题，也有一些相应的规划，整体思路是 metadata 往 adaptive tree structure方向走，adaptive tree structure 加上 RestCatalog, 再加上 servcie 就更像 DB 了。\n\nadaptive tree structure 大致如下\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20250512145432.png)\n\n另外 Iceberg 也在如下一下方面有考虑\n- Relative paths：主要是为了容灾、故障恢复考虑\n- Columnar metadata: 更方便跳过不需要的 column stat；typed lower/upper bounds/alternative sort orders\n- Adaptive metadata & Unified manifests: 更好的 manifest 结构，主要适配多模态数据，优化小表，manifest 的维护性等。\n\n后文中会从如下几方面展开描述\n- Manifest/Index：表元数据相关\n- Catalog: Catalog 相关\n- Compute&Management(Optimiztion&Service): 表查询和管理相关\n- File format: file format 相关\n- Streaming: 流式入湖\n- Ecosystem(&usecase&migration): 生态以及迁移到 Iceberg\n\n# Matadata(manifest/Index)\nIceberg 的 metadata 是核心组件，包括了支持各种功能以及查询优化所必需的信息，这里介绍一些和 metadata 相关的演讲内容。更详细的可以查看原视频（下同）。\n\n本次 Summit 中有介绍 Iceberg （正在）支持多种类型：geo 类型[2]，variant 类型[3]，支持了 deletion vector[4] -- 更好的 position delete。\n\n也有尝试将 Iceberg 的 metadata 暴露成常规的 Iceberg 表方便分析的[5]，演讲中有介绍使用 PG 来承载 metadata 的分析，发现量大之后会遇到性能瓶颈，因此希望 Iceberg 原生支持将 metadata 暴露为标准表。\n\n其中增加新类型主要是定义标准以及优化查询，geo 主要是地图相关的数据（点、线，区域等），而 variant 则主要是支持半结构化的数据 -- 比如 json。variant 在 log/event 等数据类型中大量使用，IoT/Telemetry 数据非常多，variant 的支持还有一个就是增加 shredding 过程，用于进一步加速。\n\n在 position delete 的基础上演化出了 delete vector，出要出发点在于不管是 partition-level 还是 file-level 的 position delete 文件都有局限。因此演化成现在的 delete vector 方式，这样磁盘和内存中的数据结构统一，每条数据仅会被删除一次，文件数也大大减少。\n\n也有一些分享提了类似[29] first-row/last-row 的 merge option 等需求。\n\n# Catalog\nCatalog 主要负责表层面的元数据，包括最新的元数据，事物控制协调等。现在 Iceberg 提供了多种类型的 Catalog 供用户选择。\n\n本次 Summit 中有用户介绍使用 Catalog 的具体情况[6]，也有介绍 RestCatalog 的相关事情[7][8][9]。\n\n其中 Bloomberg 对不同的 catalog 有一些总结如下\n\n- Hive\n  - Easiest to utilize, as we were already using the ApacheHive Metastore\n  - Scale and performance challenges\n- AWS Glue\n  - managed service\n  - vendor lock-in\n  - access control limited through AWS primitives\n- JDBC\n  - Easy and familiar to manage and connect to a database\n  - access control limited through AWS or DB primitives\n- Rest\n  - Gave use the most flexibility to support the Iceberg Spec and additional custom features\n  - Flexible integration with different query engines\n  - Backed by a PostgreSQL database\n  - Provided the most flexibility on access control and multi-tenancy\n\n[7][8]分享了 RestCatalog 的由来。RestCatalog 从最初解决 HiveCatalog 的问题出发（锁粒度，以及事物控制等），分析了一个 Catalog 需要满足的条件：可靠性，低延迟提交；事物/冲突管理；客户端的兼容性；数据的权限等。Iceberg 的 RestCatalog 将部分客户端的职责移到 server 端，这样客户端更轻量级；更好的事物控制（DML/DDL 的协调，合并和实时写入的协调），多表事物控制；客户端更好实现（更轻量级，更方便多语言实现）。以及 Apache Polaris 的一些实际使用情况。\n\n[9] 分享了 Pinterest 使用 Gravtino 解决 Iceberg 过程中的一些实际问题，包括：partition list 很慢；性能分析；已经引擎相关的性能问题等。\n\n# Compute&Management\n数据存储后会被查询使用，为了查询效率高也需要对数据进行管理优化。\n\n[10] 主要分享了不同参数下 Iceberg 表的性能情况。主要在 file format 层面的调优，包括 `write.target-file-size-bytes` 和 `write.parquet.row-group-size-bytes` 的调优实践。一些具体的测试数据如下：\n\n| metric | 2mb row-group size(unsorted) | 128mb row group size(unsorted) | 2m row group size(sorted) | 128mb row group size(sorted) |\n| -- | -- | -- | -- | -- |\n| num_columns | 21 | 21 | 21 | 21 |\n| num_rows | 391844 | 391844 | 1794155 | 656682 |\n| num_row_groups | 33 | 1 | 150 | 1 |\n| serialized_size | 94736 | 4824 | 424318 | 4799 |\n\n并测试了不同引擎下的查询效率\n- unsorted 情况下 2MB vs 128MB row group size 性能可以提升 15%\n- sorted 的情况下 2MB vs 128MB row group size 性能可以提升 177%\n\n[11] 分享了 Impala 优化 Iceberg MOR 的流程，主要思路是避免无限重复读取 delete 文件，单独一个算子读取 delete 文件，然后使用 broadcast join 来进行数据的删除。\n\n[12] 分享了如果给 Iceberg 查询做 I/O 优化进行加速，主要思路是尽可能的进行 filter pushdown -- `filter pushdown is the gold standard of I/O optimizations`\n\n由于不是所有的 filter 都能够 pushdown，可以可能需要 rewrite SQL。现在 Iceberg 中 filter pushdown 会有如下约束\n- Filters are only useful if they eliminate entire partitions or data files\n- Limited set of statistics to evaluate with\n  - Lower and upper bounds\n  - Null, NAN, Value Counts\n  - Partition Values\n  - Not as useful for non-numberic cols\n- Complex filters contain compute functions\n  - Iceberg transforms are only a subset\n\n然后给出了一些 rewrite 的具体例子\n\n| Before | After(completely pushable) |\n| -- | -- |\n| coalese(date, TODAY) <= TODAY | date is null or date <= TODAY |\n| zip_code in (12345, 54321, 31524) | zip_code = 12345 or zip_code = 54321 or zip_code = 31524 |\n| size / 2.0 > PARAM | size > PARAM * 2.0 |\n| username LIKE 'bill%' | STARTSWITH(username, 'bill'); |\n| tag ILIKE 'A' | tag = 'A' or tag = 'a' |\n\n对于无法全部下推的，可以考虑部分下推，如下所示\n\n| original | runtime filter | file-level filter |\n| -- | -- | -- |\n| url like 'http://%.com% | startswith(url, 'http://') and contains(url, '.com') | startswith(url, 'http://')|\n| lower(name) = 'adam' (name ilike 'adam') | lower(name) = 'adam') | name = 'ADAM' and name ='adam'|\n| qyt INT > 100 | qty INT > 100 | qty is NOT null|\n\n在最后对 Iceberg Metadata 提出一些需求，希望未来有更多可用于 file pruning 的 metadata 信息。\n\n\n[13] 分享了 partition stats 的背景，当前情况等。主要是为了更好优化查询(CBO 过程)。\n\n现在 Iceberg 有 FileLevel/Manifest Level/Snapshot Level 的指标，希望有 partition level 的指标。由于实际场景中大部分是分区表，因此 partition level 指标在现实世界中有很多使用场景。\n- 避免读取所有的 manifest（有些表的 manifest 非常多）\n- 在 plan 的时候可以 autoscaling（根据 partition level 指标动态调整并发）\n- 动态调整 query plan（join reordering，IO operator）\n- 仅在最新 snapshot 中 partition 会影响查询时进行合并\n- 根据 partition 指标刷新数据写入链路（Two sigma 无法 expire snapshot 的例子）\n\n\n[14] 分享了 Iceberg 的跨集群复制以及灾难恢复，主要思路是基于 snapshot 的增量复制。\n\n[15] 腾讯(TEG) 分享了处理超宽表的一些线上生产经验，主要在 ML/DL 等场景下，会有上千列的情况。主要问题有：\n- 表太宽，单表上 P\n  - 单表上千万的文件数量，上千数量的 manifest 文件\n  - plan 性能瓶颈\n  - batch 写入消耗内存多，容易导致 OOM\n- 列管理困难\n  - 不是所有列的价值都一样\n  - 列的频繁增删\n\n整体的思路包括：减少不必要的元数据（比如指标）；通过 column stats 知道列的使用频率，然后进行调整；将 datafile 合并到 manifest file 中，减少文件数量；另外在合并的时候通过直接操作 parquet 来加速等一系列优化方案。更详细的可以查看对应视频。\n\n[16][17][18] 有讲表管理、优化相关的事情（和 Amoro 定位类似，Linkdin 开源了他们的  OpenHouse），这里面有比较多实际生产经验可以借鉴，包括合并策略、资源优化、扩展性、观测性（用户侧，服务侧）、告警等\n\n[22] 分享了腾讯云基于 Amoro 做的流批一体的湖仓系统，包括 MixedIceberg 承接实时数据，以及支持 partial update 等需求。\n\n# File format\n为了满足不同的场景（尤其是 ML&AI），有不同的 file format 出来(lance, vertox 等)，如何在 Iceberg 中结合新型 file format 的能力是一个社区正在做的事情。\n\n[19]分享了 fileformat 出现的一些原因，以及 Iceberg 正在做的事情 -- 抽象 FileReader/Writer 的接口等。\n\n- ML workload 的特点\n  - wide columns\n  - both scan & search\n  - grow horizontally(wide schema)\n- 新硬件的特点\n  - not just(or even primarily) run on CPUS\n  - Accelerators like GPU & FPGA are embarrassingly parallel\n  - Common bottlenecks: CPU, Copying to device memory\n  - IDEA: Load compressed data, decompress on-device\n\n新的 file-format 要求和特点如下所示\n- 要求\n  - Decompression via GPU SIMT\n  - Decompression via CPU SIMD\n  - Random access on compressed data\n- 特点\n  - workload diversity\n  - flexibility & interop\n  - accelerated computing\n\n[15] 中腾讯的分享是在 parquet 中做的一些工作。\n\n# Streaming\n随着大家对实时入湖的需求，以及 Iceberg 在实时入湖上的现状，大家在寻找时效性，湖仓治理的一个平衡点。\n\n不同公司也在尝试实时入湖的事情，如何做到时效性、管理成本等的平衡是一个难点。\n\n[20] 分享了 Snowflake 在 Iceberg 上做增量计算的一些事情，这个分享包括了增量计算的定义，以及在 snowflake 中实现的一些思路，思路大概是通过 row_id 来记录数据的演进（row_id 也可以当成 watermark），然后通过代数变换讲 join 等算子变换为增量计算的算子减少计算量。比较麻烦的是多表事物的处理 -- 需要有一个全局的时间。\n\n[21] 分享了实时入湖效率，以及后续湖仓内数据治理的一些实测数据，希望达到一个全局的最优，主要思路是在不影响 compaction 的情况下增大入湖效率（增大写入并发），然后通过类似 RestCatalog 的角色来协调 commit。另外会对一些错误配置等提前预判并通知。\n\n[26] 分享了如何实时入湖相关的事情，并给出了从 Snowflake 迁移到 Iceberg 的一些情况，并且基于实际情况提出了 Flink Dynamic Schama 的需求，在最新的 Sink 中有相关的工作正在进行中。\n\n# Ecosystem(&usecase &migration)\n\n[6] 有分享迁移到 Iceberg 前后的收益\n\n| Before Iceberg | After Iceberg |\n| -- | -- |\n| Full daily restatements of 7TB+  | Incremental daily revision between 5~10 GB(<1% of total table) |\n| High ingestion overhead | Streamlined ingestion and processing |\n| Slow processing and costly storage | Efficiency gains in storage and compute |\n| Hard to diagnose and debug data quality | Easier to diagnose and debug data quality | \n\n\n[17][25][27]分享了 Hive 迁移到 Iceberg 的一些事情，描述了 Hive 的一些限制：partition 支持不好；ACID 支持不好，性能，扩展性，多引擎支持等等，以及从 Hive 迁移到 Iceberg 的详细流程和 checklist，包括前期分析，迁移计划，具体执行，以及最后验证等，对于 Hive 迁移 Iceberg 的可以参考下。从 Hive 迁移到 Iceberg 后，整体减少了 70% 的资源，查询峰值时间降低了 95%，对于 streaming 入湖也更简单了。\n\n[9] 使用 Iceberg 做流批一体存储，链路大致如下 [upstream] -> kafka -> flink -> Iceberg -> [Flink/Spark]，使用了两张表来承接实时数据：其中一张表保留全量数据，一张表保留增量数据，增量数据周期性写入全量表（Amoro 中的 mixed-iceberg 思路类似）。\n\n[23] 分享了使用 Trino 做可扩展的湖仓，主要解决如下问题：扩展性；管理难度；查询性能慢；vendor lock-in 等。\n\n在扩展性方面遇到：metadata 增长；不同的 workload；查询性能的稳定；数据倾斜的处理以及限速等。\n\n基于生产经验总结了一些最佳实践：\n- 读方面：使用 NDV Status，filter pushdown， metadata/data cache，materialized view(trino），合适的线程池大小等\n- 写方面（主要是 trino 相关）：限制写入并发；数据合理分区，专用 plan/delete 的线程池等\n\n[23] 分享了使用 Iceberg 做统一存储后，避免在各系统之间进行数据的传输，计算等，减少了整体的计算和存储量。\n\n[24] 分享了构建基于 Iceberg(+StarRocks/BigQuery) 的大规模分析系统，并且在生产中实现了 blue/green 的常规流程。 使用 Iceberg 前后的对比如下所示（之前是 PG 和 BigQuery）\n\n| Before | After |\n| -- | -- |\n| 大查询经常超时 | 查询耗时大规模减少  P95 2.976s  Avg 1.65s |\n| increasing SSD costs to store ever increasing volumes of data |  数据可以 offload 到 object storage |\n| 存算一体（耦合）|  存算分离（可以单独扩展）|\n| Hourly and daily data loads frequently resulted in SLO misses |  存储只需要在一个地方就行 | \n| 无法很容易的换计算引擎 |  可以使用多引擎查询 |\n| 数据太大需要从 PG 切到 BigQuery，无法在 on-premise 环境 | 可以在 on-premise 环境使用 | \n\n\n\n[28] 则分享了 PG 支持 Iceberg 外表的一些情况，这样可以结合 PG 和 Iceberg 的能力。\n\n[30] 分享了 Redpanda 的 iceberg table，听起来和Automq 的 iceberg table 以及 fluss 有相似之处，可以将 MQ 的数据直接 compaction 到 datalake 中，这块或许一个完整的是，有轻量级 MQ + service 能力负责 offload 和 compaction，以及现在的 datalake。\n\n[31] 则分享了生产中实际情况，比如使用 storage partitioned join 来避免大量 shuffle 的场景。\n\n另外类似 Trino/StarRocks/BigQuery 等引擎均在大会上分享介绍如何结合 Iceberg 的，在语言方面，除了 Java 之外，现在 Python/Rust/C++ 等语言也在积极推动中。\n\n# Ref\n[0] https://www.icebergsummit2025.com/agenda/\n[1] V3 and Beyond Iceberg’s ongoing evolution\n[2] Decoupling Metadata: Leveraging Queryable Iceberg Tables for Scalable, Cross-Engine Innovation\n[3] Understanding Deletion Vectors in Apache Iceberg\n[4] Iceberg Geo Type: Transforming Geospatial Data Management at Scale\n[5] Decoupling Metadata: Leveraging Queryable Iceberg Tables for Scalable, Cross-Engine Innovation\n[6] Building Bloomberg’s First Incremental Alternative Data Product Using Apache Iceberg\n[7] Pioneering the Next Frontier: The REST Revolution in Apache Iceberg Metadata\n[8] Scalable Lakehouse Architecture with Iceberg & Polaris: A Battle-tested Playbook\n[9] Scaling Iceberg Adoption at Pinterest with Gravtino\n[10] Deep Dive into Iceberg Optimizations and Best Practices for a Scalable and Performant Lakehouse\n[11] Extending the One Trillion Row Challenge to Iceberg V2 Tables\n[12] Iceberg I/O Optimizations in Compute Engines\n[13] Supercharging Apache Iceberg Strategies for Harnessing Partition Stats\n[14] Iceberg Resilience: Building a DR Strategy for the Data Lake\n[15] Efficiently Managing Table With Thousands of Columns Using Iceberg In Tencent\n[16] Learning from running large-scale Apache Iceberg Table Management Service\n[17] Airbnb Icehouse: The Journey to Iceberg\n[18] Optimizing Iceberg Table Layouts at Scale: A Multi-Objective Approach\n[19] Turbocharge Queries on Iceberg with Next-Gen File Formats\n[20] CDC Implementations on Apache Iceberg and where are we headed\n[21] Unleashing the power of Iceberg ingestion 100GB/s and beyond\n[22] Building a Batch-Stream-Unified Lakehouse on Apache Iceberg in Tencent Cloud\n[23] Eliminating redundancies in ETL with Iceberg tables on Snowflake\n[24] From zero to one: Building a petabyte-scale data analytics platform with Apache Iceberg\n[25] Hive Tables to Apache Iceberg: A Step by step Migration Blueprint\n[26] Iceberg with Flink at DoorDash\n[27] Implement Iceberg for Improved Data Management at Autodesk\n[28] Postgres meets Iceberg\n[29] Supercharging wise data lake with apache iceberg\n[30] The ‘Streamhouse’: Extending Redpanda into a fully managed, Iceberg-backed realtime data lakehouse\n[31] Adopting Apache Iceberg at Slack: Challenges, Lessons, and Best Practices\n","slug":"iceberg-summit-2025","published":1,"updated":"2025-05-20T08:45:57.588Z","_id":"cmaw4d1hg0008k3mk2ce79l16","comments":1,"layout":"post","photos":[],"link":"","content":"<p>本次 Iceberg Summit 2025[0] 上行业内众多公司做了分享，包括 Iceberg 核心技术、使用案例，优化方案，未来走向等等。其中国内的腾讯（两个 talk），小米，小红书均有分享，整体内容不错，这里做一个总结，更详细的请参考原视频。</p>\n<span id=\"more\"></span>\n<h1 id=\"Beyound-Iceberg’s-ongoing-evolution\"><a href=\"#Beyound-Iceberg’s-ongoing-evolution\" class=\"headerlink\" title=\"Beyound Iceberg’s ongoing evolution\"></a>Beyound Iceberg’s ongoing evolution</h1><p>首先是 Iceberg 的 PMC member Ryan Blue 的 talk[1], 这个 talk 整体介绍了 Iceberg 的过去，现在以及将来的一些事情。Iceberg 现在已经成为湖仓的事实标准，在各大公司被官方使用，在湖仓一体/流批一体等方案中作为共享存储存在，提供了 ACID，time travel，branch，tag 等各种功能，支持了众多查询引擎，整体生态非常繁荣。</p>\n<p>最近一年已经完成或者正在进行的一些重大特性包括</p>\n<ul>\n<li>Geo type 的支持，更好的支持地图数据</li>\n<li>Variant type 的支持，可以支持半结构化数据（这个另外一个 talk 单独有讲）</li>\n<li>全表加密（data 和 metadata）</li>\n<li>deletion vector  — 更好的 position deletes（有另外一个 talk 单独讲），在性能、文件数量以及维护成本做了一个均衡</li>\n<li>row lineage，主要方便增量消费以及数据的校验等</li>\n</ul>\n<p>在 Iceberg 中增加新的数据类型可以带来：1）有标准，各引擎更方便交互；2）能够借用 Iceberg 的 Metadata/Index 等做查询优化。</p>\n<p>另外在广泛使用过程中，大家也有提出来一些有关 metadata 的痛点，比如</p>\n<ul>\n<li>manifest 相关<ul>\n<li>文件可能会比较多：先生成 manifest 然后是 manifest list；manifest 会重写最后删除</li>\n<li>现在对小表不太友好（实际中有很多小表）：scan 需要走 manifest list 然后顺序的访问每个 manifest 文件</li>\n<li>manifest 文件太多：导致 metadata 需要周期性合并</li>\n</ul>\n</li>\n<li>故障恢复比较困难: file replication  不够恢复整张表；metadata 需要重写（主要是绝对路径）</li>\n<li>列信息是二进制的：对扩展类型不优化（比如 geo/variant 等)</li>\n<li>plan 性能可以更好: 需要读取所有列信息（不在 filter 中的列信息也需要读取）</li>\n<li>Metadata skipping 需要分区信息：数据倾斜处理不好；无法和 geo 数据很好的结合；容易过度分区</li>\n</ul>\n<p>针对这些问题，也有一些相应的规划，整体思路是 metadata 往 adaptive tree structure方向走，adaptive tree structure 加上 RestCatalog, 再加上 servcie 就更像 DB 了。</p>\n<p>adaptive tree structure 大致如下<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20250512145432.png\" alt=\"\"></p>\n<p>另外 Iceberg 也在如下一下方面有考虑</p>\n<ul>\n<li>Relative paths：主要是为了容灾、故障恢复考虑</li>\n<li>Columnar metadata: 更方便跳过不需要的 column stat；typed lower/upper bounds/alternative sort orders</li>\n<li>Adaptive metadata &amp; Unified manifests: 更好的 manifest 结构，主要适配多模态数据，优化小表，manifest 的维护性等。</li>\n</ul>\n<p>后文中会从如下几方面展开描述</p>\n<ul>\n<li>Manifest/Index：表元数据相关</li>\n<li>Catalog: Catalog 相关</li>\n<li>Compute&amp;Management(Optimiztion&amp;Service): 表查询和管理相关</li>\n<li>File format: file format 相关</li>\n<li>Streaming: 流式入湖</li>\n<li>Ecosystem(&amp;usecase&amp;migration): 生态以及迁移到 Iceberg</li>\n</ul>\n<h1 id=\"Matadata-manifest-Index\"><a href=\"#Matadata-manifest-Index\" class=\"headerlink\" title=\"Matadata(manifest/Index)\"></a>Matadata(manifest/Index)</h1><p>Iceberg 的 metadata 是核心组件，包括了支持各种功能以及查询优化所必需的信息，这里介绍一些和 metadata 相关的演讲内容。更详细的可以查看原视频（下同）。</p>\n<p>本次 Summit 中有介绍 Iceberg （正在）支持多种类型：geo 类型[2]，variant 类型[3]，支持了 deletion vector[4] — 更好的 position delete。</p>\n<p>也有尝试将 Iceberg 的 metadata 暴露成常规的 Iceberg 表方便分析的[5]，演讲中有介绍使用 PG 来承载 metadata 的分析，发现量大之后会遇到性能瓶颈，因此希望 Iceberg 原生支持将 metadata 暴露为标准表。</p>\n<p>其中增加新类型主要是定义标准以及优化查询，geo 主要是地图相关的数据（点、线，区域等），而 variant 则主要是支持半结构化的数据 — 比如 json。variant 在 log/event 等数据类型中大量使用，IoT/Telemetry 数据非常多，variant 的支持还有一个就是增加 shredding 过程，用于进一步加速。</p>\n<p>在 position delete 的基础上演化出了 delete vector，出要出发点在于不管是 partition-level 还是 file-level 的 position delete 文件都有局限。因此演化成现在的 delete vector 方式，这样磁盘和内存中的数据结构统一，每条数据仅会被删除一次，文件数也大大减少。</p>\n<p>也有一些分享提了类似[29] first-row/last-row 的 merge option 等需求。</p>\n<h1 id=\"Catalog\"><a href=\"#Catalog\" class=\"headerlink\" title=\"Catalog\"></a>Catalog</h1><p>Catalog 主要负责表层面的元数据，包括最新的元数据，事物控制协调等。现在 Iceberg 提供了多种类型的 Catalog 供用户选择。</p>\n<p>本次 Summit 中有用户介绍使用 Catalog 的具体情况[6]，也有介绍 RestCatalog 的相关事情[7][8][9]。</p>\n<p>其中 Bloomberg 对不同的 catalog 有一些总结如下</p>\n<ul>\n<li>Hive<ul>\n<li>Easiest to utilize, as we were already using the ApacheHive Metastore</li>\n<li>Scale and performance challenges</li>\n</ul>\n</li>\n<li>AWS Glue<ul>\n<li>managed service</li>\n<li>vendor lock-in</li>\n<li>access control limited through AWS primitives</li>\n</ul>\n</li>\n<li>JDBC<ul>\n<li>Easy and familiar to manage and connect to a database</li>\n<li>access control limited through AWS or DB primitives</li>\n</ul>\n</li>\n<li>Rest<ul>\n<li>Gave use the most flexibility to support the Iceberg Spec and additional custom features</li>\n<li>Flexible integration with different query engines</li>\n<li>Backed by a PostgreSQL database</li>\n<li>Provided the most flexibility on access control and multi-tenancy</li>\n</ul>\n</li>\n</ul>\n<p>[7][8]分享了 RestCatalog 的由来。RestCatalog 从最初解决 HiveCatalog 的问题出发（锁粒度，以及事物控制等），分析了一个 Catalog 需要满足的条件：可靠性，低延迟提交；事物/冲突管理；客户端的兼容性；数据的权限等。Iceberg 的 RestCatalog 将部分客户端的职责移到 server 端，这样客户端更轻量级；更好的事物控制（DML/DDL 的协调，合并和实时写入的协调），多表事物控制；客户端更好实现（更轻量级，更方便多语言实现）。以及 Apache Polaris 的一些实际使用情况。</p>\n<p>[9] 分享了 Pinterest 使用 Gravtino 解决 Iceberg 过程中的一些实际问题，包括：partition list 很慢；性能分析；已经引擎相关的性能问题等。</p>\n<h1 id=\"Compute-amp-Management\"><a href=\"#Compute-amp-Management\" class=\"headerlink\" title=\"Compute&amp;Management\"></a>Compute&amp;Management</h1><p>数据存储后会被查询使用，为了查询效率高也需要对数据进行管理优化。</p>\n<p>[10] 主要分享了不同参数下 Iceberg 表的性能情况。主要在 file format 层面的调优，包括 <code>write.target-file-size-bytes</code> 和 <code>write.parquet.row-group-size-bytes</code> 的调优实践。一些具体的测试数据如下：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>metric</th>\n<th>2mb row-group size(unsorted)</th>\n<th>128mb row group size(unsorted)</th>\n<th>2m row group size(sorted)</th>\n<th>128mb row group size(sorted)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>num_columns</td>\n<td>21</td>\n<td>21</td>\n<td>21</td>\n<td>21</td>\n</tr>\n<tr>\n<td>num_rows</td>\n<td>391844</td>\n<td>391844</td>\n<td>1794155</td>\n<td>656682</td>\n</tr>\n<tr>\n<td>num_row_groups</td>\n<td>33</td>\n<td>1</td>\n<td>150</td>\n<td>1</td>\n</tr>\n<tr>\n<td>serialized_size</td>\n<td>94736</td>\n<td>4824</td>\n<td>424318</td>\n<td>4799</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>并测试了不同引擎下的查询效率</p>\n<ul>\n<li>unsorted 情况下 2MB vs 128MB row group size 性能可以提升 15%</li>\n<li>sorted 的情况下 2MB vs 128MB row group size 性能可以提升 177%</li>\n</ul>\n<p>[11] 分享了 Impala 优化 Iceberg MOR 的流程，主要思路是避免无限重复读取 delete 文件，单独一个算子读取 delete 文件，然后使用 broadcast join 来进行数据的删除。</p>\n<p>[12] 分享了如果给 Iceberg 查询做 I/O 优化进行加速，主要思路是尽可能的进行 filter pushdown — <code>filter pushdown is the gold standard of I/O optimizations</code></p>\n<p>由于不是所有的 filter 都能够 pushdown，可以可能需要 rewrite SQL。现在 Iceberg 中 filter pushdown 会有如下约束</p>\n<ul>\n<li>Filters are only useful if they eliminate entire partitions or data files</li>\n<li>Limited set of statistics to evaluate with<ul>\n<li>Lower and upper bounds</li>\n<li>Null, NAN, Value Counts</li>\n<li>Partition Values</li>\n<li>Not as useful for non-numberic cols</li>\n</ul>\n</li>\n<li>Complex filters contain compute functions<ul>\n<li>Iceberg transforms are only a subset</li>\n</ul>\n</li>\n</ul>\n<p>然后给出了一些 rewrite 的具体例子</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Before</th>\n<th>After(completely pushable)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>coalese(date, TODAY) &lt;= TODAY</td>\n<td>date is null or date &lt;= TODAY</td>\n</tr>\n<tr>\n<td>zip_code in (12345, 54321, 31524)</td>\n<td>zip_code = 12345 or zip_code = 54321 or zip_code = 31524</td>\n</tr>\n<tr>\n<td>size / 2.0 &gt; PARAM</td>\n<td>size &gt; PARAM * 2.0</td>\n</tr>\n<tr>\n<td>username LIKE ‘bill%’</td>\n<td>STARTSWITH(username, ‘bill’);</td>\n</tr>\n<tr>\n<td>tag ILIKE ‘A’</td>\n<td>tag = ‘A’ or tag = ‘a’</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>对于无法全部下推的，可以考虑部分下推，如下所示</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>original</th>\n<th>runtime filter</th>\n<th>file-level filter</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>url like ‘<a href=\"http://%.com%\">http://%.com%</a></td>\n<td>startswith(url, ‘http://‘) and contains(url, ‘.com’)</td>\n<td>startswith(url, ‘http://‘)</td>\n</tr>\n<tr>\n<td>lower(name) = ‘adam’ (name ilike ‘adam’)</td>\n<td>lower(name) = ‘adam’)</td>\n<td>name = ‘ADAM’ and name =’adam’</td>\n</tr>\n<tr>\n<td>qyt INT &gt; 100</td>\n<td>qty INT &gt; 100</td>\n<td>qty is NOT null</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>在最后对 Iceberg Metadata 提出一些需求，希望未来有更多可用于 file pruning 的 metadata 信息。</p>\n<p>[13] 分享了 partition stats 的背景，当前情况等。主要是为了更好优化查询(CBO 过程)。</p>\n<p>现在 Iceberg 有 FileLevel/Manifest Level/Snapshot Level 的指标，希望有 partition level 的指标。由于实际场景中大部分是分区表，因此 partition level 指标在现实世界中有很多使用场景。</p>\n<ul>\n<li>避免读取所有的 manifest（有些表的 manifest 非常多）</li>\n<li>在 plan 的时候可以 autoscaling（根据 partition level 指标动态调整并发）</li>\n<li>动态调整 query plan（join reordering，IO operator）</li>\n<li>仅在最新 snapshot 中 partition 会影响查询时进行合并</li>\n<li>根据 partition 指标刷新数据写入链路（Two sigma 无法 expire snapshot 的例子）</li>\n</ul>\n<p>[14] 分享了 Iceberg 的跨集群复制以及灾难恢复，主要思路是基于 snapshot 的增量复制。</p>\n<p>[15] 腾讯(TEG) 分享了处理超宽表的一些线上生产经验，主要在 ML/DL 等场景下，会有上千列的情况。主要问题有：</p>\n<ul>\n<li>表太宽，单表上 P<ul>\n<li>单表上千万的文件数量，上千数量的 manifest 文件</li>\n<li>plan 性能瓶颈</li>\n<li>batch 写入消耗内存多，容易导致 OOM</li>\n</ul>\n</li>\n<li>列管理困难<ul>\n<li>不是所有列的价值都一样</li>\n<li>列的频繁增删</li>\n</ul>\n</li>\n</ul>\n<p>整体的思路包括：减少不必要的元数据（比如指标）；通过 column stats 知道列的使用频率，然后进行调整；将 datafile 合并到 manifest file 中，减少文件数量；另外在合并的时候通过直接操作 parquet 来加速等一系列优化方案。更详细的可以查看对应视频。</p>\n<p>[16][17][18] 有讲表管理、优化相关的事情（和 Amoro 定位类似，Linkdin 开源了他们的  OpenHouse），这里面有比较多实际生产经验可以借鉴，包括合并策略、资源优化、扩展性、观测性（用户侧，服务侧）、告警等</p>\n<p>[22] 分享了腾讯云基于 Amoro 做的流批一体的湖仓系统，包括 MixedIceberg 承接实时数据，以及支持 partial update 等需求。</p>\n<h1 id=\"File-format\"><a href=\"#File-format\" class=\"headerlink\" title=\"File format\"></a>File format</h1><p>为了满足不同的场景（尤其是 ML&amp;AI），有不同的 file format 出来(lance, vertox 等)，如何在 Iceberg 中结合新型 file format 的能力是一个社区正在做的事情。</p>\n<p>[19]分享了 fileformat 出现的一些原因，以及 Iceberg 正在做的事情 — 抽象 FileReader/Writer 的接口等。</p>\n<ul>\n<li>ML workload 的特点<ul>\n<li>wide columns</li>\n<li>both scan &amp; search</li>\n<li>grow horizontally(wide schema)</li>\n</ul>\n</li>\n<li>新硬件的特点<ul>\n<li>not just(or even primarily) run on CPUS</li>\n<li>Accelerators like GPU &amp; FPGA are embarrassingly parallel</li>\n<li>Common bottlenecks: CPU, Copying to device memory</li>\n<li>IDEA: Load compressed data, decompress on-device</li>\n</ul>\n</li>\n</ul>\n<p>新的 file-format 要求和特点如下所示</p>\n<ul>\n<li>要求<ul>\n<li>Decompression via GPU SIMT</li>\n<li>Decompression via CPU SIMD</li>\n<li>Random access on compressed data</li>\n</ul>\n</li>\n<li>特点<ul>\n<li>workload diversity</li>\n<li>flexibility &amp; interop</li>\n<li>accelerated computing</li>\n</ul>\n</li>\n</ul>\n<p>[15] 中腾讯的分享是在 parquet 中做的一些工作。</p>\n<h1 id=\"Streaming\"><a href=\"#Streaming\" class=\"headerlink\" title=\"Streaming\"></a>Streaming</h1><p>随着大家对实时入湖的需求，以及 Iceberg 在实时入湖上的现状，大家在寻找时效性，湖仓治理的一个平衡点。</p>\n<p>不同公司也在尝试实时入湖的事情，如何做到时效性、管理成本等的平衡是一个难点。</p>\n<p>[20] 分享了 Snowflake 在 Iceberg 上做增量计算的一些事情，这个分享包括了增量计算的定义，以及在 snowflake 中实现的一些思路，思路大概是通过 row_id 来记录数据的演进（row_id 也可以当成 watermark），然后通过代数变换讲 join 等算子变换为增量计算的算子减少计算量。比较麻烦的是多表事物的处理 — 需要有一个全局的时间。</p>\n<p>[21] 分享了实时入湖效率，以及后续湖仓内数据治理的一些实测数据，希望达到一个全局的最优，主要思路是在不影响 compaction 的情况下增大入湖效率（增大写入并发），然后通过类似 RestCatalog 的角色来协调 commit。另外会对一些错误配置等提前预判并通知。</p>\n<p>[26] 分享了如何实时入湖相关的事情，并给出了从 Snowflake 迁移到 Iceberg 的一些情况，并且基于实际情况提出了 Flink Dynamic Schama 的需求，在最新的 Sink 中有相关的工作正在进行中。</p>\n<h1 id=\"Ecosystem-amp-usecase-amp-migration\"><a href=\"#Ecosystem-amp-usecase-amp-migration\" class=\"headerlink\" title=\"Ecosystem(&amp;usecase &amp;migration)\"></a>Ecosystem(&amp;usecase &amp;migration)</h1><p>[6] 有分享迁移到 Iceberg 前后的收益</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Before Iceberg</th>\n<th>After Iceberg</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Full daily restatements of 7TB+</td>\n<td>Incremental daily revision between 5~10 GB(&lt;1% of total table)</td>\n</tr>\n<tr>\n<td>High ingestion overhead</td>\n<td>Streamlined ingestion and processing</td>\n</tr>\n<tr>\n<td>Slow processing and costly storage</td>\n<td>Efficiency gains in storage and compute</td>\n</tr>\n<tr>\n<td>Hard to diagnose and debug data quality</td>\n<td>Easier to diagnose and debug data quality</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>[17][25][27]分享了 Hive 迁移到 Iceberg 的一些事情，描述了 Hive 的一些限制：partition 支持不好；ACID 支持不好，性能，扩展性，多引擎支持等等，以及从 Hive 迁移到 Iceberg 的详细流程和 checklist，包括前期分析，迁移计划，具体执行，以及最后验证等，对于 Hive 迁移 Iceberg 的可以参考下。从 Hive 迁移到 Iceberg 后，整体减少了 70% 的资源，查询峰值时间降低了 95%，对于 streaming 入湖也更简单了。</p>\n<p>[9] 使用 Iceberg 做流批一体存储，链路大致如下 [upstream] -&gt; kafka -&gt; flink -&gt; Iceberg -&gt; [Flink/Spark]，使用了两张表来承接实时数据：其中一张表保留全量数据，一张表保留增量数据，增量数据周期性写入全量表（Amoro 中的 mixed-iceberg 思路类似）。</p>\n<p>[23] 分享了使用 Trino 做可扩展的湖仓，主要解决如下问题：扩展性；管理难度；查询性能慢；vendor lock-in 等。</p>\n<p>在扩展性方面遇到：metadata 增长；不同的 workload；查询性能的稳定；数据倾斜的处理以及限速等。</p>\n<p>基于生产经验总结了一些最佳实践：</p>\n<ul>\n<li>读方面：使用 NDV Status，filter pushdown， metadata/data cache，materialized view(trino），合适的线程池大小等</li>\n<li>写方面（主要是 trino 相关）：限制写入并发；数据合理分区，专用 plan/delete 的线程池等</li>\n</ul>\n<p>[23] 分享了使用 Iceberg 做统一存储后，避免在各系统之间进行数据的传输，计算等，减少了整体的计算和存储量。</p>\n<p>[24] 分享了构建基于 Iceberg(+StarRocks/BigQuery) 的大规模分析系统，并且在生产中实现了 blue/green 的常规流程。 使用 Iceberg 前后的对比如下所示（之前是 PG 和 BigQuery）</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Before</th>\n<th>After</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>大查询经常超时</td>\n<td>查询耗时大规模减少  P95 2.976s  Avg 1.65s</td>\n</tr>\n<tr>\n<td>increasing SSD costs to store ever increasing volumes of data</td>\n<td>数据可以 offload 到 object storage</td>\n</tr>\n<tr>\n<td>存算一体（耦合）</td>\n<td>存算分离（可以单独扩展）</td>\n</tr>\n<tr>\n<td>Hourly and daily data loads frequently resulted in SLO misses</td>\n<td>存储只需要在一个地方就行</td>\n</tr>\n<tr>\n<td>无法很容易的换计算引擎</td>\n<td>可以使用多引擎查询</td>\n</tr>\n<tr>\n<td>数据太大需要从 PG 切到 BigQuery，无法在 on-premise 环境</td>\n<td>可以在 on-premise 环境使用</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>[28] 则分享了 PG 支持 Iceberg 外表的一些情况，这样可以结合 PG 和 Iceberg 的能力。</p>\n<p>[30] 分享了 Redpanda 的 iceberg table，听起来和Automq 的 iceberg table 以及 fluss 有相似之处，可以将 MQ 的数据直接 compaction 到 datalake 中，这块或许一个完整的是，有轻量级 MQ + service 能力负责 offload 和 compaction，以及现在的 datalake。</p>\n<p>[31] 则分享了生产中实际情况，比如使用 storage partitioned join 来避免大量 shuffle 的场景。</p>\n<p>另外类似 Trino/StarRocks/BigQuery 等引擎均在大会上分享介绍如何结合 Iceberg 的，在语言方面，除了 Java 之外，现在 Python/Rust/C++ 等语言也在积极推动中。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[0] <a href=\"https://www.icebergsummit2025.com/agenda/\">https://www.icebergsummit2025.com/agenda/</a><br>[1] V3 and Beyond Iceberg’s ongoing evolution<br>[2] Decoupling Metadata: Leveraging Queryable Iceberg Tables for Scalable, Cross-Engine Innovation<br>[3] Understanding Deletion Vectors in Apache Iceberg<br>[4] Iceberg Geo Type: Transforming Geospatial Data Management at Scale<br>[5] Decoupling Metadata: Leveraging Queryable Iceberg Tables for Scalable, Cross-Engine Innovation<br>[6] Building Bloomberg’s First Incremental Alternative Data Product Using Apache Iceberg<br>[7] Pioneering the Next Frontier: The REST Revolution in Apache Iceberg Metadata<br>[8] Scalable Lakehouse Architecture with Iceberg &amp; Polaris: A Battle-tested Playbook<br>[9] Scaling Iceberg Adoption at Pinterest with Gravtino<br>[10] Deep Dive into Iceberg Optimizations and Best Practices for a Scalable and Performant Lakehouse<br>[11] Extending the One Trillion Row Challenge to Iceberg V2 Tables<br>[12] Iceberg I/O Optimizations in Compute Engines<br>[13] Supercharging Apache Iceberg Strategies for Harnessing Partition Stats<br>[14] Iceberg Resilience: Building a DR Strategy for the Data Lake<br>[15] Efficiently Managing Table With Thousands of Columns Using Iceberg In Tencent<br>[16] Learning from running large-scale Apache Iceberg Table Management Service<br>[17] Airbnb Icehouse: The Journey to Iceberg<br>[18] Optimizing Iceberg Table Layouts at Scale: A Multi-Objective Approach<br>[19] Turbocharge Queries on Iceberg with Next-Gen File Formats<br>[20] CDC Implementations on Apache Iceberg and where are we headed<br>[21] Unleashing the power of Iceberg ingestion 100GB/s and beyond<br>[22] Building a Batch-Stream-Unified Lakehouse on Apache Iceberg in Tencent Cloud<br>[23] Eliminating redundancies in ETL with Iceberg tables on Snowflake<br>[24] From zero to one: Building a petabyte-scale data analytics platform with Apache Iceberg<br>[25] Hive Tables to Apache Iceberg: A Step by step Migration Blueprint<br>[26] Iceberg with Flink at DoorDash<br>[27] Implement Iceberg for Improved Data Management at Autodesk<br>[28] Postgres meets Iceberg<br>[29] Supercharging wise data lake with apache iceberg<br>[30] The ‘Streamhouse’: Extending Redpanda into a fully managed, Iceberg-backed realtime data lakehouse<br>[31] Adopting Apache Iceberg at Slack: Challenges, Lessons, and Best Practices</p>\n","site":{"data":{}},"excerpt":"<p>本次 Iceberg Summit 2025[0] 上行业内众多公司做了分享，包括 Iceberg 核心技术、使用案例，优化方案，未来走向等等。其中国内的腾讯（两个 talk），小米，小红书均有分享，整体内容不错，这里做一个总结，更详细的请参考原视频。</p>","more":"<h1 id=\"Beyound-Iceberg’s-ongoing-evolution\"><a href=\"#Beyound-Iceberg’s-ongoing-evolution\" class=\"headerlink\" title=\"Beyound Iceberg’s ongoing evolution\"></a>Beyound Iceberg’s ongoing evolution</h1><p>首先是 Iceberg 的 PMC member Ryan Blue 的 talk[1], 这个 talk 整体介绍了 Iceberg 的过去，现在以及将来的一些事情。Iceberg 现在已经成为湖仓的事实标准，在各大公司被官方使用，在湖仓一体/流批一体等方案中作为共享存储存在，提供了 ACID，time travel，branch，tag 等各种功能，支持了众多查询引擎，整体生态非常繁荣。</p>\n<p>最近一年已经完成或者正在进行的一些重大特性包括</p>\n<ul>\n<li>Geo type 的支持，更好的支持地图数据</li>\n<li>Variant type 的支持，可以支持半结构化数据（这个另外一个 talk 单独有讲）</li>\n<li>全表加密（data 和 metadata）</li>\n<li>deletion vector  — 更好的 position deletes（有另外一个 talk 单独讲），在性能、文件数量以及维护成本做了一个均衡</li>\n<li>row lineage，主要方便增量消费以及数据的校验等</li>\n</ul>\n<p>在 Iceberg 中增加新的数据类型可以带来：1）有标准，各引擎更方便交互；2）能够借用 Iceberg 的 Metadata/Index 等做查询优化。</p>\n<p>另外在广泛使用过程中，大家也有提出来一些有关 metadata 的痛点，比如</p>\n<ul>\n<li>manifest 相关<ul>\n<li>文件可能会比较多：先生成 manifest 然后是 manifest list；manifest 会重写最后删除</li>\n<li>现在对小表不太友好（实际中有很多小表）：scan 需要走 manifest list 然后顺序的访问每个 manifest 文件</li>\n<li>manifest 文件太多：导致 metadata 需要周期性合并</li>\n</ul>\n</li>\n<li>故障恢复比较困难: file replication  不够恢复整张表；metadata 需要重写（主要是绝对路径）</li>\n<li>列信息是二进制的：对扩展类型不优化（比如 geo/variant 等)</li>\n<li>plan 性能可以更好: 需要读取所有列信息（不在 filter 中的列信息也需要读取）</li>\n<li>Metadata skipping 需要分区信息：数据倾斜处理不好；无法和 geo 数据很好的结合；容易过度分区</li>\n</ul>\n<p>针对这些问题，也有一些相应的规划，整体思路是 metadata 往 adaptive tree structure方向走，adaptive tree structure 加上 RestCatalog, 再加上 servcie 就更像 DB 了。</p>\n<p>adaptive tree structure 大致如下<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20250512145432.png\" alt=\"\"></p>\n<p>另外 Iceberg 也在如下一下方面有考虑</p>\n<ul>\n<li>Relative paths：主要是为了容灾、故障恢复考虑</li>\n<li>Columnar metadata: 更方便跳过不需要的 column stat；typed lower/upper bounds/alternative sort orders</li>\n<li>Adaptive metadata &amp; Unified manifests: 更好的 manifest 结构，主要适配多模态数据，优化小表，manifest 的维护性等。</li>\n</ul>\n<p>后文中会从如下几方面展开描述</p>\n<ul>\n<li>Manifest/Index：表元数据相关</li>\n<li>Catalog: Catalog 相关</li>\n<li>Compute&amp;Management(Optimiztion&amp;Service): 表查询和管理相关</li>\n<li>File format: file format 相关</li>\n<li>Streaming: 流式入湖</li>\n<li>Ecosystem(&amp;usecase&amp;migration): 生态以及迁移到 Iceberg</li>\n</ul>\n<h1 id=\"Matadata-manifest-Index\"><a href=\"#Matadata-manifest-Index\" class=\"headerlink\" title=\"Matadata(manifest/Index)\"></a>Matadata(manifest/Index)</h1><p>Iceberg 的 metadata 是核心组件，包括了支持各种功能以及查询优化所必需的信息，这里介绍一些和 metadata 相关的演讲内容。更详细的可以查看原视频（下同）。</p>\n<p>本次 Summit 中有介绍 Iceberg （正在）支持多种类型：geo 类型[2]，variant 类型[3]，支持了 deletion vector[4] — 更好的 position delete。</p>\n<p>也有尝试将 Iceberg 的 metadata 暴露成常规的 Iceberg 表方便分析的[5]，演讲中有介绍使用 PG 来承载 metadata 的分析，发现量大之后会遇到性能瓶颈，因此希望 Iceberg 原生支持将 metadata 暴露为标准表。</p>\n<p>其中增加新类型主要是定义标准以及优化查询，geo 主要是地图相关的数据（点、线，区域等），而 variant 则主要是支持半结构化的数据 — 比如 json。variant 在 log/event 等数据类型中大量使用，IoT/Telemetry 数据非常多，variant 的支持还有一个就是增加 shredding 过程，用于进一步加速。</p>\n<p>在 position delete 的基础上演化出了 delete vector，出要出发点在于不管是 partition-level 还是 file-level 的 position delete 文件都有局限。因此演化成现在的 delete vector 方式，这样磁盘和内存中的数据结构统一，每条数据仅会被删除一次，文件数也大大减少。</p>\n<p>也有一些分享提了类似[29] first-row/last-row 的 merge option 等需求。</p>\n<h1 id=\"Catalog\"><a href=\"#Catalog\" class=\"headerlink\" title=\"Catalog\"></a>Catalog</h1><p>Catalog 主要负责表层面的元数据，包括最新的元数据，事物控制协调等。现在 Iceberg 提供了多种类型的 Catalog 供用户选择。</p>\n<p>本次 Summit 中有用户介绍使用 Catalog 的具体情况[6]，也有介绍 RestCatalog 的相关事情[7][8][9]。</p>\n<p>其中 Bloomberg 对不同的 catalog 有一些总结如下</p>\n<ul>\n<li>Hive<ul>\n<li>Easiest to utilize, as we were already using the ApacheHive Metastore</li>\n<li>Scale and performance challenges</li>\n</ul>\n</li>\n<li>AWS Glue<ul>\n<li>managed service</li>\n<li>vendor lock-in</li>\n<li>access control limited through AWS primitives</li>\n</ul>\n</li>\n<li>JDBC<ul>\n<li>Easy and familiar to manage and connect to a database</li>\n<li>access control limited through AWS or DB primitives</li>\n</ul>\n</li>\n<li>Rest<ul>\n<li>Gave use the most flexibility to support the Iceberg Spec and additional custom features</li>\n<li>Flexible integration with different query engines</li>\n<li>Backed by a PostgreSQL database</li>\n<li>Provided the most flexibility on access control and multi-tenancy</li>\n</ul>\n</li>\n</ul>\n<p>[7][8]分享了 RestCatalog 的由来。RestCatalog 从最初解决 HiveCatalog 的问题出发（锁粒度，以及事物控制等），分析了一个 Catalog 需要满足的条件：可靠性，低延迟提交；事物/冲突管理；客户端的兼容性；数据的权限等。Iceberg 的 RestCatalog 将部分客户端的职责移到 server 端，这样客户端更轻量级；更好的事物控制（DML/DDL 的协调，合并和实时写入的协调），多表事物控制；客户端更好实现（更轻量级，更方便多语言实现）。以及 Apache Polaris 的一些实际使用情况。</p>\n<p>[9] 分享了 Pinterest 使用 Gravtino 解决 Iceberg 过程中的一些实际问题，包括：partition list 很慢；性能分析；已经引擎相关的性能问题等。</p>\n<h1 id=\"Compute-amp-Management\"><a href=\"#Compute-amp-Management\" class=\"headerlink\" title=\"Compute&amp;Management\"></a>Compute&amp;Management</h1><p>数据存储后会被查询使用，为了查询效率高也需要对数据进行管理优化。</p>\n<p>[10] 主要分享了不同参数下 Iceberg 表的性能情况。主要在 file format 层面的调优，包括 <code>write.target-file-size-bytes</code> 和 <code>write.parquet.row-group-size-bytes</code> 的调优实践。一些具体的测试数据如下：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>metric</th>\n<th>2mb row-group size(unsorted)</th>\n<th>128mb row group size(unsorted)</th>\n<th>2m row group size(sorted)</th>\n<th>128mb row group size(sorted)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>num_columns</td>\n<td>21</td>\n<td>21</td>\n<td>21</td>\n<td>21</td>\n</tr>\n<tr>\n<td>num_rows</td>\n<td>391844</td>\n<td>391844</td>\n<td>1794155</td>\n<td>656682</td>\n</tr>\n<tr>\n<td>num_row_groups</td>\n<td>33</td>\n<td>1</td>\n<td>150</td>\n<td>1</td>\n</tr>\n<tr>\n<td>serialized_size</td>\n<td>94736</td>\n<td>4824</td>\n<td>424318</td>\n<td>4799</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>并测试了不同引擎下的查询效率</p>\n<ul>\n<li>unsorted 情况下 2MB vs 128MB row group size 性能可以提升 15%</li>\n<li>sorted 的情况下 2MB vs 128MB row group size 性能可以提升 177%</li>\n</ul>\n<p>[11] 分享了 Impala 优化 Iceberg MOR 的流程，主要思路是避免无限重复读取 delete 文件，单独一个算子读取 delete 文件，然后使用 broadcast join 来进行数据的删除。</p>\n<p>[12] 分享了如果给 Iceberg 查询做 I/O 优化进行加速，主要思路是尽可能的进行 filter pushdown — <code>filter pushdown is the gold standard of I/O optimizations</code></p>\n<p>由于不是所有的 filter 都能够 pushdown，可以可能需要 rewrite SQL。现在 Iceberg 中 filter pushdown 会有如下约束</p>\n<ul>\n<li>Filters are only useful if they eliminate entire partitions or data files</li>\n<li>Limited set of statistics to evaluate with<ul>\n<li>Lower and upper bounds</li>\n<li>Null, NAN, Value Counts</li>\n<li>Partition Values</li>\n<li>Not as useful for non-numberic cols</li>\n</ul>\n</li>\n<li>Complex filters contain compute functions<ul>\n<li>Iceberg transforms are only a subset</li>\n</ul>\n</li>\n</ul>\n<p>然后给出了一些 rewrite 的具体例子</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Before</th>\n<th>After(completely pushable)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>coalese(date, TODAY) &lt;= TODAY</td>\n<td>date is null or date &lt;= TODAY</td>\n</tr>\n<tr>\n<td>zip_code in (12345, 54321, 31524)</td>\n<td>zip_code = 12345 or zip_code = 54321 or zip_code = 31524</td>\n</tr>\n<tr>\n<td>size / 2.0 &gt; PARAM</td>\n<td>size &gt; PARAM * 2.0</td>\n</tr>\n<tr>\n<td>username LIKE ‘bill%’</td>\n<td>STARTSWITH(username, ‘bill’);</td>\n</tr>\n<tr>\n<td>tag ILIKE ‘A’</td>\n<td>tag = ‘A’ or tag = ‘a’</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>对于无法全部下推的，可以考虑部分下推，如下所示</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>original</th>\n<th>runtime filter</th>\n<th>file-level filter</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>url like ‘<a href=\"http://%.com%\">http://%.com%</a></td>\n<td>startswith(url, ‘http://‘) and contains(url, ‘.com’)</td>\n<td>startswith(url, ‘http://‘)</td>\n</tr>\n<tr>\n<td>lower(name) = ‘adam’ (name ilike ‘adam’)</td>\n<td>lower(name) = ‘adam’)</td>\n<td>name = ‘ADAM’ and name =’adam’</td>\n</tr>\n<tr>\n<td>qyt INT &gt; 100</td>\n<td>qty INT &gt; 100</td>\n<td>qty is NOT null</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>在最后对 Iceberg Metadata 提出一些需求，希望未来有更多可用于 file pruning 的 metadata 信息。</p>\n<p>[13] 分享了 partition stats 的背景，当前情况等。主要是为了更好优化查询(CBO 过程)。</p>\n<p>现在 Iceberg 有 FileLevel/Manifest Level/Snapshot Level 的指标，希望有 partition level 的指标。由于实际场景中大部分是分区表，因此 partition level 指标在现实世界中有很多使用场景。</p>\n<ul>\n<li>避免读取所有的 manifest（有些表的 manifest 非常多）</li>\n<li>在 plan 的时候可以 autoscaling（根据 partition level 指标动态调整并发）</li>\n<li>动态调整 query plan（join reordering，IO operator）</li>\n<li>仅在最新 snapshot 中 partition 会影响查询时进行合并</li>\n<li>根据 partition 指标刷新数据写入链路（Two sigma 无法 expire snapshot 的例子）</li>\n</ul>\n<p>[14] 分享了 Iceberg 的跨集群复制以及灾难恢复，主要思路是基于 snapshot 的增量复制。</p>\n<p>[15] 腾讯(TEG) 分享了处理超宽表的一些线上生产经验，主要在 ML/DL 等场景下，会有上千列的情况。主要问题有：</p>\n<ul>\n<li>表太宽，单表上 P<ul>\n<li>单表上千万的文件数量，上千数量的 manifest 文件</li>\n<li>plan 性能瓶颈</li>\n<li>batch 写入消耗内存多，容易导致 OOM</li>\n</ul>\n</li>\n<li>列管理困难<ul>\n<li>不是所有列的价值都一样</li>\n<li>列的频繁增删</li>\n</ul>\n</li>\n</ul>\n<p>整体的思路包括：减少不必要的元数据（比如指标）；通过 column stats 知道列的使用频率，然后进行调整；将 datafile 合并到 manifest file 中，减少文件数量；另外在合并的时候通过直接操作 parquet 来加速等一系列优化方案。更详细的可以查看对应视频。</p>\n<p>[16][17][18] 有讲表管理、优化相关的事情（和 Amoro 定位类似，Linkdin 开源了他们的  OpenHouse），这里面有比较多实际生产经验可以借鉴，包括合并策略、资源优化、扩展性、观测性（用户侧，服务侧）、告警等</p>\n<p>[22] 分享了腾讯云基于 Amoro 做的流批一体的湖仓系统，包括 MixedIceberg 承接实时数据，以及支持 partial update 等需求。</p>\n<h1 id=\"File-format\"><a href=\"#File-format\" class=\"headerlink\" title=\"File format\"></a>File format</h1><p>为了满足不同的场景（尤其是 ML&amp;AI），有不同的 file format 出来(lance, vertox 等)，如何在 Iceberg 中结合新型 file format 的能力是一个社区正在做的事情。</p>\n<p>[19]分享了 fileformat 出现的一些原因，以及 Iceberg 正在做的事情 — 抽象 FileReader/Writer 的接口等。</p>\n<ul>\n<li>ML workload 的特点<ul>\n<li>wide columns</li>\n<li>both scan &amp; search</li>\n<li>grow horizontally(wide schema)</li>\n</ul>\n</li>\n<li>新硬件的特点<ul>\n<li>not just(or even primarily) run on CPUS</li>\n<li>Accelerators like GPU &amp; FPGA are embarrassingly parallel</li>\n<li>Common bottlenecks: CPU, Copying to device memory</li>\n<li>IDEA: Load compressed data, decompress on-device</li>\n</ul>\n</li>\n</ul>\n<p>新的 file-format 要求和特点如下所示</p>\n<ul>\n<li>要求<ul>\n<li>Decompression via GPU SIMT</li>\n<li>Decompression via CPU SIMD</li>\n<li>Random access on compressed data</li>\n</ul>\n</li>\n<li>特点<ul>\n<li>workload diversity</li>\n<li>flexibility &amp; interop</li>\n<li>accelerated computing</li>\n</ul>\n</li>\n</ul>\n<p>[15] 中腾讯的分享是在 parquet 中做的一些工作。</p>\n<h1 id=\"Streaming\"><a href=\"#Streaming\" class=\"headerlink\" title=\"Streaming\"></a>Streaming</h1><p>随着大家对实时入湖的需求，以及 Iceberg 在实时入湖上的现状，大家在寻找时效性，湖仓治理的一个平衡点。</p>\n<p>不同公司也在尝试实时入湖的事情，如何做到时效性、管理成本等的平衡是一个难点。</p>\n<p>[20] 分享了 Snowflake 在 Iceberg 上做增量计算的一些事情，这个分享包括了增量计算的定义，以及在 snowflake 中实现的一些思路，思路大概是通过 row_id 来记录数据的演进（row_id 也可以当成 watermark），然后通过代数变换讲 join 等算子变换为增量计算的算子减少计算量。比较麻烦的是多表事物的处理 — 需要有一个全局的时间。</p>\n<p>[21] 分享了实时入湖效率，以及后续湖仓内数据治理的一些实测数据，希望达到一个全局的最优，主要思路是在不影响 compaction 的情况下增大入湖效率（增大写入并发），然后通过类似 RestCatalog 的角色来协调 commit。另外会对一些错误配置等提前预判并通知。</p>\n<p>[26] 分享了如何实时入湖相关的事情，并给出了从 Snowflake 迁移到 Iceberg 的一些情况，并且基于实际情况提出了 Flink Dynamic Schama 的需求，在最新的 Sink 中有相关的工作正在进行中。</p>\n<h1 id=\"Ecosystem-amp-usecase-amp-migration\"><a href=\"#Ecosystem-amp-usecase-amp-migration\" class=\"headerlink\" title=\"Ecosystem(&amp;usecase &amp;migration)\"></a>Ecosystem(&amp;usecase &amp;migration)</h1><p>[6] 有分享迁移到 Iceberg 前后的收益</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Before Iceberg</th>\n<th>After Iceberg</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Full daily restatements of 7TB+</td>\n<td>Incremental daily revision between 5~10 GB(&lt;1% of total table)</td>\n</tr>\n<tr>\n<td>High ingestion overhead</td>\n<td>Streamlined ingestion and processing</td>\n</tr>\n<tr>\n<td>Slow processing and costly storage</td>\n<td>Efficiency gains in storage and compute</td>\n</tr>\n<tr>\n<td>Hard to diagnose and debug data quality</td>\n<td>Easier to diagnose and debug data quality</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>[17][25][27]分享了 Hive 迁移到 Iceberg 的一些事情，描述了 Hive 的一些限制：partition 支持不好；ACID 支持不好，性能，扩展性，多引擎支持等等，以及从 Hive 迁移到 Iceberg 的详细流程和 checklist，包括前期分析，迁移计划，具体执行，以及最后验证等，对于 Hive 迁移 Iceberg 的可以参考下。从 Hive 迁移到 Iceberg 后，整体减少了 70% 的资源，查询峰值时间降低了 95%，对于 streaming 入湖也更简单了。</p>\n<p>[9] 使用 Iceberg 做流批一体存储，链路大致如下 [upstream] -&gt; kafka -&gt; flink -&gt; Iceberg -&gt; [Flink/Spark]，使用了两张表来承接实时数据：其中一张表保留全量数据，一张表保留增量数据，增量数据周期性写入全量表（Amoro 中的 mixed-iceberg 思路类似）。</p>\n<p>[23] 分享了使用 Trino 做可扩展的湖仓，主要解决如下问题：扩展性；管理难度；查询性能慢；vendor lock-in 等。</p>\n<p>在扩展性方面遇到：metadata 增长；不同的 workload；查询性能的稳定；数据倾斜的处理以及限速等。</p>\n<p>基于生产经验总结了一些最佳实践：</p>\n<ul>\n<li>读方面：使用 NDV Status，filter pushdown， metadata/data cache，materialized view(trino），合适的线程池大小等</li>\n<li>写方面（主要是 trino 相关）：限制写入并发；数据合理分区，专用 plan/delete 的线程池等</li>\n</ul>\n<p>[23] 分享了使用 Iceberg 做统一存储后，避免在各系统之间进行数据的传输，计算等，减少了整体的计算和存储量。</p>\n<p>[24] 分享了构建基于 Iceberg(+StarRocks/BigQuery) 的大规模分析系统，并且在生产中实现了 blue/green 的常规流程。 使用 Iceberg 前后的对比如下所示（之前是 PG 和 BigQuery）</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Before</th>\n<th>After</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>大查询经常超时</td>\n<td>查询耗时大规模减少  P95 2.976s  Avg 1.65s</td>\n</tr>\n<tr>\n<td>increasing SSD costs to store ever increasing volumes of data</td>\n<td>数据可以 offload 到 object storage</td>\n</tr>\n<tr>\n<td>存算一体（耦合）</td>\n<td>存算分离（可以单独扩展）</td>\n</tr>\n<tr>\n<td>Hourly and daily data loads frequently resulted in SLO misses</td>\n<td>存储只需要在一个地方就行</td>\n</tr>\n<tr>\n<td>无法很容易的换计算引擎</td>\n<td>可以使用多引擎查询</td>\n</tr>\n<tr>\n<td>数据太大需要从 PG 切到 BigQuery，无法在 on-premise 环境</td>\n<td>可以在 on-premise 环境使用</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>[28] 则分享了 PG 支持 Iceberg 外表的一些情况，这样可以结合 PG 和 Iceberg 的能力。</p>\n<p>[30] 分享了 Redpanda 的 iceberg table，听起来和Automq 的 iceberg table 以及 fluss 有相似之处，可以将 MQ 的数据直接 compaction 到 datalake 中，这块或许一个完整的是，有轻量级 MQ + service 能力负责 offload 和 compaction，以及现在的 datalake。</p>\n<p>[31] 则分享了生产中实际情况，比如使用 storage partitioned join 来避免大量 shuffle 的场景。</p>\n<p>另外类似 Trino/StarRocks/BigQuery 等引擎均在大会上分享介绍如何结合 Iceberg 的，在语言方面，除了 Java 之外，现在 Python/Rust/C++ 等语言也在积极推动中。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[0] <a href=\"https://www.icebergsummit2025.com/agenda/\">https://www.icebergsummit2025.com/agenda/</a><br>[1] V3 and Beyond Iceberg’s ongoing evolution<br>[2] Decoupling Metadata: Leveraging Queryable Iceberg Tables for Scalable, Cross-Engine Innovation<br>[3] Understanding Deletion Vectors in Apache Iceberg<br>[4] Iceberg Geo Type: Transforming Geospatial Data Management at Scale<br>[5] Decoupling Metadata: Leveraging Queryable Iceberg Tables for Scalable, Cross-Engine Innovation<br>[6] Building Bloomberg’s First Incremental Alternative Data Product Using Apache Iceberg<br>[7] Pioneering the Next Frontier: The REST Revolution in Apache Iceberg Metadata<br>[8] Scalable Lakehouse Architecture with Iceberg &amp; Polaris: A Battle-tested Playbook<br>[9] Scaling Iceberg Adoption at Pinterest with Gravtino<br>[10] Deep Dive into Iceberg Optimizations and Best Practices for a Scalable and Performant Lakehouse<br>[11] Extending the One Trillion Row Challenge to Iceberg V2 Tables<br>[12] Iceberg I/O Optimizations in Compute Engines<br>[13] Supercharging Apache Iceberg Strategies for Harnessing Partition Stats<br>[14] Iceberg Resilience: Building a DR Strategy for the Data Lake<br>[15] Efficiently Managing Table With Thousands of Columns Using Iceberg In Tencent<br>[16] Learning from running large-scale Apache Iceberg Table Management Service<br>[17] Airbnb Icehouse: The Journey to Iceberg<br>[18] Optimizing Iceberg Table Layouts at Scale: A Multi-Objective Approach<br>[19] Turbocharge Queries on Iceberg with Next-Gen File Formats<br>[20] CDC Implementations on Apache Iceberg and where are we headed<br>[21] Unleashing the power of Iceberg ingestion 100GB/s and beyond<br>[22] Building a Batch-Stream-Unified Lakehouse on Apache Iceberg in Tencent Cloud<br>[23] Eliminating redundancies in ETL with Iceberg tables on Snowflake<br>[24] From zero to one: Building a petabyte-scale data analytics platform with Apache Iceberg<br>[25] Hive Tables to Apache Iceberg: A Step by step Migration Blueprint<br>[26] Iceberg with Flink at DoorDash<br>[27] Implement Iceberg for Improved Data Management at Autodesk<br>[28] Postgres meets Iceberg<br>[29] Supercharging wise data lake with apache iceberg<br>[30] The ‘Streamhouse’: Extending Redpanda into a fully managed, Iceberg-backed realtime data lakehouse<br>[31] Adopting Apache Iceberg at Slack: Challenges, Lessons, and Best Practices</p>"},{"_content":"\n在[上篇文章的末尾]()我们提到做决策相关的事情，本文介绍下 《Clear Thinking》这本书，以及自己的一些看法。\n\n这本书主要讲清晰思考以，以及如何做决策。本书主要有 5 部分：第一部分描述了 clear thinking 的敌人，也就是说什么会导致偏离 clear thinking；第二部分则描述了可以加强的方面，从而更好的 clear thinking；第三部分则描述了那些无法避免的弱点，通过怎么避免弱点影响自己；第四部分则以决策为例来描述 clear thinking 的应用；第五部分描述了：你最想要的是什么。最终对 clear thinking 的价值进行了总结。\n\n> They seemed to know something that was not commonly known, and I was determined to find out what.\n> While the rest of us are chasing victory, the best in the world know they must avoid losing before they can win. It turns out this is a surprisingly effective strategy.\n\n> Decisions made through clear thinking will put you in increasingly positions, and success will only compound from there.\n\n在前面的文章中说的，复利中后面增长快，是因为前面已经有不错的基础（涨上去了），复利也是因为没有更差（负增长），因此能够涨上去，只要不变的更差，那么总能涨上去。\n\n不变差是一种思维，就是要尽量考虑不要变的更差，然后通过复利来让自己变的更好。不变差的思维并不是说一定不会变差，而是希望在前期把那些可能变差的考虑清楚，然后避免掉。和《1 不要亏钱；2 基于第一点》一样，另外和《胜负已分，然后兴师动众》- 孙子兵法中的思想类似，先胜后战。\n\n延伸有一点：无聊的胜利好过热烈的失败。\n\n> If there is a tagline to my life, it is \"Mastering the best of what other people have already figured out\", and this book is a tribute to that belief.\n学习别人已经验证过的精华是一个很好的经验。\n\n<clear thinking> 的读书笔记，这本书讲了 xxx\n\n\n往往有一个误区：只有那些重大策略会改变自己的生活，实际上不是的，自己平时的选择也会改变自己的生活，而且重大决策可能也以不起眼的形式出现。\n\n如果 clear thinking 不是那么好理清楚的话，那么首先来看看 clear thinking 的对立面，clear thinkinkg 的对立面会让我们看不清自己正在经历什么，以及让自己的生活更有挑战。\n\n\n每个决策会让自己变的更好，或者更差 -- 生活更容易或者更难。clear thinking 则是让生活更容易，或者不变的更难。\n\n> You don't need to be smarter than others to outperform them if you can out-position them\n如果位置更好的话，不需要更聪明就能有更好的产出。\n\n> Time is the friend of someone who is properly positioned and the enemy of someone poorly positioned.\n\n需要给自己留 buffer\n\n> What a lot of people miss is that ordinary moments determine your position, and your position determines your options.\n平时的决策决定 position，position 决定了自己的选项\n\n> It doesn't matter what position you find yourself in right now. What matters is wheter you improve your position today.\n重点不是现在，还是未来是不是更好。\n\n\n第一部分\nThe enemies of clear thinking\n","source":"_drafts/clear-thinking.md","raw":"\n在[上篇文章的末尾]()我们提到做决策相关的事情，本文介绍下 《Clear Thinking》这本书，以及自己的一些看法。\n\n这本书主要讲清晰思考以，以及如何做决策。本书主要有 5 部分：第一部分描述了 clear thinking 的敌人，也就是说什么会导致偏离 clear thinking；第二部分则描述了可以加强的方面，从而更好的 clear thinking；第三部分则描述了那些无法避免的弱点，通过怎么避免弱点影响自己；第四部分则以决策为例来描述 clear thinking 的应用；第五部分描述了：你最想要的是什么。最终对 clear thinking 的价值进行了总结。\n\n> They seemed to know something that was not commonly known, and I was determined to find out what.\n> While the rest of us are chasing victory, the best in the world know they must avoid losing before they can win. It turns out this is a surprisingly effective strategy.\n\n> Decisions made through clear thinking will put you in increasingly positions, and success will only compound from there.\n\n在前面的文章中说的，复利中后面增长快，是因为前面已经有不错的基础（涨上去了），复利也是因为没有更差（负增长），因此能够涨上去，只要不变的更差，那么总能涨上去。\n\n不变差是一种思维，就是要尽量考虑不要变的更差，然后通过复利来让自己变的更好。不变差的思维并不是说一定不会变差，而是希望在前期把那些可能变差的考虑清楚，然后避免掉。和《1 不要亏钱；2 基于第一点》一样，另外和《胜负已分，然后兴师动众》- 孙子兵法中的思想类似，先胜后战。\n\n延伸有一点：无聊的胜利好过热烈的失败。\n\n> If there is a tagline to my life, it is \"Mastering the best of what other people have already figured out\", and this book is a tribute to that belief.\n学习别人已经验证过的精华是一个很好的经验。\n\n<clear thinking> 的读书笔记，这本书讲了 xxx\n\n\n往往有一个误区：只有那些重大策略会改变自己的生活，实际上不是的，自己平时的选择也会改变自己的生活，而且重大决策可能也以不起眼的形式出现。\n\n如果 clear thinking 不是那么好理清楚的话，那么首先来看看 clear thinking 的对立面，clear thinkinkg 的对立面会让我们看不清自己正在经历什么，以及让自己的生活更有挑战。\n\n\n每个决策会让自己变的更好，或者更差 -- 生活更容易或者更难。clear thinking 则是让生活更容易，或者不变的更难。\n\n> You don't need to be smarter than others to outperform them if you can out-position them\n如果位置更好的话，不需要更聪明就能有更好的产出。\n\n> Time is the friend of someone who is properly positioned and the enemy of someone poorly positioned.\n\n需要给自己留 buffer\n\n> What a lot of people miss is that ordinary moments determine your position, and your position determines your options.\n平时的决策决定 position，position 决定了自己的选项\n\n> It doesn't matter what position you find yourself in right now. What matters is wheter you improve your position today.\n重点不是现在，还是未来是不是更好。\n\n\n第一部分\nThe enemies of clear thinking\n","slug":"clear-thinking","published":0,"date":"2025-05-06T02:48:51.645Z","updated":"2025-05-06T02:48:51.645Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cmaw5b6520000w3mk9k9o7vwn","content":"<p>在<a href=\"\">上篇文章的末尾</a>我们提到做决策相关的事情，本文介绍下 《Clear Thinking》这本书，以及自己的一些看法。</p>\n<p>这本书主要讲清晰思考以，以及如何做决策。本书主要有 5 部分：第一部分描述了 clear thinking 的敌人，也就是说什么会导致偏离 clear thinking；第二部分则描述了可以加强的方面，从而更好的 clear thinking；第三部分则描述了那些无法避免的弱点，通过怎么避免弱点影响自己；第四部分则以决策为例来描述 clear thinking 的应用；第五部分描述了：你最想要的是什么。最终对 clear thinking 的价值进行了总结。</p>\n<blockquote>\n<p>They seemed to know something that was not commonly known, and I was determined to find out what.<br>While the rest of us are chasing victory, the best in the world know they must avoid losing before they can win. It turns out this is a surprisingly effective strategy.</p>\n<p>Decisions made through clear thinking will put you in increasingly positions, and success will only compound from there.</p>\n</blockquote>\n<p>在前面的文章中说的，复利中后面增长快，是因为前面已经有不错的基础（涨上去了），复利也是因为没有更差（负增长），因此能够涨上去，只要不变的更差，那么总能涨上去。</p>\n<p>不变差是一种思维，就是要尽量考虑不要变的更差，然后通过复利来让自己变的更好。不变差的思维并不是说一定不会变差，而是希望在前期把那些可能变差的考虑清楚，然后避免掉。和《1 不要亏钱；2 基于第一点》一样，另外和《胜负已分，然后兴师动众》- 孙子兵法中的思想类似，先胜后战。</p>\n<p>延伸有一点：无聊的胜利好过热烈的失败。</p>\n<blockquote>\n<p>If there is a tagline to my life, it is “Mastering the best of what other people have already figured out”, and this book is a tribute to that belief.<br>学习别人已经验证过的精华是一个很好的经验。</p>\n</blockquote>\n<p><clear thinking> 的读书笔记，这本书讲了 xxx</p>\n<p>往往有一个误区：只有那些重大策略会改变自己的生活，实际上不是的，自己平时的选择也会改变自己的生活，而且重大决策可能也以不起眼的形式出现。</p>\n<p>如果 clear thinking 不是那么好理清楚的话，那么首先来看看 clear thinking 的对立面，clear thinkinkg 的对立面会让我们看不清自己正在经历什么，以及让自己的生活更有挑战。</p>\n<p>每个决策会让自己变的更好，或者更差 — 生活更容易或者更难。clear thinking 则是让生活更容易，或者不变的更难。</p>\n<blockquote>\n<p>You don’t need to be smarter than others to outperform them if you can out-position them<br>如果位置更好的话，不需要更聪明就能有更好的产出。</p>\n<p>Time is the friend of someone who is properly positioned and the enemy of someone poorly positioned.</p>\n</blockquote>\n<p>需要给自己留 buffer</p>\n<blockquote>\n<p>What a lot of people miss is that ordinary moments determine your position, and your position determines your options.<br>平时的决策决定 position，position 决定了自己的选项</p>\n<p>It doesn’t matter what position you find yourself in right now. What matters is wheter you improve your position today.<br>重点不是现在，还是未来是不是更好。</p>\n</blockquote>\n<p>第一部分<br>The enemies of clear thinking</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在<a href=\"\">上篇文章的末尾</a>我们提到做决策相关的事情，本文介绍下 《Clear Thinking》这本书，以及自己的一些看法。</p>\n<p>这本书主要讲清晰思考以，以及如何做决策。本书主要有 5 部分：第一部分描述了 clear thinking 的敌人，也就是说什么会导致偏离 clear thinking；第二部分则描述了可以加强的方面，从而更好的 clear thinking；第三部分则描述了那些无法避免的弱点，通过怎么避免弱点影响自己；第四部分则以决策为例来描述 clear thinking 的应用；第五部分描述了：你最想要的是什么。最终对 clear thinking 的价值进行了总结。</p>\n<blockquote>\n<p>They seemed to know something that was not commonly known, and I was determined to find out what.<br>While the rest of us are chasing victory, the best in the world know they must avoid losing before they can win. It turns out this is a surprisingly effective strategy.</p>\n<p>Decisions made through clear thinking will put you in increasingly positions, and success will only compound from there.</p>\n</blockquote>\n<p>在前面的文章中说的，复利中后面增长快，是因为前面已经有不错的基础（涨上去了），复利也是因为没有更差（负增长），因此能够涨上去，只要不变的更差，那么总能涨上去。</p>\n<p>不变差是一种思维，就是要尽量考虑不要变的更差，然后通过复利来让自己变的更好。不变差的思维并不是说一定不会变差，而是希望在前期把那些可能变差的考虑清楚，然后避免掉。和《1 不要亏钱；2 基于第一点》一样，另外和《胜负已分，然后兴师动众》- 孙子兵法中的思想类似，先胜后战。</p>\n<p>延伸有一点：无聊的胜利好过热烈的失败。</p>\n<blockquote>\n<p>If there is a tagline to my life, it is “Mastering the best of what other people have already figured out”, and this book is a tribute to that belief.<br>学习别人已经验证过的精华是一个很好的经验。</p>\n</blockquote>\n<p><clear thinking> 的读书笔记，这本书讲了 xxx</p>\n<p>往往有一个误区：只有那些重大策略会改变自己的生活，实际上不是的，自己平时的选择也会改变自己的生活，而且重大决策可能也以不起眼的形式出现。</p>\n<p>如果 clear thinking 不是那么好理清楚的话，那么首先来看看 clear thinking 的对立面，clear thinkinkg 的对立面会让我们看不清自己正在经历什么，以及让自己的生活更有挑战。</p>\n<p>每个决策会让自己变的更好，或者更差 — 生活更容易或者更难。clear thinking 则是让生活更容易，或者不变的更难。</p>\n<blockquote>\n<p>You don’t need to be smarter than others to outperform them if you can out-position them<br>如果位置更好的话，不需要更聪明就能有更好的产出。</p>\n<p>Time is the friend of someone who is properly positioned and the enemy of someone poorly positioned.</p>\n</blockquote>\n<p>需要给自己留 buffer</p>\n<blockquote>\n<p>What a lot of people miss is that ordinary moments determine your position, and your position determines your options.<br>平时的决策决定 position，position 决定了自己的选项</p>\n<p>It doesn’t matter what position you find yourself in right now. What matters is wheter you improve your position today.<br>重点不是现在，还是未来是不是更好。</p>\n</blockquote>\n<p>第一部分<br>The enemies of clear thinking</p>\n"},{"_content":"自己的事情最终只能是自己负责，比如自己的事情，那别人最多只能帮助建议，最终还是得看自己，因为最终的决策／行动需要自己做；另外别人的事情，也最终只能 ta 自己做，自己无法替 ta 做。\n\n需要区分哪些是自己的事情，哪些是别人的事情。\n\n\n对一个事情，可能有一些阶段：不知道和知道，知道之后，是否能做到；能做到分为两种：需要自己主动注意的做到，还是形成习惯；如果能够形成习惯，那就属于自己了。\n\n这也是知行合一。\n\n其中让自己知道（比如将一些 问题/解决方案 等 能够很明显的让自己看到 -- 也就是可视化）是其中一步，也是很重要的一步。\n\n在知道后，需要有场景能够不断的联系，形成习惯/下意识。\n\n\n\n对于一件事情，按照责任相关的来划分的话，可以加上一个维度 功劳，变成 2 * 2 的矩阵\n\n|  | - | +\n| --- | --- | --- |\n| -   |  0   |  1 |\n| +   | 2   | 3|\n\n或者也可以弄成 3 * 3 的矩阵\n\n|  | - | 0 | + |\n| --- | --- | --- |\n| -  | 1 | 2 | 3 |\n| 0 | 4 | 5 | 6 |\n| + | 7 | 8 | 9 |\n\n可以先把模型中的格子排一个顺序，然后在有具体事情的时候，可以往模型里面套\n\n\n\n尽量把事情给 offload（比如写下来）这样减少自己思考时候的脑力消耗\n\n\n另外可以提前做一些预演，比如同时遇到了某两个格子内的事情（这一步可以越详细越好，越详细自己记忆越清晰），自己应该怎么做，后面出现类似的情况就直接往里面套就行了。\n\n\n\n","source":"_drafts/better-me.md","raw":"自己的事情最终只能是自己负责，比如自己的事情，那别人最多只能帮助建议，最终还是得看自己，因为最终的决策／行动需要自己做；另外别人的事情，也最终只能 ta 自己做，自己无法替 ta 做。\n\n需要区分哪些是自己的事情，哪些是别人的事情。\n\n\n对一个事情，可能有一些阶段：不知道和知道，知道之后，是否能做到；能做到分为两种：需要自己主动注意的做到，还是形成习惯；如果能够形成习惯，那就属于自己了。\n\n这也是知行合一。\n\n其中让自己知道（比如将一些 问题/解决方案 等 能够很明显的让自己看到 -- 也就是可视化）是其中一步，也是很重要的一步。\n\n在知道后，需要有场景能够不断的联系，形成习惯/下意识。\n\n\n\n对于一件事情，按照责任相关的来划分的话，可以加上一个维度 功劳，变成 2 * 2 的矩阵\n\n|  | - | +\n| --- | --- | --- |\n| -   |  0   |  1 |\n| +   | 2   | 3|\n\n或者也可以弄成 3 * 3 的矩阵\n\n|  | - | 0 | + |\n| --- | --- | --- |\n| -  | 1 | 2 | 3 |\n| 0 | 4 | 5 | 6 |\n| + | 7 | 8 | 9 |\n\n可以先把模型中的格子排一个顺序，然后在有具体事情的时候，可以往模型里面套\n\n\n\n尽量把事情给 offload（比如写下来）这样减少自己思考时候的脑力消耗\n\n\n另外可以提前做一些预演，比如同时遇到了某两个格子内的事情（这一步可以越详细越好，越详细自己记忆越清晰），自己应该怎么做，后面出现类似的情况就直接往里面套就行了。\n\n\n\n","slug":"better-me","published":0,"date":"2025-07-04T02:44:38.728Z","updated":"2025-07-04T02:44:38.728Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cmcozc23z00006xfy8i212z62","content":"<p>自己的事情最终只能是自己负责，比如自己的事情，那别人最多只能帮助建议，最终还是得看自己，因为最终的决策／行动需要自己做；另外别人的事情，也最终只能 ta 自己做，自己无法替 ta 做。</p>\n<p>需要区分哪些是自己的事情，哪些是别人的事情。</p>\n<p>对一个事情，可能有一些阶段：不知道和知道，知道之后，是否能做到；能做到分为两种：需要自己主动注意的做到，还是形成习惯；如果能够形成习惯，那就属于自己了。</p>\n<p>这也是知行合一。</p>\n<p>其中让自己知道（比如将一些 问题/解决方案 等 能够很明显的让自己看到 — 也就是可视化）是其中一步，也是很重要的一步。</p>\n<p>在知道后，需要有场景能够不断的联系，形成习惯/下意识。</p>\n<p>对于一件事情，按照责任相关的来划分的话，可以加上一个维度 功劳，变成 2 * 2 的矩阵</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>-</th>\n<th>+</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>+</td>\n<td>2</td>\n<td>3</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>或者也可以弄成 3 * 3 的矩阵</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>-</th>\n<th>0</th>\n<th>+</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-</td>\n<td>1</td>\n<td>2</td>\n<td>3</td>\n</tr>\n<tr>\n<td>0</td>\n<td>4</td>\n<td>5</td>\n<td>6</td>\n</tr>\n<tr>\n<td>+</td>\n<td>7</td>\n<td>8</td>\n<td>9</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以先把模型中的格子排一个顺序，然后在有具体事情的时候，可以往模型里面套</p>\n<p>尽量把事情给 offload（比如写下来）这样减少自己思考时候的脑力消耗</p>\n<p>另外可以提前做一些预演，比如同时遇到了某两个格子内的事情（这一步可以越详细越好，越详细自己记忆越清晰），自己应该怎么做，后面出现类似的情况就直接往里面套就行了。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>自己的事情最终只能是自己负责，比如自己的事情，那别人最多只能帮助建议，最终还是得看自己，因为最终的决策／行动需要自己做；另外别人的事情，也最终只能 ta 自己做，自己无法替 ta 做。</p>\n<p>需要区分哪些是自己的事情，哪些是别人的事情。</p>\n<p>对一个事情，可能有一些阶段：不知道和知道，知道之后，是否能做到；能做到分为两种：需要自己主动注意的做到，还是形成习惯；如果能够形成习惯，那就属于自己了。</p>\n<p>这也是知行合一。</p>\n<p>其中让自己知道（比如将一些 问题/解决方案 等 能够很明显的让自己看到 — 也就是可视化）是其中一步，也是很重要的一步。</p>\n<p>在知道后，需要有场景能够不断的联系，形成习惯/下意识。</p>\n<p>对于一件事情，按照责任相关的来划分的话，可以加上一个维度 功劳，变成 2 * 2 的矩阵</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>-</th>\n<th>+</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-</td>\n<td>0</td>\n<td>1</td>\n</tr>\n<tr>\n<td>+</td>\n<td>2</td>\n<td>3</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>或者也可以弄成 3 * 3 的矩阵</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>-</th>\n<th>0</th>\n<th>+</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-</td>\n<td>1</td>\n<td>2</td>\n<td>3</td>\n</tr>\n<tr>\n<td>0</td>\n<td>4</td>\n<td>5</td>\n<td>6</td>\n</tr>\n<tr>\n<td>+</td>\n<td>7</td>\n<td>8</td>\n<td>9</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以先把模型中的格子排一个顺序，然后在有具体事情的时候，可以往模型里面套</p>\n<p>尽量把事情给 offload（比如写下来）这样减少自己思考时候的脑力消耗</p>\n<p>另外可以提前做一些预演，比如同时遇到了某两个格子内的事情（这一步可以越详细越好，越详细自己记忆越清晰），自己应该怎么做，后面出现类似的情况就直接往里面套就行了。</p>\n"},{"title":"maotai-price-deprese","date":"2025-07-05T01:07:32.000Z","toc":true,"_content":"\n> 茅台股价和批价齐跌，作为股民我该怎么办？\n\n最近（一年）茅台股价下跌，加上现在批价下行，作为茅台股民我该怎么办呢？\n\n这个时候作为股民应该感到高兴，理由有几：1）股价下跌，导致入场成本低；2）批价下跌，会影响股价向下，转到第一点；3）股价/批价不影响茅台公司的盈利能力。\n\n<!-- more -->\n\n# 投资投什么\n投资是一项希望赚钱的游戏，本质属于套利，换句话说也就是低买高买（需要算上时间的价值）。那么对于同一个标的来说，肯定是买入价价格越低越好，这样可以在未来赚取更多的钱；未来的价格希望越高越好 -- 但是未来的价格是一种预期/估算。\n\n从 [投资是投什么](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ) 我们知道，投资标的可以和无风险利率 -- 长期国债 -- 进行对比（或者自己能找到利率最高的“无风险”标的），按照十年期国债 3% 左右的利率算，也就是需要 33 年回本，PE 毛估 33 倍。那么如果一个投资标的盈利能力没有水分的情况下，PE 长期来看一定不会一直低于 33。原因在于如果投资标的 A 盈利能力稳定，PE 低于 33 倍，那么无需 33 年就能回本，也就是说比长期国债更好，市场上的金钱自然就会流向 A，流入金钱多导致供不欲求，从而推高价格和市值，间接的推高 PE -- 买入价格变高了，回本所需要的时间也变长。这一过程最终会在投资标的的 PE 与长期国债的 PE 基本持平后稳定下来。\n\n当然上面是一个理想和简化过的模型，但是实际来看，市场长期会偏理性，短期会受情绪影响，因此长期来看市值与公司的盈利能力是正相关的。由于短期会受市场上情绪的影响（比如茅台股价和批价齐跌），因此也需要尽可能持有久一点，另一方面我们可以利用市场情绪来拉低自己的入场成本，间接增加自己的收益。\n\n# 茅台的情况\n\n上面的描述中有一个假设 -- 茅台公司的盈利能力没有变差。 这个是需要每个投资者需要确认的，同时这个这是一项需要平时做的工作，而不仅仅是在股价/批价波动时需要做的事情。下文会结合两个最近听到较多的声音一起分享下自己的看法：\n\n- 批价下行会导致茅台赚不到钱\n- 禁酒令或者年轻人已经不喝酒了\n\n## 批价和茅台公司的关系\n\n在 [赚钱机器茅台](https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA) 中有写，茅台酒的销售有几个渠道：经销商，自营，商超等。其中大家看到的批价是经销商的卖价，和茅台公司的营收无关，影响的是经销商的利润。出厂价是 1169 的前提下，如果批价 2300 那么经销商转 2300 - 1169 = 1131 每瓶，如果是 2000 的批价，则每瓶赚 831。所以批价下行影响的是茅台经销商的利润，不影响茅台公司的利润。但是如果经销商没有利润则会影响茅台的销售，可能间接影响茅台公司的收入。\n\n那么是否会由于批价下跌导致影响经销商不再采购茅台呢，有可能。这个我们看下预收款的变化，这部分是经销商提前打款，预订茅台产品的钱。\n\n首先我们简单看下公司财报中的部分数据\n\n| 时间 | 营业收入 | 利润 | 净利润 | 合同负债（预收款） |\n| --- | --- | ---  | --- | --- |\n| 23 年年报| 1500亿  | 1030 亿 |  650亿      | 141 亿 |\n| 24 年年报| 1740亿  | 1190 亿 |  890亿      | 95 亿 |\n| 24 年一季度报| 460亿  | 330 亿 |  240亿      | 95 亿 |\n| 25 年一季度报| 510亿  | 370 亿 |  270亿      | 87 亿 |\n\n从上面看有一些信息\n- 25 年第一季度比 24 年第一季度的营收有增长\n- 25 年第一季度的合同负债比 24 年第一季度要少，也就是收到的预售款比兑现的少; 24 年年报中的合同负债和 24 年第一季度的基本持平，表示 24 年后三季度收到的预售款和兑现的基本持平。\n- 不管哪一阶段，都有较多的合同负债。24 年底占营收的 5% 左右。\n- 24 年经销商已经在控制预收款的投入了，25 年第一季度还在持续, 可以看 25 年年中报再确认\n- 25 年第一季度茅台公司的营收以及利润较 24 年第一季度是增长的。\n\n## 禁酒令和年轻人不再喝酒\n\n首先酒肯定是对身体不好的，现在的酒桌文化也在慢慢的变化。但是整体白酒的营收是在逐年增加的（具体参考前文[赚钱机器茅台](https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA))，然后茅台酒和茅台系列酒的收入占整体白酒的收入也是在逐年增长的。也就是说茅台酒和茅台系列酒的增长是高于整体白酒的涨幅的。\n\n然后禁酒令是否会影响白酒或者茅台酒的销售，这个短期应该还是会有影响的，但是对公消费现在占比已经不高，另外茅台酒整体供不欲求，所以不一定会影响到茅台公司的营收（酒品质保持不变的情况下）。\n\n年轻人是否喜欢喝茅台酒不是决定性的因素，但是如果想求人办事，或者送礼，那么茅台还是一个很不错的选择，这是文化的一种体现，文化是一种共识，共识的建立和转变都需要足够长的时间。短期来看只要有迎来送往等情况，那么就有茅台酒的市场。\n\n# 茅台的买入价\n\n如果说茅台是一个不错的投资标的，那么是否什么价格都可以买呢？其实也不是，因为买入价格太高会导致自己没有利润（如前所示），那么什么价格是一个比较合理的价格呢？\n\n这里分享两种方法\n\n1 按照自己估算的盈利，如果复合年化可以超过 X -- 这个自己设定，进行打折保留安全空间\n2 如果公司有回购的话，那么在回购价一下购买基本算不错的 -- 回购价是公司对市值的一个预测\n\n其中第一个可以根据公司的净利润以及本文前面与长期国债比较的方式进行估算，然后可以根据自己对公司的了解情况做一些打折，比如公司净利润 800 亿，那么按照 33 倍 PE 也就是市值值 2.6万亿。然后如果打 7 折就是 1.82 万亿，现在总股数 12.56亿，1.82万亿 / 12.56亿 ~ 1450。也就是说 1450 一下是 ok 的。当然这只是进行股价的一个粗略估算，里面的具体数值（尤其是折数）需要自己替换。\n\n另外茅台现在每年会有分红，这部分利润（可能）无法反应在市值上，比如 25 年 6 月按照 10 股分红 276.73 计算（假设以后都不低于这个值），那么按照股价 1500 计算的话，一年两次分红总共是 276.73 * 10 * 2 = 5534.6，5534.6/(1500 * 100) = 3.68%。也就是说把茅台当定存的话也有 3.6 % 左右的年化，这个回报已经高于长期国债了。\n\n\n# 总结\n整体来说，市值的降低，以及整条销售链路上的价格波动，不一定会影响公司的盈利能力，可能是一个更好的入场机会，我们需要分析公司的情况，然后等待市值下降之后入场，从而获得更好的利润。\n","source":"_posts/maotai-price-decreasing.md","raw":"---\ntitle: maotai-price-deprese\ndate: 2025-07-05 09:07:32\ntags: \n    - stock\n    - maotai\n    - price\n    - wine\ntoc: true\n---\n\n> 茅台股价和批价齐跌，作为股民我该怎么办？\n\n最近（一年）茅台股价下跌，加上现在批价下行，作为茅台股民我该怎么办呢？\n\n这个时候作为股民应该感到高兴，理由有几：1）股价下跌，导致入场成本低；2）批价下跌，会影响股价向下，转到第一点；3）股价/批价不影响茅台公司的盈利能力。\n\n<!-- more -->\n\n# 投资投什么\n投资是一项希望赚钱的游戏，本质属于套利，换句话说也就是低买高买（需要算上时间的价值）。那么对于同一个标的来说，肯定是买入价价格越低越好，这样可以在未来赚取更多的钱；未来的价格希望越高越好 -- 但是未来的价格是一种预期/估算。\n\n从 [投资是投什么](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ) 我们知道，投资标的可以和无风险利率 -- 长期国债 -- 进行对比（或者自己能找到利率最高的“无风险”标的），按照十年期国债 3% 左右的利率算，也就是需要 33 年回本，PE 毛估 33 倍。那么如果一个投资标的盈利能力没有水分的情况下，PE 长期来看一定不会一直低于 33。原因在于如果投资标的 A 盈利能力稳定，PE 低于 33 倍，那么无需 33 年就能回本，也就是说比长期国债更好，市场上的金钱自然就会流向 A，流入金钱多导致供不欲求，从而推高价格和市值，间接的推高 PE -- 买入价格变高了，回本所需要的时间也变长。这一过程最终会在投资标的的 PE 与长期国债的 PE 基本持平后稳定下来。\n\n当然上面是一个理想和简化过的模型，但是实际来看，市场长期会偏理性，短期会受情绪影响，因此长期来看市值与公司的盈利能力是正相关的。由于短期会受市场上情绪的影响（比如茅台股价和批价齐跌），因此也需要尽可能持有久一点，另一方面我们可以利用市场情绪来拉低自己的入场成本，间接增加自己的收益。\n\n# 茅台的情况\n\n上面的描述中有一个假设 -- 茅台公司的盈利能力没有变差。 这个是需要每个投资者需要确认的，同时这个这是一项需要平时做的工作，而不仅仅是在股价/批价波动时需要做的事情。下文会结合两个最近听到较多的声音一起分享下自己的看法：\n\n- 批价下行会导致茅台赚不到钱\n- 禁酒令或者年轻人已经不喝酒了\n\n## 批价和茅台公司的关系\n\n在 [赚钱机器茅台](https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA) 中有写，茅台酒的销售有几个渠道：经销商，自营，商超等。其中大家看到的批价是经销商的卖价，和茅台公司的营收无关，影响的是经销商的利润。出厂价是 1169 的前提下，如果批价 2300 那么经销商转 2300 - 1169 = 1131 每瓶，如果是 2000 的批价，则每瓶赚 831。所以批价下行影响的是茅台经销商的利润，不影响茅台公司的利润。但是如果经销商没有利润则会影响茅台的销售，可能间接影响茅台公司的收入。\n\n那么是否会由于批价下跌导致影响经销商不再采购茅台呢，有可能。这个我们看下预收款的变化，这部分是经销商提前打款，预订茅台产品的钱。\n\n首先我们简单看下公司财报中的部分数据\n\n| 时间 | 营业收入 | 利润 | 净利润 | 合同负债（预收款） |\n| --- | --- | ---  | --- | --- |\n| 23 年年报| 1500亿  | 1030 亿 |  650亿      | 141 亿 |\n| 24 年年报| 1740亿  | 1190 亿 |  890亿      | 95 亿 |\n| 24 年一季度报| 460亿  | 330 亿 |  240亿      | 95 亿 |\n| 25 年一季度报| 510亿  | 370 亿 |  270亿      | 87 亿 |\n\n从上面看有一些信息\n- 25 年第一季度比 24 年第一季度的营收有增长\n- 25 年第一季度的合同负债比 24 年第一季度要少，也就是收到的预售款比兑现的少; 24 年年报中的合同负债和 24 年第一季度的基本持平，表示 24 年后三季度收到的预售款和兑现的基本持平。\n- 不管哪一阶段，都有较多的合同负债。24 年底占营收的 5% 左右。\n- 24 年经销商已经在控制预收款的投入了，25 年第一季度还在持续, 可以看 25 年年中报再确认\n- 25 年第一季度茅台公司的营收以及利润较 24 年第一季度是增长的。\n\n## 禁酒令和年轻人不再喝酒\n\n首先酒肯定是对身体不好的，现在的酒桌文化也在慢慢的变化。但是整体白酒的营收是在逐年增加的（具体参考前文[赚钱机器茅台](https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA))，然后茅台酒和茅台系列酒的收入占整体白酒的收入也是在逐年增长的。也就是说茅台酒和茅台系列酒的增长是高于整体白酒的涨幅的。\n\n然后禁酒令是否会影响白酒或者茅台酒的销售，这个短期应该还是会有影响的，但是对公消费现在占比已经不高，另外茅台酒整体供不欲求，所以不一定会影响到茅台公司的营收（酒品质保持不变的情况下）。\n\n年轻人是否喜欢喝茅台酒不是决定性的因素，但是如果想求人办事，或者送礼，那么茅台还是一个很不错的选择，这是文化的一种体现，文化是一种共识，共识的建立和转变都需要足够长的时间。短期来看只要有迎来送往等情况，那么就有茅台酒的市场。\n\n# 茅台的买入价\n\n如果说茅台是一个不错的投资标的，那么是否什么价格都可以买呢？其实也不是，因为买入价格太高会导致自己没有利润（如前所示），那么什么价格是一个比较合理的价格呢？\n\n这里分享两种方法\n\n1 按照自己估算的盈利，如果复合年化可以超过 X -- 这个自己设定，进行打折保留安全空间\n2 如果公司有回购的话，那么在回购价一下购买基本算不错的 -- 回购价是公司对市值的一个预测\n\n其中第一个可以根据公司的净利润以及本文前面与长期国债比较的方式进行估算，然后可以根据自己对公司的了解情况做一些打折，比如公司净利润 800 亿，那么按照 33 倍 PE 也就是市值值 2.6万亿。然后如果打 7 折就是 1.82 万亿，现在总股数 12.56亿，1.82万亿 / 12.56亿 ~ 1450。也就是说 1450 一下是 ok 的。当然这只是进行股价的一个粗略估算，里面的具体数值（尤其是折数）需要自己替换。\n\n另外茅台现在每年会有分红，这部分利润（可能）无法反应在市值上，比如 25 年 6 月按照 10 股分红 276.73 计算（假设以后都不低于这个值），那么按照股价 1500 计算的话，一年两次分红总共是 276.73 * 10 * 2 = 5534.6，5534.6/(1500 * 100) = 3.68%。也就是说把茅台当定存的话也有 3.6 % 左右的年化，这个回报已经高于长期国债了。\n\n\n# 总结\n整体来说，市值的降低，以及整条销售链路上的价格波动，不一定会影响公司的盈利能力，可能是一个更好的入场机会，我们需要分析公司的情况，然后等待市值下降之后入场，从而获得更好的利润。\n","slug":"maotai-price-decreasing","published":1,"updated":"2025-07-05T01:07:14.520Z","_id":"cmcpjktu7000b6xfy24cedmvm","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>茅台股价和批价齐跌，作为股民我该怎么办？</p>\n</blockquote>\n<p>最近（一年）茅台股价下跌，加上现在批价下行，作为茅台股民我该怎么办呢？</p>\n<p>这个时候作为股民应该感到高兴，理由有几：1）股价下跌，导致入场成本低；2）批价下跌，会影响股价向下，转到第一点；3）股价/批价不影响茅台公司的盈利能力。</p>\n<span id=\"more\"></span>\n<h1 id=\"投资投什么\"><a href=\"#投资投什么\" class=\"headerlink\" title=\"投资投什么\"></a>投资投什么</h1><p>投资是一项希望赚钱的游戏，本质属于套利，换句话说也就是低买高买（需要算上时间的价值）。那么对于同一个标的来说，肯定是买入价价格越低越好，这样可以在未来赚取更多的钱；未来的价格希望越高越好 — 但是未来的价格是一种预期/估算。</p>\n<p>从 <a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">投资是投什么</a> 我们知道，投资标的可以和无风险利率 — 长期国债 — 进行对比（或者自己能找到利率最高的“无风险”标的），按照十年期国债 3% 左右的利率算，也就是需要 33 年回本，PE 毛估 33 倍。那么如果一个投资标的盈利能力没有水分的情况下，PE 长期来看一定不会一直低于 33。原因在于如果投资标的 A 盈利能力稳定，PE 低于 33 倍，那么无需 33 年就能回本，也就是说比长期国债更好，市场上的金钱自然就会流向 A，流入金钱多导致供不欲求，从而推高价格和市值，间接的推高 PE — 买入价格变高了，回本所需要的时间也变长。这一过程最终会在投资标的的 PE 与长期国债的 PE 基本持平后稳定下来。</p>\n<p>当然上面是一个理想和简化过的模型，但是实际来看，市场长期会偏理性，短期会受情绪影响，因此长期来看市值与公司的盈利能力是正相关的。由于短期会受市场上情绪的影响（比如茅台股价和批价齐跌），因此也需要尽可能持有久一点，另一方面我们可以利用市场情绪来拉低自己的入场成本，间接增加自己的收益。</p>\n<h1 id=\"茅台的情况\"><a href=\"#茅台的情况\" class=\"headerlink\" title=\"茅台的情况\"></a>茅台的情况</h1><p>上面的描述中有一个假设 — 茅台公司的盈利能力没有变差。 这个是需要每个投资者需要确认的，同时这个这是一项需要平时做的工作，而不仅仅是在股价/批价波动时需要做的事情。下文会结合两个最近听到较多的声音一起分享下自己的看法：</p>\n<ul>\n<li>批价下行会导致茅台赚不到钱</li>\n<li>禁酒令或者年轻人已经不喝酒了</li>\n</ul>\n<h2 id=\"批价和茅台公司的关系\"><a href=\"#批价和茅台公司的关系\" class=\"headerlink\" title=\"批价和茅台公司的关系\"></a>批价和茅台公司的关系</h2><p>在 <a href=\"https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA\">赚钱机器茅台</a> 中有写，茅台酒的销售有几个渠道：经销商，自营，商超等。其中大家看到的批价是经销商的卖价，和茅台公司的营收无关，影响的是经销商的利润。出厂价是 1169 的前提下，如果批价 2300 那么经销商转 2300 - 1169 = 1131 每瓶，如果是 2000 的批价，则每瓶赚 831。所以批价下行影响的是茅台经销商的利润，不影响茅台公司的利润。但是如果经销商没有利润则会影响茅台的销售，可能间接影响茅台公司的收入。</p>\n<p>那么是否会由于批价下跌导致影响经销商不再采购茅台呢，有可能。这个我们看下预收款的变化，这部分是经销商提前打款，预订茅台产品的钱。</p>\n<p>首先我们简单看下公司财报中的部分数据</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>时间</th>\n<th>营业收入</th>\n<th>利润</th>\n<th>净利润</th>\n<th>合同负债（预收款）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>23 年年报</td>\n<td>1500亿</td>\n<td>1030 亿</td>\n<td>650亿</td>\n<td>141 亿</td>\n</tr>\n<tr>\n<td>24 年年报</td>\n<td>1740亿</td>\n<td>1190 亿</td>\n<td>890亿</td>\n<td>95 亿</td>\n</tr>\n<tr>\n<td>24 年一季度报</td>\n<td>460亿</td>\n<td>330 亿</td>\n<td>240亿</td>\n<td>95 亿</td>\n</tr>\n<tr>\n<td>25 年一季度报</td>\n<td>510亿</td>\n<td>370 亿</td>\n<td>270亿</td>\n<td>87 亿</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>从上面看有一些信息</p>\n<ul>\n<li>25 年第一季度比 24 年第一季度的营收有增长</li>\n<li>25 年第一季度的合同负债比 24 年第一季度要少，也就是收到的预售款比兑现的少; 24 年年报中的合同负债和 24 年第一季度的基本持平，表示 24 年后三季度收到的预售款和兑现的基本持平。</li>\n<li>不管哪一阶段，都有较多的合同负债。24 年底占营收的 5% 左右。</li>\n<li>24 年经销商已经在控制预收款的投入了，25 年第一季度还在持续, 可以看 25 年年中报再确认</li>\n<li>25 年第一季度茅台公司的营收以及利润较 24 年第一季度是增长的。</li>\n</ul>\n<h2 id=\"禁酒令和年轻人不再喝酒\"><a href=\"#禁酒令和年轻人不再喝酒\" class=\"headerlink\" title=\"禁酒令和年轻人不再喝酒\"></a>禁酒令和年轻人不再喝酒</h2><p>首先酒肯定是对身体不好的，现在的酒桌文化也在慢慢的变化。但是整体白酒的营收是在逐年增加的（具体参考前文<a href=\"https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA\">赚钱机器茅台</a>)，然后茅台酒和茅台系列酒的收入占整体白酒的收入也是在逐年增长的。也就是说茅台酒和茅台系列酒的增长是高于整体白酒的涨幅的。</p>\n<p>然后禁酒令是否会影响白酒或者茅台酒的销售，这个短期应该还是会有影响的，但是对公消费现在占比已经不高，另外茅台酒整体供不欲求，所以不一定会影响到茅台公司的营收（酒品质保持不变的情况下）。</p>\n<p>年轻人是否喜欢喝茅台酒不是决定性的因素，但是如果想求人办事，或者送礼，那么茅台还是一个很不错的选择，这是文化的一种体现，文化是一种共识，共识的建立和转变都需要足够长的时间。短期来看只要有迎来送往等情况，那么就有茅台酒的市场。</p>\n<h1 id=\"茅台的买入价\"><a href=\"#茅台的买入价\" class=\"headerlink\" title=\"茅台的买入价\"></a>茅台的买入价</h1><p>如果说茅台是一个不错的投资标的，那么是否什么价格都可以买呢？其实也不是，因为买入价格太高会导致自己没有利润（如前所示），那么什么价格是一个比较合理的价格呢？</p>\n<p>这里分享两种方法</p>\n<p>1 按照自己估算的盈利，如果复合年化可以超过 X — 这个自己设定，进行打折保留安全空间<br>2 如果公司有回购的话，那么在回购价一下购买基本算不错的 — 回购价是公司对市值的一个预测</p>\n<p>其中第一个可以根据公司的净利润以及本文前面与长期国债比较的方式进行估算，然后可以根据自己对公司的了解情况做一些打折，比如公司净利润 800 亿，那么按照 33 倍 PE 也就是市值值 2.6万亿。然后如果打 7 折就是 1.82 万亿，现在总股数 12.56亿，1.82万亿 / 12.56亿 ~ 1450。也就是说 1450 一下是 ok 的。当然这只是进行股价的一个粗略估算，里面的具体数值（尤其是折数）需要自己替换。</p>\n<p>另外茅台现在每年会有分红，这部分利润（可能）无法反应在市值上，比如 25 年 6 月按照 10 股分红 276.73 计算（假设以后都不低于这个值），那么按照股价 1500 计算的话，一年两次分红总共是 276.73 <em> 10 </em> 2 = 5534.6，5534.6/(1500 * 100) = 3.68%。也就是说把茅台当定存的话也有 3.6 % 左右的年化，这个回报已经高于长期国债了。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>整体来说，市值的降低，以及整条销售链路上的价格波动，不一定会影响公司的盈利能力，可能是一个更好的入场机会，我们需要分析公司的情况，然后等待市值下降之后入场，从而获得更好的利润。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>茅台股价和批价齐跌，作为股民我该怎么办？</p>\n</blockquote>\n<p>最近（一年）茅台股价下跌，加上现在批价下行，作为茅台股民我该怎么办呢？</p>\n<p>这个时候作为股民应该感到高兴，理由有几：1）股价下跌，导致入场成本低；2）批价下跌，会影响股价向下，转到第一点；3）股价/批价不影响茅台公司的盈利能力。</p>","more":"<h1 id=\"投资投什么\"><a href=\"#投资投什么\" class=\"headerlink\" title=\"投资投什么\"></a>投资投什么</h1><p>投资是一项希望赚钱的游戏，本质属于套利，换句话说也就是低买高买（需要算上时间的价值）。那么对于同一个标的来说，肯定是买入价价格越低越好，这样可以在未来赚取更多的钱；未来的价格希望越高越好 — 但是未来的价格是一种预期/估算。</p>\n<p>从 <a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">投资是投什么</a> 我们知道，投资标的可以和无风险利率 — 长期国债 — 进行对比（或者自己能找到利率最高的“无风险”标的），按照十年期国债 3% 左右的利率算，也就是需要 33 年回本，PE 毛估 33 倍。那么如果一个投资标的盈利能力没有水分的情况下，PE 长期来看一定不会一直低于 33。原因在于如果投资标的 A 盈利能力稳定，PE 低于 33 倍，那么无需 33 年就能回本，也就是说比长期国债更好，市场上的金钱自然就会流向 A，流入金钱多导致供不欲求，从而推高价格和市值，间接的推高 PE — 买入价格变高了，回本所需要的时间也变长。这一过程最终会在投资标的的 PE 与长期国债的 PE 基本持平后稳定下来。</p>\n<p>当然上面是一个理想和简化过的模型，但是实际来看，市场长期会偏理性，短期会受情绪影响，因此长期来看市值与公司的盈利能力是正相关的。由于短期会受市场上情绪的影响（比如茅台股价和批价齐跌），因此也需要尽可能持有久一点，另一方面我们可以利用市场情绪来拉低自己的入场成本，间接增加自己的收益。</p>\n<h1 id=\"茅台的情况\"><a href=\"#茅台的情况\" class=\"headerlink\" title=\"茅台的情况\"></a>茅台的情况</h1><p>上面的描述中有一个假设 — 茅台公司的盈利能力没有变差。 这个是需要每个投资者需要确认的，同时这个这是一项需要平时做的工作，而不仅仅是在股价/批价波动时需要做的事情。下文会结合两个最近听到较多的声音一起分享下自己的看法：</p>\n<ul>\n<li>批价下行会导致茅台赚不到钱</li>\n<li>禁酒令或者年轻人已经不喝酒了</li>\n</ul>\n<h2 id=\"批价和茅台公司的关系\"><a href=\"#批价和茅台公司的关系\" class=\"headerlink\" title=\"批价和茅台公司的关系\"></a>批价和茅台公司的关系</h2><p>在 <a href=\"https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA\">赚钱机器茅台</a> 中有写，茅台酒的销售有几个渠道：经销商，自营，商超等。其中大家看到的批价是经销商的卖价，和茅台公司的营收无关，影响的是经销商的利润。出厂价是 1169 的前提下，如果批价 2300 那么经销商转 2300 - 1169 = 1131 每瓶，如果是 2000 的批价，则每瓶赚 831。所以批价下行影响的是茅台经销商的利润，不影响茅台公司的利润。但是如果经销商没有利润则会影响茅台的销售，可能间接影响茅台公司的收入。</p>\n<p>那么是否会由于批价下跌导致影响经销商不再采购茅台呢，有可能。这个我们看下预收款的变化，这部分是经销商提前打款，预订茅台产品的钱。</p>\n<p>首先我们简单看下公司财报中的部分数据</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>时间</th>\n<th>营业收入</th>\n<th>利润</th>\n<th>净利润</th>\n<th>合同负债（预收款）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>23 年年报</td>\n<td>1500亿</td>\n<td>1030 亿</td>\n<td>650亿</td>\n<td>141 亿</td>\n</tr>\n<tr>\n<td>24 年年报</td>\n<td>1740亿</td>\n<td>1190 亿</td>\n<td>890亿</td>\n<td>95 亿</td>\n</tr>\n<tr>\n<td>24 年一季度报</td>\n<td>460亿</td>\n<td>330 亿</td>\n<td>240亿</td>\n<td>95 亿</td>\n</tr>\n<tr>\n<td>25 年一季度报</td>\n<td>510亿</td>\n<td>370 亿</td>\n<td>270亿</td>\n<td>87 亿</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>从上面看有一些信息</p>\n<ul>\n<li>25 年第一季度比 24 年第一季度的营收有增长</li>\n<li>25 年第一季度的合同负债比 24 年第一季度要少，也就是收到的预售款比兑现的少; 24 年年报中的合同负债和 24 年第一季度的基本持平，表示 24 年后三季度收到的预售款和兑现的基本持平。</li>\n<li>不管哪一阶段，都有较多的合同负债。24 年底占营收的 5% 左右。</li>\n<li>24 年经销商已经在控制预收款的投入了，25 年第一季度还在持续, 可以看 25 年年中报再确认</li>\n<li>25 年第一季度茅台公司的营收以及利润较 24 年第一季度是增长的。</li>\n</ul>\n<h2 id=\"禁酒令和年轻人不再喝酒\"><a href=\"#禁酒令和年轻人不再喝酒\" class=\"headerlink\" title=\"禁酒令和年轻人不再喝酒\"></a>禁酒令和年轻人不再喝酒</h2><p>首先酒肯定是对身体不好的，现在的酒桌文化也在慢慢的变化。但是整体白酒的营收是在逐年增加的（具体参考前文<a href=\"https://mp.weixin.qq.com/s/2KbUDJNn7-DLrqGPRHT0iA\">赚钱机器茅台</a>)，然后茅台酒和茅台系列酒的收入占整体白酒的收入也是在逐年增长的。也就是说茅台酒和茅台系列酒的增长是高于整体白酒的涨幅的。</p>\n<p>然后禁酒令是否会影响白酒或者茅台酒的销售，这个短期应该还是会有影响的，但是对公消费现在占比已经不高，另外茅台酒整体供不欲求，所以不一定会影响到茅台公司的营收（酒品质保持不变的情况下）。</p>\n<p>年轻人是否喜欢喝茅台酒不是决定性的因素，但是如果想求人办事，或者送礼，那么茅台还是一个很不错的选择，这是文化的一种体现，文化是一种共识，共识的建立和转变都需要足够长的时间。短期来看只要有迎来送往等情况，那么就有茅台酒的市场。</p>\n<h1 id=\"茅台的买入价\"><a href=\"#茅台的买入价\" class=\"headerlink\" title=\"茅台的买入价\"></a>茅台的买入价</h1><p>如果说茅台是一个不错的投资标的，那么是否什么价格都可以买呢？其实也不是，因为买入价格太高会导致自己没有利润（如前所示），那么什么价格是一个比较合理的价格呢？</p>\n<p>这里分享两种方法</p>\n<p>1 按照自己估算的盈利，如果复合年化可以超过 X — 这个自己设定，进行打折保留安全空间<br>2 如果公司有回购的话，那么在回购价一下购买基本算不错的 — 回购价是公司对市值的一个预测</p>\n<p>其中第一个可以根据公司的净利润以及本文前面与长期国债比较的方式进行估算，然后可以根据自己对公司的了解情况做一些打折，比如公司净利润 800 亿，那么按照 33 倍 PE 也就是市值值 2.6万亿。然后如果打 7 折就是 1.82 万亿，现在总股数 12.56亿，1.82万亿 / 12.56亿 ~ 1450。也就是说 1450 一下是 ok 的。当然这只是进行股价的一个粗略估算，里面的具体数值（尤其是折数）需要自己替换。</p>\n<p>另外茅台现在每年会有分红，这部分利润（可能）无法反应在市值上，比如 25 年 6 月按照 10 股分红 276.73 计算（假设以后都不低于这个值），那么按照股价 1500 计算的话，一年两次分红总共是 276.73 <em> 10 </em> 2 = 5534.6，5534.6/(1500 * 100) = 3.68%。也就是说把茅台当定存的话也有 3.6 % 左右的年化，这个回报已经高于长期国债了。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>整体来说，市值的降低，以及整条销售链路上的价格波动，不一定会影响公司的盈利能力，可能是一个更好的入场机会，我们需要分析公司的情况，然后等待市值下降之后入场，从而获得更好的利润。</p>"},{"title":"Arrow 中一次代码性能优化的记录","date":"2025-07-29T06:53:32.000Z","toc":true,"_content":"> 本文记录 Arrow-RS 中一次性能优化的情况。\n\n# 背景\n最近尝试在 Arrow-rs 中做一些贡献来更好的学习了解下 Arrow 和 Rust。本文的事情则是在为 Arrow-rs 支持 parquet variant 中的一个修改。当前实现的过程中，Object 和 List 会创建临时 buffer，然后在最终 copy，这样会有一定的性能损失（主要在于临时 buffer 的创建以及拷贝），希望有一种方案能够直接写入到目标的 buffer 而不需要进行拷贝，也就是 [ARROW-RS-7977](https://github.com/apache/arrow-rs/issues/7977) 所记录的事情。\n\n<!--more-->\n\n# 过程\n由于之前在 ARROW-RS#7899 中做过一个 Object 相关的，这个是类似的，因此觉得应该会是一个相对比较容易的事情。不过整个过程还是可以记录下\n\n首先我给了一个最初的版本，这个版本中我写了四份代码，分别是\n\n1. 使用 `PackedU32Iterator` 的[方案](https://github.com/apache/arrow-rs/pull/7987/commits/e4603c1d9b885c2f15871eddc87d1de45beb998e)\n2. 纯粹使用 Iterator 的[方案](https://github.com/klion26/arrow-rs/blob/1d594b3b4a461a44ad72ecac730cbdfc537767d4/parquet-variant/src/builder.rs#L1220-L1240)\n3. [该方案](https://github.com/klion26/arrow-rs/blob/7179a56258429d8431273d525ced836dd706e3e4/parquet-variant/src/builder.rs#L1220-L1241)在 2 的方式下，进行一次 iterator 的 collect，然后进行 splice\n4. [该方案](https://github.com/klion26/arrow-rs/blob/9cc1b04a007c54274db81059d317747b2512e169/parquet-variant/src/builder.rs#L1265-L1285)直接生成一个临时的 buffer，然后逐步填充 header 后进行 splice\n\n记录下 scovich 给的一些反馈\n```\n> 2. Splice with Iterator\nThis one will perform poorly because the chained iterator doesn't infer an accurate lower bound, so `Vec::splice` has to shift bytes twice (once to fit the lower bound, and again to fix the remainder).\n> 3. Collect the header with iterator before splice\n一定比 2 差，因为多一次 collect\n> Splice with actual header bytes\nThis is still iterator-based like 1, but with all the unsafety of indexing into a pre-allocated temp buffer(and the overhead of allocating said temp buffer).\n```\n针对这几个方案，给出了两外两个建议\n\n第 5 种方案\n`A fifth approach would be to use the packed u32 iterator from 1/, and splice in a pre-populated temp buffer like 5/, but to populate the temp buffer by push+extend calls instead of chain+collect:`\n\n```rust\nlet mut bytes_to_splice = vec![header];\n  ...\nbytes_to_splice.extend(num_elements_bytes);\n  ...\nbytes_to_splice.extend(offsets);\n  ...\nbytes_to_splice.extend(data_size_bytes);\nbuffer\n    .inner_mut()\n    .splice(starting_offset..starting_offset, bytes_to_splice);\n```\n\n以及第六种，主要是优化了原来的 `PackedU32Iterator`\n`A sixth approach would also use a pre-populated temp buffer, but ditch the packed u32 iterator from 1/ and just directly append the bytes:`\n\n```rust\nfn append_packed_u32(dest: &mut Vec<u8>, value: u32, value_bytes: usize) {\n    let n = dest.len() + value_bytes;\n    dest.extend(value.to_le_bytes());\n    dest.truncate(n);\n}\n\n// Calculated header size becomes a hint; being wrong only risks extra allocations.\n// Make sure to reserve enough capacity to handle the extra bytes we'll truncate.\nlet mut bytes_to_splice = Vec::with_capacity(header_size + 3);\nbytes_to_splice.push(header);\n\nappend_packed_u32(&mut bytes_to_splice, num_elements, if is_large { 4 } else { 1 });\n\nfor offset in std::mem::take(self.offsets) {\n    append_packed_u32(&mut bytes_to_splice, offset as u32, offset_size as usize);\n}\n\nappend_packed_u32(&mut bytes_to_splice, data_size as u32, offset_size as usize);\n\nbuffer\n    .inner_mut()\n    .splice(starting_offset..starting_offset, bytes_to_splice);\n```\n\n然后进行了 benchmark 的测试，发现第六种在所有的方案中会更好\n\n\n\n这里有一些性能的点\n- `Vec::splice` 需要 `Iterator` 的 lower-bound 来进行预测，不然可能会耗时更多，可以通过自定义的 Iterator 来提供\n- 使用 extend 这些可能会性能更好（？）\n- 可以通过对 U32 进行处理，直接完成 PackedU32 相关的事情，其中 U32 可以当成是 4 个 U8 然后 `to_le_bytes()` 就是按照顺序来排列的，这样的话，可以使用 `truncate`来轻量级的处理只需要 U32 部分 byte 的情况\n- 另外在 Rust 中 `into_iter()` 和 `iter()` 这些还需要继续学习了解下。\n\n\n整体看 Rust 中是可以获得更好的性能，这些需要对相对更低层的知识有更好的了解（或者这里更多的是对 API 有更好的了解），这些如果仅仅通过学习是比较难了解到的，通过实际的项目则可以更好/直观的看到不同实现的差异。\n","source":"_posts/arrow_variant_optimize.md","raw":"---\ntitle: Arrow 中一次代码性能优化的记录\ndate: 2025-07-29 14:53:32\ntags:\n    - arrow\n    - variant\n    - parquet\n    - rust\n    - optimization\ntoc: true\n---\n> 本文记录 Arrow-RS 中一次性能优化的情况。\n\n# 背景\n最近尝试在 Arrow-rs 中做一些贡献来更好的学习了解下 Arrow 和 Rust。本文的事情则是在为 Arrow-rs 支持 parquet variant 中的一个修改。当前实现的过程中，Object 和 List 会创建临时 buffer，然后在最终 copy，这样会有一定的性能损失（主要在于临时 buffer 的创建以及拷贝），希望有一种方案能够直接写入到目标的 buffer 而不需要进行拷贝，也就是 [ARROW-RS-7977](https://github.com/apache/arrow-rs/issues/7977) 所记录的事情。\n\n<!--more-->\n\n# 过程\n由于之前在 ARROW-RS#7899 中做过一个 Object 相关的，这个是类似的，因此觉得应该会是一个相对比较容易的事情。不过整个过程还是可以记录下\n\n首先我给了一个最初的版本，这个版本中我写了四份代码，分别是\n\n1. 使用 `PackedU32Iterator` 的[方案](https://github.com/apache/arrow-rs/pull/7987/commits/e4603c1d9b885c2f15871eddc87d1de45beb998e)\n2. 纯粹使用 Iterator 的[方案](https://github.com/klion26/arrow-rs/blob/1d594b3b4a461a44ad72ecac730cbdfc537767d4/parquet-variant/src/builder.rs#L1220-L1240)\n3. [该方案](https://github.com/klion26/arrow-rs/blob/7179a56258429d8431273d525ced836dd706e3e4/parquet-variant/src/builder.rs#L1220-L1241)在 2 的方式下，进行一次 iterator 的 collect，然后进行 splice\n4. [该方案](https://github.com/klion26/arrow-rs/blob/9cc1b04a007c54274db81059d317747b2512e169/parquet-variant/src/builder.rs#L1265-L1285)直接生成一个临时的 buffer，然后逐步填充 header 后进行 splice\n\n记录下 scovich 给的一些反馈\n```\n> 2. Splice with Iterator\nThis one will perform poorly because the chained iterator doesn't infer an accurate lower bound, so `Vec::splice` has to shift bytes twice (once to fit the lower bound, and again to fix the remainder).\n> 3. Collect the header with iterator before splice\n一定比 2 差，因为多一次 collect\n> Splice with actual header bytes\nThis is still iterator-based like 1, but with all the unsafety of indexing into a pre-allocated temp buffer(and the overhead of allocating said temp buffer).\n```\n针对这几个方案，给出了两外两个建议\n\n第 5 种方案\n`A fifth approach would be to use the packed u32 iterator from 1/, and splice in a pre-populated temp buffer like 5/, but to populate the temp buffer by push+extend calls instead of chain+collect:`\n\n```rust\nlet mut bytes_to_splice = vec![header];\n  ...\nbytes_to_splice.extend(num_elements_bytes);\n  ...\nbytes_to_splice.extend(offsets);\n  ...\nbytes_to_splice.extend(data_size_bytes);\nbuffer\n    .inner_mut()\n    .splice(starting_offset..starting_offset, bytes_to_splice);\n```\n\n以及第六种，主要是优化了原来的 `PackedU32Iterator`\n`A sixth approach would also use a pre-populated temp buffer, but ditch the packed u32 iterator from 1/ and just directly append the bytes:`\n\n```rust\nfn append_packed_u32(dest: &mut Vec<u8>, value: u32, value_bytes: usize) {\n    let n = dest.len() + value_bytes;\n    dest.extend(value.to_le_bytes());\n    dest.truncate(n);\n}\n\n// Calculated header size becomes a hint; being wrong only risks extra allocations.\n// Make sure to reserve enough capacity to handle the extra bytes we'll truncate.\nlet mut bytes_to_splice = Vec::with_capacity(header_size + 3);\nbytes_to_splice.push(header);\n\nappend_packed_u32(&mut bytes_to_splice, num_elements, if is_large { 4 } else { 1 });\n\nfor offset in std::mem::take(self.offsets) {\n    append_packed_u32(&mut bytes_to_splice, offset as u32, offset_size as usize);\n}\n\nappend_packed_u32(&mut bytes_to_splice, data_size as u32, offset_size as usize);\n\nbuffer\n    .inner_mut()\n    .splice(starting_offset..starting_offset, bytes_to_splice);\n```\n\n然后进行了 benchmark 的测试，发现第六种在所有的方案中会更好\n\n\n\n这里有一些性能的点\n- `Vec::splice` 需要 `Iterator` 的 lower-bound 来进行预测，不然可能会耗时更多，可以通过自定义的 Iterator 来提供\n- 使用 extend 这些可能会性能更好（？）\n- 可以通过对 U32 进行处理，直接完成 PackedU32 相关的事情，其中 U32 可以当成是 4 个 U8 然后 `to_le_bytes()` 就是按照顺序来排列的，这样的话，可以使用 `truncate`来轻量级的处理只需要 U32 部分 byte 的情况\n- 另外在 Rust 中 `into_iter()` 和 `iter()` 这些还需要继续学习了解下。\n\n\n整体看 Rust 中是可以获得更好的性能，这些需要对相对更低层的知识有更好的了解（或者这里更多的是对 API 有更好的了解），这些如果仅仅通过学习是比较难了解到的，通过实际的项目则可以更好/直观的看到不同实现的差异。\n","slug":"arrow_variant_optimize","published":1,"updated":"2025-09-18T01:27:18.224Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmfqtzost0002yafy39ds1f5c","content":"<blockquote>\n<p>本文记录 Arrow-RS 中一次性能优化的情况。</p>\n</blockquote>\n<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>最近尝试在 Arrow-rs 中做一些贡献来更好的学习了解下 Arrow 和 Rust。本文的事情则是在为 Arrow-rs 支持 parquet variant 中的一个修改。当前实现的过程中，Object 和 List 会创建临时 buffer，然后在最终 copy，这样会有一定的性能损失（主要在于临时 buffer 的创建以及拷贝），希望有一种方案能够直接写入到目标的 buffer 而不需要进行拷贝，也就是 <a href=\"https://github.com/apache/arrow-rs/issues/7977\">ARROW-RS-7977</a> 所记录的事情。</p>\n<span id=\"more\"></span>\n<h1 id=\"过程\"><a href=\"#过程\" class=\"headerlink\" title=\"过程\"></a>过程</h1><p>由于之前在 ARROW-RS#7899 中做过一个 Object 相关的，这个是类似的，因此觉得应该会是一个相对比较容易的事情。不过整个过程还是可以记录下</p>\n<p>首先我给了一个最初的版本，这个版本中我写了四份代码，分别是</p>\n<ol>\n<li>使用 <code>PackedU32Iterator</code> 的<a href=\"https://github.com/apache/arrow-rs/pull/7987/commits/e4603c1d9b885c2f15871eddc87d1de45beb998e\">方案</a></li>\n<li>纯粹使用 Iterator 的<a href=\"https://github.com/klion26/arrow-rs/blob/1d594b3b4a461a44ad72ecac730cbdfc537767d4/parquet-variant/src/builder.rs#L1220-L1240\">方案</a></li>\n<li><a href=\"https://github.com/klion26/arrow-rs/blob/7179a56258429d8431273d525ced836dd706e3e4/parquet-variant/src/builder.rs#L1220-L1241\">该方案</a>在 2 的方式下，进行一次 iterator 的 collect，然后进行 splice</li>\n<li><a href=\"https://github.com/klion26/arrow-rs/blob/9cc1b04a007c54274db81059d317747b2512e169/parquet-variant/src/builder.rs#L1265-L1285\">该方案</a>直接生成一个临时的 buffer，然后逐步填充 header 后进行 splice</li>\n</ol>\n<p>记录下 scovich 给的一些反馈<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; 2. Splice with Iterator</span><br><span class=\"line\">This one will perform poorly because the chained iterator doesn&#x27;t infer an accurate lower bound, so `Vec::splice` has to shift bytes twice (once to fit the lower bound, and again to fix the remainder).</span><br><span class=\"line\">&gt; 3. Collect the header with iterator before splice</span><br><span class=\"line\">一定比 2 差，因为多一次 collect</span><br><span class=\"line\">&gt; Splice with actual header bytes</span><br><span class=\"line\">This is still iterator-based like 1, but with all the unsafety of indexing into a pre-allocated temp buffer(and the overhead of allocating said temp buffer).</span><br></pre></td></tr></table></figure><br>针对这几个方案，给出了两外两个建议</p>\n<p>第 5 种方案<br><code>A fifth approach would be to use the packed u32 iterator from 1/, and splice in a pre-populated temp buffer like 5/, but to populate the temp buffer by push+extend calls instead of chain+collect:</code></p>\n<figure class=\"highlight rust\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">let</span> <span class=\"keyword\">mut </span><span class=\"variable\">bytes_to_splice</span> = <span class=\"built_in\">vec!</span>[header];</span><br><span class=\"line\">  ...</span><br><span class=\"line\">bytes_to_splice.<span class=\"title function_ invoke__\">extend</span>(num_elements_bytes);</span><br><span class=\"line\">  ...</span><br><span class=\"line\">bytes_to_splice.<span class=\"title function_ invoke__\">extend</span>(offsets);</span><br><span class=\"line\">  ...</span><br><span class=\"line\">bytes_to_splice.<span class=\"title function_ invoke__\">extend</span>(data_size_bytes);</span><br><span class=\"line\">buffer</span><br><span class=\"line\">    .<span class=\"title function_ invoke__\">inner_mut</span>()</span><br><span class=\"line\">    .<span class=\"title function_ invoke__\">splice</span>(starting_offset..starting_offset, bytes_to_splice);</span><br></pre></td></tr></table></figure>\n<p>以及第六种，主要是优化了原来的 <code>PackedU32Iterator</code><br><code>A sixth approach would also use a pre-populated temp buffer, but ditch the packed u32 iterator from 1/ and just directly append the bytes:</code></p>\n<figure class=\"highlight rust\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">fn</span> <span class=\"title function_\">append_packed_u32</span>(dest: &amp;<span class=\"keyword\">mut</span> <span class=\"type\">Vec</span>&lt;<span class=\"type\">u8</span>&gt;, value: <span class=\"type\">u32</span>, value_bytes: <span class=\"type\">usize</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">let</span> <span class=\"variable\">n</span> = dest.<span class=\"title function_ invoke__\">len</span>() + value_bytes;</span><br><span class=\"line\">    dest.<span class=\"title function_ invoke__\">extend</span>(value.<span class=\"title function_ invoke__\">to_le_bytes</span>());</span><br><span class=\"line\">    dest.<span class=\"title function_ invoke__\">truncate</span>(n);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Calculated header size becomes a hint; being wrong only risks extra allocations.</span></span><br><span class=\"line\"><span class=\"comment\">// Make sure to reserve enough capacity to handle the extra bytes we&#x27;ll truncate.</span></span><br><span class=\"line\"><span class=\"keyword\">let</span> <span class=\"keyword\">mut </span><span class=\"variable\">bytes_to_splice</span> = <span class=\"type\">Vec</span>::<span class=\"title function_ invoke__\">with_capacity</span>(header_size + <span class=\"number\">3</span>);</span><br><span class=\"line\">bytes_to_splice.<span class=\"title function_ invoke__\">push</span>(header);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title function_ invoke__\">append_packed_u32</span>(&amp;<span class=\"keyword\">mut</span> bytes_to_splice, num_elements, <span class=\"keyword\">if</span> is_large &#123; <span class=\"number\">4</span> &#125; <span class=\"keyword\">else</span> &#123; <span class=\"number\">1</span> &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> <span class=\"variable\">offset</span> <span class=\"keyword\">in</span> std::mem::<span class=\"title function_ invoke__\">take</span>(<span class=\"keyword\">self</span>.offsets) &#123;</span><br><span class=\"line\">    <span class=\"title function_ invoke__\">append_packed_u32</span>(&amp;<span class=\"keyword\">mut</span> bytes_to_splice, offset <span class=\"keyword\">as</span> <span class=\"type\">u32</span>, offset_size <span class=\"keyword\">as</span> <span class=\"type\">usize</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title function_ invoke__\">append_packed_u32</span>(&amp;<span class=\"keyword\">mut</span> bytes_to_splice, data_size <span class=\"keyword\">as</span> <span class=\"type\">u32</span>, offset_size <span class=\"keyword\">as</span> <span class=\"type\">usize</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">buffer</span><br><span class=\"line\">    .<span class=\"title function_ invoke__\">inner_mut</span>()</span><br><span class=\"line\">    .<span class=\"title function_ invoke__\">splice</span>(starting_offset..starting_offset, bytes_to_splice);</span><br></pre></td></tr></table></figure>\n<p>然后进行了 benchmark 的测试，发现第六种在所有的方案中会更好</p>\n<p>这里有一些性能的点</p>\n<ul>\n<li><code>Vec::splice</code> 需要 <code>Iterator</code> 的 lower-bound 来进行预测，不然可能会耗时更多，可以通过自定义的 Iterator 来提供</li>\n<li>使用 extend 这些可能会性能更好（？）</li>\n<li>可以通过对 U32 进行处理，直接完成 PackedU32 相关的事情，其中 U32 可以当成是 4 个 U8 然后 <code>to_le_bytes()</code> 就是按照顺序来排列的，这样的话，可以使用 <code>truncate</code>来轻量级的处理只需要 U32 部分 byte 的情况</li>\n<li>另外在 Rust 中 <code>into_iter()</code> 和 <code>iter()</code> 这些还需要继续学习了解下。</li>\n</ul>\n<p>整体看 Rust 中是可以获得更好的性能，这些需要对相对更低层的知识有更好的了解（或者这里更多的是对 API 有更好的了解），这些如果仅仅通过学习是比较难了解到的，通过实际的项目则可以更好/直观的看到不同实现的差异。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文记录 Arrow-RS 中一次性能优化的情况。</p>\n</blockquote>\n<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>最近尝试在 Arrow-rs 中做一些贡献来更好的学习了解下 Arrow 和 Rust。本文的事情则是在为 Arrow-rs 支持 parquet variant 中的一个修改。当前实现的过程中，Object 和 List 会创建临时 buffer，然后在最终 copy，这样会有一定的性能损失（主要在于临时 buffer 的创建以及拷贝），希望有一种方案能够直接写入到目标的 buffer 而不需要进行拷贝，也就是 <a href=\"https://github.com/apache/arrow-rs/issues/7977\">ARROW-RS-7977</a> 所记录的事情。</p>","more":"<h1 id=\"过程\"><a href=\"#过程\" class=\"headerlink\" title=\"过程\"></a>过程</h1><p>由于之前在 ARROW-RS#7899 中做过一个 Object 相关的，这个是类似的，因此觉得应该会是一个相对比较容易的事情。不过整个过程还是可以记录下</p>\n<p>首先我给了一个最初的版本，这个版本中我写了四份代码，分别是</p>\n<ol>\n<li>使用 <code>PackedU32Iterator</code> 的<a href=\"https://github.com/apache/arrow-rs/pull/7987/commits/e4603c1d9b885c2f15871eddc87d1de45beb998e\">方案</a></li>\n<li>纯粹使用 Iterator 的<a href=\"https://github.com/klion26/arrow-rs/blob/1d594b3b4a461a44ad72ecac730cbdfc537767d4/parquet-variant/src/builder.rs#L1220-L1240\">方案</a></li>\n<li><a href=\"https://github.com/klion26/arrow-rs/blob/7179a56258429d8431273d525ced836dd706e3e4/parquet-variant/src/builder.rs#L1220-L1241\">该方案</a>在 2 的方式下，进行一次 iterator 的 collect，然后进行 splice</li>\n<li><a href=\"https://github.com/klion26/arrow-rs/blob/9cc1b04a007c54274db81059d317747b2512e169/parquet-variant/src/builder.rs#L1265-L1285\">该方案</a>直接生成一个临时的 buffer，然后逐步填充 header 后进行 splice</li>\n</ol>\n<p>记录下 scovich 给的一些反馈<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; 2. Splice with Iterator</span><br><span class=\"line\">This one will perform poorly because the chained iterator doesn&#x27;t infer an accurate lower bound, so `Vec::splice` has to shift bytes twice (once to fit the lower bound, and again to fix the remainder).</span><br><span class=\"line\">&gt; 3. Collect the header with iterator before splice</span><br><span class=\"line\">一定比 2 差，因为多一次 collect</span><br><span class=\"line\">&gt; Splice with actual header bytes</span><br><span class=\"line\">This is still iterator-based like 1, but with all the unsafety of indexing into a pre-allocated temp buffer(and the overhead of allocating said temp buffer).</span><br></pre></td></tr></table></figure><br>针对这几个方案，给出了两外两个建议</p>\n<p>第 5 种方案<br><code>A fifth approach would be to use the packed u32 iterator from 1/, and splice in a pre-populated temp buffer like 5/, but to populate the temp buffer by push+extend calls instead of chain+collect:</code></p>\n<figure class=\"highlight rust\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">let</span> <span class=\"keyword\">mut </span><span class=\"variable\">bytes_to_splice</span> = <span class=\"built_in\">vec!</span>[header];</span><br><span class=\"line\">  ...</span><br><span class=\"line\">bytes_to_splice.<span class=\"title function_ invoke__\">extend</span>(num_elements_bytes);</span><br><span class=\"line\">  ...</span><br><span class=\"line\">bytes_to_splice.<span class=\"title function_ invoke__\">extend</span>(offsets);</span><br><span class=\"line\">  ...</span><br><span class=\"line\">bytes_to_splice.<span class=\"title function_ invoke__\">extend</span>(data_size_bytes);</span><br><span class=\"line\">buffer</span><br><span class=\"line\">    .<span class=\"title function_ invoke__\">inner_mut</span>()</span><br><span class=\"line\">    .<span class=\"title function_ invoke__\">splice</span>(starting_offset..starting_offset, bytes_to_splice);</span><br></pre></td></tr></table></figure>\n<p>以及第六种，主要是优化了原来的 <code>PackedU32Iterator</code><br><code>A sixth approach would also use a pre-populated temp buffer, but ditch the packed u32 iterator from 1/ and just directly append the bytes:</code></p>\n<figure class=\"highlight rust\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">fn</span> <span class=\"title function_\">append_packed_u32</span>(dest: &amp;<span class=\"keyword\">mut</span> <span class=\"type\">Vec</span>&lt;<span class=\"type\">u8</span>&gt;, value: <span class=\"type\">u32</span>, value_bytes: <span class=\"type\">usize</span>) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">let</span> <span class=\"variable\">n</span> = dest.<span class=\"title function_ invoke__\">len</span>() + value_bytes;</span><br><span class=\"line\">    dest.<span class=\"title function_ invoke__\">extend</span>(value.<span class=\"title function_ invoke__\">to_le_bytes</span>());</span><br><span class=\"line\">    dest.<span class=\"title function_ invoke__\">truncate</span>(n);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Calculated header size becomes a hint; being wrong only risks extra allocations.</span></span><br><span class=\"line\"><span class=\"comment\">// Make sure to reserve enough capacity to handle the extra bytes we&#x27;ll truncate.</span></span><br><span class=\"line\"><span class=\"keyword\">let</span> <span class=\"keyword\">mut </span><span class=\"variable\">bytes_to_splice</span> = <span class=\"type\">Vec</span>::<span class=\"title function_ invoke__\">with_capacity</span>(header_size + <span class=\"number\">3</span>);</span><br><span class=\"line\">bytes_to_splice.<span class=\"title function_ invoke__\">push</span>(header);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title function_ invoke__\">append_packed_u32</span>(&amp;<span class=\"keyword\">mut</span> bytes_to_splice, num_elements, <span class=\"keyword\">if</span> is_large &#123; <span class=\"number\">4</span> &#125; <span class=\"keyword\">else</span> &#123; <span class=\"number\">1</span> &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> <span class=\"variable\">offset</span> <span class=\"keyword\">in</span> std::mem::<span class=\"title function_ invoke__\">take</span>(<span class=\"keyword\">self</span>.offsets) &#123;</span><br><span class=\"line\">    <span class=\"title function_ invoke__\">append_packed_u32</span>(&amp;<span class=\"keyword\">mut</span> bytes_to_splice, offset <span class=\"keyword\">as</span> <span class=\"type\">u32</span>, offset_size <span class=\"keyword\">as</span> <span class=\"type\">usize</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title function_ invoke__\">append_packed_u32</span>(&amp;<span class=\"keyword\">mut</span> bytes_to_splice, data_size <span class=\"keyword\">as</span> <span class=\"type\">u32</span>, offset_size <span class=\"keyword\">as</span> <span class=\"type\">usize</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">buffer</span><br><span class=\"line\">    .<span class=\"title function_ invoke__\">inner_mut</span>()</span><br><span class=\"line\">    .<span class=\"title function_ invoke__\">splice</span>(starting_offset..starting_offset, bytes_to_splice);</span><br></pre></td></tr></table></figure>\n<p>然后进行了 benchmark 的测试，发现第六种在所有的方案中会更好</p>\n<p>这里有一些性能的点</p>\n<ul>\n<li><code>Vec::splice</code> 需要 <code>Iterator</code> 的 lower-bound 来进行预测，不然可能会耗时更多，可以通过自定义的 Iterator 来提供</li>\n<li>使用 extend 这些可能会性能更好（？）</li>\n<li>可以通过对 U32 进行处理，直接完成 PackedU32 相关的事情，其中 U32 可以当成是 4 个 U8 然后 <code>to_le_bytes()</code> 就是按照顺序来排列的，这样的话，可以使用 <code>truncate</code>来轻量级的处理只需要 U32 部分 byte 的情况</li>\n<li>另外在 Rust 中 <code>into_iter()</code> 和 <code>iter()</code> 这些还需要继续学习了解下。</li>\n</ul>\n<p>整体看 Rust 中是可以获得更好的性能，这些需要对相对更低层的知识有更好的了解（或者这里更多的是对 API 有更好的了解），这些如果仅仅通过学习是比较难了解到的，通过实际的项目则可以更好/直观的看到不同实现的差异。</p>"},{"title":"投资、创业与创新","date":"2025-09-19T12:45:32.000Z","toc":true,"_content":"\n> 尝试记录一个思想快照，供后续 review 使用。\n\n# 套利\n> Arbitrage is the practice of taking advantage of a difference in prices in two or more markets – striking a combination of matching deals to capitalize on the difference, the profit being the difference between the market prices at which the unit is traded. Arbitrage has the effect of causing prices of the same or very similar assets in different markets to converge.\n\n套利(Arbitrage)： 是一种利用资产在不同市场/不同形态进行交易获取价差来获利的行为。这里的描述中更多的是空间上的，而没有描述时间上的。加上时间维度，就变成了二维空间（时间和空间），套利行为则是在二维空间中某两个（或多个）点之间赚取利差。前面的套利则是时间（基本）一致的情况下。\n\n<!--more-->\n\n简单的图形如下所示，上图是仅空间维度上套利；下图是时间和空间维度一起进行套利。\n\n<div style=\"text-align: center;\">\n<img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202509111518153.png\" alt=\"仅空间维度\" width=\"400\" inline-block/><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202509111518647.png\" alt=\"时间和空间维度一起\" width=\"400\" inline-block/>\n</div>\n\n套利系统中的利润通常是金钱，也可以不是金钱, 广义上来说，可以是任何自己想要获得的东西。我们在时空二维范围内某个点进行 *投入*，然后在另外一个点上获得更好的回报，从而获得套利。这个回报可以是金钱，可以产品能力，可以是影响力，可以是其他任何自己想要的东西。\n\n# 投资\n这里的投资是 *价值投资* 的简称，认为资产的价格会锚定到资产本身的价值上。\n\n如[股市是不是一个好的投资渠道](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ) 一文所描述，投资是在多个资产之间进行比较，选取一个未来获益可能更大的标的，这也可以归一成一种套利 - 时间维度的套利。对于同一个标的，*现在* 与 *未来* 的价值不一样，通过现在的价格买入，在未来价格更高的时候获利。这里未来的价值涉及到估算，比如通过现金流折现，某公司在未来能赚多少钱。首先需要知道未来该公司能赚多少钱，这一步需要对公司以及公司所在的行业有一定的认识，然后需要对钱在不同时间点的价值有一定的了解 -- 也就是“折现”。二十年前的 1 万元，和现在的 1 万元是完全不同的，10 年后的 10W 和现在 8W 谁更值钱呢？这就提现“折现率”的地方，通常的折现率选择自己能找到的稳定收益中利率最高的一个，或者可以直接锚定到十年期的国债。\n\n本文中的 *未来* 是一个泛指，可以是 1 年，3 年或者更久，在这里是一个代指。在实际投资中需要考虑资金的可使用周期，如果资金仅能使用 1 年，也就是说 1 年内会强制兑现，那么需要更多时间才能盈利的标的就不太合适，就算该标的在之后的时间涨了很多，也和自己无关，对自己来说也是一次失败的投资。但是由于市场的不可预测性，因此建议投资的金钱是“闲置金钱” -- 也就是可以无限期不使用的，这样能够穿过市场的情绪周期，直到投资标的的价值被反馈到价格上。\n\n\n# 创业\n\n创业是希望提供一套能够解决某些用户需求的产品，获取更好利益的行为，是一种商业行为，本质上和小卖部等生意类似，不同的公司复杂度不一样，难度不一样，获利也会不一样。\n\n由于创业是通过产品来获利，那么就需要对目标市场/用户需求有足够了解，能够更好解决用户需求的产品，往往能够获得更多的用户，从而获得更好的回报。由于金钱会流向更赚钱的地方，因此创业不仅仅需要有解决用户需求的产品，也需要有一套系统/方法能够保证自己处于领先地位，或者较长时间处于领先地位（或者至少能够让公司存活下来），需要有自己的竞争性优势/差异化，而且需要能够持续的进行迭代演进，否则现在的竞争性优势在未来会被其他公司追赶上，并反超。\n\n了解到创业的有如下两种：1）面向 VC 的创业；2）面向客户的创业。第一类创业通过融资，以及后续的退出来赚钱，产品可能可以盈利，也可能无法盈利。第二类则主要通过客户用金钱投票来使公司活下去。这两种也可能有重合，也就是说拿 VC 钱的也可能能够产品盈利很多；通过客户盈利的在后来也可能进行融资。\n\n# 创新\n\n创新往往和创业联系在一起，说起创业都会说创新，需要做一个新的东西来创业。但实际上创新和创业是两个维度的事情，创业是做生意，创新更像是一项开创性的工作，希望突破某个边界。创新在短期来看往往是投入比回报更多的，需要在看到结果之前能够持续的投入。因此如果相对较大的创新，如果是作为创业的核心因素，则要么能够有 VC 持续的投入，要么公司能够盈利持续投入，否则可能在看到结果之前无法持续。\n\n创新成功后如果有足够的壁垒，可以给公司未来一段时间内带来竞争性优势，带来或者保证收益。如果公司有不错的盈利能力，进行一些长期创新性的投资是合理，而且是有必要的，因为客户需求随着时间发展往往会发生改变，但是拥有足够盈利能力后，往往会由于各种各样的因素导致跟不上新的形式，从而错过一些大趋势。保持一些创新（可能不是很大），则是希望能够保持一些更多的可能性，也能够在整个环境发生变化的时候，能够较快的适应和转变。\n\n# 综合\n\n投资、创业、创新都是时间空间维度上进行套利，如果按照价值投资的角度，则投资和创业基本能统一起来，要找一个市场大的（基数大，可能性更高），然后在里面找自己想比较别人有优势的（差异化），而且要确认这个差异化是用户愿意付钱的。这里面每一步都不容易，但是在这几步分析完成之后，往后的路更好走。比如在投资前详细分析了公司，那么投资出去之后，不会因为一些股价的涨跌而导致自己内心的波动。换句话说，在投资出去的那一刻，你的收益已经基本决定了 -- 长远来看涨跌是相对靠谱的，但是短期来看涨跌不定，而且浮动不定。创业和投资的差异在于创业需要自己动手去做，能获取到更多的一手信息；而投资仅投钱，由公司的人进行操盘。创新则是更长时间维度的套利，创新的大小会影响需要的时间以及资金投入。\n\n另外，不管是投资还是创业，需要弄清楚，哪些是资产，哪些是成本，哪些是负债，哪些会创造现金流。随着时间的演进，能够加强企业竞争力，增加护城河的，是资产，其他的则是成本。对于资产来说，只有买便宜和买贵的差异，最差的情况是买贵了，也就是少赚一点。对于成本则不一样，浪费了就浪费了，甚至会有负作用（比如受沉默成本等影响）。不管是投资还是创业，如果能很好的分清楚资产和成本，也能够比其他人看得更远一些，更深刻一些，长期来看也可以更坚定一些，赚大钱的概率也更大一些，如果能将成本通过某些方式转化成资产，则是更好的方式。\n","source":"_posts/investment-startup-innovation.md","raw":"---\ntitle: 投资、创业与创新\ndate: 2025-09-19 20:45:32\ntags:\n    - investment\n    - startup\n    - innovation\ntoc: true\n---\n\n> 尝试记录一个思想快照，供后续 review 使用。\n\n# 套利\n> Arbitrage is the practice of taking advantage of a difference in prices in two or more markets – striking a combination of matching deals to capitalize on the difference, the profit being the difference between the market prices at which the unit is traded. Arbitrage has the effect of causing prices of the same or very similar assets in different markets to converge.\n\n套利(Arbitrage)： 是一种利用资产在不同市场/不同形态进行交易获取价差来获利的行为。这里的描述中更多的是空间上的，而没有描述时间上的。加上时间维度，就变成了二维空间（时间和空间），套利行为则是在二维空间中某两个（或多个）点之间赚取利差。前面的套利则是时间（基本）一致的情况下。\n\n<!--more-->\n\n简单的图形如下所示，上图是仅空间维度上套利；下图是时间和空间维度一起进行套利。\n\n<div style=\"text-align: center;\">\n<img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202509111518153.png\" alt=\"仅空间维度\" width=\"400\" inline-block/><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202509111518647.png\" alt=\"时间和空间维度一起\" width=\"400\" inline-block/>\n</div>\n\n套利系统中的利润通常是金钱，也可以不是金钱, 广义上来说，可以是任何自己想要获得的东西。我们在时空二维范围内某个点进行 *投入*，然后在另外一个点上获得更好的回报，从而获得套利。这个回报可以是金钱，可以产品能力，可以是影响力，可以是其他任何自己想要的东西。\n\n# 投资\n这里的投资是 *价值投资* 的简称，认为资产的价格会锚定到资产本身的价值上。\n\n如[股市是不是一个好的投资渠道](https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ) 一文所描述，投资是在多个资产之间进行比较，选取一个未来获益可能更大的标的，这也可以归一成一种套利 - 时间维度的套利。对于同一个标的，*现在* 与 *未来* 的价值不一样，通过现在的价格买入，在未来价格更高的时候获利。这里未来的价值涉及到估算，比如通过现金流折现，某公司在未来能赚多少钱。首先需要知道未来该公司能赚多少钱，这一步需要对公司以及公司所在的行业有一定的认识，然后需要对钱在不同时间点的价值有一定的了解 -- 也就是“折现”。二十年前的 1 万元，和现在的 1 万元是完全不同的，10 年后的 10W 和现在 8W 谁更值钱呢？这就提现“折现率”的地方，通常的折现率选择自己能找到的稳定收益中利率最高的一个，或者可以直接锚定到十年期的国债。\n\n本文中的 *未来* 是一个泛指，可以是 1 年，3 年或者更久，在这里是一个代指。在实际投资中需要考虑资金的可使用周期，如果资金仅能使用 1 年，也就是说 1 年内会强制兑现，那么需要更多时间才能盈利的标的就不太合适，就算该标的在之后的时间涨了很多，也和自己无关，对自己来说也是一次失败的投资。但是由于市场的不可预测性，因此建议投资的金钱是“闲置金钱” -- 也就是可以无限期不使用的，这样能够穿过市场的情绪周期，直到投资标的的价值被反馈到价格上。\n\n\n# 创业\n\n创业是希望提供一套能够解决某些用户需求的产品，获取更好利益的行为，是一种商业行为，本质上和小卖部等生意类似，不同的公司复杂度不一样，难度不一样，获利也会不一样。\n\n由于创业是通过产品来获利，那么就需要对目标市场/用户需求有足够了解，能够更好解决用户需求的产品，往往能够获得更多的用户，从而获得更好的回报。由于金钱会流向更赚钱的地方，因此创业不仅仅需要有解决用户需求的产品，也需要有一套系统/方法能够保证自己处于领先地位，或者较长时间处于领先地位（或者至少能够让公司存活下来），需要有自己的竞争性优势/差异化，而且需要能够持续的进行迭代演进，否则现在的竞争性优势在未来会被其他公司追赶上，并反超。\n\n了解到创业的有如下两种：1）面向 VC 的创业；2）面向客户的创业。第一类创业通过融资，以及后续的退出来赚钱，产品可能可以盈利，也可能无法盈利。第二类则主要通过客户用金钱投票来使公司活下去。这两种也可能有重合，也就是说拿 VC 钱的也可能能够产品盈利很多；通过客户盈利的在后来也可能进行融资。\n\n# 创新\n\n创新往往和创业联系在一起，说起创业都会说创新，需要做一个新的东西来创业。但实际上创新和创业是两个维度的事情，创业是做生意，创新更像是一项开创性的工作，希望突破某个边界。创新在短期来看往往是投入比回报更多的，需要在看到结果之前能够持续的投入。因此如果相对较大的创新，如果是作为创业的核心因素，则要么能够有 VC 持续的投入，要么公司能够盈利持续投入，否则可能在看到结果之前无法持续。\n\n创新成功后如果有足够的壁垒，可以给公司未来一段时间内带来竞争性优势，带来或者保证收益。如果公司有不错的盈利能力，进行一些长期创新性的投资是合理，而且是有必要的，因为客户需求随着时间发展往往会发生改变，但是拥有足够盈利能力后，往往会由于各种各样的因素导致跟不上新的形式，从而错过一些大趋势。保持一些创新（可能不是很大），则是希望能够保持一些更多的可能性，也能够在整个环境发生变化的时候，能够较快的适应和转变。\n\n# 综合\n\n投资、创业、创新都是时间空间维度上进行套利，如果按照价值投资的角度，则投资和创业基本能统一起来，要找一个市场大的（基数大，可能性更高），然后在里面找自己想比较别人有优势的（差异化），而且要确认这个差异化是用户愿意付钱的。这里面每一步都不容易，但是在这几步分析完成之后，往后的路更好走。比如在投资前详细分析了公司，那么投资出去之后，不会因为一些股价的涨跌而导致自己内心的波动。换句话说，在投资出去的那一刻，你的收益已经基本决定了 -- 长远来看涨跌是相对靠谱的，但是短期来看涨跌不定，而且浮动不定。创业和投资的差异在于创业需要自己动手去做，能获取到更多的一手信息；而投资仅投钱，由公司的人进行操盘。创新则是更长时间维度的套利，创新的大小会影响需要的时间以及资金投入。\n\n另外，不管是投资还是创业，需要弄清楚，哪些是资产，哪些是成本，哪些是负债，哪些会创造现金流。随着时间的演进，能够加强企业竞争力，增加护城河的，是资产，其他的则是成本。对于资产来说，只有买便宜和买贵的差异，最差的情况是买贵了，也就是少赚一点。对于成本则不一样，浪费了就浪费了，甚至会有负作用（比如受沉默成本等影响）。不管是投资还是创业，如果能很好的分清楚资产和成本，也能够比其他人看得更远一些，更深刻一些，长期来看也可以更坚定一些，赚大钱的概率也更大一些，如果能将成本通过某些方式转化成资产，则是更好的方式。\n","slug":"investment-startup-innovation","published":1,"updated":"2025-09-19T13:04:13.823Z","_id":"cmfqtzot1000dyafyes954mop","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>尝试记录一个思想快照，供后续 review 使用。</p>\n</blockquote>\n<h1 id=\"套利\"><a href=\"#套利\" class=\"headerlink\" title=\"套利\"></a>套利</h1><blockquote>\n<p>Arbitrage is the practice of taking advantage of a difference in prices in two or more markets – striking a combination of matching deals to capitalize on the difference, the profit being the difference between the market prices at which the unit is traded. Arbitrage has the effect of causing prices of the same or very similar assets in different markets to converge.</p>\n</blockquote>\n<p>套利(Arbitrage)： 是一种利用资产在不同市场/不同形态进行交易获取价差来获利的行为。这里的描述中更多的是空间上的，而没有描述时间上的。加上时间维度，就变成了二维空间（时间和空间），套利行为则是在二维空间中某两个（或多个）点之间赚取利差。前面的套利则是时间（基本）一致的情况下。</p>\n<span id=\"more\"></span>\n<p>简单的图形如下所示，上图是仅空间维度上套利；下图是时间和空间维度一起进行套利。</p>\n<div style=\"text-align: center;\">\n<img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202509111518153.png\" alt=\"仅空间维度\" width=\"400\" inline-block/><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202509111518647.png\" alt=\"时间和空间维度一起\" width=\"400\" inline-block/>\n</div>\n\n<p>套利系统中的利润通常是金钱，也可以不是金钱, 广义上来说，可以是任何自己想要获得的东西。我们在时空二维范围内某个点进行 <em>投入</em>，然后在另外一个点上获得更好的回报，从而获得套利。这个回报可以是金钱，可以产品能力，可以是影响力，可以是其他任何自己想要的东西。</p>\n<h1 id=\"投资\"><a href=\"#投资\" class=\"headerlink\" title=\"投资\"></a>投资</h1><p>这里的投资是 <em>价值投资</em> 的简称，认为资产的价格会锚定到资产本身的价值上。</p>\n<p>如<a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">股市是不是一个好的投资渠道</a> 一文所描述，投资是在多个资产之间进行比较，选取一个未来获益可能更大的标的，这也可以归一成一种套利 - 时间维度的套利。对于同一个标的，<em>现在</em> 与 <em>未来</em> 的价值不一样，通过现在的价格买入，在未来价格更高的时候获利。这里未来的价值涉及到估算，比如通过现金流折现，某公司在未来能赚多少钱。首先需要知道未来该公司能赚多少钱，这一步需要对公司以及公司所在的行业有一定的认识，然后需要对钱在不同时间点的价值有一定的了解 — 也就是“折现”。二十年前的 1 万元，和现在的 1 万元是完全不同的，10 年后的 10W 和现在 8W 谁更值钱呢？这就提现“折现率”的地方，通常的折现率选择自己能找到的稳定收益中利率最高的一个，或者可以直接锚定到十年期的国债。</p>\n<p>本文中的 <em>未来</em> 是一个泛指，可以是 1 年，3 年或者更久，在这里是一个代指。在实际投资中需要考虑资金的可使用周期，如果资金仅能使用 1 年，也就是说 1 年内会强制兑现，那么需要更多时间才能盈利的标的就不太合适，就算该标的在之后的时间涨了很多，也和自己无关，对自己来说也是一次失败的投资。但是由于市场的不可预测性，因此建议投资的金钱是“闲置金钱” — 也就是可以无限期不使用的，这样能够穿过市场的情绪周期，直到投资标的的价值被反馈到价格上。</p>\n<h1 id=\"创业\"><a href=\"#创业\" class=\"headerlink\" title=\"创业\"></a>创业</h1><p>创业是希望提供一套能够解决某些用户需求的产品，获取更好利益的行为，是一种商业行为，本质上和小卖部等生意类似，不同的公司复杂度不一样，难度不一样，获利也会不一样。</p>\n<p>由于创业是通过产品来获利，那么就需要对目标市场/用户需求有足够了解，能够更好解决用户需求的产品，往往能够获得更多的用户，从而获得更好的回报。由于金钱会流向更赚钱的地方，因此创业不仅仅需要有解决用户需求的产品，也需要有一套系统/方法能够保证自己处于领先地位，或者较长时间处于领先地位（或者至少能够让公司存活下来），需要有自己的竞争性优势/差异化，而且需要能够持续的进行迭代演进，否则现在的竞争性优势在未来会被其他公司追赶上，并反超。</p>\n<p>了解到创业的有如下两种：1）面向 VC 的创业；2）面向客户的创业。第一类创业通过融资，以及后续的退出来赚钱，产品可能可以盈利，也可能无法盈利。第二类则主要通过客户用金钱投票来使公司活下去。这两种也可能有重合，也就是说拿 VC 钱的也可能能够产品盈利很多；通过客户盈利的在后来也可能进行融资。</p>\n<h1 id=\"创新\"><a href=\"#创新\" class=\"headerlink\" title=\"创新\"></a>创新</h1><p>创新往往和创业联系在一起，说起创业都会说创新，需要做一个新的东西来创业。但实际上创新和创业是两个维度的事情，创业是做生意，创新更像是一项开创性的工作，希望突破某个边界。创新在短期来看往往是投入比回报更多的，需要在看到结果之前能够持续的投入。因此如果相对较大的创新，如果是作为创业的核心因素，则要么能够有 VC 持续的投入，要么公司能够盈利持续投入，否则可能在看到结果之前无法持续。</p>\n<p>创新成功后如果有足够的壁垒，可以给公司未来一段时间内带来竞争性优势，带来或者保证收益。如果公司有不错的盈利能力，进行一些长期创新性的投资是合理，而且是有必要的，因为客户需求随着时间发展往往会发生改变，但是拥有足够盈利能力后，往往会由于各种各样的因素导致跟不上新的形式，从而错过一些大趋势。保持一些创新（可能不是很大），则是希望能够保持一些更多的可能性，也能够在整个环境发生变化的时候，能够较快的适应和转变。</p>\n<h1 id=\"综合\"><a href=\"#综合\" class=\"headerlink\" title=\"综合\"></a>综合</h1><p>投资、创业、创新都是时间空间维度上进行套利，如果按照价值投资的角度，则投资和创业基本能统一起来，要找一个市场大的（基数大，可能性更高），然后在里面找自己想比较别人有优势的（差异化），而且要确认这个差异化是用户愿意付钱的。这里面每一步都不容易，但是在这几步分析完成之后，往后的路更好走。比如在投资前详细分析了公司，那么投资出去之后，不会因为一些股价的涨跌而导致自己内心的波动。换句话说，在投资出去的那一刻，你的收益已经基本决定了 — 长远来看涨跌是相对靠谱的，但是短期来看涨跌不定，而且浮动不定。创业和投资的差异在于创业需要自己动手去做，能获取到更多的一手信息；而投资仅投钱，由公司的人进行操盘。创新则是更长时间维度的套利，创新的大小会影响需要的时间以及资金投入。</p>\n<p>另外，不管是投资还是创业，需要弄清楚，哪些是资产，哪些是成本，哪些是负债，哪些会创造现金流。随着时间的演进，能够加强企业竞争力，增加护城河的，是资产，其他的则是成本。对于资产来说，只有买便宜和买贵的差异，最差的情况是买贵了，也就是少赚一点。对于成本则不一样，浪费了就浪费了，甚至会有负作用（比如受沉默成本等影响）。不管是投资还是创业，如果能很好的分清楚资产和成本，也能够比其他人看得更远一些，更深刻一些，长期来看也可以更坚定一些，赚大钱的概率也更大一些，如果能将成本通过某些方式转化成资产，则是更好的方式。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>尝试记录一个思想快照，供后续 review 使用。</p>\n</blockquote>\n<h1 id=\"套利\"><a href=\"#套利\" class=\"headerlink\" title=\"套利\"></a>套利</h1><blockquote>\n<p>Arbitrage is the practice of taking advantage of a difference in prices in two or more markets – striking a combination of matching deals to capitalize on the difference, the profit being the difference between the market prices at which the unit is traded. Arbitrage has the effect of causing prices of the same or very similar assets in different markets to converge.</p>\n</blockquote>\n<p>套利(Arbitrage)： 是一种利用资产在不同市场/不同形态进行交易获取价差来获利的行为。这里的描述中更多的是空间上的，而没有描述时间上的。加上时间维度，就变成了二维空间（时间和空间），套利行为则是在二维空间中某两个（或多个）点之间赚取利差。前面的套利则是时间（基本）一致的情况下。</p>","more":"<p>简单的图形如下所示，上图是仅空间维度上套利；下图是时间和空间维度一起进行套利。</p>\n<div style=\"text-align: center;\">\n<img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202509111518153.png\" alt=\"仅空间维度\" width=\"400\" inline-block/><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202509111518647.png\" alt=\"时间和空间维度一起\" width=\"400\" inline-block/>\n</div>\n\n<p>套利系统中的利润通常是金钱，也可以不是金钱, 广义上来说，可以是任何自己想要获得的东西。我们在时空二维范围内某个点进行 <em>投入</em>，然后在另外一个点上获得更好的回报，从而获得套利。这个回报可以是金钱，可以产品能力，可以是影响力，可以是其他任何自己想要的东西。</p>\n<h1 id=\"投资\"><a href=\"#投资\" class=\"headerlink\" title=\"投资\"></a>投资</h1><p>这里的投资是 <em>价值投资</em> 的简称，认为资产的价格会锚定到资产本身的价值上。</p>\n<p>如<a href=\"https://mp.weixin.qq.com/s/MoGZimAdRqB-fWUWcMSqVQ\">股市是不是一个好的投资渠道</a> 一文所描述，投资是在多个资产之间进行比较，选取一个未来获益可能更大的标的，这也可以归一成一种套利 - 时间维度的套利。对于同一个标的，<em>现在</em> 与 <em>未来</em> 的价值不一样，通过现在的价格买入，在未来价格更高的时候获利。这里未来的价值涉及到估算，比如通过现金流折现，某公司在未来能赚多少钱。首先需要知道未来该公司能赚多少钱，这一步需要对公司以及公司所在的行业有一定的认识，然后需要对钱在不同时间点的价值有一定的了解 — 也就是“折现”。二十年前的 1 万元，和现在的 1 万元是完全不同的，10 年后的 10W 和现在 8W 谁更值钱呢？这就提现“折现率”的地方，通常的折现率选择自己能找到的稳定收益中利率最高的一个，或者可以直接锚定到十年期的国债。</p>\n<p>本文中的 <em>未来</em> 是一个泛指，可以是 1 年，3 年或者更久，在这里是一个代指。在实际投资中需要考虑资金的可使用周期，如果资金仅能使用 1 年，也就是说 1 年内会强制兑现，那么需要更多时间才能盈利的标的就不太合适，就算该标的在之后的时间涨了很多，也和自己无关，对自己来说也是一次失败的投资。但是由于市场的不可预测性，因此建议投资的金钱是“闲置金钱” — 也就是可以无限期不使用的，这样能够穿过市场的情绪周期，直到投资标的的价值被反馈到价格上。</p>\n<h1 id=\"创业\"><a href=\"#创业\" class=\"headerlink\" title=\"创业\"></a>创业</h1><p>创业是希望提供一套能够解决某些用户需求的产品，获取更好利益的行为，是一种商业行为，本质上和小卖部等生意类似，不同的公司复杂度不一样，难度不一样，获利也会不一样。</p>\n<p>由于创业是通过产品来获利，那么就需要对目标市场/用户需求有足够了解，能够更好解决用户需求的产品，往往能够获得更多的用户，从而获得更好的回报。由于金钱会流向更赚钱的地方，因此创业不仅仅需要有解决用户需求的产品，也需要有一套系统/方法能够保证自己处于领先地位，或者较长时间处于领先地位（或者至少能够让公司存活下来），需要有自己的竞争性优势/差异化，而且需要能够持续的进行迭代演进，否则现在的竞争性优势在未来会被其他公司追赶上，并反超。</p>\n<p>了解到创业的有如下两种：1）面向 VC 的创业；2）面向客户的创业。第一类创业通过融资，以及后续的退出来赚钱，产品可能可以盈利，也可能无法盈利。第二类则主要通过客户用金钱投票来使公司活下去。这两种也可能有重合，也就是说拿 VC 钱的也可能能够产品盈利很多；通过客户盈利的在后来也可能进行融资。</p>\n<h1 id=\"创新\"><a href=\"#创新\" class=\"headerlink\" title=\"创新\"></a>创新</h1><p>创新往往和创业联系在一起，说起创业都会说创新，需要做一个新的东西来创业。但实际上创新和创业是两个维度的事情，创业是做生意，创新更像是一项开创性的工作，希望突破某个边界。创新在短期来看往往是投入比回报更多的，需要在看到结果之前能够持续的投入。因此如果相对较大的创新，如果是作为创业的核心因素，则要么能够有 VC 持续的投入，要么公司能够盈利持续投入，否则可能在看到结果之前无法持续。</p>\n<p>创新成功后如果有足够的壁垒，可以给公司未来一段时间内带来竞争性优势，带来或者保证收益。如果公司有不错的盈利能力，进行一些长期创新性的投资是合理，而且是有必要的，因为客户需求随着时间发展往往会发生改变，但是拥有足够盈利能力后，往往会由于各种各样的因素导致跟不上新的形式，从而错过一些大趋势。保持一些创新（可能不是很大），则是希望能够保持一些更多的可能性，也能够在整个环境发生变化的时候，能够较快的适应和转变。</p>\n<h1 id=\"综合\"><a href=\"#综合\" class=\"headerlink\" title=\"综合\"></a>综合</h1><p>投资、创业、创新都是时间空间维度上进行套利，如果按照价值投资的角度，则投资和创业基本能统一起来，要找一个市场大的（基数大，可能性更高），然后在里面找自己想比较别人有优势的（差异化），而且要确认这个差异化是用户愿意付钱的。这里面每一步都不容易，但是在这几步分析完成之后，往后的路更好走。比如在投资前详细分析了公司，那么投资出去之后，不会因为一些股价的涨跌而导致自己内心的波动。换句话说，在投资出去的那一刻，你的收益已经基本决定了 — 长远来看涨跌是相对靠谱的，但是短期来看涨跌不定，而且浮动不定。创业和投资的差异在于创业需要自己动手去做，能获取到更多的一手信息；而投资仅投钱，由公司的人进行操盘。创新则是更长时间维度的套利，创新的大小会影响需要的时间以及资金投入。</p>\n<p>另外，不管是投资还是创业，需要弄清楚，哪些是资产，哪些是成本，哪些是负债，哪些会创造现金流。随着时间的演进，能够加强企业竞争力，增加护城河的，是资产，其他的则是成本。对于资产来说，只有买便宜和买贵的差异，最差的情况是买贵了，也就是少赚一点。对于成本则不一样，浪费了就浪费了，甚至会有负作用（比如受沉默成本等影响）。不管是投资还是创业，如果能很好的分清楚资产和成本，也能够比其他人看得更远一些，更深刻一些，长期来看也可以更坚定一些，赚大钱的概率也更大一些，如果能将成本通过某些方式转化成资产，则是更好的方式。</p>"},{"title":"价值投资是一种思维模式","date":"2025-10-07T02:23:32.000Z","toc":true,"_content":"\n> 交易市场往往在大幅波动（大涨/大跌）的时候会比较活跃，最近市场行情不错，整体活跃度增长，这里记录下自己当前关于价值投资的一些看法。值投资价值投资的好处：比较大概率能赚钱（逻辑通顺），主要依赖自己下的功夫，不需要一直盯盘（投入时间不一定少，但是不那么急迫），最近 2972 天的复合年化 22.03% ，基本没有盯盘，整体效果还不错。\n\n所有的投资都是一种 [套利](https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q)，价值投资则是在有价值的资产上以较低价格买入，然后等升值后卖出赚钱。因为在投资之前就已经进行了重复的计算，因此投资过程相对简单，但是简单并不表示容易：1）什么是有价值的资产：2）什么时候是（较）低价：3）如何能做到不受波动影响。每一步都不容易，但是做到一次之后就会越来越容易，而且这个会有复利\n\n<!-- more -->\n\n# 投资是一种资产配置\n如果把投资看成一种[资产配置](https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q)，所有人每时每刻都在进行资产配置，因为钱终归是以某种标的形式而存在。投资中有又会有不同的类型，包括固定收益和非固定收益，而非固定收益中常常以股票、基金等形式而存在，在股票中一个很常见的投资手段就是价值投资。根据个人经验而言：价值投资是挺不错的一种投资手段，能够大概率依靠自己赚钱，且不需要一直盯盘（投入时间少，不会有非常大的压力），个人最近 2972 天的复合年化 22.03% 也是一个很好的收益率。另外关于价值投资是否适合所有人，可以参考《The Superinvestors of Graham-and-Doddsville》[3]。\n\n# 价值投资\n\n投资实际是一种 [资产配置](https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q) 希望能够从配置的过程中进行 [套利](https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q)，我们希望现在的资产配置，在未来能够“更值钱”。\n具体到单个投资标的中，则可以简单到两个动作：买入和卖出。那么就是以“低价”买入，“高价”卖出，从而赚取中间差价赚钱（当然可能不需要卖出也能赚钱）。\n\n价值投资假定投资标的的价格围绕真实价值波动。因此在“买入”和“卖出” 的时候，将价格与价值进行比较，如果被低估则进行买入，被严重高估的时候进行卖出。对于价值的估算则需要对投资标的进行详细的研究，具体可以用未来现金流折现进行计算。\n\n因此整个过程会分为\n- 买入之前  -> 做研究\n- 买入      -> 根据研究结果以及价格进行买入\n- 卖出      -> 研究结论有变，或者过分高估\n\n实际在买入之前已经做了重复的研究，公司所在的行业是否足够有差异化（如果没有差异化，那么公司会获得相对比较累，赚辛苦钱），公司是否有足够的竞争力，产品是否有差异化（可以参考波特五力） -- 换句话说：用户是否愿意同等价格（甚至高价）购买自己的产品。行业的事情也可以参考头部公司的阐述以及专业公司的描述。公司的竞争力是否能够持续（也就是通常说的护城河是否够宽），在持续演化过程中，[文化](https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw)是一个很重要的因素，文化不仅仅是墙上的话语，还要看实际怎么做的。另外对于文化/价值观来说，也需要区分开 “做错的事” 和 “把对的事做错” 两者，前者是要避免的，而后者则是不能避免的 -- 任何人都会出错，都需要从错误过程中学习。\n\n在做了充分的研究之后，如果价格相对较低，则可以进行买入，买入实际是一个很简单的动作，因为相对于未来的价格来说，当前的价格是很便宜的，也就是说未来可以赚钱。当然部分足够好的投资标的不一定能够持续足够低的价格，因此可以在合适（不一定低估）的价格也可以买入 -- 相对高的价格买入好的投资标的，比低价买入差的投资标的，在长远来看更赚钱。另外任何人都可能出错，因此要视自己研究的程度给买入价格留有一定的 buffer，就算自己看错了，也不会亏太多。这一点也可以看出越好的投资标的对投资人越友好，因为买贵只是少赚一点而已，但是不好的投资标的则可能亏钱。\n\n公司的价值可以使用未来现金流折现进行 _估算_ -- 之所以是估算，因为折现率每个人可能设置的都不一样，这个和自己的机会成本有关。在投资来说，也就是自己能找到的无风险投资的最高收益率。这也很多地方说的未来现金流折现是一种思想方式，而不是用来具体进行计算的公式。\n\n买入结束之后，就剩卖出了。卖出的逻辑也相对简单\n1. 如果买入逻辑已经不成立，则考虑卖出。这里分为两种情况。第一种是之前的研究有误，那么这种情况下应该立即卖出，因为知道错误之后，立即改正的代价永远是最小的。第二种则是公司的基本情况发生变化导致之前的买入逻辑不再成立，那么这种情况也需要卖出。\n2. 如果价格严重超出了预估的价值，也可以卖出。价格围绕价值波动，如果觉得严重超出了价值，那么也必然会下降下来，或者等后续价值再涨上去。但是“严重超出”需要自己定义，尤其是好的投资标的，可能卖出后短期无法再以同样的价格进行买入，另外卖出/买入也有交易成本，这些也会减少自己的收益。\n\n这几个过程中，研究公司往往比较枯燥，但是这个确实真正决定能否赚钱的根本。研究的越清楚，才能够下更大的注，才能有更大的定力赚的更多。研究清楚之后，往往能否赚钱、能赚多少在买入的时候已经基本决定（假设投入的钱可以长期使用，不会中间被迫卖出），卖出只是在兑现之前赚取的收益。研究公司情况是贯穿整个阶段的，因为对于单个投资标的来说，需要持续跟进基本情况是否有发生变化，同时需要不断的扩展自己对其他公司的了解。研究公司的过程也能加深自己对真实世界的了解。\n\n在整套系统串起来之后，就可以把压力分摊到平时，也不需要进行那么精确的择时，不再需要时刻进行盯盘，大大减轻自己所面临的压力。\n\n\n# 投资是一项技能\n> 纸上得来终觉浅，绝知此事要躬行。\n\n投资是一项技能，有再多的理论知识，最终还是需要在实际操作过程中不断优化迭代，因此投资越早开始越好，既能够不断提升自己的投资能力，也可以享受[复利](https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A)所带来的收益。\n\n投资也是一项少有的个人可以胜过专业机构的活动。不需要依赖别人，纯靠自己本事，可以获得非常不错的回报。同时在这个过程中也可以对商业世界的运行有更好的理解。当然对现实实际有更好的了解，那么大概率是可以在投资市场有不错的回报。比如之前有人看到新东方开始带货之后的一些直播数据，通过自己的经验进行估算，觉得股价过于低估，因此就大幅买入，赚了不少钱, 这里面的“直播数据”为啥这么值钱就是自己的理解。\n\n当自己对投资了解越深，同时在实际投资过程中被验证或者证伪后，整个视角都会发生变化，最直接的变化就是如何看待价格的短期变化\n\n|    |   之前  | 之后 |\n| -- | -- | -- |\n| 1  | 价格是否还会上涨/下跌 | 价格小范围的波动已经不再关注 |\n| 2  | 价格涨了高兴，跌了伤心  | 短期价格涨了可能难过，短期下降反而会高兴 |\n| 3  | 更关心公司的股价波动    | 更关心公司的基本面情况  |\n| 4  | 我需要投资成功很多次才行 | 只需要在自己足够了解的标的上赚几次钱就足够 |\n| 5  | 价值投资只对大资金有用 | 价值投资使用所有资金 |\n| 6  | 被价格波动所影响    | 价格的波动为我所用  |\n\n对上面几点进行部分补充\n- 关于第二点中的“价格涨了难受，下降反而高兴”，可以从股本位的视角理解，价格更高的话，相同法币能兑换更少的股数，反之则能获得更多的股数。\n- 关于第四点，首先现在 A 股（算上沪港通）有足够多优秀的公司能够容纳足够的资金，而且获得不错的收益。\n   - 关于足够优秀的公司容纳足够的资金，可以以一个小目标为例，单股价格按照 300 进行计算，也就是 34W 股，现在头部公司的总股数是亿级别（单价公司），我们只需要选择几家公司即可，这也大大降低我们的工作量。\n   - 关于获得不错的收益，大家可以自行查看 A 股（沪港通）头部公司的回报率（可以算上分红再投入），ROE 以及 PE 值。\n- 关于第五点：投资关注的是收益率，与本金大小无关。\n\n那么价值投资到底要多久才能见效呢？这个和大环境､行业的周期，以及大家对公司价格预期的周期有关系，在三者的共同影响下得到一个当前的价格，价格的高低在当下是不太好实际感受到绝对值的，但是可以有一个相对值。我们希望的是能在整个周期中价格相对低点的时候进行买入，然后持有到较高点（再视情况而定是否卖出）。正因为如此，价值投资的周期也相对较长（至少以年为单位）-- 这也要求投资的钱是闲钱，这样才能够放置足够长时间，享受价格上涨带来的利润。实际经历过一个完整的周期后，也会对具体的信号、噪音等更有体感。如果暂时没有实际投资，也可以尝试进行模拟，把相关的情况记录下来，供后续复盘迭代优化使用。\n\n> 价格是大家预期 -- 交易撮合 --的结果，反应的是市场中更多人出的价格，也就是群体的共识，群体的共识不是理性的，所以短期价格的波动也是不理性的。也正是因为如此，投资不要加杠杆，因为我们无法预测市场的走向，也无法预测回归正常需要的时间，加杠杆的风险在于可能在低点被强制平仓，导致永久性的损失。\n\n如果是在不想研究单一投资标的，则可以投资指数/基金，指数会有一揽子投资标的进行均衡，可以减少波动的方差。\n\n# 最后\n投资是一项技能需要不断的学习，最简单的可以选择部分指数/基金；投资有复利，因此越早开始越好。投资是少有的个人可以比机构做的更好的活动，同时投资有风险，入市需谨慎，价值投资是一个相对靠谱的投资手段。\n\n# Ref\n[1] 投资、创业与创新 https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\n[2] 股市是不是一个好的投资渠道 https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\n[3] The Superinvestors of Graham-and-Doddsville https://business.columbia.edu/insights/chazen-global-insights/superinvestors-graham-and-doddsville\n[4] 差异化和公司文化 https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw\n[5] 复利比较与机会成本  https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A\n","source":"_posts/a-perspective-of-investment.md","raw":"---\ntitle: 价值投资是一种思维模式\ndate: 2025-10-07 10:23:32\ntags:\n    - investment\n    - pattern\n    - theory\n    - arbitrage\ntoc: true\n---\n\n> 交易市场往往在大幅波动（大涨/大跌）的时候会比较活跃，最近市场行情不错，整体活跃度增长，这里记录下自己当前关于价值投资的一些看法。值投资价值投资的好处：比较大概率能赚钱（逻辑通顺），主要依赖自己下的功夫，不需要一直盯盘（投入时间不一定少，但是不那么急迫），最近 2972 天的复合年化 22.03% ，基本没有盯盘，整体效果还不错。\n\n所有的投资都是一种 [套利](https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q)，价值投资则是在有价值的资产上以较低价格买入，然后等升值后卖出赚钱。因为在投资之前就已经进行了重复的计算，因此投资过程相对简单，但是简单并不表示容易：1）什么是有价值的资产：2）什么时候是（较）低价：3）如何能做到不受波动影响。每一步都不容易，但是做到一次之后就会越来越容易，而且这个会有复利\n\n<!-- more -->\n\n# 投资是一种资产配置\n如果把投资看成一种[资产配置](https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q)，所有人每时每刻都在进行资产配置，因为钱终归是以某种标的形式而存在。投资中有又会有不同的类型，包括固定收益和非固定收益，而非固定收益中常常以股票、基金等形式而存在，在股票中一个很常见的投资手段就是价值投资。根据个人经验而言：价值投资是挺不错的一种投资手段，能够大概率依靠自己赚钱，且不需要一直盯盘（投入时间少，不会有非常大的压力），个人最近 2972 天的复合年化 22.03% 也是一个很好的收益率。另外关于价值投资是否适合所有人，可以参考《The Superinvestors of Graham-and-Doddsville》[3]。\n\n# 价值投资\n\n投资实际是一种 [资产配置](https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q) 希望能够从配置的过程中进行 [套利](https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q)，我们希望现在的资产配置，在未来能够“更值钱”。\n具体到单个投资标的中，则可以简单到两个动作：买入和卖出。那么就是以“低价”买入，“高价”卖出，从而赚取中间差价赚钱（当然可能不需要卖出也能赚钱）。\n\n价值投资假定投资标的的价格围绕真实价值波动。因此在“买入”和“卖出” 的时候，将价格与价值进行比较，如果被低估则进行买入，被严重高估的时候进行卖出。对于价值的估算则需要对投资标的进行详细的研究，具体可以用未来现金流折现进行计算。\n\n因此整个过程会分为\n- 买入之前  -> 做研究\n- 买入      -> 根据研究结果以及价格进行买入\n- 卖出      -> 研究结论有变，或者过分高估\n\n实际在买入之前已经做了重复的研究，公司所在的行业是否足够有差异化（如果没有差异化，那么公司会获得相对比较累，赚辛苦钱），公司是否有足够的竞争力，产品是否有差异化（可以参考波特五力） -- 换句话说：用户是否愿意同等价格（甚至高价）购买自己的产品。行业的事情也可以参考头部公司的阐述以及专业公司的描述。公司的竞争力是否能够持续（也就是通常说的护城河是否够宽），在持续演化过程中，[文化](https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw)是一个很重要的因素，文化不仅仅是墙上的话语，还要看实际怎么做的。另外对于文化/价值观来说，也需要区分开 “做错的事” 和 “把对的事做错” 两者，前者是要避免的，而后者则是不能避免的 -- 任何人都会出错，都需要从错误过程中学习。\n\n在做了充分的研究之后，如果价格相对较低，则可以进行买入，买入实际是一个很简单的动作，因为相对于未来的价格来说，当前的价格是很便宜的，也就是说未来可以赚钱。当然部分足够好的投资标的不一定能够持续足够低的价格，因此可以在合适（不一定低估）的价格也可以买入 -- 相对高的价格买入好的投资标的，比低价买入差的投资标的，在长远来看更赚钱。另外任何人都可能出错，因此要视自己研究的程度给买入价格留有一定的 buffer，就算自己看错了，也不会亏太多。这一点也可以看出越好的投资标的对投资人越友好，因为买贵只是少赚一点而已，但是不好的投资标的则可能亏钱。\n\n公司的价值可以使用未来现金流折现进行 _估算_ -- 之所以是估算，因为折现率每个人可能设置的都不一样，这个和自己的机会成本有关。在投资来说，也就是自己能找到的无风险投资的最高收益率。这也很多地方说的未来现金流折现是一种思想方式，而不是用来具体进行计算的公式。\n\n买入结束之后，就剩卖出了。卖出的逻辑也相对简单\n1. 如果买入逻辑已经不成立，则考虑卖出。这里分为两种情况。第一种是之前的研究有误，那么这种情况下应该立即卖出，因为知道错误之后，立即改正的代价永远是最小的。第二种则是公司的基本情况发生变化导致之前的买入逻辑不再成立，那么这种情况也需要卖出。\n2. 如果价格严重超出了预估的价值，也可以卖出。价格围绕价值波动，如果觉得严重超出了价值，那么也必然会下降下来，或者等后续价值再涨上去。但是“严重超出”需要自己定义，尤其是好的投资标的，可能卖出后短期无法再以同样的价格进行买入，另外卖出/买入也有交易成本，这些也会减少自己的收益。\n\n这几个过程中，研究公司往往比较枯燥，但是这个确实真正决定能否赚钱的根本。研究的越清楚，才能够下更大的注，才能有更大的定力赚的更多。研究清楚之后，往往能否赚钱、能赚多少在买入的时候已经基本决定（假设投入的钱可以长期使用，不会中间被迫卖出），卖出只是在兑现之前赚取的收益。研究公司情况是贯穿整个阶段的，因为对于单个投资标的来说，需要持续跟进基本情况是否有发生变化，同时需要不断的扩展自己对其他公司的了解。研究公司的过程也能加深自己对真实世界的了解。\n\n在整套系统串起来之后，就可以把压力分摊到平时，也不需要进行那么精确的择时，不再需要时刻进行盯盘，大大减轻自己所面临的压力。\n\n\n# 投资是一项技能\n> 纸上得来终觉浅，绝知此事要躬行。\n\n投资是一项技能，有再多的理论知识，最终还是需要在实际操作过程中不断优化迭代，因此投资越早开始越好，既能够不断提升自己的投资能力，也可以享受[复利](https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A)所带来的收益。\n\n投资也是一项少有的个人可以胜过专业机构的活动。不需要依赖别人，纯靠自己本事，可以获得非常不错的回报。同时在这个过程中也可以对商业世界的运行有更好的理解。当然对现实实际有更好的了解，那么大概率是可以在投资市场有不错的回报。比如之前有人看到新东方开始带货之后的一些直播数据，通过自己的经验进行估算，觉得股价过于低估，因此就大幅买入，赚了不少钱, 这里面的“直播数据”为啥这么值钱就是自己的理解。\n\n当自己对投资了解越深，同时在实际投资过程中被验证或者证伪后，整个视角都会发生变化，最直接的变化就是如何看待价格的短期变化\n\n|    |   之前  | 之后 |\n| -- | -- | -- |\n| 1  | 价格是否还会上涨/下跌 | 价格小范围的波动已经不再关注 |\n| 2  | 价格涨了高兴，跌了伤心  | 短期价格涨了可能难过，短期下降反而会高兴 |\n| 3  | 更关心公司的股价波动    | 更关心公司的基本面情况  |\n| 4  | 我需要投资成功很多次才行 | 只需要在自己足够了解的标的上赚几次钱就足够 |\n| 5  | 价值投资只对大资金有用 | 价值投资使用所有资金 |\n| 6  | 被价格波动所影响    | 价格的波动为我所用  |\n\n对上面几点进行部分补充\n- 关于第二点中的“价格涨了难受，下降反而高兴”，可以从股本位的视角理解，价格更高的话，相同法币能兑换更少的股数，反之则能获得更多的股数。\n- 关于第四点，首先现在 A 股（算上沪港通）有足够多优秀的公司能够容纳足够的资金，而且获得不错的收益。\n   - 关于足够优秀的公司容纳足够的资金，可以以一个小目标为例，单股价格按照 300 进行计算，也就是 34W 股，现在头部公司的总股数是亿级别（单价公司），我们只需要选择几家公司即可，这也大大降低我们的工作量。\n   - 关于获得不错的收益，大家可以自行查看 A 股（沪港通）头部公司的回报率（可以算上分红再投入），ROE 以及 PE 值。\n- 关于第五点：投资关注的是收益率，与本金大小无关。\n\n那么价值投资到底要多久才能见效呢？这个和大环境､行业的周期，以及大家对公司价格预期的周期有关系，在三者的共同影响下得到一个当前的价格，价格的高低在当下是不太好实际感受到绝对值的，但是可以有一个相对值。我们希望的是能在整个周期中价格相对低点的时候进行买入，然后持有到较高点（再视情况而定是否卖出）。正因为如此，价值投资的周期也相对较长（至少以年为单位）-- 这也要求投资的钱是闲钱，这样才能够放置足够长时间，享受价格上涨带来的利润。实际经历过一个完整的周期后，也会对具体的信号、噪音等更有体感。如果暂时没有实际投资，也可以尝试进行模拟，把相关的情况记录下来，供后续复盘迭代优化使用。\n\n> 价格是大家预期 -- 交易撮合 --的结果，反应的是市场中更多人出的价格，也就是群体的共识，群体的共识不是理性的，所以短期价格的波动也是不理性的。也正是因为如此，投资不要加杠杆，因为我们无法预测市场的走向，也无法预测回归正常需要的时间，加杠杆的风险在于可能在低点被强制平仓，导致永久性的损失。\n\n如果是在不想研究单一投资标的，则可以投资指数/基金，指数会有一揽子投资标的进行均衡，可以减少波动的方差。\n\n# 最后\n投资是一项技能需要不断的学习，最简单的可以选择部分指数/基金；投资有复利，因此越早开始越好。投资是少有的个人可以比机构做的更好的活动，同时投资有风险，入市需谨慎，价值投资是一个相对靠谱的投资手段。\n\n# Ref\n[1] 投资、创业与创新 https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\n[2] 股市是不是一个好的投资渠道 https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\n[3] The Superinvestors of Graham-and-Doddsville https://business.columbia.edu/insights/chazen-global-insights/superinvestors-graham-and-doddsville\n[4] 差异化和公司文化 https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw\n[5] 复利比较与机会成本  https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A\n","slug":"a-perspective-of-investment","published":1,"updated":"2025-10-07T02:46:48.338Z","_id":"cmgfxrcd2000os1fy1axk8akx","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>交易市场往往在大幅波动（大涨/大跌）的时候会比较活跃，最近市场行情不错，整体活跃度增长，这里记录下自己当前关于价值投资的一些看法。值投资价值投资的好处：比较大概率能赚钱（逻辑通顺），主要依赖自己下的功夫，不需要一直盯盘（投入时间不一定少，但是不那么急迫），最近 2972 天的复合年化 22.03% ，基本没有盯盘，整体效果还不错。</p>\n</blockquote>\n<p>所有的投资都是一种 <a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">套利</a>，价值投资则是在有价值的资产上以较低价格买入，然后等升值后卖出赚钱。因为在投资之前就已经进行了重复的计算，因此投资过程相对简单，但是简单并不表示容易：1）什么是有价值的资产：2）什么时候是（较）低价：3）如何能做到不受波动影响。每一步都不容易，但是做到一次之后就会越来越容易，而且这个会有复利</p>\n<span id=\"more\"></span>\n<h1 id=\"投资是一种资产配置\"><a href=\"#投资是一种资产配置\" class=\"headerlink\" title=\"投资是一种资产配置\"></a>投资是一种资产配置</h1><p>如果把投资看成一种<a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">资产配置</a>，所有人每时每刻都在进行资产配置，因为钱终归是以某种标的形式而存在。投资中有又会有不同的类型，包括固定收益和非固定收益，而非固定收益中常常以股票、基金等形式而存在，在股票中一个很常见的投资手段就是价值投资。根据个人经验而言：价值投资是挺不错的一种投资手段，能够大概率依靠自己赚钱，且不需要一直盯盘（投入时间少，不会有非常大的压力），个人最近 2972 天的复合年化 22.03% 也是一个很好的收益率。另外关于价值投资是否适合所有人，可以参考《The Superinvestors of Graham-and-Doddsville》[3]。</p>\n<h1 id=\"价值投资\"><a href=\"#价值投资\" class=\"headerlink\" title=\"价值投资\"></a>价值投资</h1><p>投资实际是一种 <a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">资产配置</a> 希望能够从配置的过程中进行 <a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">套利</a>，我们希望现在的资产配置，在未来能够“更值钱”。<br>具体到单个投资标的中，则可以简单到两个动作：买入和卖出。那么就是以“低价”买入，“高价”卖出，从而赚取中间差价赚钱（当然可能不需要卖出也能赚钱）。</p>\n<p>价值投资假定投资标的的价格围绕真实价值波动。因此在“买入”和“卖出” 的时候，将价格与价值进行比较，如果被低估则进行买入，被严重高估的时候进行卖出。对于价值的估算则需要对投资标的进行详细的研究，具体可以用未来现金流折现进行计算。</p>\n<p>因此整个过程会分为</p>\n<ul>\n<li>买入之前  -&gt; 做研究</li>\n<li>买入      -&gt; 根据研究结果以及价格进行买入</li>\n<li>卖出      -&gt; 研究结论有变，或者过分高估</li>\n</ul>\n<p>实际在买入之前已经做了重复的研究，公司所在的行业是否足够有差异化（如果没有差异化，那么公司会获得相对比较累，赚辛苦钱），公司是否有足够的竞争力，产品是否有差异化（可以参考波特五力） — 换句话说：用户是否愿意同等价格（甚至高价）购买自己的产品。行业的事情也可以参考头部公司的阐述以及专业公司的描述。公司的竞争力是否能够持续（也就是通常说的护城河是否够宽），在持续演化过程中，<a href=\"https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw\">文化</a>是一个很重要的因素，文化不仅仅是墙上的话语，还要看实际怎么做的。另外对于文化/价值观来说，也需要区分开 “做错的事” 和 “把对的事做错” 两者，前者是要避免的，而后者则是不能避免的 — 任何人都会出错，都需要从错误过程中学习。</p>\n<p>在做了充分的研究之后，如果价格相对较低，则可以进行买入，买入实际是一个很简单的动作，因为相对于未来的价格来说，当前的价格是很便宜的，也就是说未来可以赚钱。当然部分足够好的投资标的不一定能够持续足够低的价格，因此可以在合适（不一定低估）的价格也可以买入 — 相对高的价格买入好的投资标的，比低价买入差的投资标的，在长远来看更赚钱。另外任何人都可能出错，因此要视自己研究的程度给买入价格留有一定的 buffer，就算自己看错了，也不会亏太多。这一点也可以看出越好的投资标的对投资人越友好，因为买贵只是少赚一点而已，但是不好的投资标的则可能亏钱。</p>\n<p>公司的价值可以使用未来现金流折现进行 _估算_ — 之所以是估算，因为折现率每个人可能设置的都不一样，这个和自己的机会成本有关。在投资来说，也就是自己能找到的无风险投资的最高收益率。这也很多地方说的未来现金流折现是一种思想方式，而不是用来具体进行计算的公式。</p>\n<p>买入结束之后，就剩卖出了。卖出的逻辑也相对简单</p>\n<ol>\n<li>如果买入逻辑已经不成立，则考虑卖出。这里分为两种情况。第一种是之前的研究有误，那么这种情况下应该立即卖出，因为知道错误之后，立即改正的代价永远是最小的。第二种则是公司的基本情况发生变化导致之前的买入逻辑不再成立，那么这种情况也需要卖出。</li>\n<li>如果价格严重超出了预估的价值，也可以卖出。价格围绕价值波动，如果觉得严重超出了价值，那么也必然会下降下来，或者等后续价值再涨上去。但是“严重超出”需要自己定义，尤其是好的投资标的，可能卖出后短期无法再以同样的价格进行买入，另外卖出/买入也有交易成本，这些也会减少自己的收益。</li>\n</ol>\n<p>这几个过程中，研究公司往往比较枯燥，但是这个确实真正决定能否赚钱的根本。研究的越清楚，才能够下更大的注，才能有更大的定力赚的更多。研究清楚之后，往往能否赚钱、能赚多少在买入的时候已经基本决定（假设投入的钱可以长期使用，不会中间被迫卖出），卖出只是在兑现之前赚取的收益。研究公司情况是贯穿整个阶段的，因为对于单个投资标的来说，需要持续跟进基本情况是否有发生变化，同时需要不断的扩展自己对其他公司的了解。研究公司的过程也能加深自己对真实世界的了解。</p>\n<p>在整套系统串起来之后，就可以把压力分摊到平时，也不需要进行那么精确的择时，不再需要时刻进行盯盘，大大减轻自己所面临的压力。</p>\n<h1 id=\"投资是一项技能\"><a href=\"#投资是一项技能\" class=\"headerlink\" title=\"投资是一项技能\"></a>投资是一项技能</h1><blockquote>\n<p>纸上得来终觉浅，绝知此事要躬行。</p>\n</blockquote>\n<p>投资是一项技能，有再多的理论知识，最终还是需要在实际操作过程中不断优化迭代，因此投资越早开始越好，既能够不断提升自己的投资能力，也可以享受<a href=\"https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A\">复利</a>所带来的收益。</p>\n<p>投资也是一项少有的个人可以胜过专业机构的活动。不需要依赖别人，纯靠自己本事，可以获得非常不错的回报。同时在这个过程中也可以对商业世界的运行有更好的理解。当然对现实实际有更好的了解，那么大概率是可以在投资市场有不错的回报。比如之前有人看到新东方开始带货之后的一些直播数据，通过自己的经验进行估算，觉得股价过于低估，因此就大幅买入，赚了不少钱, 这里面的“直播数据”为啥这么值钱就是自己的理解。</p>\n<p>当自己对投资了解越深，同时在实际投资过程中被验证或者证伪后，整个视角都会发生变化，最直接的变化就是如何看待价格的短期变化</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>之前</th>\n<th>之后</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>价格是否还会上涨/下跌</td>\n<td>价格小范围的波动已经不再关注</td>\n</tr>\n<tr>\n<td>2</td>\n<td>价格涨了高兴，跌了伤心</td>\n<td>短期价格涨了可能难过，短期下降反而会高兴</td>\n</tr>\n<tr>\n<td>3</td>\n<td>更关心公司的股价波动</td>\n<td>更关心公司的基本面情况</td>\n</tr>\n<tr>\n<td>4</td>\n<td>我需要投资成功很多次才行</td>\n<td>只需要在自己足够了解的标的上赚几次钱就足够</td>\n</tr>\n<tr>\n<td>5</td>\n<td>价值投资只对大资金有用</td>\n<td>价值投资使用所有资金</td>\n</tr>\n<tr>\n<td>6</td>\n<td>被价格波动所影响</td>\n<td>价格的波动为我所用</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>对上面几点进行部分补充</p>\n<ul>\n<li>关于第二点中的“价格涨了难受，下降反而高兴”，可以从股本位的视角理解，价格更高的话，相同法币能兑换更少的股数，反之则能获得更多的股数。</li>\n<li>关于第四点，首先现在 A 股（算上沪港通）有足够多优秀的公司能够容纳足够的资金，而且获得不错的收益。<ul>\n<li>关于足够优秀的公司容纳足够的资金，可以以一个小目标为例，单股价格按照 300 进行计算，也就是 34W 股，现在头部公司的总股数是亿级别（单价公司），我们只需要选择几家公司即可，这也大大降低我们的工作量。</li>\n<li>关于获得不错的收益，大家可以自行查看 A 股（沪港通）头部公司的回报率（可以算上分红再投入），ROE 以及 PE 值。</li>\n</ul>\n</li>\n<li>关于第五点：投资关注的是收益率，与本金大小无关。</li>\n</ul>\n<p>那么价值投资到底要多久才能见效呢？这个和大环境､行业的周期，以及大家对公司价格预期的周期有关系，在三者的共同影响下得到一个当前的价格，价格的高低在当下是不太好实际感受到绝对值的，但是可以有一个相对值。我们希望的是能在整个周期中价格相对低点的时候进行买入，然后持有到较高点（再视情况而定是否卖出）。正因为如此，价值投资的周期也相对较长（至少以年为单位）— 这也要求投资的钱是闲钱，这样才能够放置足够长时间，享受价格上涨带来的利润。实际经历过一个完整的周期后，也会对具体的信号、噪音等更有体感。如果暂时没有实际投资，也可以尝试进行模拟，把相关的情况记录下来，供后续复盘迭代优化使用。</p>\n<blockquote>\n<p>价格是大家预期 — 交易撮合 —的结果，反应的是市场中更多人出的价格，也就是群体的共识，群体的共识不是理性的，所以短期价格的波动也是不理性的。也正是因为如此，投资不要加杠杆，因为我们无法预测市场的走向，也无法预测回归正常需要的时间，加杠杆的风险在于可能在低点被强制平仓，导致永久性的损失。</p>\n</blockquote>\n<p>如果是在不想研究单一投资标的，则可以投资指数/基金，指数会有一揽子投资标的进行均衡，可以减少波动的方差。</p>\n<h1 id=\"最后\"><a href=\"#最后\" class=\"headerlink\" title=\"最后\"></a>最后</h1><p>投资是一项技能需要不断的学习，最简单的可以选择部分指数/基金；投资有复利，因此越早开始越好。投资是少有的个人可以比机构做的更好的活动，同时投资有风险，入市需谨慎，价值投资是一个相对靠谱的投资手段。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] 投资、创业与创新 <a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q</a><br>[2] 股市是不是一个好的投资渠道 <a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q</a><br>[3] The Superinvestors of Graham-and-Doddsville <a href=\"https://business.columbia.edu/insights/chazen-global-insights/superinvestors-graham-and-doddsville\">https://business.columbia.edu/insights/chazen-global-insights/superinvestors-graham-and-doddsville</a><br>[4] 差异化和公司文化 <a href=\"https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw\">https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw</a><br>[5] 复利比较与机会成本  <a href=\"https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A\">https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A</a></p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>交易市场往往在大幅波动（大涨/大跌）的时候会比较活跃，最近市场行情不错，整体活跃度增长，这里记录下自己当前关于价值投资的一些看法。值投资价值投资的好处：比较大概率能赚钱（逻辑通顺），主要依赖自己下的功夫，不需要一直盯盘（投入时间不一定少，但是不那么急迫），最近 2972 天的复合年化 22.03% ，基本没有盯盘，整体效果还不错。</p>\n</blockquote>\n<p>所有的投资都是一种 <a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">套利</a>，价值投资则是在有价值的资产上以较低价格买入，然后等升值后卖出赚钱。因为在投资之前就已经进行了重复的计算，因此投资过程相对简单，但是简单并不表示容易：1）什么是有价值的资产：2）什么时候是（较）低价：3）如何能做到不受波动影响。每一步都不容易，但是做到一次之后就会越来越容易，而且这个会有复利</p>","more":"<h1 id=\"投资是一种资产配置\"><a href=\"#投资是一种资产配置\" class=\"headerlink\" title=\"投资是一种资产配置\"></a>投资是一种资产配置</h1><p>如果把投资看成一种<a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">资产配置</a>，所有人每时每刻都在进行资产配置，因为钱终归是以某种标的形式而存在。投资中有又会有不同的类型，包括固定收益和非固定收益，而非固定收益中常常以股票、基金等形式而存在，在股票中一个很常见的投资手段就是价值投资。根据个人经验而言：价值投资是挺不错的一种投资手段，能够大概率依靠自己赚钱，且不需要一直盯盘（投入时间少，不会有非常大的压力），个人最近 2972 天的复合年化 22.03% 也是一个很好的收益率。另外关于价值投资是否适合所有人，可以参考《The Superinvestors of Graham-and-Doddsville》[3]。</p>\n<h1 id=\"价值投资\"><a href=\"#价值投资\" class=\"headerlink\" title=\"价值投资\"></a>价值投资</h1><p>投资实际是一种 <a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">资产配置</a> 希望能够从配置的过程中进行 <a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">套利</a>，我们希望现在的资产配置，在未来能够“更值钱”。<br>具体到单个投资标的中，则可以简单到两个动作：买入和卖出。那么就是以“低价”买入，“高价”卖出，从而赚取中间差价赚钱（当然可能不需要卖出也能赚钱）。</p>\n<p>价值投资假定投资标的的价格围绕真实价值波动。因此在“买入”和“卖出” 的时候，将价格与价值进行比较，如果被低估则进行买入，被严重高估的时候进行卖出。对于价值的估算则需要对投资标的进行详细的研究，具体可以用未来现金流折现进行计算。</p>\n<p>因此整个过程会分为</p>\n<ul>\n<li>买入之前  -&gt; 做研究</li>\n<li>买入      -&gt; 根据研究结果以及价格进行买入</li>\n<li>卖出      -&gt; 研究结论有变，或者过分高估</li>\n</ul>\n<p>实际在买入之前已经做了重复的研究，公司所在的行业是否足够有差异化（如果没有差异化，那么公司会获得相对比较累，赚辛苦钱），公司是否有足够的竞争力，产品是否有差异化（可以参考波特五力） — 换句话说：用户是否愿意同等价格（甚至高价）购买自己的产品。行业的事情也可以参考头部公司的阐述以及专业公司的描述。公司的竞争力是否能够持续（也就是通常说的护城河是否够宽），在持续演化过程中，<a href=\"https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw\">文化</a>是一个很重要的因素，文化不仅仅是墙上的话语，还要看实际怎么做的。另外对于文化/价值观来说，也需要区分开 “做错的事” 和 “把对的事做错” 两者，前者是要避免的，而后者则是不能避免的 — 任何人都会出错，都需要从错误过程中学习。</p>\n<p>在做了充分的研究之后，如果价格相对较低，则可以进行买入，买入实际是一个很简单的动作，因为相对于未来的价格来说，当前的价格是很便宜的，也就是说未来可以赚钱。当然部分足够好的投资标的不一定能够持续足够低的价格，因此可以在合适（不一定低估）的价格也可以买入 — 相对高的价格买入好的投资标的，比低价买入差的投资标的，在长远来看更赚钱。另外任何人都可能出错，因此要视自己研究的程度给买入价格留有一定的 buffer，就算自己看错了，也不会亏太多。这一点也可以看出越好的投资标的对投资人越友好，因为买贵只是少赚一点而已，但是不好的投资标的则可能亏钱。</p>\n<p>公司的价值可以使用未来现金流折现进行 _估算_ — 之所以是估算，因为折现率每个人可能设置的都不一样，这个和自己的机会成本有关。在投资来说，也就是自己能找到的无风险投资的最高收益率。这也很多地方说的未来现金流折现是一种思想方式，而不是用来具体进行计算的公式。</p>\n<p>买入结束之后，就剩卖出了。卖出的逻辑也相对简单</p>\n<ol>\n<li>如果买入逻辑已经不成立，则考虑卖出。这里分为两种情况。第一种是之前的研究有误，那么这种情况下应该立即卖出，因为知道错误之后，立即改正的代价永远是最小的。第二种则是公司的基本情况发生变化导致之前的买入逻辑不再成立，那么这种情况也需要卖出。</li>\n<li>如果价格严重超出了预估的价值，也可以卖出。价格围绕价值波动，如果觉得严重超出了价值，那么也必然会下降下来，或者等后续价值再涨上去。但是“严重超出”需要自己定义，尤其是好的投资标的，可能卖出后短期无法再以同样的价格进行买入，另外卖出/买入也有交易成本，这些也会减少自己的收益。</li>\n</ol>\n<p>这几个过程中，研究公司往往比较枯燥，但是这个确实真正决定能否赚钱的根本。研究的越清楚，才能够下更大的注，才能有更大的定力赚的更多。研究清楚之后，往往能否赚钱、能赚多少在买入的时候已经基本决定（假设投入的钱可以长期使用，不会中间被迫卖出），卖出只是在兑现之前赚取的收益。研究公司情况是贯穿整个阶段的，因为对于单个投资标的来说，需要持续跟进基本情况是否有发生变化，同时需要不断的扩展自己对其他公司的了解。研究公司的过程也能加深自己对真实世界的了解。</p>\n<p>在整套系统串起来之后，就可以把压力分摊到平时，也不需要进行那么精确的择时，不再需要时刻进行盯盘，大大减轻自己所面临的压力。</p>\n<h1 id=\"投资是一项技能\"><a href=\"#投资是一项技能\" class=\"headerlink\" title=\"投资是一项技能\"></a>投资是一项技能</h1><blockquote>\n<p>纸上得来终觉浅，绝知此事要躬行。</p>\n</blockquote>\n<p>投资是一项技能，有再多的理论知识，最终还是需要在实际操作过程中不断优化迭代，因此投资越早开始越好，既能够不断提升自己的投资能力，也可以享受<a href=\"https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A\">复利</a>所带来的收益。</p>\n<p>投资也是一项少有的个人可以胜过专业机构的活动。不需要依赖别人，纯靠自己本事，可以获得非常不错的回报。同时在这个过程中也可以对商业世界的运行有更好的理解。当然对现实实际有更好的了解，那么大概率是可以在投资市场有不错的回报。比如之前有人看到新东方开始带货之后的一些直播数据，通过自己的经验进行估算，觉得股价过于低估，因此就大幅买入，赚了不少钱, 这里面的“直播数据”为啥这么值钱就是自己的理解。</p>\n<p>当自己对投资了解越深，同时在实际投资过程中被验证或者证伪后，整个视角都会发生变化，最直接的变化就是如何看待价格的短期变化</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>之前</th>\n<th>之后</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>价格是否还会上涨/下跌</td>\n<td>价格小范围的波动已经不再关注</td>\n</tr>\n<tr>\n<td>2</td>\n<td>价格涨了高兴，跌了伤心</td>\n<td>短期价格涨了可能难过，短期下降反而会高兴</td>\n</tr>\n<tr>\n<td>3</td>\n<td>更关心公司的股价波动</td>\n<td>更关心公司的基本面情况</td>\n</tr>\n<tr>\n<td>4</td>\n<td>我需要投资成功很多次才行</td>\n<td>只需要在自己足够了解的标的上赚几次钱就足够</td>\n</tr>\n<tr>\n<td>5</td>\n<td>价值投资只对大资金有用</td>\n<td>价值投资使用所有资金</td>\n</tr>\n<tr>\n<td>6</td>\n<td>被价格波动所影响</td>\n<td>价格的波动为我所用</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>对上面几点进行部分补充</p>\n<ul>\n<li>关于第二点中的“价格涨了难受，下降反而高兴”，可以从股本位的视角理解，价格更高的话，相同法币能兑换更少的股数，反之则能获得更多的股数。</li>\n<li>关于第四点，首先现在 A 股（算上沪港通）有足够多优秀的公司能够容纳足够的资金，而且获得不错的收益。<ul>\n<li>关于足够优秀的公司容纳足够的资金，可以以一个小目标为例，单股价格按照 300 进行计算，也就是 34W 股，现在头部公司的总股数是亿级别（单价公司），我们只需要选择几家公司即可，这也大大降低我们的工作量。</li>\n<li>关于获得不错的收益，大家可以自行查看 A 股（沪港通）头部公司的回报率（可以算上分红再投入），ROE 以及 PE 值。</li>\n</ul>\n</li>\n<li>关于第五点：投资关注的是收益率，与本金大小无关。</li>\n</ul>\n<p>那么价值投资到底要多久才能见效呢？这个和大环境､行业的周期，以及大家对公司价格预期的周期有关系，在三者的共同影响下得到一个当前的价格，价格的高低在当下是不太好实际感受到绝对值的，但是可以有一个相对值。我们希望的是能在整个周期中价格相对低点的时候进行买入，然后持有到较高点（再视情况而定是否卖出）。正因为如此，价值投资的周期也相对较长（至少以年为单位）— 这也要求投资的钱是闲钱，这样才能够放置足够长时间，享受价格上涨带来的利润。实际经历过一个完整的周期后，也会对具体的信号、噪音等更有体感。如果暂时没有实际投资，也可以尝试进行模拟，把相关的情况记录下来，供后续复盘迭代优化使用。</p>\n<blockquote>\n<p>价格是大家预期 — 交易撮合 —的结果，反应的是市场中更多人出的价格，也就是群体的共识，群体的共识不是理性的，所以短期价格的波动也是不理性的。也正是因为如此，投资不要加杠杆，因为我们无法预测市场的走向，也无法预测回归正常需要的时间，加杠杆的风险在于可能在低点被强制平仓，导致永久性的损失。</p>\n</blockquote>\n<p>如果是在不想研究单一投资标的，则可以投资指数/基金，指数会有一揽子投资标的进行均衡，可以减少波动的方差。</p>\n<h1 id=\"最后\"><a href=\"#最后\" class=\"headerlink\" title=\"最后\"></a>最后</h1><p>投资是一项技能需要不断的学习，最简单的可以选择部分指数/基金；投资有复利，因此越早开始越好。投资是少有的个人可以比机构做的更好的活动，同时投资有风险，入市需谨慎，价值投资是一个相对靠谱的投资手段。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] 投资、创业与创新 <a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q</a><br>[2] 股市是不是一个好的投资渠道 <a href=\"https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q\">https://mp.weixin.qq.com/s/2L5CN1WoKViSk6UUduuP0Q</a><br>[3] The Superinvestors of Graham-and-Doddsville <a href=\"https://business.columbia.edu/insights/chazen-global-insights/superinvestors-graham-and-doddsville\">https://business.columbia.edu/insights/chazen-global-insights/superinvestors-graham-and-doddsville</a><br>[4] 差异化和公司文化 <a href=\"https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw\">https://mp.weixin.qq.com/s/gDbpIDbvgFKjEaSnlnzIIw</a><br>[5] 复利比较与机会成本  <a href=\"https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A\">https://mp.weixin.qq.com/s/oOCzFryqLzOdpcoLEKAu-A</a></p>"},{"_content":"多模态数据湖可以是啥样的？\n\n> 最近多模态数据湖的概念比较热门，记录下我理解中多模态数据湖的一个可能形态。\n\n\n多模态数据湖：能在一套系统中同时处理结构化数据、半结构化数据和非结构化数据。\n\n对于整套系统来说包括数据入湖，数据湖存储（主要是表格式），数据湖内数据的优化，Catalog，以及计算。\n\n> 增加一个全景架构图（包括上面所有这些流程）\n\n从数据使用角度来看\n- 数据最终是为了分析\n  - 分析性能\n    - 列存（至少是读取，可以用行存写入）\n  - 可能需要不断的变换 schema（SchemaEvolution）\n  - 需要支持 ACID\n  - 能对接尽可能广的生态\n  - 支持不同类型的数据\n    - 结构化，半结构化，非结构化数据\n  - 数据治理\n    - 为了性能调整\n    - 为了存储空间等治理\n数据同步\n  - reader + deserializer + transformer + serializer + writer\n  - schema evolution\n\n数据湖内数据治理\n- 数据湖内的数据可能对读取性能不是那么友好，需要进行优化\n- 会有 management 需求\n\n分析会有 引擎的计算，而引擎和表的对接则会需要 catalog/metadata 等\n\ncatalog/metadata\n- 跨源跨域等需求\n- 权限\n\n计算引擎\n- 功能\n- 性能\n\n增量计算可以将整个流程的计算耗时大大降低（减少不必要的计算）\n\n参考 FDAP 以及 [voltrondata](https://voltrondata.com/codex/accelerated-hardware) 的模型\n\n数据湖可以看成是 FileFormat 的一个索引（可以配合 FileFormat 一起使用）\n\nBigQuery\n\n现在 SQL 使用起来会相对复杂，可以尝试使用 PipelinedSQL 而且这个 SQL 可以更好的转换为拖拽式的。\n\nDremeal A Decade of Interactive SQL Analysis at Web Scale\nBigtable A Distributed Storage System for Structured Data\nAdaptive and Robust Query Execution for Lakehouse at Scale\nColumn Sketches A Scan Accelerator for Rapid and Robust Predicate Evaluation\n- Napa: Powering Scalable Data Warehousing with Robust Query Performance at Google\n- [x] Big Metadata: When Metadata is Big Data\n- [x] Vortex: A Stream-oriented Storage Engine For Big Data Analytics\n- BigLake: BigQuery's Evolution toward a Multi-Cloud Lakehouse\n- [x] SQL Has Problems. We Can Fix Them: Pipe Syntax in SQL\n  - 这个还是挺好的，也有开源的实现可以参考\n- [x] Procella: Unifying serving and analytical data at YouTube\nUnity Catalog\n\n# Napa\n2021-Powering Scalable Data Warehousing with Robust Query Performance at Google\n\nWe need to store and serve these planet-scale data sets under the extremely demanding requirements of scalability, sub-second query-response times, availability, and strong consistency; all this while ingesting a massive stream of updates from applciations used around the globe.\n\nThe following key aspects of Napa are the bedrock principles of its design and are aligned with our client requirements:\n- Robust Query Performance: Consistent query performance is critical to data analytics users. Our clients expect low query latency, typically around a few hundreds of milliseconds, as well as low variance in latency regardless of the query and data ingestion load. Napa is able to guarantee robust query performance with consistent results despite daunting requirements for scale and system availability.\n- Flexibility: While performance is important, our experience shows that it is not the only criterion for our clients. For instantce not all applications require millisecond response times, not all require the same freshness for ingested data, or for that matter, not all clients are willing to pay for \"performance at any cost\". Clients also require the flexibility to change system configurations to fit their dynamic requirements.\n- High-throughput Data Ingestion. All Napa functions, including storage, materialized view maintenance, and indexing, must be performed under a massive update load. Napa implements a distributed table and view maintenance framework that is based on the LSM-tree paradigm. LSM is widely used in current generation of data warehouses and databases primarily to efficiently integrate and incorporate constantly emerging data into already existing data. Napa scales LSM to meet the challenges of Google's operating environment.\n\nNapa's approach for robust query performance includes the aggressive use of amterialized views, which are maintained consistently as new data is ingested across multiple data centers.\n\n权衡三角：Data freshness, Resource costs, Query performance 三者之间做权衡\n\nA key design choice in Napa is to rely on materialized views for predicatable and high query performance.\n\nNapa's high-level architecture consists of three main components as shown in the figure above.\n- Napa's ingestion framework is responsible for committing updates into the tables. The deltas written by the ingestion framework only serve to satisfy the durability requirements of the ingestion framework, and hence are write optimized. These deltas need to be further consolidated before they can be applied to tables and their associated views.\n- The storage framework incrementally applies the updates to tables and their views. Napa tables and their views are maintained incrementally as log-structured merge-forests. Thus, each table is a collection of updates. Deltas are constantly consolidated to form larger deltas; we call this process \"compaction\" The view maintenance layer transoforms table deltas into view deltas by applying the corresponding SQL transformation. The storage layer is also responsible for periodically compacting tables and views.\n- Query serving is responsible for answering client queries. The system performs merging of necessary deltas of the table(or view) at query time. Note that query latency is a function of the query time merge effort, so the faster the storage subsystem can process updates, the fewer deltas need to be merged at query time. F1 Query is used as the query engine for data stored in Napa. We provide more details for query serving in Section 8.\n\nNapa decouples ingestion from view maintenance, and view maintenance from query processing. This decoupling provides clients knobs to meet their requirements, allowing tradeoffs among freshness, performance, and cost.\n\nUsers specify their requirements in terms of expected query performance, data freshness, and costs.\nNapa introduces the concept called `Queryable Timestamp (QT)` to provide clients with a live marker(just like an advancing timestamp). QT is the direct indicator of freshness since [NOW() - QT] indicates data delay. All data up the QT timestamp can be queried by the client.\n\n> Napa architecture showing the major system components\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202512291645719.png)\n\nNapa's high-level architecture consists of data and control planes as above. The architecture is deployed at multiple data centers to manage the replicas at each data center. The data plane consists of ingestion, storage, and query serving. The control plane is made up of a controller that coordinates work among the various subsystems. The control is also responsible for synchronizing and corrdinating metadata transactions across multiple data centers.\n\nNapa clients use ETL pipelines to insert data into their tables. The ingestion framework can sustain very high load, such as tens of GB/s of compressed data. Client data are delivered to any of the Napa replicas and Napa ensures that the data ingestion is incorporated at all the data centers. This significantly simplifies the design of ingestion pipelines.\n\nQuery serving deals with the necessary caching, prefetching and merging of deltas at runtime. The goal of query serving is to serve queries with low latency and low variance. Low latency is archieved by directing the queries to precomputed materialized views as opposed to the base table, and parallel execution of queries. Low variance is achieved by controlling the fan-in of the merges as well as a range of other I/O reduction and tail tolerance techniques.\n\nNapa relies on views as the main mechanism for good qauery performance. Napa's choice is largely motivated by the strict latency and resource requirements of its workloads, making it necessary to leverage indexed key lookups.\n\nThe Nap controller schedules compaction and view update tasks to keep the count of deltas for a table to a configurable value. These storage tasks are needed to keep the queryable Timestamp(QT) as fresh as possible given the cost tradeoffs.\n\nThe goal of the ingestion framework is to accept data, perform minima processing, and make it durable without considering the pace of subsequent view maintenance.\n\nThe queryable timestamp(QT) of a table is a timestamp which indicates the freshness of data that can be queried. If QT(table) = X, all data that was ingested into the table before time X can be queried by the client and the data after time X is not part of the query results.\n\nAn important criterion to ensure good query performance is to optimize the underlying data for reads and ensure views are available to speed up the queries.\n\nA table in Napa is a collection of all of its delta files, each delta corresponding to updates received for the table over a window of time, as below\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202512291733204.png)\n\nThe non-queryable deltas correspond to newly received updates written by the ingestion framework in the most recent time window(typically seconds.) THe largest deltas, on the other hand, span a time window of weeks or even months. Each delta is sorted by its keys, range partitioned, and has a local B-tree like index.\n\nThe QT of the database is the minimum of the QT of all the tables in the database. QT is also used to give clients a consistent view of data across all Napa replicas.\n\nNapa's storage subsystem is responsible for maintaining views and compacting deltas. It is also responsible for ensuring data integrity, durability via replication across data centers, and handling outages from individual machines to entire data centers.\n\nCompaction improves query performance and reduces storage consumption by 1) sorting inputs together and 2)aggregating multiple updates to the same rows. Since the delta files are individually sorted, compaction is essentially merge sorting. It is intentionally kept large during compaction so that the height of the merge tree is small, thus minimizing key comparisions.\n\nRobust query serving performance\nquery serving subsystem achieves robust performance, using Queryable Timestamp(QT), materialized views, and a range of other techniques.\n1. Reducing data in the critical path\nWhenever possible, Napa uses views to answer a query instead of the base table, since views with aggregation functions may have significantly less data. Nap maintains sparse B-tree indexes on its stored data, and uses them to quickly partition an input query ito thousands of subqueries that satisfy the filter predicates. This partitioning mechanism additionally looks at the latency budget and availability of query serviing resources to achieve good performance.\n\n> 增加 Figure7\n\n2. Minimizing Number of Sequential I/Os\nWhen a query is issued, Napa uses the value of QT to decide the version of metadata to be processed. The metadata in turns determines what data has to be process. Therefore, mateadata reads are on the critical path of query serving. Nap aensures all metadata can always be served from memory without contacting the persistent storage. This is achieved by affinity-based distributed metadata caching with periodic background refresheds. A particular QT is delayed to wait for the completion of periodic background refresh of metadata.\n\nNapa performs offline and online prefetching to further reduce the number of sequential I/Os in the critical path. Offline prefetching occurs as soon as data is ingested for frequently queried tables, before QT advances to make the new data available to query. Online prefetching starts when a query arrives and is performed by a shadow query executor which shares the data access pattern with the main query executor but skips all query processing steps.(like dry run?)\n\n3. Combining Small I/Os\nDuring query serving, Napa aggressively parallelizes the work by partitioning the query into fine grained units and then parallelizing I/O calls across deltas and across queried columns. To combat such amplification on tail letency, Napa uses QT to limit the number of queryable deltas. In addition, Napa also tries to combine small I/Os as much as possible, by using the fowlling two techniques: lazy merging across deltas and size-based disk layout.\n\n- lazy mering across deltas: When there are thousands(N) of subqueries and serval tens(M) of deltas, the number of parallel I/Os are in the order of tens of thousands(N * M). However, due to the parallelism each subquery reads very little data from most deltas. Meanwhile, a large fraction of Napa queries require merging based on a subset of primary keys in the subsequent phase of the query plan. In these cases, Napa adapts the query plan to avoid cross-delta merging in Delta Server and lets each Delta Server only process one delta, combining N * M parallel I/Ss into close to N parallel I/Os （merge 的数据尽量不跨 delta server？）\n- size-based disk layout: Napa uses a custom-built columnar storage format supporting multiple disk layout options, which are applied based on delta sizes. The PAX layout which can combine all column accesses into one I/O for lookup queries, is applied to small dltas. For large deltas, column-by-column layout is used that is I/O efficient for san queries but requires one I/O per column for lookup queries. This size-based choice ensures that Napa receives columnar storage benefits as well as reduces I/O operations.（基于大小选择不同的磁盘布局，PAX 作为小的布局，可以一次 IO 读取完毕，大文件则是按列存放，这样每一列需要一个 IO 但是 scan 更友好\n\n4. Tolerating tails and failures\nNapa adopts the principle of tolerating tail latency, rather than eliminating it, because eliminating all soruces of variability for such a complex and interdependent system is infeasible.\n\nFor a non-streaming RPC, such as the RPC between Metadata Server and Delta Server, Napa uses the machnism of *hedging*, which sends a secondary RPC identical to the original one to a different server after a certain delay, and waits for the faster reply.\nFor a streaming RPC, such as the RPC between F1 worker and Delta Server, Napa estimates its expected progress rate and requires the server executing it periodically to report progress, together with a *continuation* token. If the reported progress is below expectation or the report is missing, the last continuation token would be used to restart a new streaming RPC on a different server without losing progress. Pushdown operators like filtering and partial aggregation need to be carefully handled in progress reporting as they can significantly reduce the data size, causing progress reports to be superficially low or even missing. Napa uses bytes processed before filtering and partial aggregation as the progress rate metric and periodically forces these operators to flushes its internal state to generate a progress report with a continuation token.\n\nProduction metrics insights\nNapa manages thousands of tables and views in production, where many tables are petabyte scale. It serves over a billion queries per day and ingests trillions of rows. Napa is able to provide robust query performance through three techniques: 1) by more actively using views, Napa reduces raw query performance and variance even at 99th percentile, 2) by chaning storage policies, Napa can reduce the number of deltas and hence the tail latency, and 3) by decoupling ingesting, view maintenance, and query execution; Napa can mitigate the impact of infrastructure and workload changes on query performance.\n\n1. Views and QT Help achive robust query performance\nFirst, most client queries are aggregation queries, and materialized views are typically at least an order of magnitude smaller than the base tables from which they are derived. Reading from views not only improves raw performance, but also improves tail latency as their smaller size is more cache friendly, and requires less compute resources, which reduces the change of continetion for query resources.\n\n> Add the figure for #views with the query latency\n\nSecond, latency can be improved by reducing the number of deltas that have to be opend, read, and merged at query time.（相当于文件数量？）\n> Add the figure for #deltas with the query latency\n\nFigure 8(b) shows that as we change storage policies to reduce the number of deltas, the query latency improves significantly. The biggest impact is at the 99th percentile latency which reduces by more than 3.6x as the number of deltas is changed from 8 to 2. The main reasons are: 1) fewer deltas means there are less number of small, parallel IOs which are prone to cause latency tails, 2) fewer deltas also means that data is premerged and aggregated, and less processing is required at query time.（这个类似 MOR 中，文件数量少，则 IO 少，而且读取的时候需要进行的聚合计算也少）\n\n2. Handling infrastructure issues\n> Add figure 9\nFigure 9 shows that Napa is able to guarantee its client stable query performance even when the ingestion load changes or there are infrastructure outages.  Napa decouples ingestion from view maintenance and querying which allows us to optimize for low variance in query latency, in some cases by trading off data freshness. Figure 9(a) shows that the client continuously sends data to Napa, with some variance in the input rate over the course of the week. Figure 9(b) shows that the view maintennace performance dropped for the duration between X and Y indicating an infrastructure issue which affected the tasks updating views. However, the query serving latency remains near constant (Figure 9(d)) throughout the whole duration. In this particular example, client queries continued to be fast, however , for certain parts during the outage data freshness was impacted, as seen in Figure 9(c) where the value of delay is high. 就算 view 的维护因为基建受影响了，那么不影响写入和读取的性能，但是能读到的数据的新鲜度会受影响\n\n3. Client workloads\n支持不同的 tradeoff，比如 [Client A: Tradoff freshness] wants moderate query performance and low costs, but can tolerate lower freshness.\n[Client B: Tradeoff query performance] cares the most about low costs but can tolerate lower query performance\n[Client C Tradeoff costs] has high freshness and high query performance requirements, and is willing to pay high costs to achieve them.\n> Add figure 10 for different workloads\n\nNapa is a fully indexed system that is optimized for key lookups, range scans, and efficient incremental maintenance of indexes on tables and views. Napa can easily support both adhoc queries and highly selective and less diverse queries.\n\nNapa uses a varaint of B+-trees that exploits the fact that Napa tables have multi-part keys. Additionally, min/max keys(per-column min/max values) are stored along with each non-leaf block to eanble effective pruning. LSM adapt B-tree indexes for high update rates. Napa belongs to a class of  LSM systems that trade high write throughput for fast reads. (看起来是 LSM 和 B-tree 的结合）\n\n\n# 2023-Progressive Partitioning for Parallelized Query Execution in Google's Napa\nNapa holds Google's critical data warehouses in log-structured merge trees for real-time data ingestion and sub-second response for billions of queries per day. These queries are foten multi-key look-ups in highly skewed tables and indexes.\n\nIn our production experience, only progressive query-specific partitioning can achieve Napa's strict query latency SLOs.  Here we advocate good-enough partitioning that keeps the per-query partitioning time low without risking uneven work distribution. Our design combines pragmatic system choices and algorithmic innovations. For instance, B-trees are augmented with statistics of key distributions, thus serving the dual purpose of aiding lookups and partitioning. Furthermore, progressive partitioning is designed to be \"good enough\" thereby balancing partitioning time with performance. The resulting system is robust and successfully serves day-in-day-out billions of queries with very high quality of service forming a core infrastructure at Google\n\nNapa's diverse query workload consists of large scans and many-key lookups. The analytical queries with many-key lookups have strict QoS requirements and is the main focus of this paper.\n\nFrom our experience in running production services, we found the following three requirements important:\n- Query-specific partitioning. Any approach that we take should meet the latency SLOs across a diverse set of query workloads. In our experience, the partitioning granularity needs to be adjusted on a per-query basis to meet the latency and resource budget requirements. The expectation from the partitioning step is that it is able to produce number of partitions denoted by the parallelization requirement within bounded amount of error.\n- Evenness. Execution involves the partitioning of the tables into key ranges such that the partitioning results in even partitions. Partitioning should operate on tables with extreme skews where some keys span terabytes in disk. As an example, in Figure 1, a key range like < K1 = 1, K2 = 20 > may correspond to, say, a hundred GB portion of the table while another key range may be considerably smaller at a few MB.\n- Progressiveness. Query partitioning must balance overall execution time against the time and effort to produce query-specific partitions. For instance, one can produce perfectly even partiions while still ending up missing the QoS requirement. It is imperative that the partitioning method has the notion of \"good enough\" in the sense that it stops when the partitioing is the sufficient quality. Our porposed technique in hte paper is progressive such that 1) the longer the alogirhtm runs the better the quality of the resultant partitioning; 2) the algorithm stops once the desired error bound has been met.\n\nOur experimental results show that the use of statistics that is too find-grained can often result in queries spending too much time generating partitioning at the expense of overall query execution time.\n\nWe address this dilemma by leveraging B-trees to optimize access to the statistical information on the tables. Each LSM run has an associated B-tree index which are enhanced so that index nodes maintain size information for the associated key ranges. With these enhancements, we can estimate the input data size of the query starting with the root of the B-tree. If this estimation is not accurate enought or if the statistics point to areas of skews, we can descend to the next level in the index structure to obtain a finer level of statistical distributions for the key ranges overlapping with the query.\n\nOur proposed algorithm traverses the B-tree to produce even and query-specific partitioning. It is progressvie in the sense that it descends and accesses additional index information only if it does not satisfy the stipulated error bounds. In addition, the refinement is selective that it only descends to the lower levels of trees for those partitions that do not have gight enough bounds on the error.\n\nThe following key aspects of Napa are the bedrock principles of its design and are aligned with our client requirements: i) Robust Qury Performance: Napa clients expect low query latency, typically sub-seconds, as well as low variance in latency under a wide spectrum of query and data ingestion load; ii) System Flexibility: While performance is important, our clients also require the flexibility to change system configurations to their dynamic requirements such as trading freshness or recency of ingested data for better performance; iii) High-throughput Data Ingestion: Napa's ingestion, storage and query serving functions performan udner a massive update load.\n\nA Napa table consists of multiple data sets called deltas(corresponding to sorted runs of an LSM-tree) and we have one B-tree index for each delta. Not that each delta corresponds to updates on a table during a time window(e.g., last 1 minute, 1 day etc.).\n\nProgressive partitioning using B-tree: The B-trees on the deltas are fairly generic except that it hierarchically stores statistics of the underlying data. In particular, we store the number of rows that is indexed by each sub-tree and aggregate that statistics up the level. The partitioning algorithm we propose in the paper takes queried keys as input, retrieves and merges relevant keys taken from these B-tree indices, to generate an approximate histogram. Starting with the highest level histograms (i.e., the B-tree root index blocks), it tries to find accurate enough paritions. If it needs more detailed information, the algorithm will retrieve requried index blocks from the next highest level, repeating this trial and retrieve until it reaches the desired accuracy.\n\nLSM 让 partition 变的更复杂\nThe LSM data model complicates the task of query-specific partitioning in the following ways.\n- First, the keys specified in the query may be present in may(possibly all) of the deltas. Note that the same query worker must process all deltas where the keys are present in order to reconcile all relevant version.\n- Second, this proves to be a serious challenge for the evenness of the partitioning since some deltas may contribute many more matched rows than others.\n- Third, a query may involve seeking across multiple deltas and not all deltasequally contribute to the query. Thus, the paritioning effort may not be uniform across the deltas. For some deltas, it may be sufficient to perform coarser partitioning while others require significantly more effort in producing equal splits.\n\nWhy rely on progressive query-specific partitioning?\nThe ideal partitioning unit size can vary from 10MB(e.g., when reading 1GB data using 100 scan workers) to 1GB(e.g., when reading 1TB data using 1000 scan workers) on a per-query basis. \nThe next complexity here is that it is possible that there is one particular \"Date = d3\", which accounts for most of the data to be scanned in a query. So, that means that we need to partition the range <c1, d3>, <c2, d3> and <c3, d3> much more finely than the other key ranges. This means the partitioning algorithm needs to be progressive such that it can stop early on other dates and focus on generating finer grained partitions for \"Date = d3\" \nStandard write-time partitioning mechanisms are not able to address the requirements discussed above.\n\nPartitioning is highly specific to query under consideration and existing write-time partitioning is inadequate for workloads with a wide spectrum of query workloads. We have also established that one needs a way of producing both fine and coarse grained partitions even on the same key range, based on the query predicates, latency target and resource budget.\n\nProgressive partitioning\nThe progressive query-specific partitioning algorithm using *size-enhanced* B-trees. Our solution is to enhance typical B-trees with the statistics on data size in a hierarchical manner. For each delta, we maintain a B-tree pointing to data blocks, e.g. a block in the PAX layout. The index not only helps a query to efficiently seek on data using prefix keys but also provides statistical information for partitioning. Both querying and query-specific partitioning traverse the B-tree. The querying traverses the B-tree through the leaf level to visit dat ablocks. The query-specific partitioning does not visit data blocks and visits the index node at the leaf level only when required for finding \"good enough\" partitions as we describe below.\n> 使用 size-enhanced B-Tree，对于每一个 delta 都维护一个 B-tree 指向 data blocks，这样可以提供前缀查询，以及统计信息等\n\nFor a given query Q, the algorithm divides D deltas into P key range partitions that are nearly even with an error margin of \\{thelta}. Each delta has a size-enhanced B-tree, which carries keys and the size of data between these keys. We analyze the estimated size of matching data by combining keys and sizes from D indices. To get the most precise matching estimate from B-trees, we may need to visit the leaf index entries matching with the query. 但是读所有的 leaf 会很耗时，另外一种方式就是通过 root 来推测 partition 的数量，这是两个极端，文中从中间进行选择：从 root 开始，然后仅在需要下一层提供更多信息的时候才进行继续读取。\n\n文中有一个具体的例子\n> 补充 fig 4 和 fig 5\n\n其中两个 Delta，然后希望分成两个 partition（分 parition 是希望能够并行处理），然后考虑第一层的时候（从 B-tree 获得信息），Delta 1 的 [K1, K3) 有 15 个，[K4, K8) 有 20 个； Delta 2 的 [K2, K5) 有 20 个，[K6, K7) 15 个。\n\n那么把所有的数目都加在一起就是 15 +  20 + 20 + 15 = 70 个，然后会选择在 K4 和 K5 这里做分割，这样会把 [K4, K8) 和 [K2, K5) 做一些分割，然后对于第一个 partition 来说，大小可能是 15（也就是 [K2, K5) 的倾斜全在右侧，[K4, K8) 也倾斜），同样最大可能是 15+20+20 = 55,那么估算这个大小是 (15 + 55) / 2 = 35，然后 size margin = 55 -15 = 40,同样第二个 partition 类似，得到估算大小是 35, size margin 是 40,如果 (40/35, 40/35) -- 两个 parititon 的误差 -- 能满足 \\{theata} 那么就按照这么切分，如果不行，就对 B-Tree 进行下一层读取，然后再进一步进行划分\n\n> We represent this size-embedded index entry in a B-tree index node as e = <start, end, size, level, block>, which corresponds to the key range [e.start, e.end) having the estimated size e.size. The entry e is in a index block at tree level e.level(the value of 0 for e.level corresponds to the leaf level). Finally, e.block is a pointer to the child index block having range [e.start, e.end) (if e.level > 0)\n\n> 根据和 Gemini 的沟通，大概理解 Napa 的存储结构如下\n> 首先是 LSM Tree，然后每个 SSTable 是一个 B-tree，B-tree 就是文中的 Delta，B-tree 中包括多个实际的文件，以及对应的索引，然后渐进式则是「够用」就好，-- 「够用」是满足对应的误差\n\n# SQL Has Problems\n文章描述了 SQL 是一个很好的抽象，但是学习和维护不方便，重新造一个类似 SQL 的语言又很麻烦，所以有了 PipelinedSQL 这个渐进式改进的方案。\n>SQL is not an easy language to learn or use. Even for expert users, SQL is challenging to read, write and work with, which hurts user productivity. Serveral alternative languages have been prposed, but none have gained widespread adoption or displaced SQL. Migrating away from existing SQL ecosystems is expensive and generally unappealing for users.\n\nPiplined SQL 可以让 SQL 更好用，更具扩展性（more flexible, extensible and easy to use). \n\nIn SQL, the standard clauses occur in one rigidly defined order. Expressing anything else requires subqueries or other workarounds. With Pipelined SQL operationcan be composed arbitrarily, in any order.\n\n给了两个例子\n```sql\nSELECT c_count, COUNT(*) AS custdist\nFROM\n  (SELECT c_custkey, COUNT(o_orderkey) c_count\n   FROM customer\n   LEFT OUTER JOIN orders ON c_custkey = o_custkey\n        AND o_comment NOT LIKE '%unusual%packages%'\n   GROUP BY c_custkey\n  ) AS c_orders\nGROUP BY c_count\nORDER BY custdist DESC, c_count DESC;\n```\n\n然后 \n```pipelined-sql\nFROM customer\n|> LEFT OUTER JOIN orders ON c_custkey = o_custkey\n     AND o_comment NOT LIKE '%unusual%packages%'\n|> AGGREGATE COUNT(o_orderkey) c_count\n   GROUP BY c_custkey\n|> AGGREGATE COUNT(*) AS custdist\n   GROUP BY c_count\n|> ORDER BY custdist DESC, c_count DESC;\n```\n\n有讲 SQL 和 PipelinedSQL 的语义情况\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202512161155193.png)\n\n觉得 SQL 不错，那么就修复\n- SQL's foundational semantics, from relational algebra, are excellent\n- SQL's conceptual data model and top-level syntax, with statements representting requires, DDL, DML, etc, and composability via subqueries, works weel.\n- SQL's basic operations within a query(clauses like JOIN, ORDER BY, etc) all work reasonably well\n- SQL's syntactic structure for composing queries using those operations is **terrible**.\n- SQL'ls localized syntax with English-like keyword phrases is and anachronism, but we can live with it.\n- SQL's expression language is fine, and implementations typically includes a good library of existing functions.\n\n所以只需要修复第四点中的问题就行\n\npipelined SQL 使用 '|>' 这个 suffix 来衔接\n\n```\n<query> :=\n  {all existing query syntaxes}\n  | \"FROM\" <from_body>             -- New: FROM as a query\n  | <query> \"|>\" <pipe_operator>   -- New: pipe suffixes\n```\n论文中有具体算子的语法\n\n然后剩下的是一些更具体的细节，以及相关效果。\n这个如果成熟之后，应该也可以更方便的推广拖拽式的表现形式（？），能够更好的一一对应起来\n然后 ZetaSQL（已开源） 也有实现\n\n# Napa\n# BigLake\n# Procella\n> These can be categorized as: reporting and dashboarding, embedded statistics in pages, time-series monitoring, and ad-hoc analysis. Typically, organizations build specialized infrastructure for each of these use cases. This however, creates silos of data and processing, and results in a complex, expensive, and harder to maintain infrastructure.\n> At YouTube, we solved this problem by building a new SQL query engine -- Procella.\n\nThese workloads have differenet set of requirements:\n- Reporting and dashboarding: Video creators, content owners, and various internal stakeholders at YouTube need access to detailed real time dashboards to understand how their videos and channels are performing. This requieres an engine that supports executing tens of thousands of canned queries per second with low latency (tens of milliseconds), while queries may be using filters, aggregations, set operations and joins. The unique challenge here is that while our data volumen is high (each data source often contains hundreds of billions of new rows per day), we require near real-time respoinse time and access to fresh data.\n- Embedded statistics: YouTube exposes many realtime statistics to users, such as likes or views of a video, resulting in simple but every high cardinality queries. These values are constantly changin, so the system must support millions of e real-time updates concurrently with millions of low latency queries per second.\n- Monitoring: Monitoring workloads shrae many properties with the dashboarding workload, such as relatively simple canned queries and need for fresh data. The query volumne is often lower since monitoring is typically used internally by engineers. However, there is a need for aditional data management functions, such as automatic downsampling and expiry of old data, and additional query features (for example, efficient approximation functions and additional time-series functions)\n- Ad-hoc analysis: Various YouTube teams (data scientists, business analysts, product managers, engineers) need to perform complex ad-hoc analysis to understand usage trends and to determine how to improve the product. This requires low volume of queries(at most tens per second) and moderate latency (second to minutes) of complex queries (multiple levels of aggregations, set operations, analytic functions, joins, unpredcatable patterns, manipulating nested/repeated data, etc.) over enormous volumes(trillions of rows) of data. Query patterns are highly unpredictable, although some standard data modeling techniques, such as star and snowflake schemas, can be used.\n\n独立系统的问题\n- Data needed to be loaded into multiple systems using different Extract, Transform, and Load(ETL) processes, leading to significant additional resource consumption, data quality issues, data inconsistencies, slower loading times, high development and maintenance cost, and slower time-to-market.\n- Since each internal system uses different languages and API's, migrating data across these systems, to enable the utilization of existing tools, resulted in reduced usability and high learning costs. In particular since many of these systems do not support full SQL, some applications could not be built by using some backends, leading to data duplication and accessibility issues across the organization.\n- Several of the underlying componenets had performance, scalability and efficiency issues when dealing with data at YouTube scale.\n\nProcella 的特性\n- Rich API: Procella supports an almost complete implementation of standard SQL, including complex multistage joins, analytic functions and set operations, with serveral useful extensions such as approximate aggregations, ahdnling complex nested and repeated schemas, user defined functions, and more.\n- High Scalability: Procella separates compute (running on Bord) and storage (on Colussus) enabling high scalability (thousands of servers, hundreds of petabytes of data) in a cost efficient way.\n- High Performance: Procella uses state-of-the-art query execution techniques to eanble efficient execution of high volumen(millions of QPS) of queries with very low latency (milliseconds).\n- Data Freshness; Procella supports high volume, low latency data ingestion in both batch and streaming modes, the ability to work directly on existing data, and native support for lambda architecture.\n\n> Procella System Architecture\n\nProcellas 的数据按照 table 进行划分，每个 table 会有多个文件/分区。Procella 使用自己的列存 Artus，也支持其他的 file format，存在 Colossus 中，这样可以存算分离\n\nProcellas 没有使用 BTree 而是使用了更轻量级的 zonemaps, bloom filters, partition 以及 sort key 等这些二级索引，这些从文件头，或者 plan 时从 data server 获取，schema, table to file mapping, stats, 以及 zonemap 等这些存储在 BigTable/Spanner 中\n\n支持标准的 SQL 操作，支持 batch ingestion 和 streaming ingestion\n在 batch ingestion 的时候，可以根据 file header 获取，更耗时的元数据抽取会延迟处理；streaming ingestion 支持 RPC/PubSub 的方式，然后 Ingestion Server 转换为表的形式\n\n然后会有后台线程周期性进行合并操作\n\nQuery lifecycle\nClients connect to the Root Server(RS) to issue SQL queries. The RS performs query rewrites, parsing, planning and optimizations to generate the execution plan. To this end, ti uses metadata such as schema, partitioning and index infromation from the Metadata Server(MDS) to prune the files to be read. It then orchestrates the query execution as it goes through the different stages enforcing timeing/data dependencies and throttling. To address the needs of executing complex distributed query plans(timeing/ data dependencies, diverse join strategies, etc.), the RS builds a tree composed of query blocs as nodes and data streams as edges (Aggregate, Execute Remotely, Stagger Execution, etc. ) and executes it accordingly. This enables functionality such as shuffle (that requires timing dependency), uncorrelated subquery, subquery broadcast joins(data dependency) and multi-level aggregation. THis graph structure allows several optimizations by inserting custom operations into the tree based on query structure. Once the RS receives the final results, it sends the respoinse back to the client, along with statistics, error and warning messages, and any other information requested by the client.\n\nThe Data Sever(DS) receives plan fragments from the RS or another DS and does most fo the heavy lifting, such as reading the required data (from local memory, remote and distributed files in Colossus, remote memory using RDMA,  or another DS), executing the plan fragment and sending the results back to the requesting RS or DS.\n\n优化\n- Cache\n  - Colossus metadata caching  可以减少一次或多次文件打开的开销\n  - Header caching  文件头(尾）有 start offset，column size，minimum and maximum 值，缓存这些可以减少更多的文件访问（单独的 LRU）\n  - Data caching, DS 使用单独的 cache 缓存文件，列存 Artus 设计成 disk 和 memory 的 format 一致，这样可以让 cache 更友好(making cache population fairly cheap)，同时也缓存一些二级数据（比如bloom filter 等）\n  - metadata caching: metadata 存在 bigtable 这样的分布式文件系统中，访问多可能会导致有瓶颈，因此用 LRU 来 cache \n  - Affinity scheduling: Caches are more effective when each server caches a subset of the data. Procella implements affinity scheduling to the data servers and the metadata servers to ensure that operations on the same data/metadata go to the same serve with high probability. 这样每个 server 只负责一部分数据，cache 有效性也变高. 但这个不是强约束，也就是说可能被调度到其他的 server -- 这样只是性能变差（cache 无效）。\n- Data Format\n  - 一开始使用 Capacitor，但是它主要是 Ad-hoc 中使用（主要是 scan 性能），Procella 需要 lookup 和 range scan，所以开发了 Artus\n  - 使用自定义的 encoding。Uses custom encodings, avoiding generic compression algorithms like LZW. This ensures that it can seek to single rows efficiently without needing to decompress blocks of data, making it more suitable for small point lookups and range scans.\n   - Does multi-pass adaptive encoding: 第一次收集轻量级信息（ndv, min, max, sort order 等），然后使用这些去选择更合适的 encoding\n   - 选择对 sorted column 支持 binary search 的 encoding\n   - 嵌套字段的处理和 parquet 不一样，把表的 schema 当成 tree，每个字段都存在为独立的列, 针对每个父字段（如果自己本身存在的话），会记录所有子字段出现的次数，对于可选字段，该值是 0 或者 1,重复字段该值为非负。但是不记录父子段不存在的信息  \n   - Directly exposes dictionary indices, Run Length Encoding information, and other encoding information to the evaluation engine.\n   - Records rich metadata in the file and column header.\n   - Supports storing inverted inddexes. -- 搜索场景有用\n\n支持 multi-level partitioning and clustering\n\nJoin 的类型\n- Broadcast： 一方足够小可以加载到 DS 的内存。\n- Co-partitioned: fact 和 dim 可以使用同样的 key 进行 partition\n- Shuffle：数据太大，然后没有按照 join key 排序，就进行 shuffle\n- Pipelined: RHS 是负责查询，但是结果可能比较小的时候\n- Remote lookup: dim table 是分区的，但是 fact 没有\n\n怎么解决 tail latency\n- 因为数据有备份，所以如果某个数据节点的访问延迟超过了中位数(median)，就访问其他的节点 \n- RS 会控制访问同一个 DS 的频率，批次等\n- RS 会给每个请求附带一个优先级，通常来说小查询的优先级更高，大查询的优先级更低。DS 为高优和低优的分别分配资源，这样可以保证小查询的快速响应-- 不会被大查询 block\n\nIntermediate merging\n- 对于很重的聚合，最后的聚合可能会成为瓶颈 -- 需要在单机点操作很多数据。为了避免这个，添加中间节点用来做中间的聚合。\n\nQuery Optimization\n- Virtual Tables 类似 MV\n  - Index-aware aggreagte selection\n  - Stitched queries\n  - Lambda architecture awareness\n  - Join awareness\n\nQuery Optimizer\n使用静态和动态的查询优化技术 (makes use of static and adaptive query optimization techniques) At query compile time we use a rule based optimizer that applies standard logical rewrites (always benefical) such as filter push down, subquery decorrelation, constant folding, etc. At query execution time we use adaptive techniques to select/tune physical operators based on statistics (cardinality, distinct count, quantiles) collected on a smaple of the actual data used in the query.\n- Adaptive Aggregation\n- Adaptive Join\n- Adaptive sorting\n\nAdaptive 的不足：需要动态收集信息，可能导致短查询耗时更久（比如 10ms 左右的可能变成原来的数倍），这种可以让用户给定 hint 不走 adaptive optimization，另外用户愿意接受短查询变长，换来大查询的耗时变短（overhead 可能有 10% 左右）\n\n针对 serving 做优化处理\n- 数据写入后，会立即通知 dataserver 进行加载，这样可以避免冷读\n- MDS 编译进 Root Server，可以减少 RPC 交互\n- metadta 提前加载到内存，避免查询的时候加载 metadata\n- query plans are aggressively cached to eliminate parsing and planning overhead.  This is very effective since the stats query patterns are highly predicatble.\n- The RS batchs all request for the same key and sends them to a single pair of primary and secondary data servers.\n- The problematic outlier tasks are automatically moved to other machines.\n\n\n# Vortex\n> Vortex: A Stream-oriented Storage Engine For Big Data Analytics\n\nVortex is a streaming-first storage system that supports both streaming and batch data analytics. Today, BigQuery uses Vortex to support petabyte scale data ingestion with sub-second data freshness and query latency.\n\nVortex has the following key properties:\n- Consistent: Guaranteees ACID properties for all API operations.\n- Unified API for batch and streaming: Vortex offers a single unified API with support for both streaming and batch data.\n- Scalable: Vortex implements a fully distributed data and control plane and as a result supports tables of multiple petabytes size.\n- Performant: The Vortex API offers sub-second tail write latencies that simplify client side application programming.\n\nBigQuery storage provides a global namespace over all data in BigQuery. Data is organized into regional containers called datasets(analogous to schemata in traditional database management systems). Tables, logical views, metarialized views, search indexes, stored procedures, machine learning models etc. all reside in a dataset.\n\nVortex is BigQuery's scalable, distributed and synchronnously replicated storage engine that supports data ingestion, retrieval and curation.\n\nA Vortex Stream is an entity to which rows can be appended to the current end. Each row in a Vortex Stream is identified by the Stream's identifier and its row offset within the Stream. Readers can concurrently read a Stream at different row offsets. A table is an unordered collection of Stream.\n> Stream 有点像传统说的文件，比如 Parquet File？但是应该还不一样，毕竟还有 ColumnFormat\n\nStreams are backed by the following entities\n- Streamlets Vortex Streams provide durable sotrage of data. A Streamlet is a contiguous slice of rows in the Stream, all of which are present in the same 2 clusters. A Stream is an ordered list of one or more Streamlets. Given the Stream's append-only semantics, a Stream has at most one writable Streamlet. The writable Streamlet, if one exists, is always the last Streamlet in a Stream.\n\n- Fragments: Each Streamlet is further split into contiguous blocks of rows called Fragments. Fragments typically are a range of rows inside a log file. Log files are stored in Colossus.\n> Streamlets 和 Fragments 是 写入端的概念，还是类似表级别的概念\n> Streamlets and Fragments are internal physical metadata entities; they aren't visible to the users of Vortex.\n- Data formats: BigQuery operates broadly with data in two different classes of data formats. The write-optimized storage format(WOS) is the format in which data is written by Vortex's append API, The read-optimized storage format(ROS) is the format in which data is optimized for dat aprocessing. \n  BigQuery use Capacitor as ROS, BigLake use Parquet as ROS\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202512041721506.png)\n\n架构如上\n- Stream Metadata Server(SMS) is the control plane of Vortex.\nThe SMS assigns a Streamlet to a specific Stream Server. THe Stream Server maintains the set of fragments for the Streamlet.\n\n- The Stream Server is the data plane of Vortex. It owns a set of STreamlets and creates Fragments for those Streamlets. The Stream Server has its own in memory metadata about its Streamlets and Fragments, and persists this by writing to a transaction log and periodically writing checkpoitns.\nThe Stream Server knows which Fragments belong to which Streamlet, their committed size, the minimum and maximum record timestamp in each Fragment, whether a Streamlet or Fragment is finalized, the schema version, and the partitioning and clustering columns of the table.\n\n客户端通过 SMS 创建一个 Stream，SMS 会生成一个随机的 StreamId 然后 assign 到一个 Stream Server，Client 直接往 StreamServer 写数据，StreamServer 会周期性的通过心跳同步当前的数据。\nStorage Optimization Service 会从 SMS 请求一批 Fragments 然后转为 ROS 的格式，然后把 Fragements 标记为 DELETED，再过一段时间之后，SMS 会通知 Stream Server 将过期的 Fragements 进行删除。\n\nStream Server 到 SMS 的心跳只包含元数据（与上一次心跳的 Streamlet 的不同数据）\n\n- Fragment File Format\n> Fragment 像是一个适合写入的文件格式（和 ROS 的 Parquet 对比）\n> Header 包括了同一个 Streamlet 中之前为删除的 Fragment，后面包括了 bloomfilter 以及其他 footer 信息\nEach Fragment begins with a header which contains the File Map. The File Map lists the committed size and record ranges of all previous Fragments in the same Streamlet which have not yet been deleted. The File Map is used for disaster resilience.\n\nWhen a Fragment is finalized, the Stream Server appends a bloom filter, followed by a fixed length footer which describes the offset in the Fragment where the bloom filter starts. The bloom filter marks which key values are present for the partitioning and clustering columns.\n\nThe Fragment data format stores metadata records for FlushStream calls on BUFFERED streams. A flush operation is a metadata write to the Fragment which advances the committed row offset making all rows in the Streamlet(and the Stream) up to that point visible.\n\nVortex uses an end-to-end CRC to protect row data as it is sent from the client to the Stream Server, and from the Stream Server to Colossus.\n\nStream Server 会周期性（秒级）将 Streamlet 的变化同步给所有的 SMS，这些变化包括（新文件的创建，存量文件的写入，文件中的列属性）- 这个是 per-Streamlet 的，然后还有当前的 CPU，memory 以及 append throughput -- 这个用来做负载均衡。\n\n> A background service continuously optimizes data in Vortex as it is written. The goal ofStorage Optimization is to pitmize the format and layout of the data for large scale analysis. In doing so, it maintains an LSM tree of Fragments, starting with Fragments in WOS at the deepest level of the tree, with progressively more optimized ROS versions as we climb up the ree.\n使用 LSM tree 管理 Fragments，然后从 deepset 将 WOS 的转换为 ROS 的格式\n\n> To track the lifetime of Fragments, each Fragment maintains two timestamps: a *creation_timesatmp* and a *deletion_timestamp*.  A Fragment is visible to requests that read the table at a snapshot timestamp that is within the interval [creation_timestamp, deletion_timestamp). At each step of the optimization, the optimizer atomically sets the deletion_timestamp for the previous version of the fragments and the creation_timestamp for the new version. This guarantees that a row is included exactly once when reading the data from storage.\nFragment 可以有 creation_timestamp 和 deletion_timestamp，会自动给已经合并的 Fragment 赋值 deletion_timestamp（这个要保证事物）\n\n**Automatic Reclustering**, BigQuery allows users to cluster the data in a table on a set of specified columns. Clustering defines a \"weak\" sort order on the data blocks in the table. In other words, BigQuery attempts to distribute the data such that the blocks store non-overlapping ranges of values for the clustering keys. Orgamizing data in non-overlapping ranges results in more efficient processing at read time, by improving parititon prunning and or by reducing intermediate data transferred between query processing stages.\n> 可以对数据进行重排序，而且可以做分布的排列，尽量做到不重叠，这样可以做到更好的 partition prunning\n> Once the delta(WOS) is sufficiently large, the optimizer first range partitions the delta locally.\n如果 WOS 对读影响太多，就本地先合并, 形成一个新的 base\n> Figure 6 显示了一个 Automatic Reclustering 的具体例子, Base(ROS) + Delta(WOS) 可以合成新的 Base(ROS) \n\n> Vortex continuously tracks metadata for Streams, Streamlets, and Fragments.\n> An example of coarse grained metadata is the state of a Streamlet that indicates whether the Streamlet is currently writable and its currentl  length. The source of truth for Streamlet is marked finalized. As the storage optimizer moves data between the layers in hte LSM tree, BigQuery's highly scalable metadat management system, called BigMetadata\n\n> There is a tail of the Fragment and Streamlet metadata that may have not yet been indexed by Big Metadata. As the metadat of these blocks churns rapidly, we observe that scanning through the list of these tail blocks that need to be read to satisfy the snapshot read, can add latency to query processing. To address this, we continuously compact the metadat entries for the Fragments by keeping the entries corresponding to the live fragments(i.e. fragments with deletion_timestamp unset) together in our log.\n对元数据周期性做 compaction, 尽可能只保留 live fragment 的元数据\n\nVortex 会周期性的做数据正确性验证(Vortex continuously traces requests to detect data correctness issues such as missing or duplicated records), Finally, we also verify that each record is reported as converted exactly once from WOS to ROS. Additionally, for each conversion, we validate that the output records are consistent tiwth the input records.\n\nWhen Vortex SMS receives this request(read), it returns the union of the data in WOS and ROS.\n\nVortex allows a range of rows in a Fragment or Streamlet to be marked as deleted. To limit the size of these deletion masks, sometimes rows unaffected by the DML statement may also be marked deleted\n> 有点类似 pos delete？为了减少 pos delete 的数目，干脆把这重写？\n\n# BigMetadata\n主要想法\n- 使用类似系统表保存 metadata，这样可以横向扩展，而且可以使用 query engine 来处理 metadata 和 data\n- 提出了 falsifiable expression，可以改写 condition，从而大规模过滤数据\n- metadata 可能很大，所以在读取的时候可以使用 falsifiable expression，减少读取 metadata 的数据量。\n写一个 falsifiable expression 的例子\n> Traditionally, Big Data systems have tried to reduce the amount of metadata in order to scale the system, often compromising query performance. In Google BigQuery, we built a metadat management system that demonstrates that massive scale can be achived without such tradeoffs. We recognized the benefits that fine grained metadata provieds for query processing and we built a metadata system to manage it effictively. We use the same distributed query processing and data management techniques that we use for manageing data to handle Big metadata.\n\n> We present a distributed metadata management system that stores fine grained column and block level metadata for arbitrarily large tables and organizes it as a system table. We use a novel approach to process large amounts of metdata in these system tables by generating a query plan that integrates the meatdata scan into the actual data scan. In doing so, we leverage the same distributeddquery processing techniques that we use on our data to our metadat, thereby achieving performanct access to it along with high scalability. Our system has the following salient properties;\n- Consistent\n- Built for both batch and streaming APIs\n- (Almost) INfinitely scalable: Our design is built for scale and it supports tables of multiple petabytes isze, and due to its distributed nature scales in a way similar to the underlying data\n- Performance\n\nMost of the data in BigQuery is stored in columnar format blocks. Tables range from a few bytes to tens of petabytes. Large tables are stored in millions of columnar blocks. BigQuery supports tables with tens of thousands of columns. BigQuery maintains the entire mutation history of a table for a configurable amount of time in order to support queries on the table as of any timestamp in that history window\n\nWe classify storage metadata into two broad categoreis: Logical metadata and Physical metadata.\n- Logical metadata is information about the table that is generally directly visible to the user. Some examples of such metadata are: Table schema, Partitioning and clustering specifications, column and row level ACLs. This information is generally small in size and lends itself to quick access. \n- Physical metadata is information about the table's storage that BigQuery maintains internally in order to map a table name to its actual data.\n\n使用系统表来存储 physical metadata: To illustrate our idea, we describe the metadata layout using one such system table (hereafter referred to as CMETA) that stores column level information about the min/max values (called range constraints), hash bucket and modulus values (called hash constraints) and a dictionary of column values. Other variants of system tables include those that store posting lists of column values. Query optimizer chooses one or more such system tables for planning and executing the query\n\n每一列会有 totalRows/totalNulls/totalBytes/min/max/dictionary/bloom_filter 等信息\n\nBlock 是 metadata 更新的最小单元\n\nmetadata 有 changelog，记录 properties/timestamp 等\n\nA background process constantly performs LSM style merges on the change log to produce baselines and deltas of changes.\n\nFine grained metadata for rows that have not yet been compacted into capacitor blocks is maintained in the memory of ingestion servers.\n\nBigMetadata 使用了一套 condition 重写的逻辑(falsifialbe expressions)，可以更好的进行过滤比如 x > c => max(x) <= c, x < c => min(x) >= c 等等\n\nmetadata 可能会很大，所以也使用 falsiiable expression 进行读取\n\n文章说偏结论性的东西（自己理解），不要说太多细节\n- 细节别人可能不是太感兴趣\n- 纯细节不太能体现自己的东西\n- 可以在最后附加参考文献\n\n计算引擎的 execution plan 能否动态更新（根据数据的不同，动态的变动）\n- Procella\n\nProcella 的 meta 是树形结构，而且不仅仅保存叶子节\n\n从上到下，结合 fdap（或者类似想法），就是组建做标准，系统搭积木\n\nparquet 可以有不错的性能（比如 Influxdata 的优化，以及 LiquidCache 的做法等），新的 FileFormat 需要的整体工作量还挺大的\n- 首先需要知道 parquet 的瓶颈（可以看新的 fileformat 的 PR 稿）\n- parquet 的 ML 讨论（https://lists.apache.org/thread/8xmxc76nd00624qqps6s1qw6lhv1qwv5）/Influxdata 博客（https://www.influxdata.com/blog/how-good-parquet-wide-tables/）\n\n引擎 bigquery\n- 用户端\n-    sql（可以优化 sql，包括 pipelined sql）\n-    dataframe\n-    其它（处理非结构化数据）\n- 然后 query engine\n-    plan 优化\n-    优雅的调度和停止等\n- exection\n-     native（性能）\n- 分布式执行\n-     资源管理\n-      多类型资源统一管理\n\ntable format\n- catalog \n-    权限\n- metadata\n-    索引（不同类型的索引）\n-    bigemetadata（sql 改写，下推，cache 等）\n- file format\n-     结构化数据（主要是宽表，宽列，然后 map，list 这种符合类型）\n-     半结构化数据（类似 variant）\n-     非结构化数据\n-     新硬件\n- \n\n还需要能够支持非结构化数据\n- 现在有多种开源的 table/file format，其中 lance 由于国内字节在推，所以被知道的比较多。这里可以分为：1）better parquet，2）原生支持非结构化数据。其中第一个就是 parquet 现在支持不太好的情况（比如 list/map 等，这些在推荐等会有需要），点查（这个可以在 parquet 上用二级索引支持 -- 参考 datafusion 的博客），当然 lance 的二维拆分会是一个更高效的处理方式（尤其是模型处理的时候加维度）；第二个就是支持非结构化数据，这个有点类似高效支持 blob 数据，然后支持索引。\n\n\nmanagement（类似 amoro）\n- 主要是各种service（file layout 重排，索引生成，event trigger 生成 view 等）\n- 生命周期管理\n- 和 catalog 等结合（轻量级权限，）\n","source":"_drafts/how_could_the_multimode_lakehouse_be.md","raw":"多模态数据湖可以是啥样的？\n\n> 最近多模态数据湖的概念比较热门，记录下我理解中多模态数据湖的一个可能形态。\n\n\n多模态数据湖：能在一套系统中同时处理结构化数据、半结构化数据和非结构化数据。\n\n对于整套系统来说包括数据入湖，数据湖存储（主要是表格式），数据湖内数据的优化，Catalog，以及计算。\n\n> 增加一个全景架构图（包括上面所有这些流程）\n\n从数据使用角度来看\n- 数据最终是为了分析\n  - 分析性能\n    - 列存（至少是读取，可以用行存写入）\n  - 可能需要不断的变换 schema（SchemaEvolution）\n  - 需要支持 ACID\n  - 能对接尽可能广的生态\n  - 支持不同类型的数据\n    - 结构化，半结构化，非结构化数据\n  - 数据治理\n    - 为了性能调整\n    - 为了存储空间等治理\n数据同步\n  - reader + deserializer + transformer + serializer + writer\n  - schema evolution\n\n数据湖内数据治理\n- 数据湖内的数据可能对读取性能不是那么友好，需要进行优化\n- 会有 management 需求\n\n分析会有 引擎的计算，而引擎和表的对接则会需要 catalog/metadata 等\n\ncatalog/metadata\n- 跨源跨域等需求\n- 权限\n\n计算引擎\n- 功能\n- 性能\n\n增量计算可以将整个流程的计算耗时大大降低（减少不必要的计算）\n\n参考 FDAP 以及 [voltrondata](https://voltrondata.com/codex/accelerated-hardware) 的模型\n\n数据湖可以看成是 FileFormat 的一个索引（可以配合 FileFormat 一起使用）\n\nBigQuery\n\n现在 SQL 使用起来会相对复杂，可以尝试使用 PipelinedSQL 而且这个 SQL 可以更好的转换为拖拽式的。\n\nDremeal A Decade of Interactive SQL Analysis at Web Scale\nBigtable A Distributed Storage System for Structured Data\nAdaptive and Robust Query Execution for Lakehouse at Scale\nColumn Sketches A Scan Accelerator for Rapid and Robust Predicate Evaluation\n- Napa: Powering Scalable Data Warehousing with Robust Query Performance at Google\n- [x] Big Metadata: When Metadata is Big Data\n- [x] Vortex: A Stream-oriented Storage Engine For Big Data Analytics\n- BigLake: BigQuery's Evolution toward a Multi-Cloud Lakehouse\n- [x] SQL Has Problems. We Can Fix Them: Pipe Syntax in SQL\n  - 这个还是挺好的，也有开源的实现可以参考\n- [x] Procella: Unifying serving and analytical data at YouTube\nUnity Catalog\n\n# Napa\n2021-Powering Scalable Data Warehousing with Robust Query Performance at Google\n\nWe need to store and serve these planet-scale data sets under the extremely demanding requirements of scalability, sub-second query-response times, availability, and strong consistency; all this while ingesting a massive stream of updates from applciations used around the globe.\n\nThe following key aspects of Napa are the bedrock principles of its design and are aligned with our client requirements:\n- Robust Query Performance: Consistent query performance is critical to data analytics users. Our clients expect low query latency, typically around a few hundreds of milliseconds, as well as low variance in latency regardless of the query and data ingestion load. Napa is able to guarantee robust query performance with consistent results despite daunting requirements for scale and system availability.\n- Flexibility: While performance is important, our experience shows that it is not the only criterion for our clients. For instantce not all applications require millisecond response times, not all require the same freshness for ingested data, or for that matter, not all clients are willing to pay for \"performance at any cost\". Clients also require the flexibility to change system configurations to fit their dynamic requirements.\n- High-throughput Data Ingestion. All Napa functions, including storage, materialized view maintenance, and indexing, must be performed under a massive update load. Napa implements a distributed table and view maintenance framework that is based on the LSM-tree paradigm. LSM is widely used in current generation of data warehouses and databases primarily to efficiently integrate and incorporate constantly emerging data into already existing data. Napa scales LSM to meet the challenges of Google's operating environment.\n\nNapa's approach for robust query performance includes the aggressive use of amterialized views, which are maintained consistently as new data is ingested across multiple data centers.\n\n权衡三角：Data freshness, Resource costs, Query performance 三者之间做权衡\n\nA key design choice in Napa is to rely on materialized views for predicatable and high query performance.\n\nNapa's high-level architecture consists of three main components as shown in the figure above.\n- Napa's ingestion framework is responsible for committing updates into the tables. The deltas written by the ingestion framework only serve to satisfy the durability requirements of the ingestion framework, and hence are write optimized. These deltas need to be further consolidated before they can be applied to tables and their associated views.\n- The storage framework incrementally applies the updates to tables and their views. Napa tables and their views are maintained incrementally as log-structured merge-forests. Thus, each table is a collection of updates. Deltas are constantly consolidated to form larger deltas; we call this process \"compaction\" The view maintenance layer transoforms table deltas into view deltas by applying the corresponding SQL transformation. The storage layer is also responsible for periodically compacting tables and views.\n- Query serving is responsible for answering client queries. The system performs merging of necessary deltas of the table(or view) at query time. Note that query latency is a function of the query time merge effort, so the faster the storage subsystem can process updates, the fewer deltas need to be merged at query time. F1 Query is used as the query engine for data stored in Napa. We provide more details for query serving in Section 8.\n\nNapa decouples ingestion from view maintenance, and view maintenance from query processing. This decoupling provides clients knobs to meet their requirements, allowing tradeoffs among freshness, performance, and cost.\n\nUsers specify their requirements in terms of expected query performance, data freshness, and costs.\nNapa introduces the concept called `Queryable Timestamp (QT)` to provide clients with a live marker(just like an advancing timestamp). QT is the direct indicator of freshness since [NOW() - QT] indicates data delay. All data up the QT timestamp can be queried by the client.\n\n> Napa architecture showing the major system components\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202512291645719.png)\n\nNapa's high-level architecture consists of data and control planes as above. The architecture is deployed at multiple data centers to manage the replicas at each data center. The data plane consists of ingestion, storage, and query serving. The control plane is made up of a controller that coordinates work among the various subsystems. The control is also responsible for synchronizing and corrdinating metadata transactions across multiple data centers.\n\nNapa clients use ETL pipelines to insert data into their tables. The ingestion framework can sustain very high load, such as tens of GB/s of compressed data. Client data are delivered to any of the Napa replicas and Napa ensures that the data ingestion is incorporated at all the data centers. This significantly simplifies the design of ingestion pipelines.\n\nQuery serving deals with the necessary caching, prefetching and merging of deltas at runtime. The goal of query serving is to serve queries with low latency and low variance. Low latency is archieved by directing the queries to precomputed materialized views as opposed to the base table, and parallel execution of queries. Low variance is achieved by controlling the fan-in of the merges as well as a range of other I/O reduction and tail tolerance techniques.\n\nNapa relies on views as the main mechanism for good qauery performance. Napa's choice is largely motivated by the strict latency and resource requirements of its workloads, making it necessary to leverage indexed key lookups.\n\nThe Nap controller schedules compaction and view update tasks to keep the count of deltas for a table to a configurable value. These storage tasks are needed to keep the queryable Timestamp(QT) as fresh as possible given the cost tradeoffs.\n\nThe goal of the ingestion framework is to accept data, perform minima processing, and make it durable without considering the pace of subsequent view maintenance.\n\nThe queryable timestamp(QT) of a table is a timestamp which indicates the freshness of data that can be queried. If QT(table) = X, all data that was ingested into the table before time X can be queried by the client and the data after time X is not part of the query results.\n\nAn important criterion to ensure good query performance is to optimize the underlying data for reads and ensure views are available to speed up the queries.\n\nA table in Napa is a collection of all of its delta files, each delta corresponding to updates received for the table over a window of time, as below\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202512291733204.png)\n\nThe non-queryable deltas correspond to newly received updates written by the ingestion framework in the most recent time window(typically seconds.) THe largest deltas, on the other hand, span a time window of weeks or even months. Each delta is sorted by its keys, range partitioned, and has a local B-tree like index.\n\nThe QT of the database is the minimum of the QT of all the tables in the database. QT is also used to give clients a consistent view of data across all Napa replicas.\n\nNapa's storage subsystem is responsible for maintaining views and compacting deltas. It is also responsible for ensuring data integrity, durability via replication across data centers, and handling outages from individual machines to entire data centers.\n\nCompaction improves query performance and reduces storage consumption by 1) sorting inputs together and 2)aggregating multiple updates to the same rows. Since the delta files are individually sorted, compaction is essentially merge sorting. It is intentionally kept large during compaction so that the height of the merge tree is small, thus minimizing key comparisions.\n\nRobust query serving performance\nquery serving subsystem achieves robust performance, using Queryable Timestamp(QT), materialized views, and a range of other techniques.\n1. Reducing data in the critical path\nWhenever possible, Napa uses views to answer a query instead of the base table, since views with aggregation functions may have significantly less data. Nap maintains sparse B-tree indexes on its stored data, and uses them to quickly partition an input query ito thousands of subqueries that satisfy the filter predicates. This partitioning mechanism additionally looks at the latency budget and availability of query serviing resources to achieve good performance.\n\n> 增加 Figure7\n\n2. Minimizing Number of Sequential I/Os\nWhen a query is issued, Napa uses the value of QT to decide the version of metadata to be processed. The metadata in turns determines what data has to be process. Therefore, mateadata reads are on the critical path of query serving. Nap aensures all metadata can always be served from memory without contacting the persistent storage. This is achieved by affinity-based distributed metadata caching with periodic background refresheds. A particular QT is delayed to wait for the completion of periodic background refresh of metadata.\n\nNapa performs offline and online prefetching to further reduce the number of sequential I/Os in the critical path. Offline prefetching occurs as soon as data is ingested for frequently queried tables, before QT advances to make the new data available to query. Online prefetching starts when a query arrives and is performed by a shadow query executor which shares the data access pattern with the main query executor but skips all query processing steps.(like dry run?)\n\n3. Combining Small I/Os\nDuring query serving, Napa aggressively parallelizes the work by partitioning the query into fine grained units and then parallelizing I/O calls across deltas and across queried columns. To combat such amplification on tail letency, Napa uses QT to limit the number of queryable deltas. In addition, Napa also tries to combine small I/Os as much as possible, by using the fowlling two techniques: lazy merging across deltas and size-based disk layout.\n\n- lazy mering across deltas: When there are thousands(N) of subqueries and serval tens(M) of deltas, the number of parallel I/Os are in the order of tens of thousands(N * M). However, due to the parallelism each subquery reads very little data from most deltas. Meanwhile, a large fraction of Napa queries require merging based on a subset of primary keys in the subsequent phase of the query plan. In these cases, Napa adapts the query plan to avoid cross-delta merging in Delta Server and lets each Delta Server only process one delta, combining N * M parallel I/Ss into close to N parallel I/Os （merge 的数据尽量不跨 delta server？）\n- size-based disk layout: Napa uses a custom-built columnar storage format supporting multiple disk layout options, which are applied based on delta sizes. The PAX layout which can combine all column accesses into one I/O for lookup queries, is applied to small dltas. For large deltas, column-by-column layout is used that is I/O efficient for san queries but requires one I/O per column for lookup queries. This size-based choice ensures that Napa receives columnar storage benefits as well as reduces I/O operations.（基于大小选择不同的磁盘布局，PAX 作为小的布局，可以一次 IO 读取完毕，大文件则是按列存放，这样每一列需要一个 IO 但是 scan 更友好\n\n4. Tolerating tails and failures\nNapa adopts the principle of tolerating tail latency, rather than eliminating it, because eliminating all soruces of variability for such a complex and interdependent system is infeasible.\n\nFor a non-streaming RPC, such as the RPC between Metadata Server and Delta Server, Napa uses the machnism of *hedging*, which sends a secondary RPC identical to the original one to a different server after a certain delay, and waits for the faster reply.\nFor a streaming RPC, such as the RPC between F1 worker and Delta Server, Napa estimates its expected progress rate and requires the server executing it periodically to report progress, together with a *continuation* token. If the reported progress is below expectation or the report is missing, the last continuation token would be used to restart a new streaming RPC on a different server without losing progress. Pushdown operators like filtering and partial aggregation need to be carefully handled in progress reporting as they can significantly reduce the data size, causing progress reports to be superficially low or even missing. Napa uses bytes processed before filtering and partial aggregation as the progress rate metric and periodically forces these operators to flushes its internal state to generate a progress report with a continuation token.\n\nProduction metrics insights\nNapa manages thousands of tables and views in production, where many tables are petabyte scale. It serves over a billion queries per day and ingests trillions of rows. Napa is able to provide robust query performance through three techniques: 1) by more actively using views, Napa reduces raw query performance and variance even at 99th percentile, 2) by chaning storage policies, Napa can reduce the number of deltas and hence the tail latency, and 3) by decoupling ingesting, view maintenance, and query execution; Napa can mitigate the impact of infrastructure and workload changes on query performance.\n\n1. Views and QT Help achive robust query performance\nFirst, most client queries are aggregation queries, and materialized views are typically at least an order of magnitude smaller than the base tables from which they are derived. Reading from views not only improves raw performance, but also improves tail latency as their smaller size is more cache friendly, and requires less compute resources, which reduces the change of continetion for query resources.\n\n> Add the figure for #views with the query latency\n\nSecond, latency can be improved by reducing the number of deltas that have to be opend, read, and merged at query time.（相当于文件数量？）\n> Add the figure for #deltas with the query latency\n\nFigure 8(b) shows that as we change storage policies to reduce the number of deltas, the query latency improves significantly. The biggest impact is at the 99th percentile latency which reduces by more than 3.6x as the number of deltas is changed from 8 to 2. The main reasons are: 1) fewer deltas means there are less number of small, parallel IOs which are prone to cause latency tails, 2) fewer deltas also means that data is premerged and aggregated, and less processing is required at query time.（这个类似 MOR 中，文件数量少，则 IO 少，而且读取的时候需要进行的聚合计算也少）\n\n2. Handling infrastructure issues\n> Add figure 9\nFigure 9 shows that Napa is able to guarantee its client stable query performance even when the ingestion load changes or there are infrastructure outages.  Napa decouples ingestion from view maintenance and querying which allows us to optimize for low variance in query latency, in some cases by trading off data freshness. Figure 9(a) shows that the client continuously sends data to Napa, with some variance in the input rate over the course of the week. Figure 9(b) shows that the view maintennace performance dropped for the duration between X and Y indicating an infrastructure issue which affected the tasks updating views. However, the query serving latency remains near constant (Figure 9(d)) throughout the whole duration. In this particular example, client queries continued to be fast, however , for certain parts during the outage data freshness was impacted, as seen in Figure 9(c) where the value of delay is high. 就算 view 的维护因为基建受影响了，那么不影响写入和读取的性能，但是能读到的数据的新鲜度会受影响\n\n3. Client workloads\n支持不同的 tradeoff，比如 [Client A: Tradoff freshness] wants moderate query performance and low costs, but can tolerate lower freshness.\n[Client B: Tradeoff query performance] cares the most about low costs but can tolerate lower query performance\n[Client C Tradeoff costs] has high freshness and high query performance requirements, and is willing to pay high costs to achieve them.\n> Add figure 10 for different workloads\n\nNapa is a fully indexed system that is optimized for key lookups, range scans, and efficient incremental maintenance of indexes on tables and views. Napa can easily support both adhoc queries and highly selective and less diverse queries.\n\nNapa uses a varaint of B+-trees that exploits the fact that Napa tables have multi-part keys. Additionally, min/max keys(per-column min/max values) are stored along with each non-leaf block to eanble effective pruning. LSM adapt B-tree indexes for high update rates. Napa belongs to a class of  LSM systems that trade high write throughput for fast reads. (看起来是 LSM 和 B-tree 的结合）\n\n\n# 2023-Progressive Partitioning for Parallelized Query Execution in Google's Napa\nNapa holds Google's critical data warehouses in log-structured merge trees for real-time data ingestion and sub-second response for billions of queries per day. These queries are foten multi-key look-ups in highly skewed tables and indexes.\n\nIn our production experience, only progressive query-specific partitioning can achieve Napa's strict query latency SLOs.  Here we advocate good-enough partitioning that keeps the per-query partitioning time low without risking uneven work distribution. Our design combines pragmatic system choices and algorithmic innovations. For instance, B-trees are augmented with statistics of key distributions, thus serving the dual purpose of aiding lookups and partitioning. Furthermore, progressive partitioning is designed to be \"good enough\" thereby balancing partitioning time with performance. The resulting system is robust and successfully serves day-in-day-out billions of queries with very high quality of service forming a core infrastructure at Google\n\nNapa's diverse query workload consists of large scans and many-key lookups. The analytical queries with many-key lookups have strict QoS requirements and is the main focus of this paper.\n\nFrom our experience in running production services, we found the following three requirements important:\n- Query-specific partitioning. Any approach that we take should meet the latency SLOs across a diverse set of query workloads. In our experience, the partitioning granularity needs to be adjusted on a per-query basis to meet the latency and resource budget requirements. The expectation from the partitioning step is that it is able to produce number of partitions denoted by the parallelization requirement within bounded amount of error.\n- Evenness. Execution involves the partitioning of the tables into key ranges such that the partitioning results in even partitions. Partitioning should operate on tables with extreme skews where some keys span terabytes in disk. As an example, in Figure 1, a key range like < K1 = 1, K2 = 20 > may correspond to, say, a hundred GB portion of the table while another key range may be considerably smaller at a few MB.\n- Progressiveness. Query partitioning must balance overall execution time against the time and effort to produce query-specific partitions. For instance, one can produce perfectly even partiions while still ending up missing the QoS requirement. It is imperative that the partitioning method has the notion of \"good enough\" in the sense that it stops when the partitioing is the sufficient quality. Our porposed technique in hte paper is progressive such that 1) the longer the alogirhtm runs the better the quality of the resultant partitioning; 2) the algorithm stops once the desired error bound has been met.\n\nOur experimental results show that the use of statistics that is too find-grained can often result in queries spending too much time generating partitioning at the expense of overall query execution time.\n\nWe address this dilemma by leveraging B-trees to optimize access to the statistical information on the tables. Each LSM run has an associated B-tree index which are enhanced so that index nodes maintain size information for the associated key ranges. With these enhancements, we can estimate the input data size of the query starting with the root of the B-tree. If this estimation is not accurate enought or if the statistics point to areas of skews, we can descend to the next level in the index structure to obtain a finer level of statistical distributions for the key ranges overlapping with the query.\n\nOur proposed algorithm traverses the B-tree to produce even and query-specific partitioning. It is progressvie in the sense that it descends and accesses additional index information only if it does not satisfy the stipulated error bounds. In addition, the refinement is selective that it only descends to the lower levels of trees for those partitions that do not have gight enough bounds on the error.\n\nThe following key aspects of Napa are the bedrock principles of its design and are aligned with our client requirements: i) Robust Qury Performance: Napa clients expect low query latency, typically sub-seconds, as well as low variance in latency under a wide spectrum of query and data ingestion load; ii) System Flexibility: While performance is important, our clients also require the flexibility to change system configurations to their dynamic requirements such as trading freshness or recency of ingested data for better performance; iii) High-throughput Data Ingestion: Napa's ingestion, storage and query serving functions performan udner a massive update load.\n\nA Napa table consists of multiple data sets called deltas(corresponding to sorted runs of an LSM-tree) and we have one B-tree index for each delta. Not that each delta corresponds to updates on a table during a time window(e.g., last 1 minute, 1 day etc.).\n\nProgressive partitioning using B-tree: The B-trees on the deltas are fairly generic except that it hierarchically stores statistics of the underlying data. In particular, we store the number of rows that is indexed by each sub-tree and aggregate that statistics up the level. The partitioning algorithm we propose in the paper takes queried keys as input, retrieves and merges relevant keys taken from these B-tree indices, to generate an approximate histogram. Starting with the highest level histograms (i.e., the B-tree root index blocks), it tries to find accurate enough paritions. If it needs more detailed information, the algorithm will retrieve requried index blocks from the next highest level, repeating this trial and retrieve until it reaches the desired accuracy.\n\nLSM 让 partition 变的更复杂\nThe LSM data model complicates the task of query-specific partitioning in the following ways.\n- First, the keys specified in the query may be present in may(possibly all) of the deltas. Note that the same query worker must process all deltas where the keys are present in order to reconcile all relevant version.\n- Second, this proves to be a serious challenge for the evenness of the partitioning since some deltas may contribute many more matched rows than others.\n- Third, a query may involve seeking across multiple deltas and not all deltasequally contribute to the query. Thus, the paritioning effort may not be uniform across the deltas. For some deltas, it may be sufficient to perform coarser partitioning while others require significantly more effort in producing equal splits.\n\nWhy rely on progressive query-specific partitioning?\nThe ideal partitioning unit size can vary from 10MB(e.g., when reading 1GB data using 100 scan workers) to 1GB(e.g., when reading 1TB data using 1000 scan workers) on a per-query basis. \nThe next complexity here is that it is possible that there is one particular \"Date = d3\", which accounts for most of the data to be scanned in a query. So, that means that we need to partition the range <c1, d3>, <c2, d3> and <c3, d3> much more finely than the other key ranges. This means the partitioning algorithm needs to be progressive such that it can stop early on other dates and focus on generating finer grained partitions for \"Date = d3\" \nStandard write-time partitioning mechanisms are not able to address the requirements discussed above.\n\nPartitioning is highly specific to query under consideration and existing write-time partitioning is inadequate for workloads with a wide spectrum of query workloads. We have also established that one needs a way of producing both fine and coarse grained partitions even on the same key range, based on the query predicates, latency target and resource budget.\n\nProgressive partitioning\nThe progressive query-specific partitioning algorithm using *size-enhanced* B-trees. Our solution is to enhance typical B-trees with the statistics on data size in a hierarchical manner. For each delta, we maintain a B-tree pointing to data blocks, e.g. a block in the PAX layout. The index not only helps a query to efficiently seek on data using prefix keys but also provides statistical information for partitioning. Both querying and query-specific partitioning traverse the B-tree. The querying traverses the B-tree through the leaf level to visit dat ablocks. The query-specific partitioning does not visit data blocks and visits the index node at the leaf level only when required for finding \"good enough\" partitions as we describe below.\n> 使用 size-enhanced B-Tree，对于每一个 delta 都维护一个 B-tree 指向 data blocks，这样可以提供前缀查询，以及统计信息等\n\nFor a given query Q, the algorithm divides D deltas into P key range partitions that are nearly even with an error margin of \\{thelta}. Each delta has a size-enhanced B-tree, which carries keys and the size of data between these keys. We analyze the estimated size of matching data by combining keys and sizes from D indices. To get the most precise matching estimate from B-trees, we may need to visit the leaf index entries matching with the query. 但是读所有的 leaf 会很耗时，另外一种方式就是通过 root 来推测 partition 的数量，这是两个极端，文中从中间进行选择：从 root 开始，然后仅在需要下一层提供更多信息的时候才进行继续读取。\n\n文中有一个具体的例子\n> 补充 fig 4 和 fig 5\n\n其中两个 Delta，然后希望分成两个 partition（分 parition 是希望能够并行处理），然后考虑第一层的时候（从 B-tree 获得信息），Delta 1 的 [K1, K3) 有 15 个，[K4, K8) 有 20 个； Delta 2 的 [K2, K5) 有 20 个，[K6, K7) 15 个。\n\n那么把所有的数目都加在一起就是 15 +  20 + 20 + 15 = 70 个，然后会选择在 K4 和 K5 这里做分割，这样会把 [K4, K8) 和 [K2, K5) 做一些分割，然后对于第一个 partition 来说，大小可能是 15（也就是 [K2, K5) 的倾斜全在右侧，[K4, K8) 也倾斜），同样最大可能是 15+20+20 = 55,那么估算这个大小是 (15 + 55) / 2 = 35，然后 size margin = 55 -15 = 40,同样第二个 partition 类似，得到估算大小是 35, size margin 是 40,如果 (40/35, 40/35) -- 两个 parititon 的误差 -- 能满足 \\{theata} 那么就按照这么切分，如果不行，就对 B-Tree 进行下一层读取，然后再进一步进行划分\n\n> We represent this size-embedded index entry in a B-tree index node as e = <start, end, size, level, block>, which corresponds to the key range [e.start, e.end) having the estimated size e.size. The entry e is in a index block at tree level e.level(the value of 0 for e.level corresponds to the leaf level). Finally, e.block is a pointer to the child index block having range [e.start, e.end) (if e.level > 0)\n\n> 根据和 Gemini 的沟通，大概理解 Napa 的存储结构如下\n> 首先是 LSM Tree，然后每个 SSTable 是一个 B-tree，B-tree 就是文中的 Delta，B-tree 中包括多个实际的文件，以及对应的索引，然后渐进式则是「够用」就好，-- 「够用」是满足对应的误差\n\n# SQL Has Problems\n文章描述了 SQL 是一个很好的抽象，但是学习和维护不方便，重新造一个类似 SQL 的语言又很麻烦，所以有了 PipelinedSQL 这个渐进式改进的方案。\n>SQL is not an easy language to learn or use. Even for expert users, SQL is challenging to read, write and work with, which hurts user productivity. Serveral alternative languages have been prposed, but none have gained widespread adoption or displaced SQL. Migrating away from existing SQL ecosystems is expensive and generally unappealing for users.\n\nPiplined SQL 可以让 SQL 更好用，更具扩展性（more flexible, extensible and easy to use). \n\nIn SQL, the standard clauses occur in one rigidly defined order. Expressing anything else requires subqueries or other workarounds. With Pipelined SQL operationcan be composed arbitrarily, in any order.\n\n给了两个例子\n```sql\nSELECT c_count, COUNT(*) AS custdist\nFROM\n  (SELECT c_custkey, COUNT(o_orderkey) c_count\n   FROM customer\n   LEFT OUTER JOIN orders ON c_custkey = o_custkey\n        AND o_comment NOT LIKE '%unusual%packages%'\n   GROUP BY c_custkey\n  ) AS c_orders\nGROUP BY c_count\nORDER BY custdist DESC, c_count DESC;\n```\n\n然后 \n```pipelined-sql\nFROM customer\n|> LEFT OUTER JOIN orders ON c_custkey = o_custkey\n     AND o_comment NOT LIKE '%unusual%packages%'\n|> AGGREGATE COUNT(o_orderkey) c_count\n   GROUP BY c_custkey\n|> AGGREGATE COUNT(*) AS custdist\n   GROUP BY c_count\n|> ORDER BY custdist DESC, c_count DESC;\n```\n\n有讲 SQL 和 PipelinedSQL 的语义情况\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202512161155193.png)\n\n觉得 SQL 不错，那么就修复\n- SQL's foundational semantics, from relational algebra, are excellent\n- SQL's conceptual data model and top-level syntax, with statements representting requires, DDL, DML, etc, and composability via subqueries, works weel.\n- SQL's basic operations within a query(clauses like JOIN, ORDER BY, etc) all work reasonably well\n- SQL's syntactic structure for composing queries using those operations is **terrible**.\n- SQL'ls localized syntax with English-like keyword phrases is and anachronism, but we can live with it.\n- SQL's expression language is fine, and implementations typically includes a good library of existing functions.\n\n所以只需要修复第四点中的问题就行\n\npipelined SQL 使用 '|>' 这个 suffix 来衔接\n\n```\n<query> :=\n  {all existing query syntaxes}\n  | \"FROM\" <from_body>             -- New: FROM as a query\n  | <query> \"|>\" <pipe_operator>   -- New: pipe suffixes\n```\n论文中有具体算子的语法\n\n然后剩下的是一些更具体的细节，以及相关效果。\n这个如果成熟之后，应该也可以更方便的推广拖拽式的表现形式（？），能够更好的一一对应起来\n然后 ZetaSQL（已开源） 也有实现\n\n# Napa\n# BigLake\n# Procella\n> These can be categorized as: reporting and dashboarding, embedded statistics in pages, time-series monitoring, and ad-hoc analysis. Typically, organizations build specialized infrastructure for each of these use cases. This however, creates silos of data and processing, and results in a complex, expensive, and harder to maintain infrastructure.\n> At YouTube, we solved this problem by building a new SQL query engine -- Procella.\n\nThese workloads have differenet set of requirements:\n- Reporting and dashboarding: Video creators, content owners, and various internal stakeholders at YouTube need access to detailed real time dashboards to understand how their videos and channels are performing. This requieres an engine that supports executing tens of thousands of canned queries per second with low latency (tens of milliseconds), while queries may be using filters, aggregations, set operations and joins. The unique challenge here is that while our data volumen is high (each data source often contains hundreds of billions of new rows per day), we require near real-time respoinse time and access to fresh data.\n- Embedded statistics: YouTube exposes many realtime statistics to users, such as likes or views of a video, resulting in simple but every high cardinality queries. These values are constantly changin, so the system must support millions of e real-time updates concurrently with millions of low latency queries per second.\n- Monitoring: Monitoring workloads shrae many properties with the dashboarding workload, such as relatively simple canned queries and need for fresh data. The query volumne is often lower since monitoring is typically used internally by engineers. However, there is a need for aditional data management functions, such as automatic downsampling and expiry of old data, and additional query features (for example, efficient approximation functions and additional time-series functions)\n- Ad-hoc analysis: Various YouTube teams (data scientists, business analysts, product managers, engineers) need to perform complex ad-hoc analysis to understand usage trends and to determine how to improve the product. This requires low volume of queries(at most tens per second) and moderate latency (second to minutes) of complex queries (multiple levels of aggregations, set operations, analytic functions, joins, unpredcatable patterns, manipulating nested/repeated data, etc.) over enormous volumes(trillions of rows) of data. Query patterns are highly unpredictable, although some standard data modeling techniques, such as star and snowflake schemas, can be used.\n\n独立系统的问题\n- Data needed to be loaded into multiple systems using different Extract, Transform, and Load(ETL) processes, leading to significant additional resource consumption, data quality issues, data inconsistencies, slower loading times, high development and maintenance cost, and slower time-to-market.\n- Since each internal system uses different languages and API's, migrating data across these systems, to enable the utilization of existing tools, resulted in reduced usability and high learning costs. In particular since many of these systems do not support full SQL, some applications could not be built by using some backends, leading to data duplication and accessibility issues across the organization.\n- Several of the underlying componenets had performance, scalability and efficiency issues when dealing with data at YouTube scale.\n\nProcella 的特性\n- Rich API: Procella supports an almost complete implementation of standard SQL, including complex multistage joins, analytic functions and set operations, with serveral useful extensions such as approximate aggregations, ahdnling complex nested and repeated schemas, user defined functions, and more.\n- High Scalability: Procella separates compute (running on Bord) and storage (on Colussus) enabling high scalability (thousands of servers, hundreds of petabytes of data) in a cost efficient way.\n- High Performance: Procella uses state-of-the-art query execution techniques to eanble efficient execution of high volumen(millions of QPS) of queries with very low latency (milliseconds).\n- Data Freshness; Procella supports high volume, low latency data ingestion in both batch and streaming modes, the ability to work directly on existing data, and native support for lambda architecture.\n\n> Procella System Architecture\n\nProcellas 的数据按照 table 进行划分，每个 table 会有多个文件/分区。Procella 使用自己的列存 Artus，也支持其他的 file format，存在 Colossus 中，这样可以存算分离\n\nProcellas 没有使用 BTree 而是使用了更轻量级的 zonemaps, bloom filters, partition 以及 sort key 等这些二级索引，这些从文件头，或者 plan 时从 data server 获取，schema, table to file mapping, stats, 以及 zonemap 等这些存储在 BigTable/Spanner 中\n\n支持标准的 SQL 操作，支持 batch ingestion 和 streaming ingestion\n在 batch ingestion 的时候，可以根据 file header 获取，更耗时的元数据抽取会延迟处理；streaming ingestion 支持 RPC/PubSub 的方式，然后 Ingestion Server 转换为表的形式\n\n然后会有后台线程周期性进行合并操作\n\nQuery lifecycle\nClients connect to the Root Server(RS) to issue SQL queries. The RS performs query rewrites, parsing, planning and optimizations to generate the execution plan. To this end, ti uses metadata such as schema, partitioning and index infromation from the Metadata Server(MDS) to prune the files to be read. It then orchestrates the query execution as it goes through the different stages enforcing timeing/data dependencies and throttling. To address the needs of executing complex distributed query plans(timeing/ data dependencies, diverse join strategies, etc.), the RS builds a tree composed of query blocs as nodes and data streams as edges (Aggregate, Execute Remotely, Stagger Execution, etc. ) and executes it accordingly. This enables functionality such as shuffle (that requires timing dependency), uncorrelated subquery, subquery broadcast joins(data dependency) and multi-level aggregation. THis graph structure allows several optimizations by inserting custom operations into the tree based on query structure. Once the RS receives the final results, it sends the respoinse back to the client, along with statistics, error and warning messages, and any other information requested by the client.\n\nThe Data Sever(DS) receives plan fragments from the RS or another DS and does most fo the heavy lifting, such as reading the required data (from local memory, remote and distributed files in Colossus, remote memory using RDMA,  or another DS), executing the plan fragment and sending the results back to the requesting RS or DS.\n\n优化\n- Cache\n  - Colossus metadata caching  可以减少一次或多次文件打开的开销\n  - Header caching  文件头(尾）有 start offset，column size，minimum and maximum 值，缓存这些可以减少更多的文件访问（单独的 LRU）\n  - Data caching, DS 使用单独的 cache 缓存文件，列存 Artus 设计成 disk 和 memory 的 format 一致，这样可以让 cache 更友好(making cache population fairly cheap)，同时也缓存一些二级数据（比如bloom filter 等）\n  - metadata caching: metadata 存在 bigtable 这样的分布式文件系统中，访问多可能会导致有瓶颈，因此用 LRU 来 cache \n  - Affinity scheduling: Caches are more effective when each server caches a subset of the data. Procella implements affinity scheduling to the data servers and the metadata servers to ensure that operations on the same data/metadata go to the same serve with high probability. 这样每个 server 只负责一部分数据，cache 有效性也变高. 但这个不是强约束，也就是说可能被调度到其他的 server -- 这样只是性能变差（cache 无效）。\n- Data Format\n  - 一开始使用 Capacitor，但是它主要是 Ad-hoc 中使用（主要是 scan 性能），Procella 需要 lookup 和 range scan，所以开发了 Artus\n  - 使用自定义的 encoding。Uses custom encodings, avoiding generic compression algorithms like LZW. This ensures that it can seek to single rows efficiently without needing to decompress blocks of data, making it more suitable for small point lookups and range scans.\n   - Does multi-pass adaptive encoding: 第一次收集轻量级信息（ndv, min, max, sort order 等），然后使用这些去选择更合适的 encoding\n   - 选择对 sorted column 支持 binary search 的 encoding\n   - 嵌套字段的处理和 parquet 不一样，把表的 schema 当成 tree，每个字段都存在为独立的列, 针对每个父字段（如果自己本身存在的话），会记录所有子字段出现的次数，对于可选字段，该值是 0 或者 1,重复字段该值为非负。但是不记录父子段不存在的信息  \n   - Directly exposes dictionary indices, Run Length Encoding information, and other encoding information to the evaluation engine.\n   - Records rich metadata in the file and column header.\n   - Supports storing inverted inddexes. -- 搜索场景有用\n\n支持 multi-level partitioning and clustering\n\nJoin 的类型\n- Broadcast： 一方足够小可以加载到 DS 的内存。\n- Co-partitioned: fact 和 dim 可以使用同样的 key 进行 partition\n- Shuffle：数据太大，然后没有按照 join key 排序，就进行 shuffle\n- Pipelined: RHS 是负责查询，但是结果可能比较小的时候\n- Remote lookup: dim table 是分区的，但是 fact 没有\n\n怎么解决 tail latency\n- 因为数据有备份，所以如果某个数据节点的访问延迟超过了中位数(median)，就访问其他的节点 \n- RS 会控制访问同一个 DS 的频率，批次等\n- RS 会给每个请求附带一个优先级，通常来说小查询的优先级更高，大查询的优先级更低。DS 为高优和低优的分别分配资源，这样可以保证小查询的快速响应-- 不会被大查询 block\n\nIntermediate merging\n- 对于很重的聚合，最后的聚合可能会成为瓶颈 -- 需要在单机点操作很多数据。为了避免这个，添加中间节点用来做中间的聚合。\n\nQuery Optimization\n- Virtual Tables 类似 MV\n  - Index-aware aggreagte selection\n  - Stitched queries\n  - Lambda architecture awareness\n  - Join awareness\n\nQuery Optimizer\n使用静态和动态的查询优化技术 (makes use of static and adaptive query optimization techniques) At query compile time we use a rule based optimizer that applies standard logical rewrites (always benefical) such as filter push down, subquery decorrelation, constant folding, etc. At query execution time we use adaptive techniques to select/tune physical operators based on statistics (cardinality, distinct count, quantiles) collected on a smaple of the actual data used in the query.\n- Adaptive Aggregation\n- Adaptive Join\n- Adaptive sorting\n\nAdaptive 的不足：需要动态收集信息，可能导致短查询耗时更久（比如 10ms 左右的可能变成原来的数倍），这种可以让用户给定 hint 不走 adaptive optimization，另外用户愿意接受短查询变长，换来大查询的耗时变短（overhead 可能有 10% 左右）\n\n针对 serving 做优化处理\n- 数据写入后，会立即通知 dataserver 进行加载，这样可以避免冷读\n- MDS 编译进 Root Server，可以减少 RPC 交互\n- metadta 提前加载到内存，避免查询的时候加载 metadata\n- query plans are aggressively cached to eliminate parsing and planning overhead.  This is very effective since the stats query patterns are highly predicatble.\n- The RS batchs all request for the same key and sends them to a single pair of primary and secondary data servers.\n- The problematic outlier tasks are automatically moved to other machines.\n\n\n# Vortex\n> Vortex: A Stream-oriented Storage Engine For Big Data Analytics\n\nVortex is a streaming-first storage system that supports both streaming and batch data analytics. Today, BigQuery uses Vortex to support petabyte scale data ingestion with sub-second data freshness and query latency.\n\nVortex has the following key properties:\n- Consistent: Guaranteees ACID properties for all API operations.\n- Unified API for batch and streaming: Vortex offers a single unified API with support for both streaming and batch data.\n- Scalable: Vortex implements a fully distributed data and control plane and as a result supports tables of multiple petabytes size.\n- Performant: The Vortex API offers sub-second tail write latencies that simplify client side application programming.\n\nBigQuery storage provides a global namespace over all data in BigQuery. Data is organized into regional containers called datasets(analogous to schemata in traditional database management systems). Tables, logical views, metarialized views, search indexes, stored procedures, machine learning models etc. all reside in a dataset.\n\nVortex is BigQuery's scalable, distributed and synchronnously replicated storage engine that supports data ingestion, retrieval and curation.\n\nA Vortex Stream is an entity to which rows can be appended to the current end. Each row in a Vortex Stream is identified by the Stream's identifier and its row offset within the Stream. Readers can concurrently read a Stream at different row offsets. A table is an unordered collection of Stream.\n> Stream 有点像传统说的文件，比如 Parquet File？但是应该还不一样，毕竟还有 ColumnFormat\n\nStreams are backed by the following entities\n- Streamlets Vortex Streams provide durable sotrage of data. A Streamlet is a contiguous slice of rows in the Stream, all of which are present in the same 2 clusters. A Stream is an ordered list of one or more Streamlets. Given the Stream's append-only semantics, a Stream has at most one writable Streamlet. The writable Streamlet, if one exists, is always the last Streamlet in a Stream.\n\n- Fragments: Each Streamlet is further split into contiguous blocks of rows called Fragments. Fragments typically are a range of rows inside a log file. Log files are stored in Colossus.\n> Streamlets 和 Fragments 是 写入端的概念，还是类似表级别的概念\n> Streamlets and Fragments are internal physical metadata entities; they aren't visible to the users of Vortex.\n- Data formats: BigQuery operates broadly with data in two different classes of data formats. The write-optimized storage format(WOS) is the format in which data is written by Vortex's append API, The read-optimized storage format(ROS) is the format in which data is optimized for dat aprocessing. \n  BigQuery use Capacitor as ROS, BigLake use Parquet as ROS\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202512041721506.png)\n\n架构如上\n- Stream Metadata Server(SMS) is the control plane of Vortex.\nThe SMS assigns a Streamlet to a specific Stream Server. THe Stream Server maintains the set of fragments for the Streamlet.\n\n- The Stream Server is the data plane of Vortex. It owns a set of STreamlets and creates Fragments for those Streamlets. The Stream Server has its own in memory metadata about its Streamlets and Fragments, and persists this by writing to a transaction log and periodically writing checkpoitns.\nThe Stream Server knows which Fragments belong to which Streamlet, their committed size, the minimum and maximum record timestamp in each Fragment, whether a Streamlet or Fragment is finalized, the schema version, and the partitioning and clustering columns of the table.\n\n客户端通过 SMS 创建一个 Stream，SMS 会生成一个随机的 StreamId 然后 assign 到一个 Stream Server，Client 直接往 StreamServer 写数据，StreamServer 会周期性的通过心跳同步当前的数据。\nStorage Optimization Service 会从 SMS 请求一批 Fragments 然后转为 ROS 的格式，然后把 Fragements 标记为 DELETED，再过一段时间之后，SMS 会通知 Stream Server 将过期的 Fragements 进行删除。\n\nStream Server 到 SMS 的心跳只包含元数据（与上一次心跳的 Streamlet 的不同数据）\n\n- Fragment File Format\n> Fragment 像是一个适合写入的文件格式（和 ROS 的 Parquet 对比）\n> Header 包括了同一个 Streamlet 中之前为删除的 Fragment，后面包括了 bloomfilter 以及其他 footer 信息\nEach Fragment begins with a header which contains the File Map. The File Map lists the committed size and record ranges of all previous Fragments in the same Streamlet which have not yet been deleted. The File Map is used for disaster resilience.\n\nWhen a Fragment is finalized, the Stream Server appends a bloom filter, followed by a fixed length footer which describes the offset in the Fragment where the bloom filter starts. The bloom filter marks which key values are present for the partitioning and clustering columns.\n\nThe Fragment data format stores metadata records for FlushStream calls on BUFFERED streams. A flush operation is a metadata write to the Fragment which advances the committed row offset making all rows in the Streamlet(and the Stream) up to that point visible.\n\nVortex uses an end-to-end CRC to protect row data as it is sent from the client to the Stream Server, and from the Stream Server to Colossus.\n\nStream Server 会周期性（秒级）将 Streamlet 的变化同步给所有的 SMS，这些变化包括（新文件的创建，存量文件的写入，文件中的列属性）- 这个是 per-Streamlet 的，然后还有当前的 CPU，memory 以及 append throughput -- 这个用来做负载均衡。\n\n> A background service continuously optimizes data in Vortex as it is written. The goal ofStorage Optimization is to pitmize the format and layout of the data for large scale analysis. In doing so, it maintains an LSM tree of Fragments, starting with Fragments in WOS at the deepest level of the tree, with progressively more optimized ROS versions as we climb up the ree.\n使用 LSM tree 管理 Fragments，然后从 deepset 将 WOS 的转换为 ROS 的格式\n\n> To track the lifetime of Fragments, each Fragment maintains two timestamps: a *creation_timesatmp* and a *deletion_timestamp*.  A Fragment is visible to requests that read the table at a snapshot timestamp that is within the interval [creation_timestamp, deletion_timestamp). At each step of the optimization, the optimizer atomically sets the deletion_timestamp for the previous version of the fragments and the creation_timestamp for the new version. This guarantees that a row is included exactly once when reading the data from storage.\nFragment 可以有 creation_timestamp 和 deletion_timestamp，会自动给已经合并的 Fragment 赋值 deletion_timestamp（这个要保证事物）\n\n**Automatic Reclustering**, BigQuery allows users to cluster the data in a table on a set of specified columns. Clustering defines a \"weak\" sort order on the data blocks in the table. In other words, BigQuery attempts to distribute the data such that the blocks store non-overlapping ranges of values for the clustering keys. Orgamizing data in non-overlapping ranges results in more efficient processing at read time, by improving parititon prunning and or by reducing intermediate data transferred between query processing stages.\n> 可以对数据进行重排序，而且可以做分布的排列，尽量做到不重叠，这样可以做到更好的 partition prunning\n> Once the delta(WOS) is sufficiently large, the optimizer first range partitions the delta locally.\n如果 WOS 对读影响太多，就本地先合并, 形成一个新的 base\n> Figure 6 显示了一个 Automatic Reclustering 的具体例子, Base(ROS) + Delta(WOS) 可以合成新的 Base(ROS) \n\n> Vortex continuously tracks metadata for Streams, Streamlets, and Fragments.\n> An example of coarse grained metadata is the state of a Streamlet that indicates whether the Streamlet is currently writable and its currentl  length. The source of truth for Streamlet is marked finalized. As the storage optimizer moves data between the layers in hte LSM tree, BigQuery's highly scalable metadat management system, called BigMetadata\n\n> There is a tail of the Fragment and Streamlet metadata that may have not yet been indexed by Big Metadata. As the metadat of these blocks churns rapidly, we observe that scanning through the list of these tail blocks that need to be read to satisfy the snapshot read, can add latency to query processing. To address this, we continuously compact the metadat entries for the Fragments by keeping the entries corresponding to the live fragments(i.e. fragments with deletion_timestamp unset) together in our log.\n对元数据周期性做 compaction, 尽可能只保留 live fragment 的元数据\n\nVortex 会周期性的做数据正确性验证(Vortex continuously traces requests to detect data correctness issues such as missing or duplicated records), Finally, we also verify that each record is reported as converted exactly once from WOS to ROS. Additionally, for each conversion, we validate that the output records are consistent tiwth the input records.\n\nWhen Vortex SMS receives this request(read), it returns the union of the data in WOS and ROS.\n\nVortex allows a range of rows in a Fragment or Streamlet to be marked as deleted. To limit the size of these deletion masks, sometimes rows unaffected by the DML statement may also be marked deleted\n> 有点类似 pos delete？为了减少 pos delete 的数目，干脆把这重写？\n\n# BigMetadata\n主要想法\n- 使用类似系统表保存 metadata，这样可以横向扩展，而且可以使用 query engine 来处理 metadata 和 data\n- 提出了 falsifiable expression，可以改写 condition，从而大规模过滤数据\n- metadata 可能很大，所以在读取的时候可以使用 falsifiable expression，减少读取 metadata 的数据量。\n写一个 falsifiable expression 的例子\n> Traditionally, Big Data systems have tried to reduce the amount of metadata in order to scale the system, often compromising query performance. In Google BigQuery, we built a metadat management system that demonstrates that massive scale can be achived without such tradeoffs. We recognized the benefits that fine grained metadata provieds for query processing and we built a metadata system to manage it effictively. We use the same distributed query processing and data management techniques that we use for manageing data to handle Big metadata.\n\n> We present a distributed metadata management system that stores fine grained column and block level metadata for arbitrarily large tables and organizes it as a system table. We use a novel approach to process large amounts of metdata in these system tables by generating a query plan that integrates the meatdata scan into the actual data scan. In doing so, we leverage the same distributeddquery processing techniques that we use on our data to our metadat, thereby achieving performanct access to it along with high scalability. Our system has the following salient properties;\n- Consistent\n- Built for both batch and streaming APIs\n- (Almost) INfinitely scalable: Our design is built for scale and it supports tables of multiple petabytes isze, and due to its distributed nature scales in a way similar to the underlying data\n- Performance\n\nMost of the data in BigQuery is stored in columnar format blocks. Tables range from a few bytes to tens of petabytes. Large tables are stored in millions of columnar blocks. BigQuery supports tables with tens of thousands of columns. BigQuery maintains the entire mutation history of a table for a configurable amount of time in order to support queries on the table as of any timestamp in that history window\n\nWe classify storage metadata into two broad categoreis: Logical metadata and Physical metadata.\n- Logical metadata is information about the table that is generally directly visible to the user. Some examples of such metadata are: Table schema, Partitioning and clustering specifications, column and row level ACLs. This information is generally small in size and lends itself to quick access. \n- Physical metadata is information about the table's storage that BigQuery maintains internally in order to map a table name to its actual data.\n\n使用系统表来存储 physical metadata: To illustrate our idea, we describe the metadata layout using one such system table (hereafter referred to as CMETA) that stores column level information about the min/max values (called range constraints), hash bucket and modulus values (called hash constraints) and a dictionary of column values. Other variants of system tables include those that store posting lists of column values. Query optimizer chooses one or more such system tables for planning and executing the query\n\n每一列会有 totalRows/totalNulls/totalBytes/min/max/dictionary/bloom_filter 等信息\n\nBlock 是 metadata 更新的最小单元\n\nmetadata 有 changelog，记录 properties/timestamp 等\n\nA background process constantly performs LSM style merges on the change log to produce baselines and deltas of changes.\n\nFine grained metadata for rows that have not yet been compacted into capacitor blocks is maintained in the memory of ingestion servers.\n\nBigMetadata 使用了一套 condition 重写的逻辑(falsifialbe expressions)，可以更好的进行过滤比如 x > c => max(x) <= c, x < c => min(x) >= c 等等\n\nmetadata 可能会很大，所以也使用 falsiiable expression 进行读取\n\n文章说偏结论性的东西（自己理解），不要说太多细节\n- 细节别人可能不是太感兴趣\n- 纯细节不太能体现自己的东西\n- 可以在最后附加参考文献\n\n计算引擎的 execution plan 能否动态更新（根据数据的不同，动态的变动）\n- Procella\n\nProcella 的 meta 是树形结构，而且不仅仅保存叶子节\n\n从上到下，结合 fdap（或者类似想法），就是组建做标准，系统搭积木\n\nparquet 可以有不错的性能（比如 Influxdata 的优化，以及 LiquidCache 的做法等），新的 FileFormat 需要的整体工作量还挺大的\n- 首先需要知道 parquet 的瓶颈（可以看新的 fileformat 的 PR 稿）\n- parquet 的 ML 讨论（https://lists.apache.org/thread/8xmxc76nd00624qqps6s1qw6lhv1qwv5）/Influxdata 博客（https://www.influxdata.com/blog/how-good-parquet-wide-tables/）\n\n引擎 bigquery\n- 用户端\n-    sql（可以优化 sql，包括 pipelined sql）\n-    dataframe\n-    其它（处理非结构化数据）\n- 然后 query engine\n-    plan 优化\n-    优雅的调度和停止等\n- exection\n-     native（性能）\n- 分布式执行\n-     资源管理\n-      多类型资源统一管理\n\ntable format\n- catalog \n-    权限\n- metadata\n-    索引（不同类型的索引）\n-    bigemetadata（sql 改写，下推，cache 等）\n- file format\n-     结构化数据（主要是宽表，宽列，然后 map，list 这种符合类型）\n-     半结构化数据（类似 variant）\n-     非结构化数据\n-     新硬件\n- \n\n还需要能够支持非结构化数据\n- 现在有多种开源的 table/file format，其中 lance 由于国内字节在推，所以被知道的比较多。这里可以分为：1）better parquet，2）原生支持非结构化数据。其中第一个就是 parquet 现在支持不太好的情况（比如 list/map 等，这些在推荐等会有需要），点查（这个可以在 parquet 上用二级索引支持 -- 参考 datafusion 的博客），当然 lance 的二维拆分会是一个更高效的处理方式（尤其是模型处理的时候加维度）；第二个就是支持非结构化数据，这个有点类似高效支持 blob 数据，然后支持索引。\n\n\nmanagement（类似 amoro）\n- 主要是各种service（file layout 重排，索引生成，event trigger 生成 view 等）\n- 生命周期管理\n- 和 catalog 等结合（轻量级权限，）\n","slug":"how_could_the_multimode_lakehouse_be","published":0,"date":"2026-01-13T09:33:37.747Z","updated":"2026-01-13T09:33:37.750Z","_id":"cmgggnclz000ts1fyfkqfg95s","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"<p>多模态数据湖可以是啥样的？</p>\n<blockquote>\n<p>最近多模态数据湖的概念比较热门，记录下我理解中多模态数据湖的一个可能形态。</p>\n</blockquote>\n<p>多模态数据湖：能在一套系统中同时处理结构化数据、半结构化数据和非结构化数据。</p>\n<p>对于整套系统来说包括数据入湖，数据湖存储（主要是表格式），数据湖内数据的优化，Catalog，以及计算。</p>\n<blockquote>\n<p>增加一个全景架构图（包括上面所有这些流程）</p>\n</blockquote>\n<p>从数据使用角度来看</p>\n<ul>\n<li>数据最终是为了分析<ul>\n<li>分析性能<ul>\n<li>列存（至少是读取，可以用行存写入）</li>\n</ul>\n</li>\n<li>可能需要不断的变换 schema（SchemaEvolution）</li>\n<li>需要支持 ACID</li>\n<li>能对接尽可能广的生态</li>\n<li>支持不同类型的数据<ul>\n<li>结构化，半结构化，非结构化数据</li>\n</ul>\n</li>\n<li>数据治理<ul>\n<li>为了性能调整</li>\n<li>为了存储空间等治理<br>数据同步</li>\n</ul>\n</li>\n<li>reader + deserializer + transformer + serializer + writer</li>\n<li>schema evolution</li>\n</ul>\n</li>\n</ul>\n<p>数据湖内数据治理</p>\n<ul>\n<li>数据湖内的数据可能对读取性能不是那么友好，需要进行优化</li>\n<li>会有 management 需求</li>\n</ul>\n<p>分析会有 引擎的计算，而引擎和表的对接则会需要 catalog/metadata 等</p>\n<p>catalog/metadata</p>\n<ul>\n<li>跨源跨域等需求</li>\n<li>权限</li>\n</ul>\n<p>计算引擎</p>\n<ul>\n<li>功能</li>\n<li>性能</li>\n</ul>\n<p>增量计算可以将整个流程的计算耗时大大降低（减少不必要的计算）</p>\n<p>参考 FDAP 以及 <a href=\"https://voltrondata.com/codex/accelerated-hardware\">voltrondata</a> 的模型</p>\n<p>数据湖可以看成是 FileFormat 的一个索引（可以配合 FileFormat 一起使用）</p>\n<p>BigQuery</p>\n<p>现在 SQL 使用起来会相对复杂，可以尝试使用 PipelinedSQL 而且这个 SQL 可以更好的转换为拖拽式的。</p>\n<p>Dremeal A Decade of Interactive SQL Analysis at Web Scale<br>Bigtable A Distributed Storage System for Structured Data<br>Adaptive and Robust Query Execution for Lakehouse at Scale<br>Column Sketches A Scan Accelerator for Rapid and Robust Predicate Evaluation</p>\n<ul>\n<li>Napa: Powering Scalable Data Warehousing with Robust Query Performance at Google</li>\n<li>[x] Big Metadata: When Metadata is Big Data</li>\n<li>[x] Vortex: A Stream-oriented Storage Engine For Big Data Analytics</li>\n<li>BigLake: BigQuery’s Evolution toward a Multi-Cloud Lakehouse</li>\n<li>[x] SQL Has Problems. We Can Fix Them: Pipe Syntax in SQL<ul>\n<li>这个还是挺好的，也有开源的实现可以参考</li>\n</ul>\n</li>\n<li>[x] Procella: Unifying serving and analytical data at YouTube<br>Unity Catalog</li>\n</ul>\n<h1 id=\"Napa\"><a href=\"#Napa\" class=\"headerlink\" title=\"Napa\"></a>Napa</h1><p>2021-Powering Scalable Data Warehousing with Robust Query Performance at Google</p>\n<p>We need to store and serve these planet-scale data sets under the extremely demanding requirements of scalability, sub-second query-response times, availability, and strong consistency; all this while ingesting a massive stream of updates from applciations used around the globe.</p>\n<p>The following key aspects of Napa are the bedrock principles of its design and are aligned with our client requirements:</p>\n<ul>\n<li>Robust Query Performance: Consistent query performance is critical to data analytics users. Our clients expect low query latency, typically around a few hundreds of milliseconds, as well as low variance in latency regardless of the query and data ingestion load. Napa is able to guarantee robust query performance with consistent results despite daunting requirements for scale and system availability.</li>\n<li>Flexibility: While performance is important, our experience shows that it is not the only criterion for our clients. For instantce not all applications require millisecond response times, not all require the same freshness for ingested data, or for that matter, not all clients are willing to pay for “performance at any cost”. Clients also require the flexibility to change system configurations to fit their dynamic requirements.</li>\n<li>High-throughput Data Ingestion. All Napa functions, including storage, materialized view maintenance, and indexing, must be performed under a massive update load. Napa implements a distributed table and view maintenance framework that is based on the LSM-tree paradigm. LSM is widely used in current generation of data warehouses and databases primarily to efficiently integrate and incorporate constantly emerging data into already existing data. Napa scales LSM to meet the challenges of Google’s operating environment.</li>\n</ul>\n<p>Napa’s approach for robust query performance includes the aggressive use of amterialized views, which are maintained consistently as new data is ingested across multiple data centers.</p>\n<p>权衡三角：Data freshness, Resource costs, Query performance 三者之间做权衡</p>\n<p>A key design choice in Napa is to rely on materialized views for predicatable and high query performance.</p>\n<p>Napa’s high-level architecture consists of three main components as shown in the figure above.</p>\n<ul>\n<li>Napa’s ingestion framework is responsible for committing updates into the tables. The deltas written by the ingestion framework only serve to satisfy the durability requirements of the ingestion framework, and hence are write optimized. These deltas need to be further consolidated before they can be applied to tables and their associated views.</li>\n<li>The storage framework incrementally applies the updates to tables and their views. Napa tables and their views are maintained incrementally as log-structured merge-forests. Thus, each table is a collection of updates. Deltas are constantly consolidated to form larger deltas; we call this process “compaction” The view maintenance layer transoforms table deltas into view deltas by applying the corresponding SQL transformation. The storage layer is also responsible for periodically compacting tables and views.</li>\n<li>Query serving is responsible for answering client queries. The system performs merging of necessary deltas of the table(or view) at query time. Note that query latency is a function of the query time merge effort, so the faster the storage subsystem can process updates, the fewer deltas need to be merged at query time. F1 Query is used as the query engine for data stored in Napa. We provide more details for query serving in Section 8.</li>\n</ul>\n<p>Napa decouples ingestion from view maintenance, and view maintenance from query processing. This decoupling provides clients knobs to meet their requirements, allowing tradeoffs among freshness, performance, and cost.</p>\n<p>Users specify their requirements in terms of expected query performance, data freshness, and costs.<br>Napa introduces the concept called <code>Queryable Timestamp (QT)</code> to provide clients with a live marker(just like an advancing timestamp). QT is the direct indicator of freshness since [NOW() - QT] indicates data delay. All data up the QT timestamp can be queried by the client.</p>\n<blockquote>\n<p>Napa architecture showing the major system components<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202512291645719.png\" alt=\"\"></p>\n</blockquote>\n<p>Napa’s high-level architecture consists of data and control planes as above. The architecture is deployed at multiple data centers to manage the replicas at each data center. The data plane consists of ingestion, storage, and query serving. The control plane is made up of a controller that coordinates work among the various subsystems. The control is also responsible for synchronizing and corrdinating metadata transactions across multiple data centers.</p>\n<p>Napa clients use ETL pipelines to insert data into their tables. The ingestion framework can sustain very high load, such as tens of GB/s of compressed data. Client data are delivered to any of the Napa replicas and Napa ensures that the data ingestion is incorporated at all the data centers. This significantly simplifies the design of ingestion pipelines.</p>\n<p>Query serving deals with the necessary caching, prefetching and merging of deltas at runtime. The goal of query serving is to serve queries with low latency and low variance. Low latency is archieved by directing the queries to precomputed materialized views as opposed to the base table, and parallel execution of queries. Low variance is achieved by controlling the fan-in of the merges as well as a range of other I/O reduction and tail tolerance techniques.</p>\n<p>Napa relies on views as the main mechanism for good qauery performance. Napa’s choice is largely motivated by the strict latency and resource requirements of its workloads, making it necessary to leverage indexed key lookups.</p>\n<p>The Nap controller schedules compaction and view update tasks to keep the count of deltas for a table to a configurable value. These storage tasks are needed to keep the queryable Timestamp(QT) as fresh as possible given the cost tradeoffs.</p>\n<p>The goal of the ingestion framework is to accept data, perform minima processing, and make it durable without considering the pace of subsequent view maintenance.</p>\n<p>The queryable timestamp(QT) of a table is a timestamp which indicates the freshness of data that can be queried. If QT(table) = X, all data that was ingested into the table before time X can be queried by the client and the data after time X is not part of the query results.</p>\n<p>An important criterion to ensure good query performance is to optimize the underlying data for reads and ensure views are available to speed up the queries.</p>\n<p>A table in Napa is a collection of all of its delta files, each delta corresponding to updates received for the table over a window of time, as below<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202512291733204.png\" alt=\"\"></p>\n<p>The non-queryable deltas correspond to newly received updates written by the ingestion framework in the most recent time window(typically seconds.) THe largest deltas, on the other hand, span a time window of weeks or even months. Each delta is sorted by its keys, range partitioned, and has a local B-tree like index.</p>\n<p>The QT of the database is the minimum of the QT of all the tables in the database. QT is also used to give clients a consistent view of data across all Napa replicas.</p>\n<p>Napa’s storage subsystem is responsible for maintaining views and compacting deltas. It is also responsible for ensuring data integrity, durability via replication across data centers, and handling outages from individual machines to entire data centers.</p>\n<p>Compaction improves query performance and reduces storage consumption by 1) sorting inputs together and 2)aggregating multiple updates to the same rows. Since the delta files are individually sorted, compaction is essentially merge sorting. It is intentionally kept large during compaction so that the height of the merge tree is small, thus minimizing key comparisions.</p>\n<p>Robust query serving performance<br>query serving subsystem achieves robust performance, using Queryable Timestamp(QT), materialized views, and a range of other techniques.</p>\n<ol>\n<li>Reducing data in the critical path<br>Whenever possible, Napa uses views to answer a query instead of the base table, since views with aggregation functions may have significantly less data. Nap maintains sparse B-tree indexes on its stored data, and uses them to quickly partition an input query ito thousands of subqueries that satisfy the filter predicates. This partitioning mechanism additionally looks at the latency budget and availability of query serviing resources to achieve good performance.</li>\n</ol>\n<blockquote>\n<p>增加 Figure7</p>\n</blockquote>\n<ol>\n<li>Minimizing Number of Sequential I/Os<br>When a query is issued, Napa uses the value of QT to decide the version of metadata to be processed. The metadata in turns determines what data has to be process. Therefore, mateadata reads are on the critical path of query serving. Nap aensures all metadata can always be served from memory without contacting the persistent storage. This is achieved by affinity-based distributed metadata caching with periodic background refresheds. A particular QT is delayed to wait for the completion of periodic background refresh of metadata.</li>\n</ol>\n<p>Napa performs offline and online prefetching to further reduce the number of sequential I/Os in the critical path. Offline prefetching occurs as soon as data is ingested for frequently queried tables, before QT advances to make the new data available to query. Online prefetching starts when a query arrives and is performed by a shadow query executor which shares the data access pattern with the main query executor but skips all query processing steps.(like dry run?)</p>\n<ol>\n<li>Combining Small I/Os<br>During query serving, Napa aggressively parallelizes the work by partitioning the query into fine grained units and then parallelizing I/O calls across deltas and across queried columns. To combat such amplification on tail letency, Napa uses QT to limit the number of queryable deltas. In addition, Napa also tries to combine small I/Os as much as possible, by using the fowlling two techniques: lazy merging across deltas and size-based disk layout.</li>\n</ol>\n<ul>\n<li>lazy mering across deltas: When there are thousands(N) of subqueries and serval tens(M) of deltas, the number of parallel I/Os are in the order of tens of thousands(N <em> M). However, due to the parallelism each subquery reads very little data from most deltas. Meanwhile, a large fraction of Napa queries require merging based on a subset of primary keys in the subsequent phase of the query plan. In these cases, Napa adapts the query plan to avoid cross-delta merging in Delta Server and lets each Delta Server only process one delta, combining N </em> M parallel I/Ss into close to N parallel I/Os （merge 的数据尽量不跨 delta server？）</li>\n<li>size-based disk layout: Napa uses a custom-built columnar storage format supporting multiple disk layout options, which are applied based on delta sizes. The PAX layout which can combine all column accesses into one I/O for lookup queries, is applied to small dltas. For large deltas, column-by-column layout is used that is I/O efficient for san queries but requires one I/O per column for lookup queries. This size-based choice ensures that Napa receives columnar storage benefits as well as reduces I/O operations.（基于大小选择不同的磁盘布局，PAX 作为小的布局，可以一次 IO 读取完毕，大文件则是按列存放，这样每一列需要一个 IO 但是 scan 更友好</li>\n</ul>\n<ol>\n<li>Tolerating tails and failures<br>Napa adopts the principle of tolerating tail latency, rather than eliminating it, because eliminating all soruces of variability for such a complex and interdependent system is infeasible.</li>\n</ol>\n<p>For a non-streaming RPC, such as the RPC between Metadata Server and Delta Server, Napa uses the machnism of <em>hedging</em>, which sends a secondary RPC identical to the original one to a different server after a certain delay, and waits for the faster reply.<br>For a streaming RPC, such as the RPC between F1 worker and Delta Server, Napa estimates its expected progress rate and requires the server executing it periodically to report progress, together with a <em>continuation</em> token. If the reported progress is below expectation or the report is missing, the last continuation token would be used to restart a new streaming RPC on a different server without losing progress. Pushdown operators like filtering and partial aggregation need to be carefully handled in progress reporting as they can significantly reduce the data size, causing progress reports to be superficially low or even missing. Napa uses bytes processed before filtering and partial aggregation as the progress rate metric and periodically forces these operators to flushes its internal state to generate a progress report with a continuation token.</p>\n<p>Production metrics insights<br>Napa manages thousands of tables and views in production, where many tables are petabyte scale. It serves over a billion queries per day and ingests trillions of rows. Napa is able to provide robust query performance through three techniques: 1) by more actively using views, Napa reduces raw query performance and variance even at 99th percentile, 2) by chaning storage policies, Napa can reduce the number of deltas and hence the tail latency, and 3) by decoupling ingesting, view maintenance, and query execution; Napa can mitigate the impact of infrastructure and workload changes on query performance.</p>\n<ol>\n<li>Views and QT Help achive robust query performance<br>First, most client queries are aggregation queries, and materialized views are typically at least an order of magnitude smaller than the base tables from which they are derived. Reading from views not only improves raw performance, but also improves tail latency as their smaller size is more cache friendly, and requires less compute resources, which reduces the change of continetion for query resources.</li>\n</ol>\n<blockquote>\n<p>Add the figure for #views with the query latency</p>\n</blockquote>\n<p>Second, latency can be improved by reducing the number of deltas that have to be opend, read, and merged at query time.（相当于文件数量？）</p>\n<blockquote>\n<p>Add the figure for #deltas with the query latency</p>\n</blockquote>\n<p>Figure 8(b) shows that as we change storage policies to reduce the number of deltas, the query latency improves significantly. The biggest impact is at the 99th percentile latency which reduces by more than 3.6x as the number of deltas is changed from 8 to 2. The main reasons are: 1) fewer deltas means there are less number of small, parallel IOs which are prone to cause latency tails, 2) fewer deltas also means that data is premerged and aggregated, and less processing is required at query time.（这个类似 MOR 中，文件数量少，则 IO 少，而且读取的时候需要进行的聚合计算也少）</p>\n<ol>\n<li><p>Handling infrastructure issues</p>\n<blockquote>\n<p>Add figure 9<br>Figure 9 shows that Napa is able to guarantee its client stable query performance even when the ingestion load changes or there are infrastructure outages.  Napa decouples ingestion from view maintenance and querying which allows us to optimize for low variance in query latency, in some cases by trading off data freshness. Figure 9(a) shows that the client continuously sends data to Napa, with some variance in the input rate over the course of the week. Figure 9(b) shows that the view maintennace performance dropped for the duration between X and Y indicating an infrastructure issue which affected the tasks updating views. However, the query serving latency remains near constant (Figure 9(d)) throughout the whole duration. In this particular example, client queries continued to be fast, however , for certain parts during the outage data freshness was impacted, as seen in Figure 9(c) where the value of delay is high. 就算 view 的维护因为基建受影响了，那么不影响写入和读取的性能，但是能读到的数据的新鲜度会受影响</p>\n</blockquote>\n</li>\n<li><p>Client workloads<br>支持不同的 tradeoff，比如 [Client A: Tradoff freshness] wants moderate query performance and low costs, but can tolerate lower freshness.<br>[Client B: Tradeoff query performance] cares the most about low costs but can tolerate lower query performance<br>[Client C Tradeoff costs] has high freshness and high query performance requirements, and is willing to pay high costs to achieve them.</p>\n<blockquote>\n<p>Add figure 10 for different workloads</p>\n</blockquote>\n</li>\n</ol>\n<p>Napa is a fully indexed system that is optimized for key lookups, range scans, and efficient incremental maintenance of indexes on tables and views. Napa can easily support both adhoc queries and highly selective and less diverse queries.</p>\n<p>Napa uses a varaint of B+-trees that exploits the fact that Napa tables have multi-part keys. Additionally, min/max keys(per-column min/max values) are stored along with each non-leaf block to eanble effective pruning. LSM adapt B-tree indexes for high update rates. Napa belongs to a class of  LSM systems that trade high write throughput for fast reads. (看起来是 LSM 和 B-tree 的结合）</p>\n<h1 id=\"2023-Progressive-Partitioning-for-Parallelized-Query-Execution-in-Google’s-Napa\"><a href=\"#2023-Progressive-Partitioning-for-Parallelized-Query-Execution-in-Google’s-Napa\" class=\"headerlink\" title=\"2023-Progressive Partitioning for Parallelized Query Execution in Google’s Napa\"></a>2023-Progressive Partitioning for Parallelized Query Execution in Google’s Napa</h1><p>Napa holds Google’s critical data warehouses in log-structured merge trees for real-time data ingestion and sub-second response for billions of queries per day. These queries are foten multi-key look-ups in highly skewed tables and indexes.</p>\n<p>In our production experience, only progressive query-specific partitioning can achieve Napa’s strict query latency SLOs.  Here we advocate good-enough partitioning that keeps the per-query partitioning time low without risking uneven work distribution. Our design combines pragmatic system choices and algorithmic innovations. For instance, B-trees are augmented with statistics of key distributions, thus serving the dual purpose of aiding lookups and partitioning. Furthermore, progressive partitioning is designed to be “good enough” thereby balancing partitioning time with performance. The resulting system is robust and successfully serves day-in-day-out billions of queries with very high quality of service forming a core infrastructure at Google</p>\n<p>Napa’s diverse query workload consists of large scans and many-key lookups. The analytical queries with many-key lookups have strict QoS requirements and is the main focus of this paper.</p>\n<p>From our experience in running production services, we found the following three requirements important:</p>\n<ul>\n<li>Query-specific partitioning. Any approach that we take should meet the latency SLOs across a diverse set of query workloads. In our experience, the partitioning granularity needs to be adjusted on a per-query basis to meet the latency and resource budget requirements. The expectation from the partitioning step is that it is able to produce number of partitions denoted by the parallelization requirement within bounded amount of error.</li>\n<li>Evenness. Execution involves the partitioning of the tables into key ranges such that the partitioning results in even partitions. Partitioning should operate on tables with extreme skews where some keys span terabytes in disk. As an example, in Figure 1, a key range like &lt; K1 = 1, K2 = 20 &gt; may correspond to, say, a hundred GB portion of the table while another key range may be considerably smaller at a few MB.</li>\n<li>Progressiveness. Query partitioning must balance overall execution time against the time and effort to produce query-specific partitions. For instance, one can produce perfectly even partiions while still ending up missing the QoS requirement. It is imperative that the partitioning method has the notion of “good enough” in the sense that it stops when the partitioing is the sufficient quality. Our porposed technique in hte paper is progressive such that 1) the longer the alogirhtm runs the better the quality of the resultant partitioning; 2) the algorithm stops once the desired error bound has been met.</li>\n</ul>\n<p>Our experimental results show that the use of statistics that is too find-grained can often result in queries spending too much time generating partitioning at the expense of overall query execution time.</p>\n<p>We address this dilemma by leveraging B-trees to optimize access to the statistical information on the tables. Each LSM run has an associated B-tree index which are enhanced so that index nodes maintain size information for the associated key ranges. With these enhancements, we can estimate the input data size of the query starting with the root of the B-tree. If this estimation is not accurate enought or if the statistics point to areas of skews, we can descend to the next level in the index structure to obtain a finer level of statistical distributions for the key ranges overlapping with the query.</p>\n<p>Our proposed algorithm traverses the B-tree to produce even and query-specific partitioning. It is progressvie in the sense that it descends and accesses additional index information only if it does not satisfy the stipulated error bounds. In addition, the refinement is selective that it only descends to the lower levels of trees for those partitions that do not have gight enough bounds on the error.</p>\n<p>The following key aspects of Napa are the bedrock principles of its design and are aligned with our client requirements: i) Robust Qury Performance: Napa clients expect low query latency, typically sub-seconds, as well as low variance in latency under a wide spectrum of query and data ingestion load; ii) System Flexibility: While performance is important, our clients also require the flexibility to change system configurations to their dynamic requirements such as trading freshness or recency of ingested data for better performance; iii) High-throughput Data Ingestion: Napa’s ingestion, storage and query serving functions performan udner a massive update load.</p>\n<p>A Napa table consists of multiple data sets called deltas(corresponding to sorted runs of an LSM-tree) and we have one B-tree index for each delta. Not that each delta corresponds to updates on a table during a time window(e.g., last 1 minute, 1 day etc.).</p>\n<p>Progressive partitioning using B-tree: The B-trees on the deltas are fairly generic except that it hierarchically stores statistics of the underlying data. In particular, we store the number of rows that is indexed by each sub-tree and aggregate that statistics up the level. The partitioning algorithm we propose in the paper takes queried keys as input, retrieves and merges relevant keys taken from these B-tree indices, to generate an approximate histogram. Starting with the highest level histograms (i.e., the B-tree root index blocks), it tries to find accurate enough paritions. If it needs more detailed information, the algorithm will retrieve requried index blocks from the next highest level, repeating this trial and retrieve until it reaches the desired accuracy.</p>\n<p>LSM 让 partition 变的更复杂<br>The LSM data model complicates the task of query-specific partitioning in the following ways.</p>\n<ul>\n<li>First, the keys specified in the query may be present in may(possibly all) of the deltas. Note that the same query worker must process all deltas where the keys are present in order to reconcile all relevant version.</li>\n<li>Second, this proves to be a serious challenge for the evenness of the partitioning since some deltas may contribute many more matched rows than others.</li>\n<li>Third, a query may involve seeking across multiple deltas and not all deltasequally contribute to the query. Thus, the paritioning effort may not be uniform across the deltas. For some deltas, it may be sufficient to perform coarser partitioning while others require significantly more effort in producing equal splits.</li>\n</ul>\n<p>Why rely on progressive query-specific partitioning?<br>The ideal partitioning unit size can vary from 10MB(e.g., when reading 1GB data using 100 scan workers) to 1GB(e.g., when reading 1TB data using 1000 scan workers) on a per-query basis.<br>The next complexity here is that it is possible that there is one particular “Date = d3”, which accounts for most of the data to be scanned in a query. So, that means that we need to partition the range <c1, d3>, <c2, d3> and <c3, d3> much more finely than the other key ranges. This means the partitioning algorithm needs to be progressive such that it can stop early on other dates and focus on generating finer grained partitions for “Date = d3”<br>Standard write-time partitioning mechanisms are not able to address the requirements discussed above.</p>\n<p>Partitioning is highly specific to query under consideration and existing write-time partitioning is inadequate for workloads with a wide spectrum of query workloads. We have also established that one needs a way of producing both fine and coarse grained partitions even on the same key range, based on the query predicates, latency target and resource budget.</p>\n<p>Progressive partitioning<br>The progressive query-specific partitioning algorithm using <em>size-enhanced</em> B-trees. Our solution is to enhance typical B-trees with the statistics on data size in a hierarchical manner. For each delta, we maintain a B-tree pointing to data blocks, e.g. a block in the PAX layout. The index not only helps a query to efficiently seek on data using prefix keys but also provides statistical information for partitioning. Both querying and query-specific partitioning traverse the B-tree. The querying traverses the B-tree through the leaf level to visit dat ablocks. The query-specific partitioning does not visit data blocks and visits the index node at the leaf level only when required for finding “good enough” partitions as we describe below.</p>\n<blockquote>\n<p>使用 size-enhanced B-Tree，对于每一个 delta 都维护一个 B-tree 指向 data blocks，这样可以提供前缀查询，以及统计信息等</p>\n</blockquote>\n<p>For a given query Q, the algorithm divides D deltas into P key range partitions that are nearly even with an error margin of \\{thelta}. Each delta has a size-enhanced B-tree, which carries keys and the size of data between these keys. We analyze the estimated size of matching data by combining keys and sizes from D indices. To get the most precise matching estimate from B-trees, we may need to visit the leaf index entries matching with the query. 但是读所有的 leaf 会很耗时，另外一种方式就是通过 root 来推测 partition 的数量，这是两个极端，文中从中间进行选择：从 root 开始，然后仅在需要下一层提供更多信息的时候才进行继续读取。</p>\n<p>文中有一个具体的例子</p>\n<blockquote>\n<p>补充 fig 4 和 fig 5</p>\n</blockquote>\n<p>其中两个 Delta，然后希望分成两个 partition（分 parition 是希望能够并行处理），然后考虑第一层的时候（从 B-tree 获得信息），Delta 1 的 [K1, K3) 有 15 个，[K4, K8) 有 20 个； Delta 2 的 [K2, K5) 有 20 个，[K6, K7) 15 个。</p>\n<p>那么把所有的数目都加在一起就是 15 +  20 + 20 + 15 = 70 个，然后会选择在 K4 和 K5 这里做分割，这样会把 [K4, K8) 和 [K2, K5) 做一些分割，然后对于第一个 partition 来说，大小可能是 15（也就是 [K2, K5) 的倾斜全在右侧，[K4, K8) 也倾斜），同样最大可能是 15+20+20 = 55,那么估算这个大小是 (15 + 55) / 2 = 35，然后 size margin = 55 -15 = 40,同样第二个 partition 类似，得到估算大小是 35, size margin 是 40,如果 (40/35, 40/35) — 两个 parititon 的误差 — 能满足 \\{theata} 那么就按照这么切分，如果不行，就对 B-Tree 进行下一层读取，然后再进一步进行划分</p>\n<blockquote>\n<p>We represent this size-embedded index entry in a B-tree index node as e = <start, end, size, level, block>, which corresponds to the key range [e.start, e.end) having the estimated size e.size. The entry e is in a index block at tree level e.level(the value of 0 for e.level corresponds to the leaf level). Finally, e.block is a pointer to the child index block having range [e.start, e.end) (if e.level &gt; 0)</p>\n<p>根据和 Gemini 的沟通，大概理解 Napa 的存储结构如下<br>首先是 LSM Tree，然后每个 SSTable 是一个 B-tree，B-tree 就是文中的 Delta，B-tree 中包括多个实际的文件，以及对应的索引，然后渐进式则是「够用」就好，— 「够用」是满足对应的误差</p>\n</blockquote>\n<h1 id=\"SQL-Has-Problems\"><a href=\"#SQL-Has-Problems\" class=\"headerlink\" title=\"SQL Has Problems\"></a>SQL Has Problems</h1><p>文章描述了 SQL 是一个很好的抽象，但是学习和维护不方便，重新造一个类似 SQL 的语言又很麻烦，所以有了 PipelinedSQL 这个渐进式改进的方案。</p>\n<blockquote>\n<p>SQL is not an easy language to learn or use. Even for expert users, SQL is challenging to read, write and work with, which hurts user productivity. Serveral alternative languages have been prposed, but none have gained widespread adoption or displaced SQL. Migrating away from existing SQL ecosystems is expensive and generally unappealing for users.</p>\n</blockquote>\n<p>Piplined SQL 可以让 SQL 更好用，更具扩展性（more flexible, extensible and easy to use). </p>\n<p>In SQL, the standard clauses occur in one rigidly defined order. Expressing anything else requires subqueries or other workarounds. With Pipelined SQL operationcan be composed arbitrarily, in any order.</p>\n<p>给了两个例子<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span> c_count, <span class=\"built_in\">COUNT</span>(<span class=\"operator\">*</span>) <span class=\"keyword\">AS</span> custdist</span><br><span class=\"line\"><span class=\"keyword\">FROM</span></span><br><span class=\"line\">  (<span class=\"keyword\">SELECT</span> c_custkey, <span class=\"built_in\">COUNT</span>(o_orderkey) c_count</span><br><span class=\"line\">   <span class=\"keyword\">FROM</span> customer</span><br><span class=\"line\">   <span class=\"keyword\">LEFT</span> <span class=\"keyword\">OUTER</span> <span class=\"keyword\">JOIN</span> orders <span class=\"keyword\">ON</span> c_custkey <span class=\"operator\">=</span> o_custkey</span><br><span class=\"line\">        <span class=\"keyword\">AND</span> o_comment <span class=\"keyword\">NOT</span> <span class=\"keyword\">LIKE</span> <span class=\"string\">&#x27;%unusual%packages%&#x27;</span></span><br><span class=\"line\">   <span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> c_custkey</span><br><span class=\"line\">  ) <span class=\"keyword\">AS</span> c_orders</span><br><span class=\"line\"><span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> c_count</span><br><span class=\"line\"><span class=\"keyword\">ORDER</span> <span class=\"keyword\">BY</span> custdist <span class=\"keyword\">DESC</span>, c_count <span class=\"keyword\">DESC</span>;</span><br></pre></td></tr></table></figure></p>\n<p>然后<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM customer</span><br><span class=\"line\">|&gt; LEFT OUTER JOIN orders ON c_custkey = o_custkey</span><br><span class=\"line\">     AND o_comment NOT LIKE &#x27;%unusual%packages%&#x27;</span><br><span class=\"line\">|&gt; AGGREGATE COUNT(o_orderkey) c_count</span><br><span class=\"line\">   GROUP BY c_custkey</span><br><span class=\"line\">|&gt; AGGREGATE COUNT(*) AS custdist</span><br><span class=\"line\">   GROUP BY c_count</span><br><span class=\"line\">|&gt; ORDER BY custdist DESC, c_count DESC;</span><br></pre></td></tr></table></figure></p>\n<p>有讲 SQL 和 PipelinedSQL 的语义情况<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202512161155193.png\" alt=\"\"></p>\n<p>觉得 SQL 不错，那么就修复</p>\n<ul>\n<li>SQL’s foundational semantics, from relational algebra, are excellent</li>\n<li>SQL’s conceptual data model and top-level syntax, with statements representting requires, DDL, DML, etc, and composability via subqueries, works weel.</li>\n<li>SQL’s basic operations within a query(clauses like JOIN, ORDER BY, etc) all work reasonably well</li>\n<li>SQL’s syntactic structure for composing queries using those operations is <strong>terrible</strong>.</li>\n<li>SQL’ls localized syntax with English-like keyword phrases is and anachronism, but we can live with it.</li>\n<li>SQL’s expression language is fine, and implementations typically includes a good library of existing functions.</li>\n</ul>\n<p>所以只需要修复第四点中的问题就行</p>\n<p>pipelined SQL 使用 ‘|&gt;’ 这个 suffix 来衔接</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;query&gt; :=</span><br><span class=\"line\">  &#123;all existing query syntaxes&#125;</span><br><span class=\"line\">  | &quot;FROM&quot; &lt;from_body&gt;             -- New: FROM as a query</span><br><span class=\"line\">  | &lt;query&gt; &quot;|&gt;&quot; &lt;pipe_operator&gt;   -- New: pipe suffixes</span><br></pre></td></tr></table></figure>\n<p>论文中有具体算子的语法</p>\n<p>然后剩下的是一些更具体的细节，以及相关效果。<br>这个如果成熟之后，应该也可以更方便的推广拖拽式的表现形式（？），能够更好的一一对应起来<br>然后 ZetaSQL（已开源） 也有实现</p>\n<h1 id=\"Napa-1\"><a href=\"#Napa-1\" class=\"headerlink\" title=\"Napa\"></a>Napa</h1><h1 id=\"BigLake\"><a href=\"#BigLake\" class=\"headerlink\" title=\"BigLake\"></a>BigLake</h1><h1 id=\"Procella\"><a href=\"#Procella\" class=\"headerlink\" title=\"Procella\"></a>Procella</h1><blockquote>\n<p>These can be categorized as: reporting and dashboarding, embedded statistics in pages, time-series monitoring, and ad-hoc analysis. Typically, organizations build specialized infrastructure for each of these use cases. This however, creates silos of data and processing, and results in a complex, expensive, and harder to maintain infrastructure.<br>At YouTube, we solved this problem by building a new SQL query engine — Procella.</p>\n</blockquote>\n<p>These workloads have differenet set of requirements:</p>\n<ul>\n<li>Reporting and dashboarding: Video creators, content owners, and various internal stakeholders at YouTube need access to detailed real time dashboards to understand how their videos and channels are performing. This requieres an engine that supports executing tens of thousands of canned queries per second with low latency (tens of milliseconds), while queries may be using filters, aggregations, set operations and joins. The unique challenge here is that while our data volumen is high (each data source often contains hundreds of billions of new rows per day), we require near real-time respoinse time and access to fresh data.</li>\n<li>Embedded statistics: YouTube exposes many realtime statistics to users, such as likes or views of a video, resulting in simple but every high cardinality queries. These values are constantly changin, so the system must support millions of e real-time updates concurrently with millions of low latency queries per second.</li>\n<li>Monitoring: Monitoring workloads shrae many properties with the dashboarding workload, such as relatively simple canned queries and need for fresh data. The query volumne is often lower since monitoring is typically used internally by engineers. However, there is a need for aditional data management functions, such as automatic downsampling and expiry of old data, and additional query features (for example, efficient approximation functions and additional time-series functions)</li>\n<li>Ad-hoc analysis: Various YouTube teams (data scientists, business analysts, product managers, engineers) need to perform complex ad-hoc analysis to understand usage trends and to determine how to improve the product. This requires low volume of queries(at most tens per second) and moderate latency (second to minutes) of complex queries (multiple levels of aggregations, set operations, analytic functions, joins, unpredcatable patterns, manipulating nested/repeated data, etc.) over enormous volumes(trillions of rows) of data. Query patterns are highly unpredictable, although some standard data modeling techniques, such as star and snowflake schemas, can be used.</li>\n</ul>\n<p>独立系统的问题</p>\n<ul>\n<li>Data needed to be loaded into multiple systems using different Extract, Transform, and Load(ETL) processes, leading to significant additional resource consumption, data quality issues, data inconsistencies, slower loading times, high development and maintenance cost, and slower time-to-market.</li>\n<li>Since each internal system uses different languages and API’s, migrating data across these systems, to enable the utilization of existing tools, resulted in reduced usability and high learning costs. In particular since many of these systems do not support full SQL, some applications could not be built by using some backends, leading to data duplication and accessibility issues across the organization.</li>\n<li>Several of the underlying componenets had performance, scalability and efficiency issues when dealing with data at YouTube scale.</li>\n</ul>\n<p>Procella 的特性</p>\n<ul>\n<li>Rich API: Procella supports an almost complete implementation of standard SQL, including complex multistage joins, analytic functions and set operations, with serveral useful extensions such as approximate aggregations, ahdnling complex nested and repeated schemas, user defined functions, and more.</li>\n<li>High Scalability: Procella separates compute (running on Bord) and storage (on Colussus) enabling high scalability (thousands of servers, hundreds of petabytes of data) in a cost efficient way.</li>\n<li>High Performance: Procella uses state-of-the-art query execution techniques to eanble efficient execution of high volumen(millions of QPS) of queries with very low latency (milliseconds).</li>\n<li>Data Freshness; Procella supports high volume, low latency data ingestion in both batch and streaming modes, the ability to work directly on existing data, and native support for lambda architecture.</li>\n</ul>\n<blockquote>\n<p>Procella System Architecture</p>\n</blockquote>\n<p>Procellas 的数据按照 table 进行划分，每个 table 会有多个文件/分区。Procella 使用自己的列存 Artus，也支持其他的 file format，存在 Colossus 中，这样可以存算分离</p>\n<p>Procellas 没有使用 BTree 而是使用了更轻量级的 zonemaps, bloom filters, partition 以及 sort key 等这些二级索引，这些从文件头，或者 plan 时从 data server 获取，schema, table to file mapping, stats, 以及 zonemap 等这些存储在 BigTable/Spanner 中</p>\n<p>支持标准的 SQL 操作，支持 batch ingestion 和 streaming ingestion<br>在 batch ingestion 的时候，可以根据 file header 获取，更耗时的元数据抽取会延迟处理；streaming ingestion 支持 RPC/PubSub 的方式，然后 Ingestion Server 转换为表的形式</p>\n<p>然后会有后台线程周期性进行合并操作</p>\n<p>Query lifecycle<br>Clients connect to the Root Server(RS) to issue SQL queries. The RS performs query rewrites, parsing, planning and optimizations to generate the execution plan. To this end, ti uses metadata such as schema, partitioning and index infromation from the Metadata Server(MDS) to prune the files to be read. It then orchestrates the query execution as it goes through the different stages enforcing timeing/data dependencies and throttling. To address the needs of executing complex distributed query plans(timeing/ data dependencies, diverse join strategies, etc.), the RS builds a tree composed of query blocs as nodes and data streams as edges (Aggregate, Execute Remotely, Stagger Execution, etc. ) and executes it accordingly. This enables functionality such as shuffle (that requires timing dependency), uncorrelated subquery, subquery broadcast joins(data dependency) and multi-level aggregation. THis graph structure allows several optimizations by inserting custom operations into the tree based on query structure. Once the RS receives the final results, it sends the respoinse back to the client, along with statistics, error and warning messages, and any other information requested by the client.</p>\n<p>The Data Sever(DS) receives plan fragments from the RS or another DS and does most fo the heavy lifting, such as reading the required data (from local memory, remote and distributed files in Colossus, remote memory using RDMA,  or another DS), executing the plan fragment and sending the results back to the requesting RS or DS.</p>\n<p>优化</p>\n<ul>\n<li>Cache<ul>\n<li>Colossus metadata caching  可以减少一次或多次文件打开的开销</li>\n<li>Header caching  文件头(尾）有 start offset，column size，minimum and maximum 值，缓存这些可以减少更多的文件访问（单独的 LRU）</li>\n<li>Data caching, DS 使用单独的 cache 缓存文件，列存 Artus 设计成 disk 和 memory 的 format 一致，这样可以让 cache 更友好(making cache population fairly cheap)，同时也缓存一些二级数据（比如bloom filter 等）</li>\n<li>metadata caching: metadata 存在 bigtable 这样的分布式文件系统中，访问多可能会导致有瓶颈，因此用 LRU 来 cache </li>\n<li>Affinity scheduling: Caches are more effective when each server caches a subset of the data. Procella implements affinity scheduling to the data servers and the metadata servers to ensure that operations on the same data/metadata go to the same serve with high probability. 这样每个 server 只负责一部分数据，cache 有效性也变高. 但这个不是强约束，也就是说可能被调度到其他的 server — 这样只是性能变差（cache 无效）。</li>\n</ul>\n</li>\n<li>Data Format<ul>\n<li>一开始使用 Capacitor，但是它主要是 Ad-hoc 中使用（主要是 scan 性能），Procella 需要 lookup 和 range scan，所以开发了 Artus</li>\n<li>使用自定义的 encoding。Uses custom encodings, avoiding generic compression algorithms like LZW. This ensures that it can seek to single rows efficiently without needing to decompress blocks of data, making it more suitable for small point lookups and range scans.<ul>\n<li>Does multi-pass adaptive encoding: 第一次收集轻量级信息（ndv, min, max, sort order 等），然后使用这些去选择更合适的 encoding</li>\n<li>选择对 sorted column 支持 binary search 的 encoding</li>\n<li>嵌套字段的处理和 parquet 不一样，把表的 schema 当成 tree，每个字段都存在为独立的列, 针对每个父字段（如果自己本身存在的话），会记录所有子字段出现的次数，对于可选字段，该值是 0 或者 1,重复字段该值为非负。但是不记录父子段不存在的信息  </li>\n<li>Directly exposes dictionary indices, Run Length Encoding information, and other encoding information to the evaluation engine.</li>\n<li>Records rich metadata in the file and column header.</li>\n<li>Supports storing inverted inddexes. — 搜索场景有用</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>支持 multi-level partitioning and clustering</p>\n<p>Join 的类型</p>\n<ul>\n<li>Broadcast： 一方足够小可以加载到 DS 的内存。</li>\n<li>Co-partitioned: fact 和 dim 可以使用同样的 key 进行 partition</li>\n<li>Shuffle：数据太大，然后没有按照 join key 排序，就进行 shuffle</li>\n<li>Pipelined: RHS 是负责查询，但是结果可能比较小的时候</li>\n<li>Remote lookup: dim table 是分区的，但是 fact 没有</li>\n</ul>\n<p>怎么解决 tail latency</p>\n<ul>\n<li>因为数据有备份，所以如果某个数据节点的访问延迟超过了中位数(median)，就访问其他的节点 </li>\n<li>RS 会控制访问同一个 DS 的频率，批次等</li>\n<li>RS 会给每个请求附带一个优先级，通常来说小查询的优先级更高，大查询的优先级更低。DS 为高优和低优的分别分配资源，这样可以保证小查询的快速响应— 不会被大查询 block</li>\n</ul>\n<p>Intermediate merging</p>\n<ul>\n<li>对于很重的聚合，最后的聚合可能会成为瓶颈 — 需要在单机点操作很多数据。为了避免这个，添加中间节点用来做中间的聚合。</li>\n</ul>\n<p>Query Optimization</p>\n<ul>\n<li>Virtual Tables 类似 MV<ul>\n<li>Index-aware aggreagte selection</li>\n<li>Stitched queries</li>\n<li>Lambda architecture awareness</li>\n<li>Join awareness</li>\n</ul>\n</li>\n</ul>\n<p>Query Optimizer<br>使用静态和动态的查询优化技术 (makes use of static and adaptive query optimization techniques) At query compile time we use a rule based optimizer that applies standard logical rewrites (always benefical) such as filter push down, subquery decorrelation, constant folding, etc. At query execution time we use adaptive techniques to select/tune physical operators based on statistics (cardinality, distinct count, quantiles) collected on a smaple of the actual data used in the query.</p>\n<ul>\n<li>Adaptive Aggregation</li>\n<li>Adaptive Join</li>\n<li>Adaptive sorting</li>\n</ul>\n<p>Adaptive 的不足：需要动态收集信息，可能导致短查询耗时更久（比如 10ms 左右的可能变成原来的数倍），这种可以让用户给定 hint 不走 adaptive optimization，另外用户愿意接受短查询变长，换来大查询的耗时变短（overhead 可能有 10% 左右）</p>\n<p>针对 serving 做优化处理</p>\n<ul>\n<li>数据写入后，会立即通知 dataserver 进行加载，这样可以避免冷读</li>\n<li>MDS 编译进 Root Server，可以减少 RPC 交互</li>\n<li>metadta 提前加载到内存，避免查询的时候加载 metadata</li>\n<li>query plans are aggressively cached to eliminate parsing and planning overhead.  This is very effective since the stats query patterns are highly predicatble.</li>\n<li>The RS batchs all request for the same key and sends them to a single pair of primary and secondary data servers.</li>\n<li>The problematic outlier tasks are automatically moved to other machines.</li>\n</ul>\n<h1 id=\"Vortex\"><a href=\"#Vortex\" class=\"headerlink\" title=\"Vortex\"></a>Vortex</h1><blockquote>\n<p>Vortex: A Stream-oriented Storage Engine For Big Data Analytics</p>\n</blockquote>\n<p>Vortex is a streaming-first storage system that supports both streaming and batch data analytics. Today, BigQuery uses Vortex to support petabyte scale data ingestion with sub-second data freshness and query latency.</p>\n<p>Vortex has the following key properties:</p>\n<ul>\n<li>Consistent: Guaranteees ACID properties for all API operations.</li>\n<li>Unified API for batch and streaming: Vortex offers a single unified API with support for both streaming and batch data.</li>\n<li>Scalable: Vortex implements a fully distributed data and control plane and as a result supports tables of multiple petabytes size.</li>\n<li>Performant: The Vortex API offers sub-second tail write latencies that simplify client side application programming.</li>\n</ul>\n<p>BigQuery storage provides a global namespace over all data in BigQuery. Data is organized into regional containers called datasets(analogous to schemata in traditional database management systems). Tables, logical views, metarialized views, search indexes, stored procedures, machine learning models etc. all reside in a dataset.</p>\n<p>Vortex is BigQuery’s scalable, distributed and synchronnously replicated storage engine that supports data ingestion, retrieval and curation.</p>\n<p>A Vortex Stream is an entity to which rows can be appended to the current end. Each row in a Vortex Stream is identified by the Stream’s identifier and its row offset within the Stream. Readers can concurrently read a Stream at different row offsets. A table is an unordered collection of Stream.</p>\n<blockquote>\n<p>Stream 有点像传统说的文件，比如 Parquet File？但是应该还不一样，毕竟还有 ColumnFormat</p>\n</blockquote>\n<p>Streams are backed by the following entities</p>\n<ul>\n<li><p>Streamlets Vortex Streams provide durable sotrage of data. A Streamlet is a contiguous slice of rows in the Stream, all of which are present in the same 2 clusters. A Stream is an ordered list of one or more Streamlets. Given the Stream’s append-only semantics, a Stream has at most one writable Streamlet. The writable Streamlet, if one exists, is always the last Streamlet in a Stream.</p>\n</li>\n<li><p>Fragments: Each Streamlet is further split into contiguous blocks of rows called Fragments. Fragments typically are a range of rows inside a log file. Log files are stored in Colossus.</p>\n<blockquote>\n<p>Streamlets 和 Fragments 是 写入端的概念，还是类似表级别的概念<br>Streamlets and Fragments are internal physical metadata entities; they aren’t visible to the users of Vortex.</p>\n</blockquote>\n</li>\n<li>Data formats: BigQuery operates broadly with data in two different classes of data formats. The write-optimized storage format(WOS) is the format in which data is written by Vortex’s append API, The read-optimized storage format(ROS) is the format in which data is optimized for dat aprocessing.<br>BigQuery use Capacitor as ROS, BigLake use Parquet as ROS</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202512041721506.png\" alt=\"\"></p>\n<p>架构如上</p>\n<ul>\n<li><p>Stream Metadata Server(SMS) is the control plane of Vortex.<br>The SMS assigns a Streamlet to a specific Stream Server. THe Stream Server maintains the set of fragments for the Streamlet.</p>\n</li>\n<li><p>The Stream Server is the data plane of Vortex. It owns a set of STreamlets and creates Fragments for those Streamlets. The Stream Server has its own in memory metadata about its Streamlets and Fragments, and persists this by writing to a transaction log and periodically writing checkpoitns.<br>The Stream Server knows which Fragments belong to which Streamlet, their committed size, the minimum and maximum record timestamp in each Fragment, whether a Streamlet or Fragment is finalized, the schema version, and the partitioning and clustering columns of the table.</p>\n</li>\n</ul>\n<p>客户端通过 SMS 创建一个 Stream，SMS 会生成一个随机的 StreamId 然后 assign 到一个 Stream Server，Client 直接往 StreamServer 写数据，StreamServer 会周期性的通过心跳同步当前的数据。<br>Storage Optimization Service 会从 SMS 请求一批 Fragments 然后转为 ROS 的格式，然后把 Fragements 标记为 DELETED，再过一段时间之后，SMS 会通知 Stream Server 将过期的 Fragements 进行删除。</p>\n<p>Stream Server 到 SMS 的心跳只包含元数据（与上一次心跳的 Streamlet 的不同数据）</p>\n<ul>\n<li>Fragment File Format<blockquote>\n<p>Fragment 像是一个适合写入的文件格式（和 ROS 的 Parquet 对比）<br>Header 包括了同一个 Streamlet 中之前为删除的 Fragment，后面包括了 bloomfilter 以及其他 footer 信息<br>Each Fragment begins with a header which contains the File Map. The File Map lists the committed size and record ranges of all previous Fragments in the same Streamlet which have not yet been deleted. The File Map is used for disaster resilience.</p>\n</blockquote>\n</li>\n</ul>\n<p>When a Fragment is finalized, the Stream Server appends a bloom filter, followed by a fixed length footer which describes the offset in the Fragment where the bloom filter starts. The bloom filter marks which key values are present for the partitioning and clustering columns.</p>\n<p>The Fragment data format stores metadata records for FlushStream calls on BUFFERED streams. A flush operation is a metadata write to the Fragment which advances the committed row offset making all rows in the Streamlet(and the Stream) up to that point visible.</p>\n<p>Vortex uses an end-to-end CRC to protect row data as it is sent from the client to the Stream Server, and from the Stream Server to Colossus.</p>\n<p>Stream Server 会周期性（秒级）将 Streamlet 的变化同步给所有的 SMS，这些变化包括（新文件的创建，存量文件的写入，文件中的列属性）- 这个是 per-Streamlet 的，然后还有当前的 CPU，memory 以及 append throughput — 这个用来做负载均衡。</p>\n<blockquote>\n<p>A background service continuously optimizes data in Vortex as it is written. The goal ofStorage Optimization is to pitmize the format and layout of the data for large scale analysis. In doing so, it maintains an LSM tree of Fragments, starting with Fragments in WOS at the deepest level of the tree, with progressively more optimized ROS versions as we climb up the ree.<br>使用 LSM tree 管理 Fragments，然后从 deepset 将 WOS 的转换为 ROS 的格式</p>\n<p>To track the lifetime of Fragments, each Fragment maintains two timestamps: a <em>creation_timesatmp</em> and a <em>deletion_timestamp</em>.  A Fragment is visible to requests that read the table at a snapshot timestamp that is within the interval [creation_timestamp, deletion_timestamp). At each step of the optimization, the optimizer atomically sets the deletion_timestamp for the previous version of the fragments and the creation_timestamp for the new version. This guarantees that a row is included exactly once when reading the data from storage.<br>Fragment 可以有 creation_timestamp 和 deletion_timestamp，会自动给已经合并的 Fragment 赋值 deletion_timestamp（这个要保证事物）</p>\n</blockquote>\n<p><strong>Automatic Reclustering</strong>, BigQuery allows users to cluster the data in a table on a set of specified columns. Clustering defines a “weak” sort order on the data blocks in the table. In other words, BigQuery attempts to distribute the data such that the blocks store non-overlapping ranges of values for the clustering keys. Orgamizing data in non-overlapping ranges results in more efficient processing at read time, by improving parititon prunning and or by reducing intermediate data transferred between query processing stages.</p>\n<blockquote>\n<p>可以对数据进行重排序，而且可以做分布的排列，尽量做到不重叠，这样可以做到更好的 partition prunning<br>Once the delta(WOS) is sufficiently large, the optimizer first range partitions the delta locally.<br>如果 WOS 对读影响太多，就本地先合并, 形成一个新的 base<br>Figure 6 显示了一个 Automatic Reclustering 的具体例子, Base(ROS) + Delta(WOS) 可以合成新的 Base(ROS) </p>\n<p>Vortex continuously tracks metadata for Streams, Streamlets, and Fragments.<br>An example of coarse grained metadata is the state of a Streamlet that indicates whether the Streamlet is currently writable and its currentl  length. The source of truth for Streamlet is marked finalized. As the storage optimizer moves data between the layers in hte LSM tree, BigQuery’s highly scalable metadat management system, called BigMetadata</p>\n<p>There is a tail of the Fragment and Streamlet metadata that may have not yet been indexed by Big Metadata. As the metadat of these blocks churns rapidly, we observe that scanning through the list of these tail blocks that need to be read to satisfy the snapshot read, can add latency to query processing. To address this, we continuously compact the metadat entries for the Fragments by keeping the entries corresponding to the live fragments(i.e. fragments with deletion_timestamp unset) together in our log.<br>对元数据周期性做 compaction, 尽可能只保留 live fragment 的元数据</p>\n</blockquote>\n<p>Vortex 会周期性的做数据正确性验证(Vortex continuously traces requests to detect data correctness issues such as missing or duplicated records), Finally, we also verify that each record is reported as converted exactly once from WOS to ROS. Additionally, for each conversion, we validate that the output records are consistent tiwth the input records.</p>\n<p>When Vortex SMS receives this request(read), it returns the union of the data in WOS and ROS.</p>\n<p>Vortex allows a range of rows in a Fragment or Streamlet to be marked as deleted. To limit the size of these deletion masks, sometimes rows unaffected by the DML statement may also be marked deleted</p>\n<blockquote>\n<p>有点类似 pos delete？为了减少 pos delete 的数目，干脆把这重写？</p>\n</blockquote>\n<h1 id=\"BigMetadata\"><a href=\"#BigMetadata\" class=\"headerlink\" title=\"BigMetadata\"></a>BigMetadata</h1><p>主要想法</p>\n<ul>\n<li>使用类似系统表保存 metadata，这样可以横向扩展，而且可以使用 query engine 来处理 metadata 和 data</li>\n<li>提出了 falsifiable expression，可以改写 condition，从而大规模过滤数据</li>\n<li>metadata 可能很大，所以在读取的时候可以使用 falsifiable expression，减少读取 metadata 的数据量。<br>写一个 falsifiable expression 的例子<blockquote>\n<p>Traditionally, Big Data systems have tried to reduce the amount of metadata in order to scale the system, often compromising query performance. In Google BigQuery, we built a metadat management system that demonstrates that massive scale can be achived without such tradeoffs. We recognized the benefits that fine grained metadata provieds for query processing and we built a metadata system to manage it effictively. We use the same distributed query processing and data management techniques that we use for manageing data to handle Big metadata.</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>We present a distributed metadata management system that stores fine grained column and block level metadata for arbitrarily large tables and organizes it as a system table. We use a novel approach to process large amounts of metdata in these system tables by generating a query plan that integrates the meatdata scan into the actual data scan. In doing so, we leverage the same distributeddquery processing techniques that we use on our data to our metadat, thereby achieving performanct access to it along with high scalability. Our system has the following salient properties;</p>\n<ul>\n<li>Consistent</li>\n<li>Built for both batch and streaming APIs</li>\n<li>(Almost) INfinitely scalable: Our design is built for scale and it supports tables of multiple petabytes isze, and due to its distributed nature scales in a way similar to the underlying data</li>\n<li>Performance</li>\n</ul>\n</blockquote>\n<p>Most of the data in BigQuery is stored in columnar format blocks. Tables range from a few bytes to tens of petabytes. Large tables are stored in millions of columnar blocks. BigQuery supports tables with tens of thousands of columns. BigQuery maintains the entire mutation history of a table for a configurable amount of time in order to support queries on the table as of any timestamp in that history window</p>\n<p>We classify storage metadata into two broad categoreis: Logical metadata and Physical metadata.</p>\n<ul>\n<li>Logical metadata is information about the table that is generally directly visible to the user. Some examples of such metadata are: Table schema, Partitioning and clustering specifications, column and row level ACLs. This information is generally small in size and lends itself to quick access. </li>\n<li>Physical metadata is information about the table’s storage that BigQuery maintains internally in order to map a table name to its actual data.</li>\n</ul>\n<p>使用系统表来存储 physical metadata: To illustrate our idea, we describe the metadata layout using one such system table (hereafter referred to as CMETA) that stores column level information about the min/max values (called range constraints), hash bucket and modulus values (called hash constraints) and a dictionary of column values. Other variants of system tables include those that store posting lists of column values. Query optimizer chooses one or more such system tables for planning and executing the query</p>\n<p>每一列会有 totalRows/totalNulls/totalBytes/min/max/dictionary/bloom_filter 等信息</p>\n<p>Block 是 metadata 更新的最小单元</p>\n<p>metadata 有 changelog，记录 properties/timestamp 等</p>\n<p>A background process constantly performs LSM style merges on the change log to produce baselines and deltas of changes.</p>\n<p>Fine grained metadata for rows that have not yet been compacted into capacitor blocks is maintained in the memory of ingestion servers.</p>\n<p>BigMetadata 使用了一套 condition 重写的逻辑(falsifialbe expressions)，可以更好的进行过滤比如 x &gt; c =&gt; max(x) &lt;= c, x &lt; c =&gt; min(x) &gt;= c 等等</p>\n<p>metadata 可能会很大，所以也使用 falsiiable expression 进行读取</p>\n<p>文章说偏结论性的东西（自己理解），不要说太多细节</p>\n<ul>\n<li>细节别人可能不是太感兴趣</li>\n<li>纯细节不太能体现自己的东西</li>\n<li>可以在最后附加参考文献</li>\n</ul>\n<p>计算引擎的 execution plan 能否动态更新（根据数据的不同，动态的变动）</p>\n<ul>\n<li>Procella</li>\n</ul>\n<p>Procella 的 meta 是树形结构，而且不仅仅保存叶子节</p>\n<p>从上到下，结合 fdap（或者类似想法），就是组建做标准，系统搭积木</p>\n<p>parquet 可以有不错的性能（比如 Influxdata 的优化，以及 LiquidCache 的做法等），新的 FileFormat 需要的整体工作量还挺大的</p>\n<ul>\n<li>首先需要知道 parquet 的瓶颈（可以看新的 fileformat 的 PR 稿）</li>\n<li>parquet 的 ML 讨论（<a href=\"https://lists.apache.org/thread/8xmxc76nd00624qqps6s1qw6lhv1qwv5）/Influxdata\">https://lists.apache.org/thread/8xmxc76nd00624qqps6s1qw6lhv1qwv5）/Influxdata</a> 博客（<a href=\"https://www.influxdata.com/blog/how-good-parquet-wide-tables/）\">https://www.influxdata.com/blog/how-good-parquet-wide-tables/）</a></li>\n</ul>\n<p>引擎 bigquery</p>\n<ul>\n<li>用户端</li>\n<li>sql（可以优化 sql，包括 pipelined sql）</li>\n<li>dataframe</li>\n<li>其它（处理非结构化数据）</li>\n<li>然后 query engine</li>\n<li>plan 优化</li>\n<li>优雅的调度和停止等</li>\n<li>exection</li>\n<li>native（性能）</li>\n<li>分布式执行</li>\n<li>资源管理</li>\n<li>多类型资源统一管理</li>\n</ul>\n<p>table format</p>\n<ul>\n<li>catalog </li>\n<li>权限</li>\n<li>metadata</li>\n<li>索引（不同类型的索引）</li>\n<li>bigemetadata（sql 改写，下推，cache 等）</li>\n<li>file format</li>\n<li>结构化数据（主要是宽表，宽列，然后 map，list 这种符合类型）</li>\n<li>半结构化数据（类似 variant）</li>\n<li>非结构化数据</li>\n<li>新硬件</li>\n<li></li>\n</ul>\n<p>还需要能够支持非结构化数据</p>\n<ul>\n<li>现在有多种开源的 table/file format，其中 lance 由于国内字节在推，所以被知道的比较多。这里可以分为：1）better parquet，2）原生支持非结构化数据。其中第一个就是 parquet 现在支持不太好的情况（比如 list/map 等，这些在推荐等会有需要），点查（这个可以在 parquet 上用二级索引支持 — 参考 datafusion 的博客），当然 lance 的二维拆分会是一个更高效的处理方式（尤其是模型处理的时候加维度）；第二个就是支持非结构化数据，这个有点类似高效支持 blob 数据，然后支持索引。</li>\n</ul>\n<p>management（类似 amoro）</p>\n<ul>\n<li>主要是各种service（file layout 重排，索引生成，event trigger 生成 view 等）</li>\n<li>生命周期管理</li>\n<li>和 catalog 等结合（轻量级权限，）</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>多模态数据湖可以是啥样的？</p>\n<blockquote>\n<p>最近多模态数据湖的概念比较热门，记录下我理解中多模态数据湖的一个可能形态。</p>\n</blockquote>\n<p>多模态数据湖：能在一套系统中同时处理结构化数据、半结构化数据和非结构化数据。</p>\n<p>对于整套系统来说包括数据入湖，数据湖存储（主要是表格式），数据湖内数据的优化，Catalog，以及计算。</p>\n<blockquote>\n<p>增加一个全景架构图（包括上面所有这些流程）</p>\n</blockquote>\n<p>从数据使用角度来看</p>\n<ul>\n<li>数据最终是为了分析<ul>\n<li>分析性能<ul>\n<li>列存（至少是读取，可以用行存写入）</li>\n</ul>\n</li>\n<li>可能需要不断的变换 schema（SchemaEvolution）</li>\n<li>需要支持 ACID</li>\n<li>能对接尽可能广的生态</li>\n<li>支持不同类型的数据<ul>\n<li>结构化，半结构化，非结构化数据</li>\n</ul>\n</li>\n<li>数据治理<ul>\n<li>为了性能调整</li>\n<li>为了存储空间等治理<br>数据同步</li>\n</ul>\n</li>\n<li>reader + deserializer + transformer + serializer + writer</li>\n<li>schema evolution</li>\n</ul>\n</li>\n</ul>\n<p>数据湖内数据治理</p>\n<ul>\n<li>数据湖内的数据可能对读取性能不是那么友好，需要进行优化</li>\n<li>会有 management 需求</li>\n</ul>\n<p>分析会有 引擎的计算，而引擎和表的对接则会需要 catalog/metadata 等</p>\n<p>catalog/metadata</p>\n<ul>\n<li>跨源跨域等需求</li>\n<li>权限</li>\n</ul>\n<p>计算引擎</p>\n<ul>\n<li>功能</li>\n<li>性能</li>\n</ul>\n<p>增量计算可以将整个流程的计算耗时大大降低（减少不必要的计算）</p>\n<p>参考 FDAP 以及 <a href=\"https://voltrondata.com/codex/accelerated-hardware\">voltrondata</a> 的模型</p>\n<p>数据湖可以看成是 FileFormat 的一个索引（可以配合 FileFormat 一起使用）</p>\n<p>BigQuery</p>\n<p>现在 SQL 使用起来会相对复杂，可以尝试使用 PipelinedSQL 而且这个 SQL 可以更好的转换为拖拽式的。</p>\n<p>Dremeal A Decade of Interactive SQL Analysis at Web Scale<br>Bigtable A Distributed Storage System for Structured Data<br>Adaptive and Robust Query Execution for Lakehouse at Scale<br>Column Sketches A Scan Accelerator for Rapid and Robust Predicate Evaluation</p>\n<ul>\n<li>Napa: Powering Scalable Data Warehousing with Robust Query Performance at Google</li>\n<li>[x] Big Metadata: When Metadata is Big Data</li>\n<li>[x] Vortex: A Stream-oriented Storage Engine For Big Data Analytics</li>\n<li>BigLake: BigQuery’s Evolution toward a Multi-Cloud Lakehouse</li>\n<li>[x] SQL Has Problems. We Can Fix Them: Pipe Syntax in SQL<ul>\n<li>这个还是挺好的，也有开源的实现可以参考</li>\n</ul>\n</li>\n<li>[x] Procella: Unifying serving and analytical data at YouTube<br>Unity Catalog</li>\n</ul>\n<h1 id=\"Napa\"><a href=\"#Napa\" class=\"headerlink\" title=\"Napa\"></a>Napa</h1><p>2021-Powering Scalable Data Warehousing with Robust Query Performance at Google</p>\n<p>We need to store and serve these planet-scale data sets under the extremely demanding requirements of scalability, sub-second query-response times, availability, and strong consistency; all this while ingesting a massive stream of updates from applciations used around the globe.</p>\n<p>The following key aspects of Napa are the bedrock principles of its design and are aligned with our client requirements:</p>\n<ul>\n<li>Robust Query Performance: Consistent query performance is critical to data analytics users. Our clients expect low query latency, typically around a few hundreds of milliseconds, as well as low variance in latency regardless of the query and data ingestion load. Napa is able to guarantee robust query performance with consistent results despite daunting requirements for scale and system availability.</li>\n<li>Flexibility: While performance is important, our experience shows that it is not the only criterion for our clients. For instantce not all applications require millisecond response times, not all require the same freshness for ingested data, or for that matter, not all clients are willing to pay for “performance at any cost”. Clients also require the flexibility to change system configurations to fit their dynamic requirements.</li>\n<li>High-throughput Data Ingestion. All Napa functions, including storage, materialized view maintenance, and indexing, must be performed under a massive update load. Napa implements a distributed table and view maintenance framework that is based on the LSM-tree paradigm. LSM is widely used in current generation of data warehouses and databases primarily to efficiently integrate and incorporate constantly emerging data into already existing data. Napa scales LSM to meet the challenges of Google’s operating environment.</li>\n</ul>\n<p>Napa’s approach for robust query performance includes the aggressive use of amterialized views, which are maintained consistently as new data is ingested across multiple data centers.</p>\n<p>权衡三角：Data freshness, Resource costs, Query performance 三者之间做权衡</p>\n<p>A key design choice in Napa is to rely on materialized views for predicatable and high query performance.</p>\n<p>Napa’s high-level architecture consists of three main components as shown in the figure above.</p>\n<ul>\n<li>Napa’s ingestion framework is responsible for committing updates into the tables. The deltas written by the ingestion framework only serve to satisfy the durability requirements of the ingestion framework, and hence are write optimized. These deltas need to be further consolidated before they can be applied to tables and their associated views.</li>\n<li>The storage framework incrementally applies the updates to tables and their views. Napa tables and their views are maintained incrementally as log-structured merge-forests. Thus, each table is a collection of updates. Deltas are constantly consolidated to form larger deltas; we call this process “compaction” The view maintenance layer transoforms table deltas into view deltas by applying the corresponding SQL transformation. The storage layer is also responsible for periodically compacting tables and views.</li>\n<li>Query serving is responsible for answering client queries. The system performs merging of necessary deltas of the table(or view) at query time. Note that query latency is a function of the query time merge effort, so the faster the storage subsystem can process updates, the fewer deltas need to be merged at query time. F1 Query is used as the query engine for data stored in Napa. We provide more details for query serving in Section 8.</li>\n</ul>\n<p>Napa decouples ingestion from view maintenance, and view maintenance from query processing. This decoupling provides clients knobs to meet their requirements, allowing tradeoffs among freshness, performance, and cost.</p>\n<p>Users specify their requirements in terms of expected query performance, data freshness, and costs.<br>Napa introduces the concept called <code>Queryable Timestamp (QT)</code> to provide clients with a live marker(just like an advancing timestamp). QT is the direct indicator of freshness since [NOW() - QT] indicates data delay. All data up the QT timestamp can be queried by the client.</p>\n<blockquote>\n<p>Napa architecture showing the major system components<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202512291645719.png\" alt=\"\"></p>\n</blockquote>\n<p>Napa’s high-level architecture consists of data and control planes as above. The architecture is deployed at multiple data centers to manage the replicas at each data center. The data plane consists of ingestion, storage, and query serving. The control plane is made up of a controller that coordinates work among the various subsystems. The control is also responsible for synchronizing and corrdinating metadata transactions across multiple data centers.</p>\n<p>Napa clients use ETL pipelines to insert data into their tables. The ingestion framework can sustain very high load, such as tens of GB/s of compressed data. Client data are delivered to any of the Napa replicas and Napa ensures that the data ingestion is incorporated at all the data centers. This significantly simplifies the design of ingestion pipelines.</p>\n<p>Query serving deals with the necessary caching, prefetching and merging of deltas at runtime. The goal of query serving is to serve queries with low latency and low variance. Low latency is archieved by directing the queries to precomputed materialized views as opposed to the base table, and parallel execution of queries. Low variance is achieved by controlling the fan-in of the merges as well as a range of other I/O reduction and tail tolerance techniques.</p>\n<p>Napa relies on views as the main mechanism for good qauery performance. Napa’s choice is largely motivated by the strict latency and resource requirements of its workloads, making it necessary to leverage indexed key lookups.</p>\n<p>The Nap controller schedules compaction and view update tasks to keep the count of deltas for a table to a configurable value. These storage tasks are needed to keep the queryable Timestamp(QT) as fresh as possible given the cost tradeoffs.</p>\n<p>The goal of the ingestion framework is to accept data, perform minima processing, and make it durable without considering the pace of subsequent view maintenance.</p>\n<p>The queryable timestamp(QT) of a table is a timestamp which indicates the freshness of data that can be queried. If QT(table) = X, all data that was ingested into the table before time X can be queried by the client and the data after time X is not part of the query results.</p>\n<p>An important criterion to ensure good query performance is to optimize the underlying data for reads and ensure views are available to speed up the queries.</p>\n<p>A table in Napa is a collection of all of its delta files, each delta corresponding to updates received for the table over a window of time, as below<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202512291733204.png\" alt=\"\"></p>\n<p>The non-queryable deltas correspond to newly received updates written by the ingestion framework in the most recent time window(typically seconds.) THe largest deltas, on the other hand, span a time window of weeks or even months. Each delta is sorted by its keys, range partitioned, and has a local B-tree like index.</p>\n<p>The QT of the database is the minimum of the QT of all the tables in the database. QT is also used to give clients a consistent view of data across all Napa replicas.</p>\n<p>Napa’s storage subsystem is responsible for maintaining views and compacting deltas. It is also responsible for ensuring data integrity, durability via replication across data centers, and handling outages from individual machines to entire data centers.</p>\n<p>Compaction improves query performance and reduces storage consumption by 1) sorting inputs together and 2)aggregating multiple updates to the same rows. Since the delta files are individually sorted, compaction is essentially merge sorting. It is intentionally kept large during compaction so that the height of the merge tree is small, thus minimizing key comparisions.</p>\n<p>Robust query serving performance<br>query serving subsystem achieves robust performance, using Queryable Timestamp(QT), materialized views, and a range of other techniques.</p>\n<ol>\n<li>Reducing data in the critical path<br>Whenever possible, Napa uses views to answer a query instead of the base table, since views with aggregation functions may have significantly less data. Nap maintains sparse B-tree indexes on its stored data, and uses them to quickly partition an input query ito thousands of subqueries that satisfy the filter predicates. This partitioning mechanism additionally looks at the latency budget and availability of query serviing resources to achieve good performance.</li>\n</ol>\n<blockquote>\n<p>增加 Figure7</p>\n</blockquote>\n<ol>\n<li>Minimizing Number of Sequential I/Os<br>When a query is issued, Napa uses the value of QT to decide the version of metadata to be processed. The metadata in turns determines what data has to be process. Therefore, mateadata reads are on the critical path of query serving. Nap aensures all metadata can always be served from memory without contacting the persistent storage. This is achieved by affinity-based distributed metadata caching with periodic background refresheds. A particular QT is delayed to wait for the completion of periodic background refresh of metadata.</li>\n</ol>\n<p>Napa performs offline and online prefetching to further reduce the number of sequential I/Os in the critical path. Offline prefetching occurs as soon as data is ingested for frequently queried tables, before QT advances to make the new data available to query. Online prefetching starts when a query arrives and is performed by a shadow query executor which shares the data access pattern with the main query executor but skips all query processing steps.(like dry run?)</p>\n<ol>\n<li>Combining Small I/Os<br>During query serving, Napa aggressively parallelizes the work by partitioning the query into fine grained units and then parallelizing I/O calls across deltas and across queried columns. To combat such amplification on tail letency, Napa uses QT to limit the number of queryable deltas. In addition, Napa also tries to combine small I/Os as much as possible, by using the fowlling two techniques: lazy merging across deltas and size-based disk layout.</li>\n</ol>\n<ul>\n<li>lazy mering across deltas: When there are thousands(N) of subqueries and serval tens(M) of deltas, the number of parallel I/Os are in the order of tens of thousands(N <em> M). However, due to the parallelism each subquery reads very little data from most deltas. Meanwhile, a large fraction of Napa queries require merging based on a subset of primary keys in the subsequent phase of the query plan. In these cases, Napa adapts the query plan to avoid cross-delta merging in Delta Server and lets each Delta Server only process one delta, combining N </em> M parallel I/Ss into close to N parallel I/Os （merge 的数据尽量不跨 delta server？）</li>\n<li>size-based disk layout: Napa uses a custom-built columnar storage format supporting multiple disk layout options, which are applied based on delta sizes. The PAX layout which can combine all column accesses into one I/O for lookup queries, is applied to small dltas. For large deltas, column-by-column layout is used that is I/O efficient for san queries but requires one I/O per column for lookup queries. This size-based choice ensures that Napa receives columnar storage benefits as well as reduces I/O operations.（基于大小选择不同的磁盘布局，PAX 作为小的布局，可以一次 IO 读取完毕，大文件则是按列存放，这样每一列需要一个 IO 但是 scan 更友好</li>\n</ul>\n<ol>\n<li>Tolerating tails and failures<br>Napa adopts the principle of tolerating tail latency, rather than eliminating it, because eliminating all soruces of variability for such a complex and interdependent system is infeasible.</li>\n</ol>\n<p>For a non-streaming RPC, such as the RPC between Metadata Server and Delta Server, Napa uses the machnism of <em>hedging</em>, which sends a secondary RPC identical to the original one to a different server after a certain delay, and waits for the faster reply.<br>For a streaming RPC, such as the RPC between F1 worker and Delta Server, Napa estimates its expected progress rate and requires the server executing it periodically to report progress, together with a <em>continuation</em> token. If the reported progress is below expectation or the report is missing, the last continuation token would be used to restart a new streaming RPC on a different server without losing progress. Pushdown operators like filtering and partial aggregation need to be carefully handled in progress reporting as they can significantly reduce the data size, causing progress reports to be superficially low or even missing. Napa uses bytes processed before filtering and partial aggregation as the progress rate metric and periodically forces these operators to flushes its internal state to generate a progress report with a continuation token.</p>\n<p>Production metrics insights<br>Napa manages thousands of tables and views in production, where many tables are petabyte scale. It serves over a billion queries per day and ingests trillions of rows. Napa is able to provide robust query performance through three techniques: 1) by more actively using views, Napa reduces raw query performance and variance even at 99th percentile, 2) by chaning storage policies, Napa can reduce the number of deltas and hence the tail latency, and 3) by decoupling ingesting, view maintenance, and query execution; Napa can mitigate the impact of infrastructure and workload changes on query performance.</p>\n<ol>\n<li>Views and QT Help achive robust query performance<br>First, most client queries are aggregation queries, and materialized views are typically at least an order of magnitude smaller than the base tables from which they are derived. Reading from views not only improves raw performance, but also improves tail latency as their smaller size is more cache friendly, and requires less compute resources, which reduces the change of continetion for query resources.</li>\n</ol>\n<blockquote>\n<p>Add the figure for #views with the query latency</p>\n</blockquote>\n<p>Second, latency can be improved by reducing the number of deltas that have to be opend, read, and merged at query time.（相当于文件数量？）</p>\n<blockquote>\n<p>Add the figure for #deltas with the query latency</p>\n</blockquote>\n<p>Figure 8(b) shows that as we change storage policies to reduce the number of deltas, the query latency improves significantly. The biggest impact is at the 99th percentile latency which reduces by more than 3.6x as the number of deltas is changed from 8 to 2. The main reasons are: 1) fewer deltas means there are less number of small, parallel IOs which are prone to cause latency tails, 2) fewer deltas also means that data is premerged and aggregated, and less processing is required at query time.（这个类似 MOR 中，文件数量少，则 IO 少，而且读取的时候需要进行的聚合计算也少）</p>\n<ol>\n<li><p>Handling infrastructure issues</p>\n<blockquote>\n<p>Add figure 9<br>Figure 9 shows that Napa is able to guarantee its client stable query performance even when the ingestion load changes or there are infrastructure outages.  Napa decouples ingestion from view maintenance and querying which allows us to optimize for low variance in query latency, in some cases by trading off data freshness. Figure 9(a) shows that the client continuously sends data to Napa, with some variance in the input rate over the course of the week. Figure 9(b) shows that the view maintennace performance dropped for the duration between X and Y indicating an infrastructure issue which affected the tasks updating views. However, the query serving latency remains near constant (Figure 9(d)) throughout the whole duration. In this particular example, client queries continued to be fast, however , for certain parts during the outage data freshness was impacted, as seen in Figure 9(c) where the value of delay is high. 就算 view 的维护因为基建受影响了，那么不影响写入和读取的性能，但是能读到的数据的新鲜度会受影响</p>\n</blockquote>\n</li>\n<li><p>Client workloads<br>支持不同的 tradeoff，比如 [Client A: Tradoff freshness] wants moderate query performance and low costs, but can tolerate lower freshness.<br>[Client B: Tradeoff query performance] cares the most about low costs but can tolerate lower query performance<br>[Client C Tradeoff costs] has high freshness and high query performance requirements, and is willing to pay high costs to achieve them.</p>\n<blockquote>\n<p>Add figure 10 for different workloads</p>\n</blockquote>\n</li>\n</ol>\n<p>Napa is a fully indexed system that is optimized for key lookups, range scans, and efficient incremental maintenance of indexes on tables and views. Napa can easily support both adhoc queries and highly selective and less diverse queries.</p>\n<p>Napa uses a varaint of B+-trees that exploits the fact that Napa tables have multi-part keys. Additionally, min/max keys(per-column min/max values) are stored along with each non-leaf block to eanble effective pruning. LSM adapt B-tree indexes for high update rates. Napa belongs to a class of  LSM systems that trade high write throughput for fast reads. (看起来是 LSM 和 B-tree 的结合）</p>\n<h1 id=\"2023-Progressive-Partitioning-for-Parallelized-Query-Execution-in-Google’s-Napa\"><a href=\"#2023-Progressive-Partitioning-for-Parallelized-Query-Execution-in-Google’s-Napa\" class=\"headerlink\" title=\"2023-Progressive Partitioning for Parallelized Query Execution in Google’s Napa\"></a>2023-Progressive Partitioning for Parallelized Query Execution in Google’s Napa</h1><p>Napa holds Google’s critical data warehouses in log-structured merge trees for real-time data ingestion and sub-second response for billions of queries per day. These queries are foten multi-key look-ups in highly skewed tables and indexes.</p>\n<p>In our production experience, only progressive query-specific partitioning can achieve Napa’s strict query latency SLOs.  Here we advocate good-enough partitioning that keeps the per-query partitioning time low without risking uneven work distribution. Our design combines pragmatic system choices and algorithmic innovations. For instance, B-trees are augmented with statistics of key distributions, thus serving the dual purpose of aiding lookups and partitioning. Furthermore, progressive partitioning is designed to be “good enough” thereby balancing partitioning time with performance. The resulting system is robust and successfully serves day-in-day-out billions of queries with very high quality of service forming a core infrastructure at Google</p>\n<p>Napa’s diverse query workload consists of large scans and many-key lookups. The analytical queries with many-key lookups have strict QoS requirements and is the main focus of this paper.</p>\n<p>From our experience in running production services, we found the following three requirements important:</p>\n<ul>\n<li>Query-specific partitioning. Any approach that we take should meet the latency SLOs across a diverse set of query workloads. In our experience, the partitioning granularity needs to be adjusted on a per-query basis to meet the latency and resource budget requirements. The expectation from the partitioning step is that it is able to produce number of partitions denoted by the parallelization requirement within bounded amount of error.</li>\n<li>Evenness. Execution involves the partitioning of the tables into key ranges such that the partitioning results in even partitions. Partitioning should operate on tables with extreme skews where some keys span terabytes in disk. As an example, in Figure 1, a key range like &lt; K1 = 1, K2 = 20 &gt; may correspond to, say, a hundred GB portion of the table while another key range may be considerably smaller at a few MB.</li>\n<li>Progressiveness. Query partitioning must balance overall execution time against the time and effort to produce query-specific partitions. For instance, one can produce perfectly even partiions while still ending up missing the QoS requirement. It is imperative that the partitioning method has the notion of “good enough” in the sense that it stops when the partitioing is the sufficient quality. Our porposed technique in hte paper is progressive such that 1) the longer the alogirhtm runs the better the quality of the resultant partitioning; 2) the algorithm stops once the desired error bound has been met.</li>\n</ul>\n<p>Our experimental results show that the use of statistics that is too find-grained can often result in queries spending too much time generating partitioning at the expense of overall query execution time.</p>\n<p>We address this dilemma by leveraging B-trees to optimize access to the statistical information on the tables. Each LSM run has an associated B-tree index which are enhanced so that index nodes maintain size information for the associated key ranges. With these enhancements, we can estimate the input data size of the query starting with the root of the B-tree. If this estimation is not accurate enought or if the statistics point to areas of skews, we can descend to the next level in the index structure to obtain a finer level of statistical distributions for the key ranges overlapping with the query.</p>\n<p>Our proposed algorithm traverses the B-tree to produce even and query-specific partitioning. It is progressvie in the sense that it descends and accesses additional index information only if it does not satisfy the stipulated error bounds. In addition, the refinement is selective that it only descends to the lower levels of trees for those partitions that do not have gight enough bounds on the error.</p>\n<p>The following key aspects of Napa are the bedrock principles of its design and are aligned with our client requirements: i) Robust Qury Performance: Napa clients expect low query latency, typically sub-seconds, as well as low variance in latency under a wide spectrum of query and data ingestion load; ii) System Flexibility: While performance is important, our clients also require the flexibility to change system configurations to their dynamic requirements such as trading freshness or recency of ingested data for better performance; iii) High-throughput Data Ingestion: Napa’s ingestion, storage and query serving functions performan udner a massive update load.</p>\n<p>A Napa table consists of multiple data sets called deltas(corresponding to sorted runs of an LSM-tree) and we have one B-tree index for each delta. Not that each delta corresponds to updates on a table during a time window(e.g., last 1 minute, 1 day etc.).</p>\n<p>Progressive partitioning using B-tree: The B-trees on the deltas are fairly generic except that it hierarchically stores statistics of the underlying data. In particular, we store the number of rows that is indexed by each sub-tree and aggregate that statistics up the level. The partitioning algorithm we propose in the paper takes queried keys as input, retrieves and merges relevant keys taken from these B-tree indices, to generate an approximate histogram. Starting with the highest level histograms (i.e., the B-tree root index blocks), it tries to find accurate enough paritions. If it needs more detailed information, the algorithm will retrieve requried index blocks from the next highest level, repeating this trial and retrieve until it reaches the desired accuracy.</p>\n<p>LSM 让 partition 变的更复杂<br>The LSM data model complicates the task of query-specific partitioning in the following ways.</p>\n<ul>\n<li>First, the keys specified in the query may be present in may(possibly all) of the deltas. Note that the same query worker must process all deltas where the keys are present in order to reconcile all relevant version.</li>\n<li>Second, this proves to be a serious challenge for the evenness of the partitioning since some deltas may contribute many more matched rows than others.</li>\n<li>Third, a query may involve seeking across multiple deltas and not all deltasequally contribute to the query. Thus, the paritioning effort may not be uniform across the deltas. For some deltas, it may be sufficient to perform coarser partitioning while others require significantly more effort in producing equal splits.</li>\n</ul>\n<p>Why rely on progressive query-specific partitioning?<br>The ideal partitioning unit size can vary from 10MB(e.g., when reading 1GB data using 100 scan workers) to 1GB(e.g., when reading 1TB data using 1000 scan workers) on a per-query basis.<br>The next complexity here is that it is possible that there is one particular “Date = d3”, which accounts for most of the data to be scanned in a query. So, that means that we need to partition the range <c1, d3>, <c2, d3> and <c3, d3> much more finely than the other key ranges. This means the partitioning algorithm needs to be progressive such that it can stop early on other dates and focus on generating finer grained partitions for “Date = d3”<br>Standard write-time partitioning mechanisms are not able to address the requirements discussed above.</p>\n<p>Partitioning is highly specific to query under consideration and existing write-time partitioning is inadequate for workloads with a wide spectrum of query workloads. We have also established that one needs a way of producing both fine and coarse grained partitions even on the same key range, based on the query predicates, latency target and resource budget.</p>\n<p>Progressive partitioning<br>The progressive query-specific partitioning algorithm using <em>size-enhanced</em> B-trees. Our solution is to enhance typical B-trees with the statistics on data size in a hierarchical manner. For each delta, we maintain a B-tree pointing to data blocks, e.g. a block in the PAX layout. The index not only helps a query to efficiently seek on data using prefix keys but also provides statistical information for partitioning. Both querying and query-specific partitioning traverse the B-tree. The querying traverses the B-tree through the leaf level to visit dat ablocks. The query-specific partitioning does not visit data blocks and visits the index node at the leaf level only when required for finding “good enough” partitions as we describe below.</p>\n<blockquote>\n<p>使用 size-enhanced B-Tree，对于每一个 delta 都维护一个 B-tree 指向 data blocks，这样可以提供前缀查询，以及统计信息等</p>\n</blockquote>\n<p>For a given query Q, the algorithm divides D deltas into P key range partitions that are nearly even with an error margin of \\{thelta}. Each delta has a size-enhanced B-tree, which carries keys and the size of data between these keys. We analyze the estimated size of matching data by combining keys and sizes from D indices. To get the most precise matching estimate from B-trees, we may need to visit the leaf index entries matching with the query. 但是读所有的 leaf 会很耗时，另外一种方式就是通过 root 来推测 partition 的数量，这是两个极端，文中从中间进行选择：从 root 开始，然后仅在需要下一层提供更多信息的时候才进行继续读取。</p>\n<p>文中有一个具体的例子</p>\n<blockquote>\n<p>补充 fig 4 和 fig 5</p>\n</blockquote>\n<p>其中两个 Delta，然后希望分成两个 partition（分 parition 是希望能够并行处理），然后考虑第一层的时候（从 B-tree 获得信息），Delta 1 的 [K1, K3) 有 15 个，[K4, K8) 有 20 个； Delta 2 的 [K2, K5) 有 20 个，[K6, K7) 15 个。</p>\n<p>那么把所有的数目都加在一起就是 15 +  20 + 20 + 15 = 70 个，然后会选择在 K4 和 K5 这里做分割，这样会把 [K4, K8) 和 [K2, K5) 做一些分割，然后对于第一个 partition 来说，大小可能是 15（也就是 [K2, K5) 的倾斜全在右侧，[K4, K8) 也倾斜），同样最大可能是 15+20+20 = 55,那么估算这个大小是 (15 + 55) / 2 = 35，然后 size margin = 55 -15 = 40,同样第二个 partition 类似，得到估算大小是 35, size margin 是 40,如果 (40/35, 40/35) — 两个 parititon 的误差 — 能满足 \\{theata} 那么就按照这么切分，如果不行，就对 B-Tree 进行下一层读取，然后再进一步进行划分</p>\n<blockquote>\n<p>We represent this size-embedded index entry in a B-tree index node as e = <start, end, size, level, block>, which corresponds to the key range [e.start, e.end) having the estimated size e.size. The entry e is in a index block at tree level e.level(the value of 0 for e.level corresponds to the leaf level). Finally, e.block is a pointer to the child index block having range [e.start, e.end) (if e.level &gt; 0)</p>\n<p>根据和 Gemini 的沟通，大概理解 Napa 的存储结构如下<br>首先是 LSM Tree，然后每个 SSTable 是一个 B-tree，B-tree 就是文中的 Delta，B-tree 中包括多个实际的文件，以及对应的索引，然后渐进式则是「够用」就好，— 「够用」是满足对应的误差</p>\n</blockquote>\n<h1 id=\"SQL-Has-Problems\"><a href=\"#SQL-Has-Problems\" class=\"headerlink\" title=\"SQL Has Problems\"></a>SQL Has Problems</h1><p>文章描述了 SQL 是一个很好的抽象，但是学习和维护不方便，重新造一个类似 SQL 的语言又很麻烦，所以有了 PipelinedSQL 这个渐进式改进的方案。</p>\n<blockquote>\n<p>SQL is not an easy language to learn or use. Even for expert users, SQL is challenging to read, write and work with, which hurts user productivity. Serveral alternative languages have been prposed, but none have gained widespread adoption or displaced SQL. Migrating away from existing SQL ecosystems is expensive and generally unappealing for users.</p>\n</blockquote>\n<p>Piplined SQL 可以让 SQL 更好用，更具扩展性（more flexible, extensible and easy to use). </p>\n<p>In SQL, the standard clauses occur in one rigidly defined order. Expressing anything else requires subqueries or other workarounds. With Pipelined SQL operationcan be composed arbitrarily, in any order.</p>\n<p>给了两个例子<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">SELECT</span> c_count, <span class=\"built_in\">COUNT</span>(<span class=\"operator\">*</span>) <span class=\"keyword\">AS</span> custdist</span><br><span class=\"line\"><span class=\"keyword\">FROM</span></span><br><span class=\"line\">  (<span class=\"keyword\">SELECT</span> c_custkey, <span class=\"built_in\">COUNT</span>(o_orderkey) c_count</span><br><span class=\"line\">   <span class=\"keyword\">FROM</span> customer</span><br><span class=\"line\">   <span class=\"keyword\">LEFT</span> <span class=\"keyword\">OUTER</span> <span class=\"keyword\">JOIN</span> orders <span class=\"keyword\">ON</span> c_custkey <span class=\"operator\">=</span> o_custkey</span><br><span class=\"line\">        <span class=\"keyword\">AND</span> o_comment <span class=\"keyword\">NOT</span> <span class=\"keyword\">LIKE</span> <span class=\"string\">&#x27;%unusual%packages%&#x27;</span></span><br><span class=\"line\">   <span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> c_custkey</span><br><span class=\"line\">  ) <span class=\"keyword\">AS</span> c_orders</span><br><span class=\"line\"><span class=\"keyword\">GROUP</span> <span class=\"keyword\">BY</span> c_count</span><br><span class=\"line\"><span class=\"keyword\">ORDER</span> <span class=\"keyword\">BY</span> custdist <span class=\"keyword\">DESC</span>, c_count <span class=\"keyword\">DESC</span>;</span><br></pre></td></tr></table></figure></p>\n<p>然后<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM customer</span><br><span class=\"line\">|&gt; LEFT OUTER JOIN orders ON c_custkey = o_custkey</span><br><span class=\"line\">     AND o_comment NOT LIKE &#x27;%unusual%packages%&#x27;</span><br><span class=\"line\">|&gt; AGGREGATE COUNT(o_orderkey) c_count</span><br><span class=\"line\">   GROUP BY c_custkey</span><br><span class=\"line\">|&gt; AGGREGATE COUNT(*) AS custdist</span><br><span class=\"line\">   GROUP BY c_count</span><br><span class=\"line\">|&gt; ORDER BY custdist DESC, c_count DESC;</span><br></pre></td></tr></table></figure></p>\n<p>有讲 SQL 和 PipelinedSQL 的语义情况<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202512161155193.png\" alt=\"\"></p>\n<p>觉得 SQL 不错，那么就修复</p>\n<ul>\n<li>SQL’s foundational semantics, from relational algebra, are excellent</li>\n<li>SQL’s conceptual data model and top-level syntax, with statements representting requires, DDL, DML, etc, and composability via subqueries, works weel.</li>\n<li>SQL’s basic operations within a query(clauses like JOIN, ORDER BY, etc) all work reasonably well</li>\n<li>SQL’s syntactic structure for composing queries using those operations is <strong>terrible</strong>.</li>\n<li>SQL’ls localized syntax with English-like keyword phrases is and anachronism, but we can live with it.</li>\n<li>SQL’s expression language is fine, and implementations typically includes a good library of existing functions.</li>\n</ul>\n<p>所以只需要修复第四点中的问题就行</p>\n<p>pipelined SQL 使用 ‘|&gt;’ 这个 suffix 来衔接</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;query&gt; :=</span><br><span class=\"line\">  &#123;all existing query syntaxes&#125;</span><br><span class=\"line\">  | &quot;FROM&quot; &lt;from_body&gt;             -- New: FROM as a query</span><br><span class=\"line\">  | &lt;query&gt; &quot;|&gt;&quot; &lt;pipe_operator&gt;   -- New: pipe suffixes</span><br></pre></td></tr></table></figure>\n<p>论文中有具体算子的语法</p>\n<p>然后剩下的是一些更具体的细节，以及相关效果。<br>这个如果成熟之后，应该也可以更方便的推广拖拽式的表现形式（？），能够更好的一一对应起来<br>然后 ZetaSQL（已开源） 也有实现</p>\n<h1 id=\"Napa-1\"><a href=\"#Napa-1\" class=\"headerlink\" title=\"Napa\"></a>Napa</h1><h1 id=\"BigLake\"><a href=\"#BigLake\" class=\"headerlink\" title=\"BigLake\"></a>BigLake</h1><h1 id=\"Procella\"><a href=\"#Procella\" class=\"headerlink\" title=\"Procella\"></a>Procella</h1><blockquote>\n<p>These can be categorized as: reporting and dashboarding, embedded statistics in pages, time-series monitoring, and ad-hoc analysis. Typically, organizations build specialized infrastructure for each of these use cases. This however, creates silos of data and processing, and results in a complex, expensive, and harder to maintain infrastructure.<br>At YouTube, we solved this problem by building a new SQL query engine — Procella.</p>\n</blockquote>\n<p>These workloads have differenet set of requirements:</p>\n<ul>\n<li>Reporting and dashboarding: Video creators, content owners, and various internal stakeholders at YouTube need access to detailed real time dashboards to understand how their videos and channels are performing. This requieres an engine that supports executing tens of thousands of canned queries per second with low latency (tens of milliseconds), while queries may be using filters, aggregations, set operations and joins. The unique challenge here is that while our data volumen is high (each data source often contains hundreds of billions of new rows per day), we require near real-time respoinse time and access to fresh data.</li>\n<li>Embedded statistics: YouTube exposes many realtime statistics to users, such as likes or views of a video, resulting in simple but every high cardinality queries. These values are constantly changin, so the system must support millions of e real-time updates concurrently with millions of low latency queries per second.</li>\n<li>Monitoring: Monitoring workloads shrae many properties with the dashboarding workload, such as relatively simple canned queries and need for fresh data. The query volumne is often lower since monitoring is typically used internally by engineers. However, there is a need for aditional data management functions, such as automatic downsampling and expiry of old data, and additional query features (for example, efficient approximation functions and additional time-series functions)</li>\n<li>Ad-hoc analysis: Various YouTube teams (data scientists, business analysts, product managers, engineers) need to perform complex ad-hoc analysis to understand usage trends and to determine how to improve the product. This requires low volume of queries(at most tens per second) and moderate latency (second to minutes) of complex queries (multiple levels of aggregations, set operations, analytic functions, joins, unpredcatable patterns, manipulating nested/repeated data, etc.) over enormous volumes(trillions of rows) of data. Query patterns are highly unpredictable, although some standard data modeling techniques, such as star and snowflake schemas, can be used.</li>\n</ul>\n<p>独立系统的问题</p>\n<ul>\n<li>Data needed to be loaded into multiple systems using different Extract, Transform, and Load(ETL) processes, leading to significant additional resource consumption, data quality issues, data inconsistencies, slower loading times, high development and maintenance cost, and slower time-to-market.</li>\n<li>Since each internal system uses different languages and API’s, migrating data across these systems, to enable the utilization of existing tools, resulted in reduced usability and high learning costs. In particular since many of these systems do not support full SQL, some applications could not be built by using some backends, leading to data duplication and accessibility issues across the organization.</li>\n<li>Several of the underlying componenets had performance, scalability and efficiency issues when dealing with data at YouTube scale.</li>\n</ul>\n<p>Procella 的特性</p>\n<ul>\n<li>Rich API: Procella supports an almost complete implementation of standard SQL, including complex multistage joins, analytic functions and set operations, with serveral useful extensions such as approximate aggregations, ahdnling complex nested and repeated schemas, user defined functions, and more.</li>\n<li>High Scalability: Procella separates compute (running on Bord) and storage (on Colussus) enabling high scalability (thousands of servers, hundreds of petabytes of data) in a cost efficient way.</li>\n<li>High Performance: Procella uses state-of-the-art query execution techniques to eanble efficient execution of high volumen(millions of QPS) of queries with very low latency (milliseconds).</li>\n<li>Data Freshness; Procella supports high volume, low latency data ingestion in both batch and streaming modes, the ability to work directly on existing data, and native support for lambda architecture.</li>\n</ul>\n<blockquote>\n<p>Procella System Architecture</p>\n</blockquote>\n<p>Procellas 的数据按照 table 进行划分，每个 table 会有多个文件/分区。Procella 使用自己的列存 Artus，也支持其他的 file format，存在 Colossus 中，这样可以存算分离</p>\n<p>Procellas 没有使用 BTree 而是使用了更轻量级的 zonemaps, bloom filters, partition 以及 sort key 等这些二级索引，这些从文件头，或者 plan 时从 data server 获取，schema, table to file mapping, stats, 以及 zonemap 等这些存储在 BigTable/Spanner 中</p>\n<p>支持标准的 SQL 操作，支持 batch ingestion 和 streaming ingestion<br>在 batch ingestion 的时候，可以根据 file header 获取，更耗时的元数据抽取会延迟处理；streaming ingestion 支持 RPC/PubSub 的方式，然后 Ingestion Server 转换为表的形式</p>\n<p>然后会有后台线程周期性进行合并操作</p>\n<p>Query lifecycle<br>Clients connect to the Root Server(RS) to issue SQL queries. The RS performs query rewrites, parsing, planning and optimizations to generate the execution plan. To this end, ti uses metadata such as schema, partitioning and index infromation from the Metadata Server(MDS) to prune the files to be read. It then orchestrates the query execution as it goes through the different stages enforcing timeing/data dependencies and throttling. To address the needs of executing complex distributed query plans(timeing/ data dependencies, diverse join strategies, etc.), the RS builds a tree composed of query blocs as nodes and data streams as edges (Aggregate, Execute Remotely, Stagger Execution, etc. ) and executes it accordingly. This enables functionality such as shuffle (that requires timing dependency), uncorrelated subquery, subquery broadcast joins(data dependency) and multi-level aggregation. THis graph structure allows several optimizations by inserting custom operations into the tree based on query structure. Once the RS receives the final results, it sends the respoinse back to the client, along with statistics, error and warning messages, and any other information requested by the client.</p>\n<p>The Data Sever(DS) receives plan fragments from the RS or another DS and does most fo the heavy lifting, such as reading the required data (from local memory, remote and distributed files in Colossus, remote memory using RDMA,  or another DS), executing the plan fragment and sending the results back to the requesting RS or DS.</p>\n<p>优化</p>\n<ul>\n<li>Cache<ul>\n<li>Colossus metadata caching  可以减少一次或多次文件打开的开销</li>\n<li>Header caching  文件头(尾）有 start offset，column size，minimum and maximum 值，缓存这些可以减少更多的文件访问（单独的 LRU）</li>\n<li>Data caching, DS 使用单独的 cache 缓存文件，列存 Artus 设计成 disk 和 memory 的 format 一致，这样可以让 cache 更友好(making cache population fairly cheap)，同时也缓存一些二级数据（比如bloom filter 等）</li>\n<li>metadata caching: metadata 存在 bigtable 这样的分布式文件系统中，访问多可能会导致有瓶颈，因此用 LRU 来 cache </li>\n<li>Affinity scheduling: Caches are more effective when each server caches a subset of the data. Procella implements affinity scheduling to the data servers and the metadata servers to ensure that operations on the same data/metadata go to the same serve with high probability. 这样每个 server 只负责一部分数据，cache 有效性也变高. 但这个不是强约束，也就是说可能被调度到其他的 server — 这样只是性能变差（cache 无效）。</li>\n</ul>\n</li>\n<li>Data Format<ul>\n<li>一开始使用 Capacitor，但是它主要是 Ad-hoc 中使用（主要是 scan 性能），Procella 需要 lookup 和 range scan，所以开发了 Artus</li>\n<li>使用自定义的 encoding。Uses custom encodings, avoiding generic compression algorithms like LZW. This ensures that it can seek to single rows efficiently without needing to decompress blocks of data, making it more suitable for small point lookups and range scans.<ul>\n<li>Does multi-pass adaptive encoding: 第一次收集轻量级信息（ndv, min, max, sort order 等），然后使用这些去选择更合适的 encoding</li>\n<li>选择对 sorted column 支持 binary search 的 encoding</li>\n<li>嵌套字段的处理和 parquet 不一样，把表的 schema 当成 tree，每个字段都存在为独立的列, 针对每个父字段（如果自己本身存在的话），会记录所有子字段出现的次数，对于可选字段，该值是 0 或者 1,重复字段该值为非负。但是不记录父子段不存在的信息  </li>\n<li>Directly exposes dictionary indices, Run Length Encoding information, and other encoding information to the evaluation engine.</li>\n<li>Records rich metadata in the file and column header.</li>\n<li>Supports storing inverted inddexes. — 搜索场景有用</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>支持 multi-level partitioning and clustering</p>\n<p>Join 的类型</p>\n<ul>\n<li>Broadcast： 一方足够小可以加载到 DS 的内存。</li>\n<li>Co-partitioned: fact 和 dim 可以使用同样的 key 进行 partition</li>\n<li>Shuffle：数据太大，然后没有按照 join key 排序，就进行 shuffle</li>\n<li>Pipelined: RHS 是负责查询，但是结果可能比较小的时候</li>\n<li>Remote lookup: dim table 是分区的，但是 fact 没有</li>\n</ul>\n<p>怎么解决 tail latency</p>\n<ul>\n<li>因为数据有备份，所以如果某个数据节点的访问延迟超过了中位数(median)，就访问其他的节点 </li>\n<li>RS 会控制访问同一个 DS 的频率，批次等</li>\n<li>RS 会给每个请求附带一个优先级，通常来说小查询的优先级更高，大查询的优先级更低。DS 为高优和低优的分别分配资源，这样可以保证小查询的快速响应— 不会被大查询 block</li>\n</ul>\n<p>Intermediate merging</p>\n<ul>\n<li>对于很重的聚合，最后的聚合可能会成为瓶颈 — 需要在单机点操作很多数据。为了避免这个，添加中间节点用来做中间的聚合。</li>\n</ul>\n<p>Query Optimization</p>\n<ul>\n<li>Virtual Tables 类似 MV<ul>\n<li>Index-aware aggreagte selection</li>\n<li>Stitched queries</li>\n<li>Lambda architecture awareness</li>\n<li>Join awareness</li>\n</ul>\n</li>\n</ul>\n<p>Query Optimizer<br>使用静态和动态的查询优化技术 (makes use of static and adaptive query optimization techniques) At query compile time we use a rule based optimizer that applies standard logical rewrites (always benefical) such as filter push down, subquery decorrelation, constant folding, etc. At query execution time we use adaptive techniques to select/tune physical operators based on statistics (cardinality, distinct count, quantiles) collected on a smaple of the actual data used in the query.</p>\n<ul>\n<li>Adaptive Aggregation</li>\n<li>Adaptive Join</li>\n<li>Adaptive sorting</li>\n</ul>\n<p>Adaptive 的不足：需要动态收集信息，可能导致短查询耗时更久（比如 10ms 左右的可能变成原来的数倍），这种可以让用户给定 hint 不走 adaptive optimization，另外用户愿意接受短查询变长，换来大查询的耗时变短（overhead 可能有 10% 左右）</p>\n<p>针对 serving 做优化处理</p>\n<ul>\n<li>数据写入后，会立即通知 dataserver 进行加载，这样可以避免冷读</li>\n<li>MDS 编译进 Root Server，可以减少 RPC 交互</li>\n<li>metadta 提前加载到内存，避免查询的时候加载 metadata</li>\n<li>query plans are aggressively cached to eliminate parsing and planning overhead.  This is very effective since the stats query patterns are highly predicatble.</li>\n<li>The RS batchs all request for the same key and sends them to a single pair of primary and secondary data servers.</li>\n<li>The problematic outlier tasks are automatically moved to other machines.</li>\n</ul>\n<h1 id=\"Vortex\"><a href=\"#Vortex\" class=\"headerlink\" title=\"Vortex\"></a>Vortex</h1><blockquote>\n<p>Vortex: A Stream-oriented Storage Engine For Big Data Analytics</p>\n</blockquote>\n<p>Vortex is a streaming-first storage system that supports both streaming and batch data analytics. Today, BigQuery uses Vortex to support petabyte scale data ingestion with sub-second data freshness and query latency.</p>\n<p>Vortex has the following key properties:</p>\n<ul>\n<li>Consistent: Guaranteees ACID properties for all API operations.</li>\n<li>Unified API for batch and streaming: Vortex offers a single unified API with support for both streaming and batch data.</li>\n<li>Scalable: Vortex implements a fully distributed data and control plane and as a result supports tables of multiple petabytes size.</li>\n<li>Performant: The Vortex API offers sub-second tail write latencies that simplify client side application programming.</li>\n</ul>\n<p>BigQuery storage provides a global namespace over all data in BigQuery. Data is organized into regional containers called datasets(analogous to schemata in traditional database management systems). Tables, logical views, metarialized views, search indexes, stored procedures, machine learning models etc. all reside in a dataset.</p>\n<p>Vortex is BigQuery’s scalable, distributed and synchronnously replicated storage engine that supports data ingestion, retrieval and curation.</p>\n<p>A Vortex Stream is an entity to which rows can be appended to the current end. Each row in a Vortex Stream is identified by the Stream’s identifier and its row offset within the Stream. Readers can concurrently read a Stream at different row offsets. A table is an unordered collection of Stream.</p>\n<blockquote>\n<p>Stream 有点像传统说的文件，比如 Parquet File？但是应该还不一样，毕竟还有 ColumnFormat</p>\n</blockquote>\n<p>Streams are backed by the following entities</p>\n<ul>\n<li><p>Streamlets Vortex Streams provide durable sotrage of data. A Streamlet is a contiguous slice of rows in the Stream, all of which are present in the same 2 clusters. A Stream is an ordered list of one or more Streamlets. Given the Stream’s append-only semantics, a Stream has at most one writable Streamlet. The writable Streamlet, if one exists, is always the last Streamlet in a Stream.</p>\n</li>\n<li><p>Fragments: Each Streamlet is further split into contiguous blocks of rows called Fragments. Fragments typically are a range of rows inside a log file. Log files are stored in Colossus.</p>\n<blockquote>\n<p>Streamlets 和 Fragments 是 写入端的概念，还是类似表级别的概念<br>Streamlets and Fragments are internal physical metadata entities; they aren’t visible to the users of Vortex.</p>\n</blockquote>\n</li>\n<li>Data formats: BigQuery operates broadly with data in two different classes of data formats. The write-optimized storage format(WOS) is the format in which data is written by Vortex’s append API, The read-optimized storage format(ROS) is the format in which data is optimized for dat aprocessing.<br>BigQuery use Capacitor as ROS, BigLake use Parquet as ROS</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202512041721506.png\" alt=\"\"></p>\n<p>架构如上</p>\n<ul>\n<li><p>Stream Metadata Server(SMS) is the control plane of Vortex.<br>The SMS assigns a Streamlet to a specific Stream Server. THe Stream Server maintains the set of fragments for the Streamlet.</p>\n</li>\n<li><p>The Stream Server is the data plane of Vortex. It owns a set of STreamlets and creates Fragments for those Streamlets. The Stream Server has its own in memory metadata about its Streamlets and Fragments, and persists this by writing to a transaction log and periodically writing checkpoitns.<br>The Stream Server knows which Fragments belong to which Streamlet, their committed size, the minimum and maximum record timestamp in each Fragment, whether a Streamlet or Fragment is finalized, the schema version, and the partitioning and clustering columns of the table.</p>\n</li>\n</ul>\n<p>客户端通过 SMS 创建一个 Stream，SMS 会生成一个随机的 StreamId 然后 assign 到一个 Stream Server，Client 直接往 StreamServer 写数据，StreamServer 会周期性的通过心跳同步当前的数据。<br>Storage Optimization Service 会从 SMS 请求一批 Fragments 然后转为 ROS 的格式，然后把 Fragements 标记为 DELETED，再过一段时间之后，SMS 会通知 Stream Server 将过期的 Fragements 进行删除。</p>\n<p>Stream Server 到 SMS 的心跳只包含元数据（与上一次心跳的 Streamlet 的不同数据）</p>\n<ul>\n<li>Fragment File Format<blockquote>\n<p>Fragment 像是一个适合写入的文件格式（和 ROS 的 Parquet 对比）<br>Header 包括了同一个 Streamlet 中之前为删除的 Fragment，后面包括了 bloomfilter 以及其他 footer 信息<br>Each Fragment begins with a header which contains the File Map. The File Map lists the committed size and record ranges of all previous Fragments in the same Streamlet which have not yet been deleted. The File Map is used for disaster resilience.</p>\n</blockquote>\n</li>\n</ul>\n<p>When a Fragment is finalized, the Stream Server appends a bloom filter, followed by a fixed length footer which describes the offset in the Fragment where the bloom filter starts. The bloom filter marks which key values are present for the partitioning and clustering columns.</p>\n<p>The Fragment data format stores metadata records for FlushStream calls on BUFFERED streams. A flush operation is a metadata write to the Fragment which advances the committed row offset making all rows in the Streamlet(and the Stream) up to that point visible.</p>\n<p>Vortex uses an end-to-end CRC to protect row data as it is sent from the client to the Stream Server, and from the Stream Server to Colossus.</p>\n<p>Stream Server 会周期性（秒级）将 Streamlet 的变化同步给所有的 SMS，这些变化包括（新文件的创建，存量文件的写入，文件中的列属性）- 这个是 per-Streamlet 的，然后还有当前的 CPU，memory 以及 append throughput — 这个用来做负载均衡。</p>\n<blockquote>\n<p>A background service continuously optimizes data in Vortex as it is written. The goal ofStorage Optimization is to pitmize the format and layout of the data for large scale analysis. In doing so, it maintains an LSM tree of Fragments, starting with Fragments in WOS at the deepest level of the tree, with progressively more optimized ROS versions as we climb up the ree.<br>使用 LSM tree 管理 Fragments，然后从 deepset 将 WOS 的转换为 ROS 的格式</p>\n<p>To track the lifetime of Fragments, each Fragment maintains two timestamps: a <em>creation_timesatmp</em> and a <em>deletion_timestamp</em>.  A Fragment is visible to requests that read the table at a snapshot timestamp that is within the interval [creation_timestamp, deletion_timestamp). At each step of the optimization, the optimizer atomically sets the deletion_timestamp for the previous version of the fragments and the creation_timestamp for the new version. This guarantees that a row is included exactly once when reading the data from storage.<br>Fragment 可以有 creation_timestamp 和 deletion_timestamp，会自动给已经合并的 Fragment 赋值 deletion_timestamp（这个要保证事物）</p>\n</blockquote>\n<p><strong>Automatic Reclustering</strong>, BigQuery allows users to cluster the data in a table on a set of specified columns. Clustering defines a “weak” sort order on the data blocks in the table. In other words, BigQuery attempts to distribute the data such that the blocks store non-overlapping ranges of values for the clustering keys. Orgamizing data in non-overlapping ranges results in more efficient processing at read time, by improving parititon prunning and or by reducing intermediate data transferred between query processing stages.</p>\n<blockquote>\n<p>可以对数据进行重排序，而且可以做分布的排列，尽量做到不重叠，这样可以做到更好的 partition prunning<br>Once the delta(WOS) is sufficiently large, the optimizer first range partitions the delta locally.<br>如果 WOS 对读影响太多，就本地先合并, 形成一个新的 base<br>Figure 6 显示了一个 Automatic Reclustering 的具体例子, Base(ROS) + Delta(WOS) 可以合成新的 Base(ROS) </p>\n<p>Vortex continuously tracks metadata for Streams, Streamlets, and Fragments.<br>An example of coarse grained metadata is the state of a Streamlet that indicates whether the Streamlet is currently writable and its currentl  length. The source of truth for Streamlet is marked finalized. As the storage optimizer moves data between the layers in hte LSM tree, BigQuery’s highly scalable metadat management system, called BigMetadata</p>\n<p>There is a tail of the Fragment and Streamlet metadata that may have not yet been indexed by Big Metadata. As the metadat of these blocks churns rapidly, we observe that scanning through the list of these tail blocks that need to be read to satisfy the snapshot read, can add latency to query processing. To address this, we continuously compact the metadat entries for the Fragments by keeping the entries corresponding to the live fragments(i.e. fragments with deletion_timestamp unset) together in our log.<br>对元数据周期性做 compaction, 尽可能只保留 live fragment 的元数据</p>\n</blockquote>\n<p>Vortex 会周期性的做数据正确性验证(Vortex continuously traces requests to detect data correctness issues such as missing or duplicated records), Finally, we also verify that each record is reported as converted exactly once from WOS to ROS. Additionally, for each conversion, we validate that the output records are consistent tiwth the input records.</p>\n<p>When Vortex SMS receives this request(read), it returns the union of the data in WOS and ROS.</p>\n<p>Vortex allows a range of rows in a Fragment or Streamlet to be marked as deleted. To limit the size of these deletion masks, sometimes rows unaffected by the DML statement may also be marked deleted</p>\n<blockquote>\n<p>有点类似 pos delete？为了减少 pos delete 的数目，干脆把这重写？</p>\n</blockquote>\n<h1 id=\"BigMetadata\"><a href=\"#BigMetadata\" class=\"headerlink\" title=\"BigMetadata\"></a>BigMetadata</h1><p>主要想法</p>\n<ul>\n<li>使用类似系统表保存 metadata，这样可以横向扩展，而且可以使用 query engine 来处理 metadata 和 data</li>\n<li>提出了 falsifiable expression，可以改写 condition，从而大规模过滤数据</li>\n<li>metadata 可能很大，所以在读取的时候可以使用 falsifiable expression，减少读取 metadata 的数据量。<br>写一个 falsifiable expression 的例子<blockquote>\n<p>Traditionally, Big Data systems have tried to reduce the amount of metadata in order to scale the system, often compromising query performance. In Google BigQuery, we built a metadat management system that demonstrates that massive scale can be achived without such tradeoffs. We recognized the benefits that fine grained metadata provieds for query processing and we built a metadata system to manage it effictively. We use the same distributed query processing and data management techniques that we use for manageing data to handle Big metadata.</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>We present a distributed metadata management system that stores fine grained column and block level metadata for arbitrarily large tables and organizes it as a system table. We use a novel approach to process large amounts of metdata in these system tables by generating a query plan that integrates the meatdata scan into the actual data scan. In doing so, we leverage the same distributeddquery processing techniques that we use on our data to our metadat, thereby achieving performanct access to it along with high scalability. Our system has the following salient properties;</p>\n<ul>\n<li>Consistent</li>\n<li>Built for both batch and streaming APIs</li>\n<li>(Almost) INfinitely scalable: Our design is built for scale and it supports tables of multiple petabytes isze, and due to its distributed nature scales in a way similar to the underlying data</li>\n<li>Performance</li>\n</ul>\n</blockquote>\n<p>Most of the data in BigQuery is stored in columnar format blocks. Tables range from a few bytes to tens of petabytes. Large tables are stored in millions of columnar blocks. BigQuery supports tables with tens of thousands of columns. BigQuery maintains the entire mutation history of a table for a configurable amount of time in order to support queries on the table as of any timestamp in that history window</p>\n<p>We classify storage metadata into two broad categoreis: Logical metadata and Physical metadata.</p>\n<ul>\n<li>Logical metadata is information about the table that is generally directly visible to the user. Some examples of such metadata are: Table schema, Partitioning and clustering specifications, column and row level ACLs. This information is generally small in size and lends itself to quick access. </li>\n<li>Physical metadata is information about the table’s storage that BigQuery maintains internally in order to map a table name to its actual data.</li>\n</ul>\n<p>使用系统表来存储 physical metadata: To illustrate our idea, we describe the metadata layout using one such system table (hereafter referred to as CMETA) that stores column level information about the min/max values (called range constraints), hash bucket and modulus values (called hash constraints) and a dictionary of column values. Other variants of system tables include those that store posting lists of column values. Query optimizer chooses one or more such system tables for planning and executing the query</p>\n<p>每一列会有 totalRows/totalNulls/totalBytes/min/max/dictionary/bloom_filter 等信息</p>\n<p>Block 是 metadata 更新的最小单元</p>\n<p>metadata 有 changelog，记录 properties/timestamp 等</p>\n<p>A background process constantly performs LSM style merges on the change log to produce baselines and deltas of changes.</p>\n<p>Fine grained metadata for rows that have not yet been compacted into capacitor blocks is maintained in the memory of ingestion servers.</p>\n<p>BigMetadata 使用了一套 condition 重写的逻辑(falsifialbe expressions)，可以更好的进行过滤比如 x &gt; c =&gt; max(x) &lt;= c, x &lt; c =&gt; min(x) &gt;= c 等等</p>\n<p>metadata 可能会很大，所以也使用 falsiiable expression 进行读取</p>\n<p>文章说偏结论性的东西（自己理解），不要说太多细节</p>\n<ul>\n<li>细节别人可能不是太感兴趣</li>\n<li>纯细节不太能体现自己的东西</li>\n<li>可以在最后附加参考文献</li>\n</ul>\n<p>计算引擎的 execution plan 能否动态更新（根据数据的不同，动态的变动）</p>\n<ul>\n<li>Procella</li>\n</ul>\n<p>Procella 的 meta 是树形结构，而且不仅仅保存叶子节</p>\n<p>从上到下，结合 fdap（或者类似想法），就是组建做标准，系统搭积木</p>\n<p>parquet 可以有不错的性能（比如 Influxdata 的优化，以及 LiquidCache 的做法等），新的 FileFormat 需要的整体工作量还挺大的</p>\n<ul>\n<li>首先需要知道 parquet 的瓶颈（可以看新的 fileformat 的 PR 稿）</li>\n<li>parquet 的 ML 讨论（<a href=\"https://lists.apache.org/thread/8xmxc76nd00624qqps6s1qw6lhv1qwv5）/Influxdata\">https://lists.apache.org/thread/8xmxc76nd00624qqps6s1qw6lhv1qwv5）/Influxdata</a> 博客（<a href=\"https://www.influxdata.com/blog/how-good-parquet-wide-tables/）\">https://www.influxdata.com/blog/how-good-parquet-wide-tables/）</a></li>\n</ul>\n<p>引擎 bigquery</p>\n<ul>\n<li>用户端</li>\n<li>sql（可以优化 sql，包括 pipelined sql）</li>\n<li>dataframe</li>\n<li>其它（处理非结构化数据）</li>\n<li>然后 query engine</li>\n<li>plan 优化</li>\n<li>优雅的调度和停止等</li>\n<li>exection</li>\n<li>native（性能）</li>\n<li>分布式执行</li>\n<li>资源管理</li>\n<li>多类型资源统一管理</li>\n</ul>\n<p>table format</p>\n<ul>\n<li>catalog </li>\n<li>权限</li>\n<li>metadata</li>\n<li>索引（不同类型的索引）</li>\n<li>bigemetadata（sql 改写，下推，cache 等）</li>\n<li>file format</li>\n<li>结构化数据（主要是宽表，宽列，然后 map，list 这种符合类型）</li>\n<li>半结构化数据（类似 variant）</li>\n<li>非结构化数据</li>\n<li>新硬件</li>\n<li></li>\n</ul>\n<p>还需要能够支持非结构化数据</p>\n<ul>\n<li>现在有多种开源的 table/file format，其中 lance 由于国内字节在推，所以被知道的比较多。这里可以分为：1）better parquet，2）原生支持非结构化数据。其中第一个就是 parquet 现在支持不太好的情况（比如 list/map 等，这些在推荐等会有需要），点查（这个可以在 parquet 上用二级索引支持 — 参考 datafusion 的博客），当然 lance 的二维拆分会是一个更高效的处理方式（尤其是模型处理的时候加维度）；第二个就是支持非结构化数据，这个有点类似高效支持 blob 数据，然后支持索引。</li>\n</ul>\n<p>management（类似 amoro）</p>\n<ul>\n<li>主要是各种service（file layout 重排，索引生成，event trigger 生成 view 等）</li>\n<li>生命周期管理</li>\n<li>和 catalog 等结合（轻量级权限，）</li>\n</ul>\n"},{"_content":"A 股\n发行股数  1,800,000,000\n发行价  36.99\n发行日期 20070925\n发行后总股本  19,889,620,455\n- A  16,491,037,955\n- H  3,398,582,500\n\n\n\n\n业务\n- 煤炭生产\n- 电力生产\n- 热力生产和供应\n- 相关铁路，港口运输服务（神朔铁路，朔黄铁路，黄骅港和神华天津煤码头）\n\n\n专业词汇\n- 煤炭相关技术词汇\n- 电力相关技术词汇\n\n发电设备平均利用小时：统计期间内总发电量与平均发电设备容量的比值，单位为小时。衡量发电厂发电设备利用程度的核心指标。\n\n\n\n本公司是世界领先的、立足于煤炭的综合性能源公司，专注于煤炭和电力业务。主要业务包括煤炭生产、销售，电力生产、热力生产和供应，相关铁路、港口等运输服务。\n2006 年本公司煤炭产量和销售量分别达到 136.6 百万吨和 171.1 百万吨，是我国最大的煤炭生产企业和销售企业。以 2006 年煤炭销量计，本公司是全球第二大煤炭上市公司。2007 年上半年，本公司煤炭产量和销售量分别达到 76.6 百万吨和 97.8 百万吨。\n\n本公司拥有由铁路和港口组成的一体化运输网络，为本公司煤炭的生产和销售提供了充分的保障。该一体化运输网络目前包括五条总运营里程为 1367 公里的铁路线和专用海港黄骅港及神话天津港码头。2006 年，黄骅港煤炭下水量达到 79.2 百万吨，成为中国第二大煤炭下水港口。2007 年上半年，黄骅港煤炭下水量达到 39.8 百万吨，神华天津码头煤炭下水量达到 9.2 百万吨。\n\n本公司拥有高效率、快速发展的电力业务。截至 2006 年 12 月 31 日，本公司控制并运营的 11 家火力发电厂，总装机容量和售电量分别达到了 11960 兆瓦和 517.1 亿千瓦时，从 2004 年至 2006 年年复合增长率分别达到 41.7% 和 20.7%。截至 2007 年 6 月 30 日，本公司电力业务总装机容量和售电量分别达到了 12560 兆和瓦和 337 亿千瓦时。\n\n> 煤炭产量需要区分是 原煤产量还是商品煤产量。\n\n行业概述\n\n- 煤炭行业\n煤炭是我国最重要的能源。国家统计局统计（这里可以查看每年的用电、用煤数据），2005 年煤炭占我国一次性能源总消费量的 68.9%，2006 年我国燃煤发电机组的发电量站总发电量的 83.2%。我国经济的发展带动了电力需求的快速增长，从而推动了动力煤需求的快速增长。2004 年至2006 年，我国煤炭产量年均符合增长率达 10.3%，2006 年、2007 年上半年我过煤炭总产量分别为 2380 百万吨和 1082 百万吨。\n\n煤炭是世界上储量最丰富、最经济的能源资源之一。根据 BP 统计概览（这个搞清楚 BP 统计是啥），2006 年全球煤炭产量为 62亿吨，约占世界一次能源消费总量的 28.45.\n\n由于运输成本相对较高，煤炭，特别是动力煤消费及价格受运输距离影响较大，全球煤炭市场呈现出按地域分割的布局特点，各个地域性市场之间的煤价存在很大差别。在世界各煤炭市场中，澳大利亚和南非等国家煤炭资源丰富但国内需求相对较小，而日本和韩国等国家煤炭需求大但资源匮乏。在煤炭资源匮乏的地区，电厂和其他煤炭用户主要从其他国家或地区购入煤炭，因此煤炭运输至关重要。\n\n近年来，全球经济持续增长，欧洲各国纷纷以进口煤替代当地煤炭（为什么呢？），且石油及天然气价格大幅波动（煤炭的竞品有哪些？），因此全球煤炭需求也有所增长。\n\n\n我国煤炭行业\n煤炭是我国的基础能源。近年来，我国煤炭产量和消费量都呈较快增长趋势。我国煤炭生产和需求的地理分布不均衡（可以加一张煤矿的分布图？），煤炭行业集中度较低，正处于行业整合阶段（现在的情况？）\n\n- 需求和供给\n根据 BP 统计概览，2006 年，我国是世界上最大的煤炭生产国，也是最大的煤炭消费国。根据国家统计局数据，2006 年我国煤炭产量约为 2380 百万吨，煤炭消费量约为 2370 百万吨，\n\n|  年份 | 消费量 | 产量 | 出口量 | 进口量|\n| -- | -- | -- | -- | -- |\n| 2004 | 1936 | 1956 | 86.7 | 18.6 |\n| 2005 | 2166 | 2190 | 71.7 | 26.2 |\n| 2006 | 2370 | 2380 | 63.3 | 38.2 |\n\n受煤炭进出口税率变化，国内煤炭需求旺盛和人民币升值影响，预计中国煤炭未来一定时期内出口量进一步减少，进口量进一步增加。\n\n发电用煤仍是我国煤炭消费中占主要地位，所占比例超过 50%。钢铁、建材和化工等行业也在煤炭消费中占有相当大的比例。中国煤炭工业协会（可以查看协会相关信息）预计，煤炭构成我国一次能源生产总量主要部分的状况还将长期持续。\n\n发电 52.6%\n- 钢铁  17.3%\n- 建材  14.7%\n- 化工 5.7% \n- 其他 9.7%\n\n在我国，除了大型国有煤炭生产企业以外，还有数量众多的小型企业进行煤炭开采和销售。随着我国工业化进程的不断加快，能源紧缺的问题愈加凸显，安全、环保和煤炭资源合理利用的重要性日益增加。鉴于上述原因，我国政府加快煤炭行业整合的调控力度，促进加快发展大型煤炭基地和大企业集团，坚持整顿关闭小煤矿。国家发改委规划 2007 年底前将 3万吨以下的小煤矿全部关闭（有一定的准入门槛？）。\n\n根据安监总局（可以查看现在的数据？）的统计数据，2006 年我国最大的 10 家煤炭生产企业的产量综合为 595 百万吨，约占当年国内煤炭总产量的 25.6%。\n\n> 具体前十的在招股书 85 页有，中国神话是第一\n\n今年来，我国沿海省份的煤炭需求一直很大。但我国约 90% 的煤炭资源和生产能力分布在西部和北部地区，中国煤炭运输呈现“西煤东运”和“北煤南运”的格局。煤炭资源和需求的地理分布不均衡使煤炭运输成为制约我国煤炭行业发展的关键因素。\n\n2006 年我国煤炭产量最大的五个省区 ：山西 > 内蒙 > 河南 > 陕西 > 山东 （来源国家统计局，可以查看现在的数据）\n>87 页有各省的煤炭产量和缺口量情况（国家统计局和省统计局）\n\n煤炭运输\n在我国，将煤炭从西部和北部地区运往东部和南部地区，是煤炭销售的重要途径，对于煤炭行业的发展十分重要（现在还是这样吗？）神朔-朔黄铁路及大秦铁路是我国众多煤炭企业进行长距离运输的主要通道。随着能源需求的增加，煤炭运输能力的不足已经成为制约我国煤炭行业发展的瓶颈。虽然我国政府在增加铁路运力方面做出了很大努力，并将对国铁系统进行进一步扩能，但目前仍不能完全满足煤炭运输的需求，运力短缺的局面在近期内仍然难以得到根本性的改变。因而，使得拥有稳定而充足的运输能力的本公司具备了重要的竞争优势。\n\n在我国，相当部分煤炭需从西部和北部产煤区运输到我国东部港口，装船后经海运销售到华东和华南市场或国际市场，也有部分煤炭通过内河进行运输。我国主要的煤炭运输港包括秦皇岛港、黄骅港、天津港、日照港、连云港和青岛港。其中黄骅港作为本公司专用煤炭运输港口，是我国第二大煤炭港口，2006 年、2007 年上半年，从黄骅港下水的煤炭分别为 79.2 百万吨和 39.8 百万吨。\n\n从 2004 年 7 月开始，我国煤炭出口必须获得政府配额，只有具有煤炭出口经营权的企业才能申请并取得煤炭出口配额。目前全国只有四家企业具有煤炭出口经营权（这个也是门槛之一，如果出口占比大的话，这个优势还不小），4 家还包括一家本公司非排他代理商。\n\n亚太市场主要动力煤进口国家及地区为日本、韩国、中国台湾等（现在的出口占比？）2006 年 日本、韩国和中国台湾进口量分列前三位（这个是什么口径的前三？），其中日本动力煤进口量为 91.4 百万吨，同比下降 5%，韩国动力煤进口量为 59 百万吨，同比增长 5.2%；中国台湾动力煤进口量为 57 百万吨，同比增长 3.3%。2006 年，中国动力煤进口量为 10.9 百万吨，同比增长 43.9%。由于进口关税的调整、人民币升值及我国煤炭需求快速增长的影响，预计中国动力煤进口量将进一步增长（这个对国内的煤炭行业是啥影响？表示需求大？）\n\n亚太市场的动力煤出口国家主要有印度尼西亚、澳大利亚、中国、俄罗斯、南非等。2006 年印度尼西亚动力煤出口 125 百万吨，同比增长 13.6%；澳大利亚动力煤出口 111.6 百万吨，同比增长 4.4%；俄罗斯动力煤对亚洲出口 11 百万吨，与上年持平。受运费高涨影响，南非动力煤出口亚洲地区只有 3 百万吨，同比下降 31%。中国动力煤出口 53.8 百万吨，同比下降 11.5%，下降的主要原因是内需增长（为啥中国有煤炭进口和出口同时存在？赚差价？）\n\n行业竞争情况\n- 国内竞争\n近年来，尽管我国政府积极推动煤炭行业整合，但煤炭行业仍处于较为分散的状态。根据安监总局的统计，2006 年包括本公司在内的我国最大的 10 家煤炭生产商的煤炭产量总和仅占全国总产量的 25.6%；\n> 88 页有公司 2004 - 2007 年的产量，以及占全国产量的比例\n\n本公司煤炭销售量主要受市场需求、自身生产能力和运输能力的影响，在煤炭供应的稳定性、供货的可靠性和及时性、客户服务、煤炭质量和价格等方面都面临来自于国内其他主要动力煤生产商激烈的市场竞争。公司的主要竞争对手为中国中煤能源集团公司、大同煤矿集团公司、衮矿集团有限公司等。由于公司具有一体化运营模式的独特竞争优势和煤炭质量，与公司的主要国内竞争者相比，公司处于有利地位。\n\n- 国际竞争\n公司 2004 年 - 2006年以及 2007 年上半年的煤炭出口量分别是 26.6 百万吨、23.3 百万吨、23.9 百万吨和 12.2 百万吨，分别站同期全国煤炭出口总量的 30.7%，32.5%，37.8%，52.8%。公司主要的出口市场是韩国、中国台湾和日本。2004 - 2006和 2007 上半年，公司出口到这些国家和地区的煤炭分别站公司总出口量的 81.6%，83.3%，77.4%和 91.8%\n\n在出口方面，公司主要与其他的国内公司竞争，竞争对手主要包括：中国中煤能源集团公司、山西煤炭进口集团公司等，同时公司还与服务于亚太海运动力煤出口市场的海外公司竞争，竞争对手主要包括：BHP Billiton、Rio Tinto 和 Xstrata 公司等。公司在煤炭质量、价格、供应的稳定性、送货及时性和客服服务等方面都面临竞争。公司良好的煤质、具有竞争力的价格、靠近主要出口市场的地理位置、自有一体化的运输体系所保证的稳定供应能力和满足客户特殊需求的服务等构成公司显著的竞争优势。\n\n\n影响行业发展的因素\n- 宏观经济\n随着我国经济持续高速增长，包括煤炭、石油等在内的能源需求增长明显加快，呈现出供不应求的局面。尤其是近几年，随着国民经济的快速发展，煤炭供求矛盾有所体现，煤炭市场价格稳中有升，预期今后几年供求基本平衡，煤炭价格依然处于高位。由于我国富煤、贫油、少气的能源结构特点，煤炭行业已经成为国民经济发展的支柱产业，煤炭需求旺盛的势头在相当时期内不会改变，根据《煤炭工业发展“十一五”规划》（这个可以看最近的规划？）预计 2010 年全国煤炭总需求为 26 亿吨\n\n- 产业政策\n煤炭、电力、运输是国民经济发展的基础行业，煤炭行业的发展一贯受到政府政策的支持。国家宏观调控和产业政策对于煤炭行业有着至关重要的影响。国家发改委制订的《煤炭工业发展“十一五”规划》，基本确定了加强宏观调控，重视煤炭对国家能源安全的作用，实施建立煤炭大集团、大公司战略，促进资源的合理综合利用，加强保护环境，抓好洁净煤技术的推广应用，发展替代产业，延伸煤炭产业链等内容。\n\n- 环境保护和安全\n环保问题和安全问题是与煤炭企业生产经营息息相关的两大问题。《煤炭工业发展“十一五”规划》提出：要转变观念、坚持用科学发展观指导煤矿环境保护工作，建立与完善环境管理制度，大力推广使用洁净煤技术、努力建立煤矿环境保护投入机制， 积极推行清洁生产，大力发展环保产业。\n\n任何一个煤矿项目的建设，其安全设计和程序都要经过国家相关部位，特别是环保总局和煤矿安全监察局的审查批准。在建成后投产前，环保总局和煤矿安全监察局还要对环保和安全设施进行竣工验收检查。此外，国家煤矿安全监察局会按照《矿山安全法》和《煤炭安全规程》及其他相关法规对煤矿进行不定期安全检查。没有达到安全规定的煤矿要受到罚款、暂停运营直至关闭的惩罚。\n\n- 国际市场\n随着经济全球化和贸易自由化进程的加快，我国煤炭工业的发展面临着机遇和挑战。加入世界贸易组织后，我国能源供应应将在一个更加开放的体现中进行配置，国际石油和天然气等能源价格的变化，将直接影响国际煤炭市场的供需关系，从而对中国煤炭市场产生影响。\n> 了解国际石油和天然气的价格变化，以及和煤炭的关系\n\n\n- 进入行业的壁垒\n进入煤炭行业的主要壁垒是煤炭资源的限制。此外，近年来我国对煤炭行业进行了产业调整，对煤炭生产企业的规模、生产工艺、环保要求、矿井回采率及安全生产等各方面提出了新的行业政策，提高了行业进入门槛。\n\n-- 电力行业\n电力行业的演变\n\n自20世纪80年代中期起，我国政府开始开放电力市场，并相继实施了放宽投资限制，鼓励投资以及电厂与电网系统分离等一系列政策，这些政策促进了全国新电厂的开发，电力行业得到了快速发展。\n2002 年实施的国家电力体制改革中，原国家电力公司发电资源被大体平均分配到五家发电集团公司 -- 中国华能集团公司、中国大唐集团公司、中国华电集团公司、中国国电集团公司和中国电力投资集团公司。除中国华能集团公司外，其余四家均为新成立的发电集团公司。\n\n-- 市场发展与供求状况\n我国的电力消费量近年来增长迅猛。根据国家统计局的统计，2004 年--2006 年间，国内电力消费量的年复合增长率为 13.4%，电力消费量的增长归因于我国工业化进程带来的经济增长和居民生活水平提高。\n\n> 91 页有 装机容量、发电量和利用小时的相关统计数据\n> 可以查看《电力行业年鉴》，《xxx 年全国电力工业统计快报》\n\n据《2006 年全国电力工业统计快报》，2006 年末全国拥有总装机容量为 6.22 亿千瓦，然而我国电厂现有的装机容量仍然无法满足目前的电力需求。我国人均拥有的装机容量和人均电力消费水平相对较低（这个在哪有指标吗？），2006 年分别为473 瓦和 2149 千瓦时，远低于美国和日本（和发达国家比的情况？）。因此，我国电力行业具有持续强劲增长的潜力。\n\n-- 行业竞争情况\n目前，我国发电市场的竞争主题包括：五大发电集团及包括本公司在内的部分独立发电商。其中，五大发电集团的发电资产规模最大；地方政府拥有的发电资产（含发电类上市公司股权）是地方的支柱型产业；受政策限制，民营资本和外国资本对电力行业的涉足还不深，权益规模页相对较小，但他们看好中国的电力行业（为啥？），近年来在参建电力项目和并购地方性电力企业方面非常活跃（查看建设项目和并购？）\n\n从全国市场售电主体装机容量看，公司电力装机容量低于五大发电集团，与华润电力控股有限公司、广东省粤电集团有限公司等独立发电商共处于第二梯队的领先位置。截至2007年6月30日，公司电力装机容量达到 1256万千瓦，占全国总装机容量的 2.0%，发电量 360.2 亿千瓦时，占全国发电量的 2.4%\n> 92 页有公司和五大发电集团及全国发电装机容量\n> 中国电力企业联合会 情况，信息\n\n2006年度、2007 年上半年，公司发电设备平均利用小时分别为 6302 小时和 2963 小时，继续显著高于同期我国火电平均利用小时 5633 小时和 2638 小时。截至2007年6月30日，公司运营并控制 27 台火电机组，平均单机容量达到 465.2 兆瓦，继续领先国内同业。公司电力业务以其优异的经营业绩、高效的运营和快速的发展，成为我国最有竞争力的电力企业之一。\n\n-- 影响行业发展的因素\n宏观经济\n\n近年来我国经济发展速度较快并带动电力需求持续快速增长，我国电力需求结构以工业用电为主（在哪可以看工业用电、民用电的需求情况？）根据 《2006 年全国电力工业统计快报》，2006 年工业耗电量占我国电力消耗量的 74.9%。2004 年至2006 年间，工业耗电量年均增长 14.1%。我国 2004 -2006 年 GDP 增长率、电力消耗量增长率及弹性系数如下\n> 93 页相关数据。\n> GDP 和 电力消费量有啥关系吗？电力消费能否间接的说明发展？等\n\n电力体制改革\n我国电力行业发展的主要影响因素是目前正在进行的以”厂网分开，竞价上网“为主要内容的电力体制改革。目前电力体制改革已经迈出实质性的步伐，未来的电力市场竞争趋势已经形成，以市场竞争为基础的电价形成机制也在摸索中。多方式的竞价上网和电力供给模式，给电力生产企业带来新的发展挑战，促进电力企业加强投资建设规模和力度，控制成本、提高管理效率以增强在市场中的竞争能力。同时市场化的改革趋势，会进一步促进电力资源的优化配置，促进网间电力输送能力的提高，实现全国电力供求均衡的格局，从而提高整个电力行业的经济效益，进一步激发电力企业的运行活力。\n\n\n竞争加剧\n根据中国电力年鉴统计，2004 年、2005 年及2006 年底，全国发电装机容量分别为 4.42 亿千瓦、5.08亿千瓦和 6.22 亿千瓦，预计 2007 年底将突破 7亿千瓦。而2004 年、2005 年及 2006 年，火电电厂利用小时数逐年下降，分别为 5991、5876、5633 小时，根据中国电力企业联合会统计，2007 年火电电厂利用小时数将继下降至 5200 - 5300 小时，市场竞争进一步加剧\n> 查看现在火电发电站的利用小时数，以及整体的情况\n> 为啥会用不满，是因为电没法储藏吗？现在是否有改善？\n\n环保\n随着中国经济的飞速发展，工业生产与环境保护的矛盾逐渐尖yue，火电比例超过 77.8% 的电力行业面临日益严重的环保压力（现在的情况？）。从 2003 年7 月1 日起实行的《排污费征收使用管理条例》增加了火电企业环保方面的支出；国家鼓励火电长主动进行环保技术改造，对安装并按规定运行烟气脱硫设施的机组提高上网电价；”十一五“期间国家将重点推进火电机组节能、减排工作，加大”上大压下“的力度，加快关停小火电机组。\n\n- 进入行业的壁垒\n行业准入\n我国新建电源项目需要经过相当严格的审批程序，只有获得了相关的批准，方能开始建设。同时，电监会颁布的《电力监管条例》规定，对发电、输配电企业实行许可证管理，通过许可证来规范市场准入的条件以及准入主体的权利和义务。\n\n技术壁垒\n电力生产经营是技术密集型行业，需要有很强的专业技术队伍。发电厂是复杂的电力系统中的一个环节，接入和退出均会对系统产生影响，因此必须协调发电商、电网公司、当地政府和用户等多方利益后，才能够使新的电源项目接入系统。\n\n环保壁垒\n火电发电在环保方面的要求较高，必须具有符合国家环境保护标准的技术和设备，取得国家环保部门的批准。\n\n\n煤炭及电力行业监管情况\n- 基本情况\n煤炭和电力行业收到政府的监管。这些监管涉及的范围很广，煤炭行业的监管包括煤炭相关的投资、勘查、开采、生产、销售、贸易、运输和出口，电力行业的监管包括电力相关的投资、发电、定价、调度和安全，设计的主要监管机关包括国家发改委、国土资源部、铁道部、交通部、商务部、环保总局、水利部、国家税务总局、安监总监和电监会等（可以查看这些监管机构对不同公司的情况，公告？）此外，国务院国资委作为国务院授权的国有资产监督管理机构，依法对本公司控股股东神华集团履行出资人职责，并对企业国有资产的保值增值进行监督。\n\n- 煤炭生产、运输相关的主要政策法规\n煤炭生产设计的相关法规\n\n煤炭生产的主要政策法规包括《中华人民共和国矿山安全法》、《中华人民共和国矿产资源法》、《中华人民共和国煤炭法》、《中华人民共和国价格法》、《中华人民共和国海域使用管理法》《中华人民共和国安全生产法》、《中华人民共和国港口法》、《煤矿企业安全生产许可证实施办法》、《港口经营管理规定》、《中华人民共和国对外贸易法》、《煤炭出口配额管理办法》、《国务院关于投资体制改革的决定》、《关于建立煤电价格联动机制的意见的通知》和《关于核查电煤价格情况的通知》、《煤矿安全规程》、《关于预防煤矿生产安全事故的特别规定》、《国土资源部等部门对矿产资源开发整合意见的通知》、《关于深化煤炭资源有偿使用制度改革试点的实施方案》、《国家安全监管总局关于印发煤矿安全生产“十一五” 规划的通知》、《山西省煤炭可持续发展基金征收管理办法》等。\n\n《中华人民共和国煤炭法》和《中华人民共和国矿产资源法》是煤炭行业主要监管法规。《煤炭法》自1996年12月1日开始生效。该法设计到煤炭生产过程中的众多方面，包括煤矿资源勘查、煤矿建设的审批、煤炭生产许可证的颁发、安全生产管理、煤炭贸易、煤矿矿区保护、对煤矿企业职工的保护措施以及监督检查等。（能否看到公告或者年报的情况，这样可以查看市场整体的公司情况？）\n\n根据 1986 年 3 月 19 日颁发、后于 1996 年 8 月 29 日修订的现行《矿产资源法》的规定，我国的矿产资源属于国家所有。《矿产资源法》对采矿许可证的颁发进行了规定。矿产资源的勘查、开采都必须符合《矿产资源法》的规定，并且受国土资源主管部门的监督。\n\n开采经营\n根据《煤炭法》和《矿产资源法》的规定，煤炭的勘查和开采必须接受国土资源部和相关省级国土资源部门的监督。一旦获得审批，国土资源部或在当地辖区内负责监督和审查矿井勘查和开采的国土资源主管部门，将为提出申请的区块颁发勘查许可证，或为每一个矿井颁发采矿许可证。采矿许可证的持有人必须按规定向颁发该采矿许可证的相关行政机关递交年度报告。在我国，煤炭生产企业生产煤炭必须为每一矿井取得煤炭生产许可证。此外，国家发改委和相关的省级主管部门每年都会对每个煤矿的生产能力做出审查。煤炭生产经验非本企业生产、加工的煤炭产品，例如从事煤炭贸易，应当对煤炭经营资格审查部门提出申请，取得煤炭经营资格。\n\n依照国务院于 2004 年7 月19日出台的《国务院关于投资体制改革的决定》，所有国家规划矿区的煤矿开发项目都需要经国家发改委和国土资源部核准，而其他采矿项目则应向地方政府及地方国土资源主管部门提交。国家发改委将重大的采矿项目上报给国务院进行核准。\n\n按照《煤炭法》和《矿产资源法》，煤炭生产企业必须达到一定的回采率（什么是回采率？）。未达到规定的回采率标准的生产企业可能收到吊销许可证等处罚。\n\n任何单位或个人在他人拥有开采权的区域内进行任何开采皆属非法开采行为。开采矿产资源给他人的生产或生活造成损失的，应当负责赔偿并采取必要的补救措施。按照《矿产资源法》的实施细则，煤矿经营者在关闭矿井时必须遵照一定的程序，其中包括向原批准开采矿井的主管部门提出关闭申请，并提交闭坑地质报告。\n\n2006 年 12 月 31 日，国务院办公厅转发了《国土资源等部门对矿产资源开发进行整合意见的通知》，目的是通过整合，使矿山企业“多、小、散”的局面得到明显改变，以小并大，以优并劣，以规模大和技术、管理、装备水平高的矿山作为主体，整合其他矿山。使矿山开发布局趋于合理，矿山企业结构不断优化，矿产资源开采利用水平明显提高，矿山安全生产条件和矿区生态环境得到明显改善，矿产资源对经济社会可持续发展的保障能力明显增强，为中国大型企业的发展创造良好的外部环境。\n\n2007 年 2 月2日，国土资源部下发了《关于暂停受理煤炭探矿权申请的通知》国家关于 2 年内暂停受理煤炭探矿权申请的规定，避免因煤炭勘查投资过热而出现产能过剩问题，可暂缓目前资源矿业权市场过热的局面。根据我过煤炭资源分别特点，国家已制定和实施了大型煤炭基地规划，优化资源勘探和开发布局，规范资源市场和矿业权管理，加快大型煤矿项目建设，促进大型煤炭基地建设和发展。因此该项政策的出台，对中国神华这样的大型企业集团未来获取资源是有利的。当前，国内大部分探矿权配置给国有的地质勘探单位，本次暂停受理煤炭探矿权的2年内对我公司资源获取不受影响。\n\n定价\n在计划经济向市场经济转变的转轨过程中，我国政府逐渐放松了对煤炭定价的管制。1993年1月以前，国家煤炭调配计划内的煤炭价格由政府制订。此后，我国政府放松了大部分煤炭产品价格的控制，转而通过制订国家指导价格的方式继续控制电煤的价格，这种情况一直持续到 2002 年。2001 年7月，原国家计委宣布，从 2002年1月1日起取消对电煤的国家指导价。从 2002年起，煤炭产品的价格主要由市场力量决定。\n另外，我国今年对煤炭的进出口关税税率进行调整，主要包括《关于调整部分商品出口退税率和增补加工贸易禁止类商品目录的通知》、《关于调整部分商品净出口暂定税率的通知》等。2007年上半年，财政部门发布了“取消煤炭1%进口关税、将焦炭及半焦炭出口关税从5%上调至15%”的公告，自2007年6月1日起生效。\n\n煤炭运输相关法规\n煤炭运输相关的主要政策法规包括《中华人民共和国铁路法》、《中华人民共和国港口法》、《<港口设施保安符合证书>年度核验办法》、《港口工程竣工验收办法》、《中华人民共和国港口收费规则（内贸部分）》、《港口统计规则》、《港口建设管理规定》等。\n\n铁路建设  任何铁路线的建设计划都必须符合全国铁路发展规划，同时征得铁道部或铁道部授权机构的同意。 任何新建或增建的跨省（区、市）铁路线和100公里及以上的铁路线，也需要获得国家发改委的核准。在投入商业运营前，铁路必须由按照国家规定设立的验收机构组织验收。\n\n运费   国有铁路系统按照国家发改委批准的统一货物运价费率结算运费。按照规定，公司拥有和经营的各条铁路线收取的运费也不得超过由国家发改委批准的最高运费。国家发改委制订的最高运费反映了铁路的建设成本以及合理的投资回报。任何对此最高运费的修改都必须经过国家发改委的批准。\n\n港口经营  根据 2004 年 1月1日生效的《中华人民共和国港口法》，港口设施建设项目竣工后，应当按照国家有关规定组织验收。经验收合格，方可投入使用。验收合格以后，从事港口经营的企业应当向港口行政管理部门书面申请取得港口经营许可证。交通部依据《港口法》制订的于2004年6月1日生效的《港口经营管理规定》，对港口经营涉及的港口经营许可证的申请及审批、经营管理、监督检查等方面作出了更为详细的规定。此外，依照《投资改革决定》，对于煤炭、矿石、油气的专用泊位，新建港区和年吞吐能力200万吨及以上项目的申请，均需获得国家发改委和交通部核准。\n\n电力行业主要政策法规\n电力行业主要政策法规包括：《中华人民共和国电力法》、《关于规范电价管理有关问题的通知》、《电网调度管理条例》、《电价改革方案》、《关于调整电价的通知》、《电力安全生产监管办法》、《国家发展改革委关于东北区域电力市场上网电价改革试点有关问题的通知》、《华东电力市场监管实施办法（试行）》、《关于建立煤电价格联动机制的意见的通知》、《电力监管条例》、《上网电价管理暂行办法》、《输配电价管理暂行办法》、《销售电价管理暂行办法》、《关于华北电网实施煤电价格联动有关问题的通知》、《关于”十一五“ 深化电力体制改革的实施意见》、《新建发电机组进入商业运营管理办法（试行）》等。\n\n于1996年4月1日生效的《中华人民共和国电力法》，规定了电力行业的监管框架。国家制定《电力法》的主要目的之一是保护投资商、运营商和消费者的合法权益。《电力法》还规定，政府鼓励国内外资本投资于电力行业，并对这些投资活动实行监管。\n\n国务院于2005年2月15日颁布《电力监管条例》，该条例于2005年5月1日起生效。《电力监管条例》规定了电力行业中诸多方面的监管要求，其中包括：颁发电力业务许可证、对发电商和电网公司实施监管性质的审查，以及违反监管需求的企业的法律责任。\n\n电厂的批准\n2004年7月前，新建电力项目和扩容的电厂，都需要按顺序经过国家发改委的三轮审批：1）项目建议书；2）可行性研究报告；3）开工报告。在《投资改革决定》生效之后，所有新建燃煤电厂均须经过国家发改委的核准，除了国家出资建设的电力项目，其它新建电力项目仅需向国家发改委提交项目申请报告，不再经过批准项目建议书、可行性研究报告和开工报告的程序。\n\n此外，国家发改委还将重大的电厂项目申请提交国务院核准。电监会目前正筹划在电力行业中实行市场准入机制。如果实施市场准入制度，发电厂将被要求取得电力经营许可证，并到电监会或其他的指定机构进行登记。\n\n定价\n在《电力法》生效前，电价一般按照国家计划制订，发电厂的大部分发电量按政府制订的国家计划电价出售。自1996年《电力法》生效以来，《电力法》对电力价格的确定作出了原则性的规定。《电力法》规定电价应体现对发电成本的合理补偿和合理投资回报，以便能公平地分担支出并鼓励电厂建设。计划电量和超发电量的上网价格（现在的上网价格怎么定的？），都要经过国家发改委和各省物价部门的审查和批准程序。\n\n2001年4月23日，原国家发展计划委员会发布了《关于规范电价管理有关问题的通知》，该通知改变了以前上网电价的决定方法。原先定价机制是基于发电厂的成本和固定收益，而改革后的定价机制是基于电厂的经营周期和同一省级电网内的同类电厂的评价成本。对于新建的发电厂，上网电价将按照同一时期在同一地区建设的同类型的先进发电机组的社会平均成本为基础计算。这种平均成本通常考虑到各种因素，包括建设成本、经营和管理费用、维护和修理成本以及利息支出等。\n\n2003 年6月，电监会在华东和东北地区建立了试点性的区域电力市场，并且试行竞价上网。根据国务院于2003年12月制订的《东北区域电力市场暂行办法的通知》，在东北电力市场上以竞价上网方式销售的电力可以占到该市场上网总电力的 20%。根据电监会于2004年3月30日制订的《华东电力市场监管实施办法（试行）》，自2004年5月起，在华东地区电力市场上以竞价上网方式销售的电力可占到该市场上网总电力的一定比例（现在的竞价上网占比？）。迄今为止的试运行结果显示，由竞价上网确定的平均电价可能会略低于计划电量的平均电价。\n\n2003 年7月3日，国务院批准了《电价改革方案》，电价改革的长期目标是在进一步改革电力体制的基础上，将电价划分为上网电价、输电价格、配电价格和终端销售电价（现在是啥样的？）；发电、售电价格由市场竞争形成；输电、配电价格有政府指定（现在这个整体的是啥样的？）。同时，建立规范、透明的电价管理制度。2005年出台的《上网电价管理暂行办法》、《输配电价管理暂行办法》和《销售电价管理暂行办法》被作为电价改革方案实施方法。\n\n2004 年12月，经国务院批准，国家发改委发布了《关于建立煤电价格联动机制意见的通知》（这个现在有啥变化吗？），决定建立煤电价格联动机制。通知指出：为促进电力企业降低成本、提高效率，电力企业要消化 30% 的煤价上涨因素，这意味着电力公司可能通过上调上网电价的方式，向最终用户转移 70% 由于电煤涨价而造成的成本上升。（这里怎么理解 30% 和 70%）根据煤电价格联动机制的意见，国家要建立电煤价格消息系统及指标体系；原则上以不少于 6 个月为一个煤电价格联动周期，若周期内平均煤价比之前一周期变化幅度达到或超过 5%，相应调整电价；如果变化幅度不到 5%，则下一周期累计计算，直到累及变化幅度或超过 5%，进行电价调整，而30%的煤炭价格上涨将由发电企业自行消费。首次煤电价格联动以2004年5月底煤炭企业销售电煤的车板价为基础，根据此后6-11月电煤车板价的平均涨幅，按照煤电价格联动公式测算和调整发电企业上网电价和销售电价。\n\n2005 年3月28日，国家发改委发布了《上网电价管理暂行办法》（现在的上网价？），为 2003 年7月国务院批准的《电价改革方案》提供了监管准则。\n\n2005 年 4 月22日，经国务院批准，国家发展改革委员会发出《关于华北电网实施煤电价格联动有关问题的通知》，决定自2005年5月1日起在华北电网实施煤电价格联动措施，疏导突出的电价矛盾，相应调整上网电价和销售电价水平。\n\n2006 年6月，国家发改委在此调整电价，主要考虑了解决煤价上涨以及铁路运价调整对电价的影响，同时投运烟气脱硫设施导致成本增加而提高上网电价；对于 2006 年之前投产的烟气脱硫设施且尚未在上网电价中考虑脱硫成本的统调燃煤机组，经省级环保部门验收合格并经省级价格主管部门确认后，上网电价每兆瓦时提高人民币15元（含税）。公司未来如果投产新的发电机组，投产后如脱硫设施投入运行，并获省级环保部门验收及省级物价部门确认后，将获得每兆瓦时 15 元的脱硫加价（为啥要脱硫，已经影响成本？）\n\n电力调度\n在我国，除了未接入电网的电厂所发出的电量以外，所有的电量都由电网调度，由电网公司拥有并运营的调度中心管理向电网配电。每一个调度中心都必须按照国务院发布的、于1993年11月1日生效的《电网调度管理条例》和用电计划的规定调度电力。\n\n环境保护相关政策法规\n环境保护主要政策法规包括：《中华人民共和国环境保护法》、《海洋倾废管理条例实施办法》、《联合国气候变化框架公约》、《中华人民共和国水污染防治法》、《铁路环境保护规定》、《中华人民共和国森林法》、《建设项目环境保护管理条例》、《中华人民共和国森林法实施条例》、《中华人民共和国大气污染防治法》、《森林植被恢复费征收使用管理暂行办法》、《排污费征收使用管理条例》、《中华人民共和国环境影响评价法》、《中华人民共和国土地管理法》、《节能减排综合性工作方案》等。\n\n\n风险\n- 市场风险（煤炭价格波动；产品集中；宏观经济周期性波动）\n- 经营风险（业务发展依靠于连续有效开发煤炭储量能力的风险；煤炭安全事故的风险；煤炭和电力行业的竞争风险）\n- 煤炭和电力行业的竞争风险\n- 自然灾害和日常运营的风险\n- 长期煤炭供应合同状况和煤炭购买模式变化的风险\n- 大客户的风险\n- 运力不足的风险\n- 公司尚未获得部分土地产权证的风险\n- 成本上升的风险\n\n最近几个月 电力 情况（核电、风电、太阳能电发电总量增加，火电有降低的趋势）？\n\n神华集团 （73.86% 股份）\n\n\n煤炭行业竞争\n- 煤田赋存条件\n- 煤质煤种\n- 生产效率\n- 成本\n- 配煤能力\n- 品牌和服务\n\n电力竞争\n- [2007] 五大发电集团（中国华能，中国大唐，中国国电，中国华电和中国电力投资集团）和独立发电商\n   2006 年底 五大发电集团 总装机容量 39.1%\n- 业务规模，新项目的开发权\n- 有利的电量调度（？）和更高的上网价格（？）\n\n神东煤炭主要业务为煤X（石干）石发电、供暖、供水并向本公司神东矿区提供包括物业管理、环保绿化、工程建设及房地产开发、医疗服务及煤炭投资等业务。\n神东电力主要包括煤X（石干）石发电、煤矿开采、煤化工、燃料采购及运输等配套业务。\n\n\n<发行人的组织架构> 图\n\n<本公司的控股、参股子公司的情况> 图\n\n> 本章行业概述部分，煤炭产量如不特殊注明，均指原煤产量；本章其他部分中，煤炭产量如不特殊注明均为商品煤产量。\n> 涉及煤炭价格与电力价格时，如不特殊说明，均指不含增值税价格。\n\n> 本公司是世界领先的、立足于煤炭的综合性能源公司，专注于煤炭和电力业务。主要业务包括煤炭生产、销售，电力生产、热力生产和供应，相关铁路、港口等运输服务。\n\n\nQ\n- 为啥发行后的 A 股和发行股数不一样\n- 煤分多少种（发电用动力煤，还有其他的哪些？）\n- 电量调度是啥\n- 现在的电力上网价格怎么定的\n- 股权性质（除了国家股，还有哪些）\n- 上市时，每股 36 元，每股面值 1 元，这个怎么理解这里的 36 和 1 呢\n- 现在的母公司，子公司等情况，以及占比\n- 采矿权，这个是啥，有啥门槛之类的吗？\n- 煤炭的  产量、销量、进口量 等可以在国家统计局的数据查询\n","source":"_drafts/zhong-guo-shen-hua-init.md","raw":"A 股\n发行股数  1,800,000,000\n发行价  36.99\n发行日期 20070925\n发行后总股本  19,889,620,455\n- A  16,491,037,955\n- H  3,398,582,500\n\n\n\n\n业务\n- 煤炭生产\n- 电力生产\n- 热力生产和供应\n- 相关铁路，港口运输服务（神朔铁路，朔黄铁路，黄骅港和神华天津煤码头）\n\n\n专业词汇\n- 煤炭相关技术词汇\n- 电力相关技术词汇\n\n发电设备平均利用小时：统计期间内总发电量与平均发电设备容量的比值，单位为小时。衡量发电厂发电设备利用程度的核心指标。\n\n\n\n本公司是世界领先的、立足于煤炭的综合性能源公司，专注于煤炭和电力业务。主要业务包括煤炭生产、销售，电力生产、热力生产和供应，相关铁路、港口等运输服务。\n2006 年本公司煤炭产量和销售量分别达到 136.6 百万吨和 171.1 百万吨，是我国最大的煤炭生产企业和销售企业。以 2006 年煤炭销量计，本公司是全球第二大煤炭上市公司。2007 年上半年，本公司煤炭产量和销售量分别达到 76.6 百万吨和 97.8 百万吨。\n\n本公司拥有由铁路和港口组成的一体化运输网络，为本公司煤炭的生产和销售提供了充分的保障。该一体化运输网络目前包括五条总运营里程为 1367 公里的铁路线和专用海港黄骅港及神话天津港码头。2006 年，黄骅港煤炭下水量达到 79.2 百万吨，成为中国第二大煤炭下水港口。2007 年上半年，黄骅港煤炭下水量达到 39.8 百万吨，神华天津码头煤炭下水量达到 9.2 百万吨。\n\n本公司拥有高效率、快速发展的电力业务。截至 2006 年 12 月 31 日，本公司控制并运营的 11 家火力发电厂，总装机容量和售电量分别达到了 11960 兆瓦和 517.1 亿千瓦时，从 2004 年至 2006 年年复合增长率分别达到 41.7% 和 20.7%。截至 2007 年 6 月 30 日，本公司电力业务总装机容量和售电量分别达到了 12560 兆和瓦和 337 亿千瓦时。\n\n> 煤炭产量需要区分是 原煤产量还是商品煤产量。\n\n行业概述\n\n- 煤炭行业\n煤炭是我国最重要的能源。国家统计局统计（这里可以查看每年的用电、用煤数据），2005 年煤炭占我国一次性能源总消费量的 68.9%，2006 年我国燃煤发电机组的发电量站总发电量的 83.2%。我国经济的发展带动了电力需求的快速增长，从而推动了动力煤需求的快速增长。2004 年至2006 年，我国煤炭产量年均符合增长率达 10.3%，2006 年、2007 年上半年我过煤炭总产量分别为 2380 百万吨和 1082 百万吨。\n\n煤炭是世界上储量最丰富、最经济的能源资源之一。根据 BP 统计概览（这个搞清楚 BP 统计是啥），2006 年全球煤炭产量为 62亿吨，约占世界一次能源消费总量的 28.45.\n\n由于运输成本相对较高，煤炭，特别是动力煤消费及价格受运输距离影响较大，全球煤炭市场呈现出按地域分割的布局特点，各个地域性市场之间的煤价存在很大差别。在世界各煤炭市场中，澳大利亚和南非等国家煤炭资源丰富但国内需求相对较小，而日本和韩国等国家煤炭需求大但资源匮乏。在煤炭资源匮乏的地区，电厂和其他煤炭用户主要从其他国家或地区购入煤炭，因此煤炭运输至关重要。\n\n近年来，全球经济持续增长，欧洲各国纷纷以进口煤替代当地煤炭（为什么呢？），且石油及天然气价格大幅波动（煤炭的竞品有哪些？），因此全球煤炭需求也有所增长。\n\n\n我国煤炭行业\n煤炭是我国的基础能源。近年来，我国煤炭产量和消费量都呈较快增长趋势。我国煤炭生产和需求的地理分布不均衡（可以加一张煤矿的分布图？），煤炭行业集中度较低，正处于行业整合阶段（现在的情况？）\n\n- 需求和供给\n根据 BP 统计概览，2006 年，我国是世界上最大的煤炭生产国，也是最大的煤炭消费国。根据国家统计局数据，2006 年我国煤炭产量约为 2380 百万吨，煤炭消费量约为 2370 百万吨，\n\n|  年份 | 消费量 | 产量 | 出口量 | 进口量|\n| -- | -- | -- | -- | -- |\n| 2004 | 1936 | 1956 | 86.7 | 18.6 |\n| 2005 | 2166 | 2190 | 71.7 | 26.2 |\n| 2006 | 2370 | 2380 | 63.3 | 38.2 |\n\n受煤炭进出口税率变化，国内煤炭需求旺盛和人民币升值影响，预计中国煤炭未来一定时期内出口量进一步减少，进口量进一步增加。\n\n发电用煤仍是我国煤炭消费中占主要地位，所占比例超过 50%。钢铁、建材和化工等行业也在煤炭消费中占有相当大的比例。中国煤炭工业协会（可以查看协会相关信息）预计，煤炭构成我国一次能源生产总量主要部分的状况还将长期持续。\n\n发电 52.6%\n- 钢铁  17.3%\n- 建材  14.7%\n- 化工 5.7% \n- 其他 9.7%\n\n在我国，除了大型国有煤炭生产企业以外，还有数量众多的小型企业进行煤炭开采和销售。随着我国工业化进程的不断加快，能源紧缺的问题愈加凸显，安全、环保和煤炭资源合理利用的重要性日益增加。鉴于上述原因，我国政府加快煤炭行业整合的调控力度，促进加快发展大型煤炭基地和大企业集团，坚持整顿关闭小煤矿。国家发改委规划 2007 年底前将 3万吨以下的小煤矿全部关闭（有一定的准入门槛？）。\n\n根据安监总局（可以查看现在的数据？）的统计数据，2006 年我国最大的 10 家煤炭生产企业的产量综合为 595 百万吨，约占当年国内煤炭总产量的 25.6%。\n\n> 具体前十的在招股书 85 页有，中国神话是第一\n\n今年来，我国沿海省份的煤炭需求一直很大。但我国约 90% 的煤炭资源和生产能力分布在西部和北部地区，中国煤炭运输呈现“西煤东运”和“北煤南运”的格局。煤炭资源和需求的地理分布不均衡使煤炭运输成为制约我国煤炭行业发展的关键因素。\n\n2006 年我国煤炭产量最大的五个省区 ：山西 > 内蒙 > 河南 > 陕西 > 山东 （来源国家统计局，可以查看现在的数据）\n>87 页有各省的煤炭产量和缺口量情况（国家统计局和省统计局）\n\n煤炭运输\n在我国，将煤炭从西部和北部地区运往东部和南部地区，是煤炭销售的重要途径，对于煤炭行业的发展十分重要（现在还是这样吗？）神朔-朔黄铁路及大秦铁路是我国众多煤炭企业进行长距离运输的主要通道。随着能源需求的增加，煤炭运输能力的不足已经成为制约我国煤炭行业发展的瓶颈。虽然我国政府在增加铁路运力方面做出了很大努力，并将对国铁系统进行进一步扩能，但目前仍不能完全满足煤炭运输的需求，运力短缺的局面在近期内仍然难以得到根本性的改变。因而，使得拥有稳定而充足的运输能力的本公司具备了重要的竞争优势。\n\n在我国，相当部分煤炭需从西部和北部产煤区运输到我国东部港口，装船后经海运销售到华东和华南市场或国际市场，也有部分煤炭通过内河进行运输。我国主要的煤炭运输港包括秦皇岛港、黄骅港、天津港、日照港、连云港和青岛港。其中黄骅港作为本公司专用煤炭运输港口，是我国第二大煤炭港口，2006 年、2007 年上半年，从黄骅港下水的煤炭分别为 79.2 百万吨和 39.8 百万吨。\n\n从 2004 年 7 月开始，我国煤炭出口必须获得政府配额，只有具有煤炭出口经营权的企业才能申请并取得煤炭出口配额。目前全国只有四家企业具有煤炭出口经营权（这个也是门槛之一，如果出口占比大的话，这个优势还不小），4 家还包括一家本公司非排他代理商。\n\n亚太市场主要动力煤进口国家及地区为日本、韩国、中国台湾等（现在的出口占比？）2006 年 日本、韩国和中国台湾进口量分列前三位（这个是什么口径的前三？），其中日本动力煤进口量为 91.4 百万吨，同比下降 5%，韩国动力煤进口量为 59 百万吨，同比增长 5.2%；中国台湾动力煤进口量为 57 百万吨，同比增长 3.3%。2006 年，中国动力煤进口量为 10.9 百万吨，同比增长 43.9%。由于进口关税的调整、人民币升值及我国煤炭需求快速增长的影响，预计中国动力煤进口量将进一步增长（这个对国内的煤炭行业是啥影响？表示需求大？）\n\n亚太市场的动力煤出口国家主要有印度尼西亚、澳大利亚、中国、俄罗斯、南非等。2006 年印度尼西亚动力煤出口 125 百万吨，同比增长 13.6%；澳大利亚动力煤出口 111.6 百万吨，同比增长 4.4%；俄罗斯动力煤对亚洲出口 11 百万吨，与上年持平。受运费高涨影响，南非动力煤出口亚洲地区只有 3 百万吨，同比下降 31%。中国动力煤出口 53.8 百万吨，同比下降 11.5%，下降的主要原因是内需增长（为啥中国有煤炭进口和出口同时存在？赚差价？）\n\n行业竞争情况\n- 国内竞争\n近年来，尽管我国政府积极推动煤炭行业整合，但煤炭行业仍处于较为分散的状态。根据安监总局的统计，2006 年包括本公司在内的我国最大的 10 家煤炭生产商的煤炭产量总和仅占全国总产量的 25.6%；\n> 88 页有公司 2004 - 2007 年的产量，以及占全国产量的比例\n\n本公司煤炭销售量主要受市场需求、自身生产能力和运输能力的影响，在煤炭供应的稳定性、供货的可靠性和及时性、客户服务、煤炭质量和价格等方面都面临来自于国内其他主要动力煤生产商激烈的市场竞争。公司的主要竞争对手为中国中煤能源集团公司、大同煤矿集团公司、衮矿集团有限公司等。由于公司具有一体化运营模式的独特竞争优势和煤炭质量，与公司的主要国内竞争者相比，公司处于有利地位。\n\n- 国际竞争\n公司 2004 年 - 2006年以及 2007 年上半年的煤炭出口量分别是 26.6 百万吨、23.3 百万吨、23.9 百万吨和 12.2 百万吨，分别站同期全国煤炭出口总量的 30.7%，32.5%，37.8%，52.8%。公司主要的出口市场是韩国、中国台湾和日本。2004 - 2006和 2007 上半年，公司出口到这些国家和地区的煤炭分别站公司总出口量的 81.6%，83.3%，77.4%和 91.8%\n\n在出口方面，公司主要与其他的国内公司竞争，竞争对手主要包括：中国中煤能源集团公司、山西煤炭进口集团公司等，同时公司还与服务于亚太海运动力煤出口市场的海外公司竞争，竞争对手主要包括：BHP Billiton、Rio Tinto 和 Xstrata 公司等。公司在煤炭质量、价格、供应的稳定性、送货及时性和客服服务等方面都面临竞争。公司良好的煤质、具有竞争力的价格、靠近主要出口市场的地理位置、自有一体化的运输体系所保证的稳定供应能力和满足客户特殊需求的服务等构成公司显著的竞争优势。\n\n\n影响行业发展的因素\n- 宏观经济\n随着我国经济持续高速增长，包括煤炭、石油等在内的能源需求增长明显加快，呈现出供不应求的局面。尤其是近几年，随着国民经济的快速发展，煤炭供求矛盾有所体现，煤炭市场价格稳中有升，预期今后几年供求基本平衡，煤炭价格依然处于高位。由于我国富煤、贫油、少气的能源结构特点，煤炭行业已经成为国民经济发展的支柱产业，煤炭需求旺盛的势头在相当时期内不会改变，根据《煤炭工业发展“十一五”规划》（这个可以看最近的规划？）预计 2010 年全国煤炭总需求为 26 亿吨\n\n- 产业政策\n煤炭、电力、运输是国民经济发展的基础行业，煤炭行业的发展一贯受到政府政策的支持。国家宏观调控和产业政策对于煤炭行业有着至关重要的影响。国家发改委制订的《煤炭工业发展“十一五”规划》，基本确定了加强宏观调控，重视煤炭对国家能源安全的作用，实施建立煤炭大集团、大公司战略，促进资源的合理综合利用，加强保护环境，抓好洁净煤技术的推广应用，发展替代产业，延伸煤炭产业链等内容。\n\n- 环境保护和安全\n环保问题和安全问题是与煤炭企业生产经营息息相关的两大问题。《煤炭工业发展“十一五”规划》提出：要转变观念、坚持用科学发展观指导煤矿环境保护工作，建立与完善环境管理制度，大力推广使用洁净煤技术、努力建立煤矿环境保护投入机制， 积极推行清洁生产，大力发展环保产业。\n\n任何一个煤矿项目的建设，其安全设计和程序都要经过国家相关部位，特别是环保总局和煤矿安全监察局的审查批准。在建成后投产前，环保总局和煤矿安全监察局还要对环保和安全设施进行竣工验收检查。此外，国家煤矿安全监察局会按照《矿山安全法》和《煤炭安全规程》及其他相关法规对煤矿进行不定期安全检查。没有达到安全规定的煤矿要受到罚款、暂停运营直至关闭的惩罚。\n\n- 国际市场\n随着经济全球化和贸易自由化进程的加快，我国煤炭工业的发展面临着机遇和挑战。加入世界贸易组织后，我国能源供应应将在一个更加开放的体现中进行配置，国际石油和天然气等能源价格的变化，将直接影响国际煤炭市场的供需关系，从而对中国煤炭市场产生影响。\n> 了解国际石油和天然气的价格变化，以及和煤炭的关系\n\n\n- 进入行业的壁垒\n进入煤炭行业的主要壁垒是煤炭资源的限制。此外，近年来我国对煤炭行业进行了产业调整，对煤炭生产企业的规模、生产工艺、环保要求、矿井回采率及安全生产等各方面提出了新的行业政策，提高了行业进入门槛。\n\n-- 电力行业\n电力行业的演变\n\n自20世纪80年代中期起，我国政府开始开放电力市场，并相继实施了放宽投资限制，鼓励投资以及电厂与电网系统分离等一系列政策，这些政策促进了全国新电厂的开发，电力行业得到了快速发展。\n2002 年实施的国家电力体制改革中，原国家电力公司发电资源被大体平均分配到五家发电集团公司 -- 中国华能集团公司、中国大唐集团公司、中国华电集团公司、中国国电集团公司和中国电力投资集团公司。除中国华能集团公司外，其余四家均为新成立的发电集团公司。\n\n-- 市场发展与供求状况\n我国的电力消费量近年来增长迅猛。根据国家统计局的统计，2004 年--2006 年间，国内电力消费量的年复合增长率为 13.4%，电力消费量的增长归因于我国工业化进程带来的经济增长和居民生活水平提高。\n\n> 91 页有 装机容量、发电量和利用小时的相关统计数据\n> 可以查看《电力行业年鉴》，《xxx 年全国电力工业统计快报》\n\n据《2006 年全国电力工业统计快报》，2006 年末全国拥有总装机容量为 6.22 亿千瓦，然而我国电厂现有的装机容量仍然无法满足目前的电力需求。我国人均拥有的装机容量和人均电力消费水平相对较低（这个在哪有指标吗？），2006 年分别为473 瓦和 2149 千瓦时，远低于美国和日本（和发达国家比的情况？）。因此，我国电力行业具有持续强劲增长的潜力。\n\n-- 行业竞争情况\n目前，我国发电市场的竞争主题包括：五大发电集团及包括本公司在内的部分独立发电商。其中，五大发电集团的发电资产规模最大；地方政府拥有的发电资产（含发电类上市公司股权）是地方的支柱型产业；受政策限制，民营资本和外国资本对电力行业的涉足还不深，权益规模页相对较小，但他们看好中国的电力行业（为啥？），近年来在参建电力项目和并购地方性电力企业方面非常活跃（查看建设项目和并购？）\n\n从全国市场售电主体装机容量看，公司电力装机容量低于五大发电集团，与华润电力控股有限公司、广东省粤电集团有限公司等独立发电商共处于第二梯队的领先位置。截至2007年6月30日，公司电力装机容量达到 1256万千瓦，占全国总装机容量的 2.0%，发电量 360.2 亿千瓦时，占全国发电量的 2.4%\n> 92 页有公司和五大发电集团及全国发电装机容量\n> 中国电力企业联合会 情况，信息\n\n2006年度、2007 年上半年，公司发电设备平均利用小时分别为 6302 小时和 2963 小时，继续显著高于同期我国火电平均利用小时 5633 小时和 2638 小时。截至2007年6月30日，公司运营并控制 27 台火电机组，平均单机容量达到 465.2 兆瓦，继续领先国内同业。公司电力业务以其优异的经营业绩、高效的运营和快速的发展，成为我国最有竞争力的电力企业之一。\n\n-- 影响行业发展的因素\n宏观经济\n\n近年来我国经济发展速度较快并带动电力需求持续快速增长，我国电力需求结构以工业用电为主（在哪可以看工业用电、民用电的需求情况？）根据 《2006 年全国电力工业统计快报》，2006 年工业耗电量占我国电力消耗量的 74.9%。2004 年至2006 年间，工业耗电量年均增长 14.1%。我国 2004 -2006 年 GDP 增长率、电力消耗量增长率及弹性系数如下\n> 93 页相关数据。\n> GDP 和 电力消费量有啥关系吗？电力消费能否间接的说明发展？等\n\n电力体制改革\n我国电力行业发展的主要影响因素是目前正在进行的以”厂网分开，竞价上网“为主要内容的电力体制改革。目前电力体制改革已经迈出实质性的步伐，未来的电力市场竞争趋势已经形成，以市场竞争为基础的电价形成机制也在摸索中。多方式的竞价上网和电力供给模式，给电力生产企业带来新的发展挑战，促进电力企业加强投资建设规模和力度，控制成本、提高管理效率以增强在市场中的竞争能力。同时市场化的改革趋势，会进一步促进电力资源的优化配置，促进网间电力输送能力的提高，实现全国电力供求均衡的格局，从而提高整个电力行业的经济效益，进一步激发电力企业的运行活力。\n\n\n竞争加剧\n根据中国电力年鉴统计，2004 年、2005 年及2006 年底，全国发电装机容量分别为 4.42 亿千瓦、5.08亿千瓦和 6.22 亿千瓦，预计 2007 年底将突破 7亿千瓦。而2004 年、2005 年及 2006 年，火电电厂利用小时数逐年下降，分别为 5991、5876、5633 小时，根据中国电力企业联合会统计，2007 年火电电厂利用小时数将继下降至 5200 - 5300 小时，市场竞争进一步加剧\n> 查看现在火电发电站的利用小时数，以及整体的情况\n> 为啥会用不满，是因为电没法储藏吗？现在是否有改善？\n\n环保\n随着中国经济的飞速发展，工业生产与环境保护的矛盾逐渐尖yue，火电比例超过 77.8% 的电力行业面临日益严重的环保压力（现在的情况？）。从 2003 年7 月1 日起实行的《排污费征收使用管理条例》增加了火电企业环保方面的支出；国家鼓励火电长主动进行环保技术改造，对安装并按规定运行烟气脱硫设施的机组提高上网电价；”十一五“期间国家将重点推进火电机组节能、减排工作，加大”上大压下“的力度，加快关停小火电机组。\n\n- 进入行业的壁垒\n行业准入\n我国新建电源项目需要经过相当严格的审批程序，只有获得了相关的批准，方能开始建设。同时，电监会颁布的《电力监管条例》规定，对发电、输配电企业实行许可证管理，通过许可证来规范市场准入的条件以及准入主体的权利和义务。\n\n技术壁垒\n电力生产经营是技术密集型行业，需要有很强的专业技术队伍。发电厂是复杂的电力系统中的一个环节，接入和退出均会对系统产生影响，因此必须协调发电商、电网公司、当地政府和用户等多方利益后，才能够使新的电源项目接入系统。\n\n环保壁垒\n火电发电在环保方面的要求较高，必须具有符合国家环境保护标准的技术和设备，取得国家环保部门的批准。\n\n\n煤炭及电力行业监管情况\n- 基本情况\n煤炭和电力行业收到政府的监管。这些监管涉及的范围很广，煤炭行业的监管包括煤炭相关的投资、勘查、开采、生产、销售、贸易、运输和出口，电力行业的监管包括电力相关的投资、发电、定价、调度和安全，设计的主要监管机关包括国家发改委、国土资源部、铁道部、交通部、商务部、环保总局、水利部、国家税务总局、安监总监和电监会等（可以查看这些监管机构对不同公司的情况，公告？）此外，国务院国资委作为国务院授权的国有资产监督管理机构，依法对本公司控股股东神华集团履行出资人职责，并对企业国有资产的保值增值进行监督。\n\n- 煤炭生产、运输相关的主要政策法规\n煤炭生产设计的相关法规\n\n煤炭生产的主要政策法规包括《中华人民共和国矿山安全法》、《中华人民共和国矿产资源法》、《中华人民共和国煤炭法》、《中华人民共和国价格法》、《中华人民共和国海域使用管理法》《中华人民共和国安全生产法》、《中华人民共和国港口法》、《煤矿企业安全生产许可证实施办法》、《港口经营管理规定》、《中华人民共和国对外贸易法》、《煤炭出口配额管理办法》、《国务院关于投资体制改革的决定》、《关于建立煤电价格联动机制的意见的通知》和《关于核查电煤价格情况的通知》、《煤矿安全规程》、《关于预防煤矿生产安全事故的特别规定》、《国土资源部等部门对矿产资源开发整合意见的通知》、《关于深化煤炭资源有偿使用制度改革试点的实施方案》、《国家安全监管总局关于印发煤矿安全生产“十一五” 规划的通知》、《山西省煤炭可持续发展基金征收管理办法》等。\n\n《中华人民共和国煤炭法》和《中华人民共和国矿产资源法》是煤炭行业主要监管法规。《煤炭法》自1996年12月1日开始生效。该法设计到煤炭生产过程中的众多方面，包括煤矿资源勘查、煤矿建设的审批、煤炭生产许可证的颁发、安全生产管理、煤炭贸易、煤矿矿区保护、对煤矿企业职工的保护措施以及监督检查等。（能否看到公告或者年报的情况，这样可以查看市场整体的公司情况？）\n\n根据 1986 年 3 月 19 日颁发、后于 1996 年 8 月 29 日修订的现行《矿产资源法》的规定，我国的矿产资源属于国家所有。《矿产资源法》对采矿许可证的颁发进行了规定。矿产资源的勘查、开采都必须符合《矿产资源法》的规定，并且受国土资源主管部门的监督。\n\n开采经营\n根据《煤炭法》和《矿产资源法》的规定，煤炭的勘查和开采必须接受国土资源部和相关省级国土资源部门的监督。一旦获得审批，国土资源部或在当地辖区内负责监督和审查矿井勘查和开采的国土资源主管部门，将为提出申请的区块颁发勘查许可证，或为每一个矿井颁发采矿许可证。采矿许可证的持有人必须按规定向颁发该采矿许可证的相关行政机关递交年度报告。在我国，煤炭生产企业生产煤炭必须为每一矿井取得煤炭生产许可证。此外，国家发改委和相关的省级主管部门每年都会对每个煤矿的生产能力做出审查。煤炭生产经验非本企业生产、加工的煤炭产品，例如从事煤炭贸易，应当对煤炭经营资格审查部门提出申请，取得煤炭经营资格。\n\n依照国务院于 2004 年7 月19日出台的《国务院关于投资体制改革的决定》，所有国家规划矿区的煤矿开发项目都需要经国家发改委和国土资源部核准，而其他采矿项目则应向地方政府及地方国土资源主管部门提交。国家发改委将重大的采矿项目上报给国务院进行核准。\n\n按照《煤炭法》和《矿产资源法》，煤炭生产企业必须达到一定的回采率（什么是回采率？）。未达到规定的回采率标准的生产企业可能收到吊销许可证等处罚。\n\n任何单位或个人在他人拥有开采权的区域内进行任何开采皆属非法开采行为。开采矿产资源给他人的生产或生活造成损失的，应当负责赔偿并采取必要的补救措施。按照《矿产资源法》的实施细则，煤矿经营者在关闭矿井时必须遵照一定的程序，其中包括向原批准开采矿井的主管部门提出关闭申请，并提交闭坑地质报告。\n\n2006 年 12 月 31 日，国务院办公厅转发了《国土资源等部门对矿产资源开发进行整合意见的通知》，目的是通过整合，使矿山企业“多、小、散”的局面得到明显改变，以小并大，以优并劣，以规模大和技术、管理、装备水平高的矿山作为主体，整合其他矿山。使矿山开发布局趋于合理，矿山企业结构不断优化，矿产资源开采利用水平明显提高，矿山安全生产条件和矿区生态环境得到明显改善，矿产资源对经济社会可持续发展的保障能力明显增强，为中国大型企业的发展创造良好的外部环境。\n\n2007 年 2 月2日，国土资源部下发了《关于暂停受理煤炭探矿权申请的通知》国家关于 2 年内暂停受理煤炭探矿权申请的规定，避免因煤炭勘查投资过热而出现产能过剩问题，可暂缓目前资源矿业权市场过热的局面。根据我过煤炭资源分别特点，国家已制定和实施了大型煤炭基地规划，优化资源勘探和开发布局，规范资源市场和矿业权管理，加快大型煤矿项目建设，促进大型煤炭基地建设和发展。因此该项政策的出台，对中国神华这样的大型企业集团未来获取资源是有利的。当前，国内大部分探矿权配置给国有的地质勘探单位，本次暂停受理煤炭探矿权的2年内对我公司资源获取不受影响。\n\n定价\n在计划经济向市场经济转变的转轨过程中，我国政府逐渐放松了对煤炭定价的管制。1993年1月以前，国家煤炭调配计划内的煤炭价格由政府制订。此后，我国政府放松了大部分煤炭产品价格的控制，转而通过制订国家指导价格的方式继续控制电煤的价格，这种情况一直持续到 2002 年。2001 年7月，原国家计委宣布，从 2002年1月1日起取消对电煤的国家指导价。从 2002年起，煤炭产品的价格主要由市场力量决定。\n另外，我国今年对煤炭的进出口关税税率进行调整，主要包括《关于调整部分商品出口退税率和增补加工贸易禁止类商品目录的通知》、《关于调整部分商品净出口暂定税率的通知》等。2007年上半年，财政部门发布了“取消煤炭1%进口关税、将焦炭及半焦炭出口关税从5%上调至15%”的公告，自2007年6月1日起生效。\n\n煤炭运输相关法规\n煤炭运输相关的主要政策法规包括《中华人民共和国铁路法》、《中华人民共和国港口法》、《<港口设施保安符合证书>年度核验办法》、《港口工程竣工验收办法》、《中华人民共和国港口收费规则（内贸部分）》、《港口统计规则》、《港口建设管理规定》等。\n\n铁路建设  任何铁路线的建设计划都必须符合全国铁路发展规划，同时征得铁道部或铁道部授权机构的同意。 任何新建或增建的跨省（区、市）铁路线和100公里及以上的铁路线，也需要获得国家发改委的核准。在投入商业运营前，铁路必须由按照国家规定设立的验收机构组织验收。\n\n运费   国有铁路系统按照国家发改委批准的统一货物运价费率结算运费。按照规定，公司拥有和经营的各条铁路线收取的运费也不得超过由国家发改委批准的最高运费。国家发改委制订的最高运费反映了铁路的建设成本以及合理的投资回报。任何对此最高运费的修改都必须经过国家发改委的批准。\n\n港口经营  根据 2004 年 1月1日生效的《中华人民共和国港口法》，港口设施建设项目竣工后，应当按照国家有关规定组织验收。经验收合格，方可投入使用。验收合格以后，从事港口经营的企业应当向港口行政管理部门书面申请取得港口经营许可证。交通部依据《港口法》制订的于2004年6月1日生效的《港口经营管理规定》，对港口经营涉及的港口经营许可证的申请及审批、经营管理、监督检查等方面作出了更为详细的规定。此外，依照《投资改革决定》，对于煤炭、矿石、油气的专用泊位，新建港区和年吞吐能力200万吨及以上项目的申请，均需获得国家发改委和交通部核准。\n\n电力行业主要政策法规\n电力行业主要政策法规包括：《中华人民共和国电力法》、《关于规范电价管理有关问题的通知》、《电网调度管理条例》、《电价改革方案》、《关于调整电价的通知》、《电力安全生产监管办法》、《国家发展改革委关于东北区域电力市场上网电价改革试点有关问题的通知》、《华东电力市场监管实施办法（试行）》、《关于建立煤电价格联动机制的意见的通知》、《电力监管条例》、《上网电价管理暂行办法》、《输配电价管理暂行办法》、《销售电价管理暂行办法》、《关于华北电网实施煤电价格联动有关问题的通知》、《关于”十一五“ 深化电力体制改革的实施意见》、《新建发电机组进入商业运营管理办法（试行）》等。\n\n于1996年4月1日生效的《中华人民共和国电力法》，规定了电力行业的监管框架。国家制定《电力法》的主要目的之一是保护投资商、运营商和消费者的合法权益。《电力法》还规定，政府鼓励国内外资本投资于电力行业，并对这些投资活动实行监管。\n\n国务院于2005年2月15日颁布《电力监管条例》，该条例于2005年5月1日起生效。《电力监管条例》规定了电力行业中诸多方面的监管要求，其中包括：颁发电力业务许可证、对发电商和电网公司实施监管性质的审查，以及违反监管需求的企业的法律责任。\n\n电厂的批准\n2004年7月前，新建电力项目和扩容的电厂，都需要按顺序经过国家发改委的三轮审批：1）项目建议书；2）可行性研究报告；3）开工报告。在《投资改革决定》生效之后，所有新建燃煤电厂均须经过国家发改委的核准，除了国家出资建设的电力项目，其它新建电力项目仅需向国家发改委提交项目申请报告，不再经过批准项目建议书、可行性研究报告和开工报告的程序。\n\n此外，国家发改委还将重大的电厂项目申请提交国务院核准。电监会目前正筹划在电力行业中实行市场准入机制。如果实施市场准入制度，发电厂将被要求取得电力经营许可证，并到电监会或其他的指定机构进行登记。\n\n定价\n在《电力法》生效前，电价一般按照国家计划制订，发电厂的大部分发电量按政府制订的国家计划电价出售。自1996年《电力法》生效以来，《电力法》对电力价格的确定作出了原则性的规定。《电力法》规定电价应体现对发电成本的合理补偿和合理投资回报，以便能公平地分担支出并鼓励电厂建设。计划电量和超发电量的上网价格（现在的上网价格怎么定的？），都要经过国家发改委和各省物价部门的审查和批准程序。\n\n2001年4月23日，原国家发展计划委员会发布了《关于规范电价管理有关问题的通知》，该通知改变了以前上网电价的决定方法。原先定价机制是基于发电厂的成本和固定收益，而改革后的定价机制是基于电厂的经营周期和同一省级电网内的同类电厂的评价成本。对于新建的发电厂，上网电价将按照同一时期在同一地区建设的同类型的先进发电机组的社会平均成本为基础计算。这种平均成本通常考虑到各种因素，包括建设成本、经营和管理费用、维护和修理成本以及利息支出等。\n\n2003 年6月，电监会在华东和东北地区建立了试点性的区域电力市场，并且试行竞价上网。根据国务院于2003年12月制订的《东北区域电力市场暂行办法的通知》，在东北电力市场上以竞价上网方式销售的电力可以占到该市场上网总电力的 20%。根据电监会于2004年3月30日制订的《华东电力市场监管实施办法（试行）》，自2004年5月起，在华东地区电力市场上以竞价上网方式销售的电力可占到该市场上网总电力的一定比例（现在的竞价上网占比？）。迄今为止的试运行结果显示，由竞价上网确定的平均电价可能会略低于计划电量的平均电价。\n\n2003 年7月3日，国务院批准了《电价改革方案》，电价改革的长期目标是在进一步改革电力体制的基础上，将电价划分为上网电价、输电价格、配电价格和终端销售电价（现在是啥样的？）；发电、售电价格由市场竞争形成；输电、配电价格有政府指定（现在这个整体的是啥样的？）。同时，建立规范、透明的电价管理制度。2005年出台的《上网电价管理暂行办法》、《输配电价管理暂行办法》和《销售电价管理暂行办法》被作为电价改革方案实施方法。\n\n2004 年12月，经国务院批准，国家发改委发布了《关于建立煤电价格联动机制意见的通知》（这个现在有啥变化吗？），决定建立煤电价格联动机制。通知指出：为促进电力企业降低成本、提高效率，电力企业要消化 30% 的煤价上涨因素，这意味着电力公司可能通过上调上网电价的方式，向最终用户转移 70% 由于电煤涨价而造成的成本上升。（这里怎么理解 30% 和 70%）根据煤电价格联动机制的意见，国家要建立电煤价格消息系统及指标体系；原则上以不少于 6 个月为一个煤电价格联动周期，若周期内平均煤价比之前一周期变化幅度达到或超过 5%，相应调整电价；如果变化幅度不到 5%，则下一周期累计计算，直到累及变化幅度或超过 5%，进行电价调整，而30%的煤炭价格上涨将由发电企业自行消费。首次煤电价格联动以2004年5月底煤炭企业销售电煤的车板价为基础，根据此后6-11月电煤车板价的平均涨幅，按照煤电价格联动公式测算和调整发电企业上网电价和销售电价。\n\n2005 年3月28日，国家发改委发布了《上网电价管理暂行办法》（现在的上网价？），为 2003 年7月国务院批准的《电价改革方案》提供了监管准则。\n\n2005 年 4 月22日，经国务院批准，国家发展改革委员会发出《关于华北电网实施煤电价格联动有关问题的通知》，决定自2005年5月1日起在华北电网实施煤电价格联动措施，疏导突出的电价矛盾，相应调整上网电价和销售电价水平。\n\n2006 年6月，国家发改委在此调整电价，主要考虑了解决煤价上涨以及铁路运价调整对电价的影响，同时投运烟气脱硫设施导致成本增加而提高上网电价；对于 2006 年之前投产的烟气脱硫设施且尚未在上网电价中考虑脱硫成本的统调燃煤机组，经省级环保部门验收合格并经省级价格主管部门确认后，上网电价每兆瓦时提高人民币15元（含税）。公司未来如果投产新的发电机组，投产后如脱硫设施投入运行，并获省级环保部门验收及省级物价部门确认后，将获得每兆瓦时 15 元的脱硫加价（为啥要脱硫，已经影响成本？）\n\n电力调度\n在我国，除了未接入电网的电厂所发出的电量以外，所有的电量都由电网调度，由电网公司拥有并运营的调度中心管理向电网配电。每一个调度中心都必须按照国务院发布的、于1993年11月1日生效的《电网调度管理条例》和用电计划的规定调度电力。\n\n环境保护相关政策法规\n环境保护主要政策法规包括：《中华人民共和国环境保护法》、《海洋倾废管理条例实施办法》、《联合国气候变化框架公约》、《中华人民共和国水污染防治法》、《铁路环境保护规定》、《中华人民共和国森林法》、《建设项目环境保护管理条例》、《中华人民共和国森林法实施条例》、《中华人民共和国大气污染防治法》、《森林植被恢复费征收使用管理暂行办法》、《排污费征收使用管理条例》、《中华人民共和国环境影响评价法》、《中华人民共和国土地管理法》、《节能减排综合性工作方案》等。\n\n\n风险\n- 市场风险（煤炭价格波动；产品集中；宏观经济周期性波动）\n- 经营风险（业务发展依靠于连续有效开发煤炭储量能力的风险；煤炭安全事故的风险；煤炭和电力行业的竞争风险）\n- 煤炭和电力行业的竞争风险\n- 自然灾害和日常运营的风险\n- 长期煤炭供应合同状况和煤炭购买模式变化的风险\n- 大客户的风险\n- 运力不足的风险\n- 公司尚未获得部分土地产权证的风险\n- 成本上升的风险\n\n最近几个月 电力 情况（核电、风电、太阳能电发电总量增加，火电有降低的趋势）？\n\n神华集团 （73.86% 股份）\n\n\n煤炭行业竞争\n- 煤田赋存条件\n- 煤质煤种\n- 生产效率\n- 成本\n- 配煤能力\n- 品牌和服务\n\n电力竞争\n- [2007] 五大发电集团（中国华能，中国大唐，中国国电，中国华电和中国电力投资集团）和独立发电商\n   2006 年底 五大发电集团 总装机容量 39.1%\n- 业务规模，新项目的开发权\n- 有利的电量调度（？）和更高的上网价格（？）\n\n神东煤炭主要业务为煤X（石干）石发电、供暖、供水并向本公司神东矿区提供包括物业管理、环保绿化、工程建设及房地产开发、医疗服务及煤炭投资等业务。\n神东电力主要包括煤X（石干）石发电、煤矿开采、煤化工、燃料采购及运输等配套业务。\n\n\n<发行人的组织架构> 图\n\n<本公司的控股、参股子公司的情况> 图\n\n> 本章行业概述部分，煤炭产量如不特殊注明，均指原煤产量；本章其他部分中，煤炭产量如不特殊注明均为商品煤产量。\n> 涉及煤炭价格与电力价格时，如不特殊说明，均指不含增值税价格。\n\n> 本公司是世界领先的、立足于煤炭的综合性能源公司，专注于煤炭和电力业务。主要业务包括煤炭生产、销售，电力生产、热力生产和供应，相关铁路、港口等运输服务。\n\n\nQ\n- 为啥发行后的 A 股和发行股数不一样\n- 煤分多少种（发电用动力煤，还有其他的哪些？）\n- 电量调度是啥\n- 现在的电力上网价格怎么定的\n- 股权性质（除了国家股，还有哪些）\n- 上市时，每股 36 元，每股面值 1 元，这个怎么理解这里的 36 和 1 呢\n- 现在的母公司，子公司等情况，以及占比\n- 采矿权，这个是啥，有啥门槛之类的吗？\n- 煤炭的  产量、销量、进口量 等可以在国家统计局的数据查询\n","slug":"zhong-guo-shen-hua-init","published":0,"date":"2025-10-14T12:05:29.313Z","updated":"2025-10-14T12:05:29.314Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cmhvrxzqh0001gnmk361d825a","content":"<p>A 股<br>发行股数  1,800,000,000<br>发行价  36.99<br>发行日期 20070925<br>发行后总股本  19,889,620,455</p>\n<ul>\n<li>A  16,491,037,955</li>\n<li>H  3,398,582,500</li>\n</ul>\n<p>业务</p>\n<ul>\n<li>煤炭生产</li>\n<li>电力生产</li>\n<li>热力生产和供应</li>\n<li>相关铁路，港口运输服务（神朔铁路，朔黄铁路，黄骅港和神华天津煤码头）</li>\n</ul>\n<p>专业词汇</p>\n<ul>\n<li>煤炭相关技术词汇</li>\n<li>电力相关技术词汇</li>\n</ul>\n<p>发电设备平均利用小时：统计期间内总发电量与平均发电设备容量的比值，单位为小时。衡量发电厂发电设备利用程度的核心指标。</p>\n<p>本公司是世界领先的、立足于煤炭的综合性能源公司，专注于煤炭和电力业务。主要业务包括煤炭生产、销售，电力生产、热力生产和供应，相关铁路、港口等运输服务。<br>2006 年本公司煤炭产量和销售量分别达到 136.6 百万吨和 171.1 百万吨，是我国最大的煤炭生产企业和销售企业。以 2006 年煤炭销量计，本公司是全球第二大煤炭上市公司。2007 年上半年，本公司煤炭产量和销售量分别达到 76.6 百万吨和 97.8 百万吨。</p>\n<p>本公司拥有由铁路和港口组成的一体化运输网络，为本公司煤炭的生产和销售提供了充分的保障。该一体化运输网络目前包括五条总运营里程为 1367 公里的铁路线和专用海港黄骅港及神话天津港码头。2006 年，黄骅港煤炭下水量达到 79.2 百万吨，成为中国第二大煤炭下水港口。2007 年上半年，黄骅港煤炭下水量达到 39.8 百万吨，神华天津码头煤炭下水量达到 9.2 百万吨。</p>\n<p>本公司拥有高效率、快速发展的电力业务。截至 2006 年 12 月 31 日，本公司控制并运营的 11 家火力发电厂，总装机容量和售电量分别达到了 11960 兆瓦和 517.1 亿千瓦时，从 2004 年至 2006 年年复合增长率分别达到 41.7% 和 20.7%。截至 2007 年 6 月 30 日，本公司电力业务总装机容量和售电量分别达到了 12560 兆和瓦和 337 亿千瓦时。</p>\n<blockquote>\n<p>煤炭产量需要区分是 原煤产量还是商品煤产量。</p>\n</blockquote>\n<p>行业概述</p>\n<ul>\n<li>煤炭行业<br>煤炭是我国最重要的能源。国家统计局统计（这里可以查看每年的用电、用煤数据），2005 年煤炭占我国一次性能源总消费量的 68.9%，2006 年我国燃煤发电机组的发电量站总发电量的 83.2%。我国经济的发展带动了电力需求的快速增长，从而推动了动力煤需求的快速增长。2004 年至2006 年，我国煤炭产量年均符合增长率达 10.3%，2006 年、2007 年上半年我过煤炭总产量分别为 2380 百万吨和 1082 百万吨。</li>\n</ul>\n<p>煤炭是世界上储量最丰富、最经济的能源资源之一。根据 BP 统计概览（这个搞清楚 BP 统计是啥），2006 年全球煤炭产量为 62亿吨，约占世界一次能源消费总量的 28.45.</p>\n<p>由于运输成本相对较高，煤炭，特别是动力煤消费及价格受运输距离影响较大，全球煤炭市场呈现出按地域分割的布局特点，各个地域性市场之间的煤价存在很大差别。在世界各煤炭市场中，澳大利亚和南非等国家煤炭资源丰富但国内需求相对较小，而日本和韩国等国家煤炭需求大但资源匮乏。在煤炭资源匮乏的地区，电厂和其他煤炭用户主要从其他国家或地区购入煤炭，因此煤炭运输至关重要。</p>\n<p>近年来，全球经济持续增长，欧洲各国纷纷以进口煤替代当地煤炭（为什么呢？），且石油及天然气价格大幅波动（煤炭的竞品有哪些？），因此全球煤炭需求也有所增长。</p>\n<p>我国煤炭行业<br>煤炭是我国的基础能源。近年来，我国煤炭产量和消费量都呈较快增长趋势。我国煤炭生产和需求的地理分布不均衡（可以加一张煤矿的分布图？），煤炭行业集中度较低，正处于行业整合阶段（现在的情况？）</p>\n<ul>\n<li>需求和供给<br>根据 BP 统计概览，2006 年，我国是世界上最大的煤炭生产国，也是最大的煤炭消费国。根据国家统计局数据，2006 年我国煤炭产量约为 2380 百万吨，煤炭消费量约为 2370 百万吨，</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>消费量</th>\n<th>产量</th>\n<th>出口量</th>\n<th>进口量</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2004</td>\n<td>1936</td>\n<td>1956</td>\n<td>86.7</td>\n<td>18.6</td>\n</tr>\n<tr>\n<td>2005</td>\n<td>2166</td>\n<td>2190</td>\n<td>71.7</td>\n<td>26.2</td>\n</tr>\n<tr>\n<td>2006</td>\n<td>2370</td>\n<td>2380</td>\n<td>63.3</td>\n<td>38.2</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>受煤炭进出口税率变化，国内煤炭需求旺盛和人民币升值影响，预计中国煤炭未来一定时期内出口量进一步减少，进口量进一步增加。</p>\n<p>发电用煤仍是我国煤炭消费中占主要地位，所占比例超过 50%。钢铁、建材和化工等行业也在煤炭消费中占有相当大的比例。中国煤炭工业协会（可以查看协会相关信息）预计，煤炭构成我国一次能源生产总量主要部分的状况还将长期持续。</p>\n<p>发电 52.6%</p>\n<ul>\n<li>钢铁  17.3%</li>\n<li>建材  14.7%</li>\n<li>化工 5.7% </li>\n<li>其他 9.7%</li>\n</ul>\n<p>在我国，除了大型国有煤炭生产企业以外，还有数量众多的小型企业进行煤炭开采和销售。随着我国工业化进程的不断加快，能源紧缺的问题愈加凸显，安全、环保和煤炭资源合理利用的重要性日益增加。鉴于上述原因，我国政府加快煤炭行业整合的调控力度，促进加快发展大型煤炭基地和大企业集团，坚持整顿关闭小煤矿。国家发改委规划 2007 年底前将 3万吨以下的小煤矿全部关闭（有一定的准入门槛？）。</p>\n<p>根据安监总局（可以查看现在的数据？）的统计数据，2006 年我国最大的 10 家煤炭生产企业的产量综合为 595 百万吨，约占当年国内煤炭总产量的 25.6%。</p>\n<blockquote>\n<p>具体前十的在招股书 85 页有，中国神话是第一</p>\n</blockquote>\n<p>今年来，我国沿海省份的煤炭需求一直很大。但我国约 90% 的煤炭资源和生产能力分布在西部和北部地区，中国煤炭运输呈现“西煤东运”和“北煤南运”的格局。煤炭资源和需求的地理分布不均衡使煤炭运输成为制约我国煤炭行业发展的关键因素。</p>\n<p>2006 年我国煤炭产量最大的五个省区 ：山西 &gt; 内蒙 &gt; 河南 &gt; 陕西 &gt; 山东 （来源国家统计局，可以查看现在的数据）</p>\n<blockquote>\n<p>87 页有各省的煤炭产量和缺口量情况（国家统计局和省统计局）</p>\n</blockquote>\n<p>煤炭运输<br>在我国，将煤炭从西部和北部地区运往东部和南部地区，是煤炭销售的重要途径，对于煤炭行业的发展十分重要（现在还是这样吗？）神朔-朔黄铁路及大秦铁路是我国众多煤炭企业进行长距离运输的主要通道。随着能源需求的增加，煤炭运输能力的不足已经成为制约我国煤炭行业发展的瓶颈。虽然我国政府在增加铁路运力方面做出了很大努力，并将对国铁系统进行进一步扩能，但目前仍不能完全满足煤炭运输的需求，运力短缺的局面在近期内仍然难以得到根本性的改变。因而，使得拥有稳定而充足的运输能力的本公司具备了重要的竞争优势。</p>\n<p>在我国，相当部分煤炭需从西部和北部产煤区运输到我国东部港口，装船后经海运销售到华东和华南市场或国际市场，也有部分煤炭通过内河进行运输。我国主要的煤炭运输港包括秦皇岛港、黄骅港、天津港、日照港、连云港和青岛港。其中黄骅港作为本公司专用煤炭运输港口，是我国第二大煤炭港口，2006 年、2007 年上半年，从黄骅港下水的煤炭分别为 79.2 百万吨和 39.8 百万吨。</p>\n<p>从 2004 年 7 月开始，我国煤炭出口必须获得政府配额，只有具有煤炭出口经营权的企业才能申请并取得煤炭出口配额。目前全国只有四家企业具有煤炭出口经营权（这个也是门槛之一，如果出口占比大的话，这个优势还不小），4 家还包括一家本公司非排他代理商。</p>\n<p>亚太市场主要动力煤进口国家及地区为日本、韩国、中国台湾等（现在的出口占比？）2006 年 日本、韩国和中国台湾进口量分列前三位（这个是什么口径的前三？），其中日本动力煤进口量为 91.4 百万吨，同比下降 5%，韩国动力煤进口量为 59 百万吨，同比增长 5.2%；中国台湾动力煤进口量为 57 百万吨，同比增长 3.3%。2006 年，中国动力煤进口量为 10.9 百万吨，同比增长 43.9%。由于进口关税的调整、人民币升值及我国煤炭需求快速增长的影响，预计中国动力煤进口量将进一步增长（这个对国内的煤炭行业是啥影响？表示需求大？）</p>\n<p>亚太市场的动力煤出口国家主要有印度尼西亚、澳大利亚、中国、俄罗斯、南非等。2006 年印度尼西亚动力煤出口 125 百万吨，同比增长 13.6%；澳大利亚动力煤出口 111.6 百万吨，同比增长 4.4%；俄罗斯动力煤对亚洲出口 11 百万吨，与上年持平。受运费高涨影响，南非动力煤出口亚洲地区只有 3 百万吨，同比下降 31%。中国动力煤出口 53.8 百万吨，同比下降 11.5%，下降的主要原因是内需增长（为啥中国有煤炭进口和出口同时存在？赚差价？）</p>\n<p>行业竞争情况</p>\n<ul>\n<li>国内竞争<br>近年来，尽管我国政府积极推动煤炭行业整合，但煤炭行业仍处于较为分散的状态。根据安监总局的统计，2006 年包括本公司在内的我国最大的 10 家煤炭生产商的煤炭产量总和仅占全国总产量的 25.6%；<blockquote>\n<p>88 页有公司 2004 - 2007 年的产量，以及占全国产量的比例</p>\n</blockquote>\n</li>\n</ul>\n<p>本公司煤炭销售量主要受市场需求、自身生产能力和运输能力的影响，在煤炭供应的稳定性、供货的可靠性和及时性、客户服务、煤炭质量和价格等方面都面临来自于国内其他主要动力煤生产商激烈的市场竞争。公司的主要竞争对手为中国中煤能源集团公司、大同煤矿集团公司、衮矿集团有限公司等。由于公司具有一体化运营模式的独特竞争优势和煤炭质量，与公司的主要国内竞争者相比，公司处于有利地位。</p>\n<ul>\n<li>国际竞争<br>公司 2004 年 - 2006年以及 2007 年上半年的煤炭出口量分别是 26.6 百万吨、23.3 百万吨、23.9 百万吨和 12.2 百万吨，分别站同期全国煤炭出口总量的 30.7%，32.5%，37.8%，52.8%。公司主要的出口市场是韩国、中国台湾和日本。2004 - 2006和 2007 上半年，公司出口到这些国家和地区的煤炭分别站公司总出口量的 81.6%，83.3%，77.4%和 91.8%</li>\n</ul>\n<p>在出口方面，公司主要与其他的国内公司竞争，竞争对手主要包括：中国中煤能源集团公司、山西煤炭进口集团公司等，同时公司还与服务于亚太海运动力煤出口市场的海外公司竞争，竞争对手主要包括：BHP Billiton、Rio Tinto 和 Xstrata 公司等。公司在煤炭质量、价格、供应的稳定性、送货及时性和客服服务等方面都面临竞争。公司良好的煤质、具有竞争力的价格、靠近主要出口市场的地理位置、自有一体化的运输体系所保证的稳定供应能力和满足客户特殊需求的服务等构成公司显著的竞争优势。</p>\n<p>影响行业发展的因素</p>\n<ul>\n<li><p>宏观经济<br>随着我国经济持续高速增长，包括煤炭、石油等在内的能源需求增长明显加快，呈现出供不应求的局面。尤其是近几年，随着国民经济的快速发展，煤炭供求矛盾有所体现，煤炭市场价格稳中有升，预期今后几年供求基本平衡，煤炭价格依然处于高位。由于我国富煤、贫油、少气的能源结构特点，煤炭行业已经成为国民经济发展的支柱产业，煤炭需求旺盛的势头在相当时期内不会改变，根据《煤炭工业发展“十一五”规划》（这个可以看最近的规划？）预计 2010 年全国煤炭总需求为 26 亿吨</p>\n</li>\n<li><p>产业政策<br>煤炭、电力、运输是国民经济发展的基础行业，煤炭行业的发展一贯受到政府政策的支持。国家宏观调控和产业政策对于煤炭行业有着至关重要的影响。国家发改委制订的《煤炭工业发展“十一五”规划》，基本确定了加强宏观调控，重视煤炭对国家能源安全的作用，实施建立煤炭大集团、大公司战略，促进资源的合理综合利用，加强保护环境，抓好洁净煤技术的推广应用，发展替代产业，延伸煤炭产业链等内容。</p>\n</li>\n<li><p>环境保护和安全<br>环保问题和安全问题是与煤炭企业生产经营息息相关的两大问题。《煤炭工业发展“十一五”规划》提出：要转变观念、坚持用科学发展观指导煤矿环境保护工作，建立与完善环境管理制度，大力推广使用洁净煤技术、努力建立煤矿环境保护投入机制， 积极推行清洁生产，大力发展环保产业。</p>\n</li>\n</ul>\n<p>任何一个煤矿项目的建设，其安全设计和程序都要经过国家相关部位，特别是环保总局和煤矿安全监察局的审查批准。在建成后投产前，环保总局和煤矿安全监察局还要对环保和安全设施进行竣工验收检查。此外，国家煤矿安全监察局会按照《矿山安全法》和《煤炭安全规程》及其他相关法规对煤矿进行不定期安全检查。没有达到安全规定的煤矿要受到罚款、暂停运营直至关闭的惩罚。</p>\n<ul>\n<li>国际市场<br>随着经济全球化和贸易自由化进程的加快，我国煤炭工业的发展面临着机遇和挑战。加入世界贸易组织后，我国能源供应应将在一个更加开放的体现中进行配置，国际石油和天然气等能源价格的变化，将直接影响国际煤炭市场的供需关系，从而对中国煤炭市场产生影响。<blockquote>\n<p>了解国际石油和天然气的价格变化，以及和煤炭的关系</p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li>进入行业的壁垒<br>进入煤炭行业的主要壁垒是煤炭资源的限制。此外，近年来我国对煤炭行业进行了产业调整，对煤炭生产企业的规模、生产工艺、环保要求、矿井回采率及安全生产等各方面提出了新的行业政策，提高了行业进入门槛。</li>\n</ul>\n<p>— 电力行业<br>电力行业的演变</p>\n<p>自20世纪80年代中期起，我国政府开始开放电力市场，并相继实施了放宽投资限制，鼓励投资以及电厂与电网系统分离等一系列政策，这些政策促进了全国新电厂的开发，电力行业得到了快速发展。<br>2002 年实施的国家电力体制改革中，原国家电力公司发电资源被大体平均分配到五家发电集团公司 — 中国华能集团公司、中国大唐集团公司、中国华电集团公司、中国国电集团公司和中国电力投资集团公司。除中国华能集团公司外，其余四家均为新成立的发电集团公司。</p>\n<p>— 市场发展与供求状况<br>我国的电力消费量近年来增长迅猛。根据国家统计局的统计，2004 年—2006 年间，国内电力消费量的年复合增长率为 13.4%，电力消费量的增长归因于我国工业化进程带来的经济增长和居民生活水平提高。</p>\n<blockquote>\n<p>91 页有 装机容量、发电量和利用小时的相关统计数据<br>可以查看《电力行业年鉴》，《xxx 年全国电力工业统计快报》</p>\n</blockquote>\n<p>据《2006 年全国电力工业统计快报》，2006 年末全国拥有总装机容量为 6.22 亿千瓦，然而我国电厂现有的装机容量仍然无法满足目前的电力需求。我国人均拥有的装机容量和人均电力消费水平相对较低（这个在哪有指标吗？），2006 年分别为473 瓦和 2149 千瓦时，远低于美国和日本（和发达国家比的情况？）。因此，我国电力行业具有持续强劲增长的潜力。</p>\n<p>— 行业竞争情况<br>目前，我国发电市场的竞争主题包括：五大发电集团及包括本公司在内的部分独立发电商。其中，五大发电集团的发电资产规模最大；地方政府拥有的发电资产（含发电类上市公司股权）是地方的支柱型产业；受政策限制，民营资本和外国资本对电力行业的涉足还不深，权益规模页相对较小，但他们看好中国的电力行业（为啥？），近年来在参建电力项目和并购地方性电力企业方面非常活跃（查看建设项目和并购？）</p>\n<p>从全国市场售电主体装机容量看，公司电力装机容量低于五大发电集团，与华润电力控股有限公司、广东省粤电集团有限公司等独立发电商共处于第二梯队的领先位置。截至2007年6月30日，公司电力装机容量达到 1256万千瓦，占全国总装机容量的 2.0%，发电量 360.2 亿千瓦时，占全国发电量的 2.4%</p>\n<blockquote>\n<p>92 页有公司和五大发电集团及全国发电装机容量<br>中国电力企业联合会 情况，信息</p>\n</blockquote>\n<p>2006年度、2007 年上半年，公司发电设备平均利用小时分别为 6302 小时和 2963 小时，继续显著高于同期我国火电平均利用小时 5633 小时和 2638 小时。截至2007年6月30日，公司运营并控制 27 台火电机组，平均单机容量达到 465.2 兆瓦，继续领先国内同业。公司电力业务以其优异的经营业绩、高效的运营和快速的发展，成为我国最有竞争力的电力企业之一。</p>\n<p>— 影响行业发展的因素<br>宏观经济</p>\n<p>近年来我国经济发展速度较快并带动电力需求持续快速增长，我国电力需求结构以工业用电为主（在哪可以看工业用电、民用电的需求情况？）根据 《2006 年全国电力工业统计快报》，2006 年工业耗电量占我国电力消耗量的 74.9%。2004 年至2006 年间，工业耗电量年均增长 14.1%。我国 2004 -2006 年 GDP 增长率、电力消耗量增长率及弹性系数如下</p>\n<blockquote>\n<p>93 页相关数据。<br>GDP 和 电力消费量有啥关系吗？电力消费能否间接的说明发展？等</p>\n</blockquote>\n<p>电力体制改革<br>我国电力行业发展的主要影响因素是目前正在进行的以”厂网分开，竞价上网“为主要内容的电力体制改革。目前电力体制改革已经迈出实质性的步伐，未来的电力市场竞争趋势已经形成，以市场竞争为基础的电价形成机制也在摸索中。多方式的竞价上网和电力供给模式，给电力生产企业带来新的发展挑战，促进电力企业加强投资建设规模和力度，控制成本、提高管理效率以增强在市场中的竞争能力。同时市场化的改革趋势，会进一步促进电力资源的优化配置，促进网间电力输送能力的提高，实现全国电力供求均衡的格局，从而提高整个电力行业的经济效益，进一步激发电力企业的运行活力。</p>\n<p>竞争加剧<br>根据中国电力年鉴统计，2004 年、2005 年及2006 年底，全国发电装机容量分别为 4.42 亿千瓦、5.08亿千瓦和 6.22 亿千瓦，预计 2007 年底将突破 7亿千瓦。而2004 年、2005 年及 2006 年，火电电厂利用小时数逐年下降，分别为 5991、5876、5633 小时，根据中国电力企业联合会统计，2007 年火电电厂利用小时数将继下降至 5200 - 5300 小时，市场竞争进一步加剧</p>\n<blockquote>\n<p>查看现在火电发电站的利用小时数，以及整体的情况<br>为啥会用不满，是因为电没法储藏吗？现在是否有改善？</p>\n</blockquote>\n<p>环保<br>随着中国经济的飞速发展，工业生产与环境保护的矛盾逐渐尖yue，火电比例超过 77.8% 的电力行业面临日益严重的环保压力（现在的情况？）。从 2003 年7 月1 日起实行的《排污费征收使用管理条例》增加了火电企业环保方面的支出；国家鼓励火电长主动进行环保技术改造，对安装并按规定运行烟气脱硫设施的机组提高上网电价；”十一五“期间国家将重点推进火电机组节能、减排工作，加大”上大压下“的力度，加快关停小火电机组。</p>\n<ul>\n<li>进入行业的壁垒<br>行业准入<br>我国新建电源项目需要经过相当严格的审批程序，只有获得了相关的批准，方能开始建设。同时，电监会颁布的《电力监管条例》规定，对发电、输配电企业实行许可证管理，通过许可证来规范市场准入的条件以及准入主体的权利和义务。</li>\n</ul>\n<p>技术壁垒<br>电力生产经营是技术密集型行业，需要有很强的专业技术队伍。发电厂是复杂的电力系统中的一个环节，接入和退出均会对系统产生影响，因此必须协调发电商、电网公司、当地政府和用户等多方利益后，才能够使新的电源项目接入系统。</p>\n<p>环保壁垒<br>火电发电在环保方面的要求较高，必须具有符合国家环境保护标准的技术和设备，取得国家环保部门的批准。</p>\n<p>煤炭及电力行业监管情况</p>\n<ul>\n<li><p>基本情况<br>煤炭和电力行业收到政府的监管。这些监管涉及的范围很广，煤炭行业的监管包括煤炭相关的投资、勘查、开采、生产、销售、贸易、运输和出口，电力行业的监管包括电力相关的投资、发电、定价、调度和安全，设计的主要监管机关包括国家发改委、国土资源部、铁道部、交通部、商务部、环保总局、水利部、国家税务总局、安监总监和电监会等（可以查看这些监管机构对不同公司的情况，公告？）此外，国务院国资委作为国务院授权的国有资产监督管理机构，依法对本公司控股股东神华集团履行出资人职责，并对企业国有资产的保值增值进行监督。</p>\n</li>\n<li><p>煤炭生产、运输相关的主要政策法规<br>煤炭生产设计的相关法规</p>\n</li>\n</ul>\n<p>煤炭生产的主要政策法规包括《中华人民共和国矿山安全法》、《中华人民共和国矿产资源法》、《中华人民共和国煤炭法》、《中华人民共和国价格法》、《中华人民共和国海域使用管理法》《中华人民共和国安全生产法》、《中华人民共和国港口法》、《煤矿企业安全生产许可证实施办法》、《港口经营管理规定》、《中华人民共和国对外贸易法》、《煤炭出口配额管理办法》、《国务院关于投资体制改革的决定》、《关于建立煤电价格联动机制的意见的通知》和《关于核查电煤价格情况的通知》、《煤矿安全规程》、《关于预防煤矿生产安全事故的特别规定》、《国土资源部等部门对矿产资源开发整合意见的通知》、《关于深化煤炭资源有偿使用制度改革试点的实施方案》、《国家安全监管总局关于印发煤矿安全生产“十一五” 规划的通知》、《山西省煤炭可持续发展基金征收管理办法》等。</p>\n<p>《中华人民共和国煤炭法》和《中华人民共和国矿产资源法》是煤炭行业主要监管法规。《煤炭法》自1996年12月1日开始生效。该法设计到煤炭生产过程中的众多方面，包括煤矿资源勘查、煤矿建设的审批、煤炭生产许可证的颁发、安全生产管理、煤炭贸易、煤矿矿区保护、对煤矿企业职工的保护措施以及监督检查等。（能否看到公告或者年报的情况，这样可以查看市场整体的公司情况？）</p>\n<p>根据 1986 年 3 月 19 日颁发、后于 1996 年 8 月 29 日修订的现行《矿产资源法》的规定，我国的矿产资源属于国家所有。《矿产资源法》对采矿许可证的颁发进行了规定。矿产资源的勘查、开采都必须符合《矿产资源法》的规定，并且受国土资源主管部门的监督。</p>\n<p>开采经营<br>根据《煤炭法》和《矿产资源法》的规定，煤炭的勘查和开采必须接受国土资源部和相关省级国土资源部门的监督。一旦获得审批，国土资源部或在当地辖区内负责监督和审查矿井勘查和开采的国土资源主管部门，将为提出申请的区块颁发勘查许可证，或为每一个矿井颁发采矿许可证。采矿许可证的持有人必须按规定向颁发该采矿许可证的相关行政机关递交年度报告。在我国，煤炭生产企业生产煤炭必须为每一矿井取得煤炭生产许可证。此外，国家发改委和相关的省级主管部门每年都会对每个煤矿的生产能力做出审查。煤炭生产经验非本企业生产、加工的煤炭产品，例如从事煤炭贸易，应当对煤炭经营资格审查部门提出申请，取得煤炭经营资格。</p>\n<p>依照国务院于 2004 年7 月19日出台的《国务院关于投资体制改革的决定》，所有国家规划矿区的煤矿开发项目都需要经国家发改委和国土资源部核准，而其他采矿项目则应向地方政府及地方国土资源主管部门提交。国家发改委将重大的采矿项目上报给国务院进行核准。</p>\n<p>按照《煤炭法》和《矿产资源法》，煤炭生产企业必须达到一定的回采率（什么是回采率？）。未达到规定的回采率标准的生产企业可能收到吊销许可证等处罚。</p>\n<p>任何单位或个人在他人拥有开采权的区域内进行任何开采皆属非法开采行为。开采矿产资源给他人的生产或生活造成损失的，应当负责赔偿并采取必要的补救措施。按照《矿产资源法》的实施细则，煤矿经营者在关闭矿井时必须遵照一定的程序，其中包括向原批准开采矿井的主管部门提出关闭申请，并提交闭坑地质报告。</p>\n<p>2006 年 12 月 31 日，国务院办公厅转发了《国土资源等部门对矿产资源开发进行整合意见的通知》，目的是通过整合，使矿山企业“多、小、散”的局面得到明显改变，以小并大，以优并劣，以规模大和技术、管理、装备水平高的矿山作为主体，整合其他矿山。使矿山开发布局趋于合理，矿山企业结构不断优化，矿产资源开采利用水平明显提高，矿山安全生产条件和矿区生态环境得到明显改善，矿产资源对经济社会可持续发展的保障能力明显增强，为中国大型企业的发展创造良好的外部环境。</p>\n<p>2007 年 2 月2日，国土资源部下发了《关于暂停受理煤炭探矿权申请的通知》国家关于 2 年内暂停受理煤炭探矿权申请的规定，避免因煤炭勘查投资过热而出现产能过剩问题，可暂缓目前资源矿业权市场过热的局面。根据我过煤炭资源分别特点，国家已制定和实施了大型煤炭基地规划，优化资源勘探和开发布局，规范资源市场和矿业权管理，加快大型煤矿项目建设，促进大型煤炭基地建设和发展。因此该项政策的出台，对中国神华这样的大型企业集团未来获取资源是有利的。当前，国内大部分探矿权配置给国有的地质勘探单位，本次暂停受理煤炭探矿权的2年内对我公司资源获取不受影响。</p>\n<p>定价<br>在计划经济向市场经济转变的转轨过程中，我国政府逐渐放松了对煤炭定价的管制。1993年1月以前，国家煤炭调配计划内的煤炭价格由政府制订。此后，我国政府放松了大部分煤炭产品价格的控制，转而通过制订国家指导价格的方式继续控制电煤的价格，这种情况一直持续到 2002 年。2001 年7月，原国家计委宣布，从 2002年1月1日起取消对电煤的国家指导价。从 2002年起，煤炭产品的价格主要由市场力量决定。<br>另外，我国今年对煤炭的进出口关税税率进行调整，主要包括《关于调整部分商品出口退税率和增补加工贸易禁止类商品目录的通知》、《关于调整部分商品净出口暂定税率的通知》等。2007年上半年，财政部门发布了“取消煤炭1%进口关税、将焦炭及半焦炭出口关税从5%上调至15%”的公告，自2007年6月1日起生效。</p>\n<p>煤炭运输相关法规<br>煤炭运输相关的主要政策法规包括《中华人民共和国铁路法》、《中华人民共和国港口法》、《&lt;港口设施保安符合证书&gt;年度核验办法》、《港口工程竣工验收办法》、《中华人民共和国港口收费规则（内贸部分）》、《港口统计规则》、《港口建设管理规定》等。</p>\n<p>铁路建设  任何铁路线的建设计划都必须符合全国铁路发展规划，同时征得铁道部或铁道部授权机构的同意。 任何新建或增建的跨省（区、市）铁路线和100公里及以上的铁路线，也需要获得国家发改委的核准。在投入商业运营前，铁路必须由按照国家规定设立的验收机构组织验收。</p>\n<p>运费   国有铁路系统按照国家发改委批准的统一货物运价费率结算运费。按照规定，公司拥有和经营的各条铁路线收取的运费也不得超过由国家发改委批准的最高运费。国家发改委制订的最高运费反映了铁路的建设成本以及合理的投资回报。任何对此最高运费的修改都必须经过国家发改委的批准。</p>\n<p>港口经营  根据 2004 年 1月1日生效的《中华人民共和国港口法》，港口设施建设项目竣工后，应当按照国家有关规定组织验收。经验收合格，方可投入使用。验收合格以后，从事港口经营的企业应当向港口行政管理部门书面申请取得港口经营许可证。交通部依据《港口法》制订的于2004年6月1日生效的《港口经营管理规定》，对港口经营涉及的港口经营许可证的申请及审批、经营管理、监督检查等方面作出了更为详细的规定。此外，依照《投资改革决定》，对于煤炭、矿石、油气的专用泊位，新建港区和年吞吐能力200万吨及以上项目的申请，均需获得国家发改委和交通部核准。</p>\n<p>电力行业主要政策法规<br>电力行业主要政策法规包括：《中华人民共和国电力法》、《关于规范电价管理有关问题的通知》、《电网调度管理条例》、《电价改革方案》、《关于调整电价的通知》、《电力安全生产监管办法》、《国家发展改革委关于东北区域电力市场上网电价改革试点有关问题的通知》、《华东电力市场监管实施办法（试行）》、《关于建立煤电价格联动机制的意见的通知》、《电力监管条例》、《上网电价管理暂行办法》、《输配电价管理暂行办法》、《销售电价管理暂行办法》、《关于华北电网实施煤电价格联动有关问题的通知》、《关于”十一五“ 深化电力体制改革的实施意见》、《新建发电机组进入商业运营管理办法（试行）》等。</p>\n<p>于1996年4月1日生效的《中华人民共和国电力法》，规定了电力行业的监管框架。国家制定《电力法》的主要目的之一是保护投资商、运营商和消费者的合法权益。《电力法》还规定，政府鼓励国内外资本投资于电力行业，并对这些投资活动实行监管。</p>\n<p>国务院于2005年2月15日颁布《电力监管条例》，该条例于2005年5月1日起生效。《电力监管条例》规定了电力行业中诸多方面的监管要求，其中包括：颁发电力业务许可证、对发电商和电网公司实施监管性质的审查，以及违反监管需求的企业的法律责任。</p>\n<p>电厂的批准<br>2004年7月前，新建电力项目和扩容的电厂，都需要按顺序经过国家发改委的三轮审批：1）项目建议书；2）可行性研究报告；3）开工报告。在《投资改革决定》生效之后，所有新建燃煤电厂均须经过国家发改委的核准，除了国家出资建设的电力项目，其它新建电力项目仅需向国家发改委提交项目申请报告，不再经过批准项目建议书、可行性研究报告和开工报告的程序。</p>\n<p>此外，国家发改委还将重大的电厂项目申请提交国务院核准。电监会目前正筹划在电力行业中实行市场准入机制。如果实施市场准入制度，发电厂将被要求取得电力经营许可证，并到电监会或其他的指定机构进行登记。</p>\n<p>定价<br>在《电力法》生效前，电价一般按照国家计划制订，发电厂的大部分发电量按政府制订的国家计划电价出售。自1996年《电力法》生效以来，《电力法》对电力价格的确定作出了原则性的规定。《电力法》规定电价应体现对发电成本的合理补偿和合理投资回报，以便能公平地分担支出并鼓励电厂建设。计划电量和超发电量的上网价格（现在的上网价格怎么定的？），都要经过国家发改委和各省物价部门的审查和批准程序。</p>\n<p>2001年4月23日，原国家发展计划委员会发布了《关于规范电价管理有关问题的通知》，该通知改变了以前上网电价的决定方法。原先定价机制是基于发电厂的成本和固定收益，而改革后的定价机制是基于电厂的经营周期和同一省级电网内的同类电厂的评价成本。对于新建的发电厂，上网电价将按照同一时期在同一地区建设的同类型的先进发电机组的社会平均成本为基础计算。这种平均成本通常考虑到各种因素，包括建设成本、经营和管理费用、维护和修理成本以及利息支出等。</p>\n<p>2003 年6月，电监会在华东和东北地区建立了试点性的区域电力市场，并且试行竞价上网。根据国务院于2003年12月制订的《东北区域电力市场暂行办法的通知》，在东北电力市场上以竞价上网方式销售的电力可以占到该市场上网总电力的 20%。根据电监会于2004年3月30日制订的《华东电力市场监管实施办法（试行）》，自2004年5月起，在华东地区电力市场上以竞价上网方式销售的电力可占到该市场上网总电力的一定比例（现在的竞价上网占比？）。迄今为止的试运行结果显示，由竞价上网确定的平均电价可能会略低于计划电量的平均电价。</p>\n<p>2003 年7月3日，国务院批准了《电价改革方案》，电价改革的长期目标是在进一步改革电力体制的基础上，将电价划分为上网电价、输电价格、配电价格和终端销售电价（现在是啥样的？）；发电、售电价格由市场竞争形成；输电、配电价格有政府指定（现在这个整体的是啥样的？）。同时，建立规范、透明的电价管理制度。2005年出台的《上网电价管理暂行办法》、《输配电价管理暂行办法》和《销售电价管理暂行办法》被作为电价改革方案实施方法。</p>\n<p>2004 年12月，经国务院批准，国家发改委发布了《关于建立煤电价格联动机制意见的通知》（这个现在有啥变化吗？），决定建立煤电价格联动机制。通知指出：为促进电力企业降低成本、提高效率，电力企业要消化 30% 的煤价上涨因素，这意味着电力公司可能通过上调上网电价的方式，向最终用户转移 70% 由于电煤涨价而造成的成本上升。（这里怎么理解 30% 和 70%）根据煤电价格联动机制的意见，国家要建立电煤价格消息系统及指标体系；原则上以不少于 6 个月为一个煤电价格联动周期，若周期内平均煤价比之前一周期变化幅度达到或超过 5%，相应调整电价；如果变化幅度不到 5%，则下一周期累计计算，直到累及变化幅度或超过 5%，进行电价调整，而30%的煤炭价格上涨将由发电企业自行消费。首次煤电价格联动以2004年5月底煤炭企业销售电煤的车板价为基础，根据此后6-11月电煤车板价的平均涨幅，按照煤电价格联动公式测算和调整发电企业上网电价和销售电价。</p>\n<p>2005 年3月28日，国家发改委发布了《上网电价管理暂行办法》（现在的上网价？），为 2003 年7月国务院批准的《电价改革方案》提供了监管准则。</p>\n<p>2005 年 4 月22日，经国务院批准，国家发展改革委员会发出《关于华北电网实施煤电价格联动有关问题的通知》，决定自2005年5月1日起在华北电网实施煤电价格联动措施，疏导突出的电价矛盾，相应调整上网电价和销售电价水平。</p>\n<p>2006 年6月，国家发改委在此调整电价，主要考虑了解决煤价上涨以及铁路运价调整对电价的影响，同时投运烟气脱硫设施导致成本增加而提高上网电价；对于 2006 年之前投产的烟气脱硫设施且尚未在上网电价中考虑脱硫成本的统调燃煤机组，经省级环保部门验收合格并经省级价格主管部门确认后，上网电价每兆瓦时提高人民币15元（含税）。公司未来如果投产新的发电机组，投产后如脱硫设施投入运行，并获省级环保部门验收及省级物价部门确认后，将获得每兆瓦时 15 元的脱硫加价（为啥要脱硫，已经影响成本？）</p>\n<p>电力调度<br>在我国，除了未接入电网的电厂所发出的电量以外，所有的电量都由电网调度，由电网公司拥有并运营的调度中心管理向电网配电。每一个调度中心都必须按照国务院发布的、于1993年11月1日生效的《电网调度管理条例》和用电计划的规定调度电力。</p>\n<p>环境保护相关政策法规<br>环境保护主要政策法规包括：《中华人民共和国环境保护法》、《海洋倾废管理条例实施办法》、《联合国气候变化框架公约》、《中华人民共和国水污染防治法》、《铁路环境保护规定》、《中华人民共和国森林法》、《建设项目环境保护管理条例》、《中华人民共和国森林法实施条例》、《中华人民共和国大气污染防治法》、《森林植被恢复费征收使用管理暂行办法》、《排污费征收使用管理条例》、《中华人民共和国环境影响评价法》、《中华人民共和国土地管理法》、《节能减排综合性工作方案》等。</p>\n<p>风险</p>\n<ul>\n<li>市场风险（煤炭价格波动；产品集中；宏观经济周期性波动）</li>\n<li>经营风险（业务发展依靠于连续有效开发煤炭储量能力的风险；煤炭安全事故的风险；煤炭和电力行业的竞争风险）</li>\n<li>煤炭和电力行业的竞争风险</li>\n<li>自然灾害和日常运营的风险</li>\n<li>长期煤炭供应合同状况和煤炭购买模式变化的风险</li>\n<li>大客户的风险</li>\n<li>运力不足的风险</li>\n<li>公司尚未获得部分土地产权证的风险</li>\n<li>成本上升的风险</li>\n</ul>\n<p>最近几个月 电力 情况（核电、风电、太阳能电发电总量增加，火电有降低的趋势）？</p>\n<p>神华集团 （73.86% 股份）</p>\n<p>煤炭行业竞争</p>\n<ul>\n<li>煤田赋存条件</li>\n<li>煤质煤种</li>\n<li>生产效率</li>\n<li>成本</li>\n<li>配煤能力</li>\n<li>品牌和服务</li>\n</ul>\n<p>电力竞争</p>\n<ul>\n<li>[2007] 五大发电集团（中国华能，中国大唐，中国国电，中国华电和中国电力投资集团）和独立发电商<br> 2006 年底 五大发电集团 总装机容量 39.1%</li>\n<li>业务规模，新项目的开发权</li>\n<li>有利的电量调度（？）和更高的上网价格（？）</li>\n</ul>\n<p>神东煤炭主要业务为煤X（石干）石发电、供暖、供水并向本公司神东矿区提供包括物业管理、环保绿化、工程建设及房地产开发、医疗服务及煤炭投资等业务。<br>神东电力主要包括煤X（石干）石发电、煤矿开采、煤化工、燃料采购及运输等配套业务。</p>\n<p>&lt;发行人的组织架构&gt; 图</p>\n<p>&lt;本公司的控股、参股子公司的情况&gt; 图</p>\n<blockquote>\n<p>本章行业概述部分，煤炭产量如不特殊注明，均指原煤产量；本章其他部分中，煤炭产量如不特殊注明均为商品煤产量。<br>涉及煤炭价格与电力价格时，如不特殊说明，均指不含增值税价格。</p>\n<p>本公司是世界领先的、立足于煤炭的综合性能源公司，专注于煤炭和电力业务。主要业务包括煤炭生产、销售，电力生产、热力生产和供应，相关铁路、港口等运输服务。</p>\n</blockquote>\n<p>Q</p>\n<ul>\n<li>为啥发行后的 A 股和发行股数不一样</li>\n<li>煤分多少种（发电用动力煤，还有其他的哪些？）</li>\n<li>电量调度是啥</li>\n<li>现在的电力上网价格怎么定的</li>\n<li>股权性质（除了国家股，还有哪些）</li>\n<li>上市时，每股 36 元，每股面值 1 元，这个怎么理解这里的 36 和 1 呢</li>\n<li>现在的母公司，子公司等情况，以及占比</li>\n<li>采矿权，这个是啥，有啥门槛之类的吗？</li>\n<li>煤炭的  产量、销量、进口量 等可以在国家统计局的数据查询</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>A 股<br>发行股数  1,800,000,000<br>发行价  36.99<br>发行日期 20070925<br>发行后总股本  19,889,620,455</p>\n<ul>\n<li>A  16,491,037,955</li>\n<li>H  3,398,582,500</li>\n</ul>\n<p>业务</p>\n<ul>\n<li>煤炭生产</li>\n<li>电力生产</li>\n<li>热力生产和供应</li>\n<li>相关铁路，港口运输服务（神朔铁路，朔黄铁路，黄骅港和神华天津煤码头）</li>\n</ul>\n<p>专业词汇</p>\n<ul>\n<li>煤炭相关技术词汇</li>\n<li>电力相关技术词汇</li>\n</ul>\n<p>发电设备平均利用小时：统计期间内总发电量与平均发电设备容量的比值，单位为小时。衡量发电厂发电设备利用程度的核心指标。</p>\n<p>本公司是世界领先的、立足于煤炭的综合性能源公司，专注于煤炭和电力业务。主要业务包括煤炭生产、销售，电力生产、热力生产和供应，相关铁路、港口等运输服务。<br>2006 年本公司煤炭产量和销售量分别达到 136.6 百万吨和 171.1 百万吨，是我国最大的煤炭生产企业和销售企业。以 2006 年煤炭销量计，本公司是全球第二大煤炭上市公司。2007 年上半年，本公司煤炭产量和销售量分别达到 76.6 百万吨和 97.8 百万吨。</p>\n<p>本公司拥有由铁路和港口组成的一体化运输网络，为本公司煤炭的生产和销售提供了充分的保障。该一体化运输网络目前包括五条总运营里程为 1367 公里的铁路线和专用海港黄骅港及神话天津港码头。2006 年，黄骅港煤炭下水量达到 79.2 百万吨，成为中国第二大煤炭下水港口。2007 年上半年，黄骅港煤炭下水量达到 39.8 百万吨，神华天津码头煤炭下水量达到 9.2 百万吨。</p>\n<p>本公司拥有高效率、快速发展的电力业务。截至 2006 年 12 月 31 日，本公司控制并运营的 11 家火力发电厂，总装机容量和售电量分别达到了 11960 兆瓦和 517.1 亿千瓦时，从 2004 年至 2006 年年复合增长率分别达到 41.7% 和 20.7%。截至 2007 年 6 月 30 日，本公司电力业务总装机容量和售电量分别达到了 12560 兆和瓦和 337 亿千瓦时。</p>\n<blockquote>\n<p>煤炭产量需要区分是 原煤产量还是商品煤产量。</p>\n</blockquote>\n<p>行业概述</p>\n<ul>\n<li>煤炭行业<br>煤炭是我国最重要的能源。国家统计局统计（这里可以查看每年的用电、用煤数据），2005 年煤炭占我国一次性能源总消费量的 68.9%，2006 年我国燃煤发电机组的发电量站总发电量的 83.2%。我国经济的发展带动了电力需求的快速增长，从而推动了动力煤需求的快速增长。2004 年至2006 年，我国煤炭产量年均符合增长率达 10.3%，2006 年、2007 年上半年我过煤炭总产量分别为 2380 百万吨和 1082 百万吨。</li>\n</ul>\n<p>煤炭是世界上储量最丰富、最经济的能源资源之一。根据 BP 统计概览（这个搞清楚 BP 统计是啥），2006 年全球煤炭产量为 62亿吨，约占世界一次能源消费总量的 28.45.</p>\n<p>由于运输成本相对较高，煤炭，特别是动力煤消费及价格受运输距离影响较大，全球煤炭市场呈现出按地域分割的布局特点，各个地域性市场之间的煤价存在很大差别。在世界各煤炭市场中，澳大利亚和南非等国家煤炭资源丰富但国内需求相对较小，而日本和韩国等国家煤炭需求大但资源匮乏。在煤炭资源匮乏的地区，电厂和其他煤炭用户主要从其他国家或地区购入煤炭，因此煤炭运输至关重要。</p>\n<p>近年来，全球经济持续增长，欧洲各国纷纷以进口煤替代当地煤炭（为什么呢？），且石油及天然气价格大幅波动（煤炭的竞品有哪些？），因此全球煤炭需求也有所增长。</p>\n<p>我国煤炭行业<br>煤炭是我国的基础能源。近年来，我国煤炭产量和消费量都呈较快增长趋势。我国煤炭生产和需求的地理分布不均衡（可以加一张煤矿的分布图？），煤炭行业集中度较低，正处于行业整合阶段（现在的情况？）</p>\n<ul>\n<li>需求和供给<br>根据 BP 统计概览，2006 年，我国是世界上最大的煤炭生产国，也是最大的煤炭消费国。根据国家统计局数据，2006 年我国煤炭产量约为 2380 百万吨，煤炭消费量约为 2370 百万吨，</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>年份</th>\n<th>消费量</th>\n<th>产量</th>\n<th>出口量</th>\n<th>进口量</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2004</td>\n<td>1936</td>\n<td>1956</td>\n<td>86.7</td>\n<td>18.6</td>\n</tr>\n<tr>\n<td>2005</td>\n<td>2166</td>\n<td>2190</td>\n<td>71.7</td>\n<td>26.2</td>\n</tr>\n<tr>\n<td>2006</td>\n<td>2370</td>\n<td>2380</td>\n<td>63.3</td>\n<td>38.2</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>受煤炭进出口税率变化，国内煤炭需求旺盛和人民币升值影响，预计中国煤炭未来一定时期内出口量进一步减少，进口量进一步增加。</p>\n<p>发电用煤仍是我国煤炭消费中占主要地位，所占比例超过 50%。钢铁、建材和化工等行业也在煤炭消费中占有相当大的比例。中国煤炭工业协会（可以查看协会相关信息）预计，煤炭构成我国一次能源生产总量主要部分的状况还将长期持续。</p>\n<p>发电 52.6%</p>\n<ul>\n<li>钢铁  17.3%</li>\n<li>建材  14.7%</li>\n<li>化工 5.7% </li>\n<li>其他 9.7%</li>\n</ul>\n<p>在我国，除了大型国有煤炭生产企业以外，还有数量众多的小型企业进行煤炭开采和销售。随着我国工业化进程的不断加快，能源紧缺的问题愈加凸显，安全、环保和煤炭资源合理利用的重要性日益增加。鉴于上述原因，我国政府加快煤炭行业整合的调控力度，促进加快发展大型煤炭基地和大企业集团，坚持整顿关闭小煤矿。国家发改委规划 2007 年底前将 3万吨以下的小煤矿全部关闭（有一定的准入门槛？）。</p>\n<p>根据安监总局（可以查看现在的数据？）的统计数据，2006 年我国最大的 10 家煤炭生产企业的产量综合为 595 百万吨，约占当年国内煤炭总产量的 25.6%。</p>\n<blockquote>\n<p>具体前十的在招股书 85 页有，中国神话是第一</p>\n</blockquote>\n<p>今年来，我国沿海省份的煤炭需求一直很大。但我国约 90% 的煤炭资源和生产能力分布在西部和北部地区，中国煤炭运输呈现“西煤东运”和“北煤南运”的格局。煤炭资源和需求的地理分布不均衡使煤炭运输成为制约我国煤炭行业发展的关键因素。</p>\n<p>2006 年我国煤炭产量最大的五个省区 ：山西 &gt; 内蒙 &gt; 河南 &gt; 陕西 &gt; 山东 （来源国家统计局，可以查看现在的数据）</p>\n<blockquote>\n<p>87 页有各省的煤炭产量和缺口量情况（国家统计局和省统计局）</p>\n</blockquote>\n<p>煤炭运输<br>在我国，将煤炭从西部和北部地区运往东部和南部地区，是煤炭销售的重要途径，对于煤炭行业的发展十分重要（现在还是这样吗？）神朔-朔黄铁路及大秦铁路是我国众多煤炭企业进行长距离运输的主要通道。随着能源需求的增加，煤炭运输能力的不足已经成为制约我国煤炭行业发展的瓶颈。虽然我国政府在增加铁路运力方面做出了很大努力，并将对国铁系统进行进一步扩能，但目前仍不能完全满足煤炭运输的需求，运力短缺的局面在近期内仍然难以得到根本性的改变。因而，使得拥有稳定而充足的运输能力的本公司具备了重要的竞争优势。</p>\n<p>在我国，相当部分煤炭需从西部和北部产煤区运输到我国东部港口，装船后经海运销售到华东和华南市场或国际市场，也有部分煤炭通过内河进行运输。我国主要的煤炭运输港包括秦皇岛港、黄骅港、天津港、日照港、连云港和青岛港。其中黄骅港作为本公司专用煤炭运输港口，是我国第二大煤炭港口，2006 年、2007 年上半年，从黄骅港下水的煤炭分别为 79.2 百万吨和 39.8 百万吨。</p>\n<p>从 2004 年 7 月开始，我国煤炭出口必须获得政府配额，只有具有煤炭出口经营权的企业才能申请并取得煤炭出口配额。目前全国只有四家企业具有煤炭出口经营权（这个也是门槛之一，如果出口占比大的话，这个优势还不小），4 家还包括一家本公司非排他代理商。</p>\n<p>亚太市场主要动力煤进口国家及地区为日本、韩国、中国台湾等（现在的出口占比？）2006 年 日本、韩国和中国台湾进口量分列前三位（这个是什么口径的前三？），其中日本动力煤进口量为 91.4 百万吨，同比下降 5%，韩国动力煤进口量为 59 百万吨，同比增长 5.2%；中国台湾动力煤进口量为 57 百万吨，同比增长 3.3%。2006 年，中国动力煤进口量为 10.9 百万吨，同比增长 43.9%。由于进口关税的调整、人民币升值及我国煤炭需求快速增长的影响，预计中国动力煤进口量将进一步增长（这个对国内的煤炭行业是啥影响？表示需求大？）</p>\n<p>亚太市场的动力煤出口国家主要有印度尼西亚、澳大利亚、中国、俄罗斯、南非等。2006 年印度尼西亚动力煤出口 125 百万吨，同比增长 13.6%；澳大利亚动力煤出口 111.6 百万吨，同比增长 4.4%；俄罗斯动力煤对亚洲出口 11 百万吨，与上年持平。受运费高涨影响，南非动力煤出口亚洲地区只有 3 百万吨，同比下降 31%。中国动力煤出口 53.8 百万吨，同比下降 11.5%，下降的主要原因是内需增长（为啥中国有煤炭进口和出口同时存在？赚差价？）</p>\n<p>行业竞争情况</p>\n<ul>\n<li>国内竞争<br>近年来，尽管我国政府积极推动煤炭行业整合，但煤炭行业仍处于较为分散的状态。根据安监总局的统计，2006 年包括本公司在内的我国最大的 10 家煤炭生产商的煤炭产量总和仅占全国总产量的 25.6%；<blockquote>\n<p>88 页有公司 2004 - 2007 年的产量，以及占全国产量的比例</p>\n</blockquote>\n</li>\n</ul>\n<p>本公司煤炭销售量主要受市场需求、自身生产能力和运输能力的影响，在煤炭供应的稳定性、供货的可靠性和及时性、客户服务、煤炭质量和价格等方面都面临来自于国内其他主要动力煤生产商激烈的市场竞争。公司的主要竞争对手为中国中煤能源集团公司、大同煤矿集团公司、衮矿集团有限公司等。由于公司具有一体化运营模式的独特竞争优势和煤炭质量，与公司的主要国内竞争者相比，公司处于有利地位。</p>\n<ul>\n<li>国际竞争<br>公司 2004 年 - 2006年以及 2007 年上半年的煤炭出口量分别是 26.6 百万吨、23.3 百万吨、23.9 百万吨和 12.2 百万吨，分别站同期全国煤炭出口总量的 30.7%，32.5%，37.8%，52.8%。公司主要的出口市场是韩国、中国台湾和日本。2004 - 2006和 2007 上半年，公司出口到这些国家和地区的煤炭分别站公司总出口量的 81.6%，83.3%，77.4%和 91.8%</li>\n</ul>\n<p>在出口方面，公司主要与其他的国内公司竞争，竞争对手主要包括：中国中煤能源集团公司、山西煤炭进口集团公司等，同时公司还与服务于亚太海运动力煤出口市场的海外公司竞争，竞争对手主要包括：BHP Billiton、Rio Tinto 和 Xstrata 公司等。公司在煤炭质量、价格、供应的稳定性、送货及时性和客服服务等方面都面临竞争。公司良好的煤质、具有竞争力的价格、靠近主要出口市场的地理位置、自有一体化的运输体系所保证的稳定供应能力和满足客户特殊需求的服务等构成公司显著的竞争优势。</p>\n<p>影响行业发展的因素</p>\n<ul>\n<li><p>宏观经济<br>随着我国经济持续高速增长，包括煤炭、石油等在内的能源需求增长明显加快，呈现出供不应求的局面。尤其是近几年，随着国民经济的快速发展，煤炭供求矛盾有所体现，煤炭市场价格稳中有升，预期今后几年供求基本平衡，煤炭价格依然处于高位。由于我国富煤、贫油、少气的能源结构特点，煤炭行业已经成为国民经济发展的支柱产业，煤炭需求旺盛的势头在相当时期内不会改变，根据《煤炭工业发展“十一五”规划》（这个可以看最近的规划？）预计 2010 年全国煤炭总需求为 26 亿吨</p>\n</li>\n<li><p>产业政策<br>煤炭、电力、运输是国民经济发展的基础行业，煤炭行业的发展一贯受到政府政策的支持。国家宏观调控和产业政策对于煤炭行业有着至关重要的影响。国家发改委制订的《煤炭工业发展“十一五”规划》，基本确定了加强宏观调控，重视煤炭对国家能源安全的作用，实施建立煤炭大集团、大公司战略，促进资源的合理综合利用，加强保护环境，抓好洁净煤技术的推广应用，发展替代产业，延伸煤炭产业链等内容。</p>\n</li>\n<li><p>环境保护和安全<br>环保问题和安全问题是与煤炭企业生产经营息息相关的两大问题。《煤炭工业发展“十一五”规划》提出：要转变观念、坚持用科学发展观指导煤矿环境保护工作，建立与完善环境管理制度，大力推广使用洁净煤技术、努力建立煤矿环境保护投入机制， 积极推行清洁生产，大力发展环保产业。</p>\n</li>\n</ul>\n<p>任何一个煤矿项目的建设，其安全设计和程序都要经过国家相关部位，特别是环保总局和煤矿安全监察局的审查批准。在建成后投产前，环保总局和煤矿安全监察局还要对环保和安全设施进行竣工验收检查。此外，国家煤矿安全监察局会按照《矿山安全法》和《煤炭安全规程》及其他相关法规对煤矿进行不定期安全检查。没有达到安全规定的煤矿要受到罚款、暂停运营直至关闭的惩罚。</p>\n<ul>\n<li>国际市场<br>随着经济全球化和贸易自由化进程的加快，我国煤炭工业的发展面临着机遇和挑战。加入世界贸易组织后，我国能源供应应将在一个更加开放的体现中进行配置，国际石油和天然气等能源价格的变化，将直接影响国际煤炭市场的供需关系，从而对中国煤炭市场产生影响。<blockquote>\n<p>了解国际石油和天然气的价格变化，以及和煤炭的关系</p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li>进入行业的壁垒<br>进入煤炭行业的主要壁垒是煤炭资源的限制。此外，近年来我国对煤炭行业进行了产业调整，对煤炭生产企业的规模、生产工艺、环保要求、矿井回采率及安全生产等各方面提出了新的行业政策，提高了行业进入门槛。</li>\n</ul>\n<p>— 电力行业<br>电力行业的演变</p>\n<p>自20世纪80年代中期起，我国政府开始开放电力市场，并相继实施了放宽投资限制，鼓励投资以及电厂与电网系统分离等一系列政策，这些政策促进了全国新电厂的开发，电力行业得到了快速发展。<br>2002 年实施的国家电力体制改革中，原国家电力公司发电资源被大体平均分配到五家发电集团公司 — 中国华能集团公司、中国大唐集团公司、中国华电集团公司、中国国电集团公司和中国电力投资集团公司。除中国华能集团公司外，其余四家均为新成立的发电集团公司。</p>\n<p>— 市场发展与供求状况<br>我国的电力消费量近年来增长迅猛。根据国家统计局的统计，2004 年—2006 年间，国内电力消费量的年复合增长率为 13.4%，电力消费量的增长归因于我国工业化进程带来的经济增长和居民生活水平提高。</p>\n<blockquote>\n<p>91 页有 装机容量、发电量和利用小时的相关统计数据<br>可以查看《电力行业年鉴》，《xxx 年全国电力工业统计快报》</p>\n</blockquote>\n<p>据《2006 年全国电力工业统计快报》，2006 年末全国拥有总装机容量为 6.22 亿千瓦，然而我国电厂现有的装机容量仍然无法满足目前的电力需求。我国人均拥有的装机容量和人均电力消费水平相对较低（这个在哪有指标吗？），2006 年分别为473 瓦和 2149 千瓦时，远低于美国和日本（和发达国家比的情况？）。因此，我国电力行业具有持续强劲增长的潜力。</p>\n<p>— 行业竞争情况<br>目前，我国发电市场的竞争主题包括：五大发电集团及包括本公司在内的部分独立发电商。其中，五大发电集团的发电资产规模最大；地方政府拥有的发电资产（含发电类上市公司股权）是地方的支柱型产业；受政策限制，民营资本和外国资本对电力行业的涉足还不深，权益规模页相对较小，但他们看好中国的电力行业（为啥？），近年来在参建电力项目和并购地方性电力企业方面非常活跃（查看建设项目和并购？）</p>\n<p>从全国市场售电主体装机容量看，公司电力装机容量低于五大发电集团，与华润电力控股有限公司、广东省粤电集团有限公司等独立发电商共处于第二梯队的领先位置。截至2007年6月30日，公司电力装机容量达到 1256万千瓦，占全国总装机容量的 2.0%，发电量 360.2 亿千瓦时，占全国发电量的 2.4%</p>\n<blockquote>\n<p>92 页有公司和五大发电集团及全国发电装机容量<br>中国电力企业联合会 情况，信息</p>\n</blockquote>\n<p>2006年度、2007 年上半年，公司发电设备平均利用小时分别为 6302 小时和 2963 小时，继续显著高于同期我国火电平均利用小时 5633 小时和 2638 小时。截至2007年6月30日，公司运营并控制 27 台火电机组，平均单机容量达到 465.2 兆瓦，继续领先国内同业。公司电力业务以其优异的经营业绩、高效的运营和快速的发展，成为我国最有竞争力的电力企业之一。</p>\n<p>— 影响行业发展的因素<br>宏观经济</p>\n<p>近年来我国经济发展速度较快并带动电力需求持续快速增长，我国电力需求结构以工业用电为主（在哪可以看工业用电、民用电的需求情况？）根据 《2006 年全国电力工业统计快报》，2006 年工业耗电量占我国电力消耗量的 74.9%。2004 年至2006 年间，工业耗电量年均增长 14.1%。我国 2004 -2006 年 GDP 增长率、电力消耗量增长率及弹性系数如下</p>\n<blockquote>\n<p>93 页相关数据。<br>GDP 和 电力消费量有啥关系吗？电力消费能否间接的说明发展？等</p>\n</blockquote>\n<p>电力体制改革<br>我国电力行业发展的主要影响因素是目前正在进行的以”厂网分开，竞价上网“为主要内容的电力体制改革。目前电力体制改革已经迈出实质性的步伐，未来的电力市场竞争趋势已经形成，以市场竞争为基础的电价形成机制也在摸索中。多方式的竞价上网和电力供给模式，给电力生产企业带来新的发展挑战，促进电力企业加强投资建设规模和力度，控制成本、提高管理效率以增强在市场中的竞争能力。同时市场化的改革趋势，会进一步促进电力资源的优化配置，促进网间电力输送能力的提高，实现全国电力供求均衡的格局，从而提高整个电力行业的经济效益，进一步激发电力企业的运行活力。</p>\n<p>竞争加剧<br>根据中国电力年鉴统计，2004 年、2005 年及2006 年底，全国发电装机容量分别为 4.42 亿千瓦、5.08亿千瓦和 6.22 亿千瓦，预计 2007 年底将突破 7亿千瓦。而2004 年、2005 年及 2006 年，火电电厂利用小时数逐年下降，分别为 5991、5876、5633 小时，根据中国电力企业联合会统计，2007 年火电电厂利用小时数将继下降至 5200 - 5300 小时，市场竞争进一步加剧</p>\n<blockquote>\n<p>查看现在火电发电站的利用小时数，以及整体的情况<br>为啥会用不满，是因为电没法储藏吗？现在是否有改善？</p>\n</blockquote>\n<p>环保<br>随着中国经济的飞速发展，工业生产与环境保护的矛盾逐渐尖yue，火电比例超过 77.8% 的电力行业面临日益严重的环保压力（现在的情况？）。从 2003 年7 月1 日起实行的《排污费征收使用管理条例》增加了火电企业环保方面的支出；国家鼓励火电长主动进行环保技术改造，对安装并按规定运行烟气脱硫设施的机组提高上网电价；”十一五“期间国家将重点推进火电机组节能、减排工作，加大”上大压下“的力度，加快关停小火电机组。</p>\n<ul>\n<li>进入行业的壁垒<br>行业准入<br>我国新建电源项目需要经过相当严格的审批程序，只有获得了相关的批准，方能开始建设。同时，电监会颁布的《电力监管条例》规定，对发电、输配电企业实行许可证管理，通过许可证来规范市场准入的条件以及准入主体的权利和义务。</li>\n</ul>\n<p>技术壁垒<br>电力生产经营是技术密集型行业，需要有很强的专业技术队伍。发电厂是复杂的电力系统中的一个环节，接入和退出均会对系统产生影响，因此必须协调发电商、电网公司、当地政府和用户等多方利益后，才能够使新的电源项目接入系统。</p>\n<p>环保壁垒<br>火电发电在环保方面的要求较高，必须具有符合国家环境保护标准的技术和设备，取得国家环保部门的批准。</p>\n<p>煤炭及电力行业监管情况</p>\n<ul>\n<li><p>基本情况<br>煤炭和电力行业收到政府的监管。这些监管涉及的范围很广，煤炭行业的监管包括煤炭相关的投资、勘查、开采、生产、销售、贸易、运输和出口，电力行业的监管包括电力相关的投资、发电、定价、调度和安全，设计的主要监管机关包括国家发改委、国土资源部、铁道部、交通部、商务部、环保总局、水利部、国家税务总局、安监总监和电监会等（可以查看这些监管机构对不同公司的情况，公告？）此外，国务院国资委作为国务院授权的国有资产监督管理机构，依法对本公司控股股东神华集团履行出资人职责，并对企业国有资产的保值增值进行监督。</p>\n</li>\n<li><p>煤炭生产、运输相关的主要政策法规<br>煤炭生产设计的相关法规</p>\n</li>\n</ul>\n<p>煤炭生产的主要政策法规包括《中华人民共和国矿山安全法》、《中华人民共和国矿产资源法》、《中华人民共和国煤炭法》、《中华人民共和国价格法》、《中华人民共和国海域使用管理法》《中华人民共和国安全生产法》、《中华人民共和国港口法》、《煤矿企业安全生产许可证实施办法》、《港口经营管理规定》、《中华人民共和国对外贸易法》、《煤炭出口配额管理办法》、《国务院关于投资体制改革的决定》、《关于建立煤电价格联动机制的意见的通知》和《关于核查电煤价格情况的通知》、《煤矿安全规程》、《关于预防煤矿生产安全事故的特别规定》、《国土资源部等部门对矿产资源开发整合意见的通知》、《关于深化煤炭资源有偿使用制度改革试点的实施方案》、《国家安全监管总局关于印发煤矿安全生产“十一五” 规划的通知》、《山西省煤炭可持续发展基金征收管理办法》等。</p>\n<p>《中华人民共和国煤炭法》和《中华人民共和国矿产资源法》是煤炭行业主要监管法规。《煤炭法》自1996年12月1日开始生效。该法设计到煤炭生产过程中的众多方面，包括煤矿资源勘查、煤矿建设的审批、煤炭生产许可证的颁发、安全生产管理、煤炭贸易、煤矿矿区保护、对煤矿企业职工的保护措施以及监督检查等。（能否看到公告或者年报的情况，这样可以查看市场整体的公司情况？）</p>\n<p>根据 1986 年 3 月 19 日颁发、后于 1996 年 8 月 29 日修订的现行《矿产资源法》的规定，我国的矿产资源属于国家所有。《矿产资源法》对采矿许可证的颁发进行了规定。矿产资源的勘查、开采都必须符合《矿产资源法》的规定，并且受国土资源主管部门的监督。</p>\n<p>开采经营<br>根据《煤炭法》和《矿产资源法》的规定，煤炭的勘查和开采必须接受国土资源部和相关省级国土资源部门的监督。一旦获得审批，国土资源部或在当地辖区内负责监督和审查矿井勘查和开采的国土资源主管部门，将为提出申请的区块颁发勘查许可证，或为每一个矿井颁发采矿许可证。采矿许可证的持有人必须按规定向颁发该采矿许可证的相关行政机关递交年度报告。在我国，煤炭生产企业生产煤炭必须为每一矿井取得煤炭生产许可证。此外，国家发改委和相关的省级主管部门每年都会对每个煤矿的生产能力做出审查。煤炭生产经验非本企业生产、加工的煤炭产品，例如从事煤炭贸易，应当对煤炭经营资格审查部门提出申请，取得煤炭经营资格。</p>\n<p>依照国务院于 2004 年7 月19日出台的《国务院关于投资体制改革的决定》，所有国家规划矿区的煤矿开发项目都需要经国家发改委和国土资源部核准，而其他采矿项目则应向地方政府及地方国土资源主管部门提交。国家发改委将重大的采矿项目上报给国务院进行核准。</p>\n<p>按照《煤炭法》和《矿产资源法》，煤炭生产企业必须达到一定的回采率（什么是回采率？）。未达到规定的回采率标准的生产企业可能收到吊销许可证等处罚。</p>\n<p>任何单位或个人在他人拥有开采权的区域内进行任何开采皆属非法开采行为。开采矿产资源给他人的生产或生活造成损失的，应当负责赔偿并采取必要的补救措施。按照《矿产资源法》的实施细则，煤矿经营者在关闭矿井时必须遵照一定的程序，其中包括向原批准开采矿井的主管部门提出关闭申请，并提交闭坑地质报告。</p>\n<p>2006 年 12 月 31 日，国务院办公厅转发了《国土资源等部门对矿产资源开发进行整合意见的通知》，目的是通过整合，使矿山企业“多、小、散”的局面得到明显改变，以小并大，以优并劣，以规模大和技术、管理、装备水平高的矿山作为主体，整合其他矿山。使矿山开发布局趋于合理，矿山企业结构不断优化，矿产资源开采利用水平明显提高，矿山安全生产条件和矿区生态环境得到明显改善，矿产资源对经济社会可持续发展的保障能力明显增强，为中国大型企业的发展创造良好的外部环境。</p>\n<p>2007 年 2 月2日，国土资源部下发了《关于暂停受理煤炭探矿权申请的通知》国家关于 2 年内暂停受理煤炭探矿权申请的规定，避免因煤炭勘查投资过热而出现产能过剩问题，可暂缓目前资源矿业权市场过热的局面。根据我过煤炭资源分别特点，国家已制定和实施了大型煤炭基地规划，优化资源勘探和开发布局，规范资源市场和矿业权管理，加快大型煤矿项目建设，促进大型煤炭基地建设和发展。因此该项政策的出台，对中国神华这样的大型企业集团未来获取资源是有利的。当前，国内大部分探矿权配置给国有的地质勘探单位，本次暂停受理煤炭探矿权的2年内对我公司资源获取不受影响。</p>\n<p>定价<br>在计划经济向市场经济转变的转轨过程中，我国政府逐渐放松了对煤炭定价的管制。1993年1月以前，国家煤炭调配计划内的煤炭价格由政府制订。此后，我国政府放松了大部分煤炭产品价格的控制，转而通过制订国家指导价格的方式继续控制电煤的价格，这种情况一直持续到 2002 年。2001 年7月，原国家计委宣布，从 2002年1月1日起取消对电煤的国家指导价。从 2002年起，煤炭产品的价格主要由市场力量决定。<br>另外，我国今年对煤炭的进出口关税税率进行调整，主要包括《关于调整部分商品出口退税率和增补加工贸易禁止类商品目录的通知》、《关于调整部分商品净出口暂定税率的通知》等。2007年上半年，财政部门发布了“取消煤炭1%进口关税、将焦炭及半焦炭出口关税从5%上调至15%”的公告，自2007年6月1日起生效。</p>\n<p>煤炭运输相关法规<br>煤炭运输相关的主要政策法规包括《中华人民共和国铁路法》、《中华人民共和国港口法》、《&lt;港口设施保安符合证书&gt;年度核验办法》、《港口工程竣工验收办法》、《中华人民共和国港口收费规则（内贸部分）》、《港口统计规则》、《港口建设管理规定》等。</p>\n<p>铁路建设  任何铁路线的建设计划都必须符合全国铁路发展规划，同时征得铁道部或铁道部授权机构的同意。 任何新建或增建的跨省（区、市）铁路线和100公里及以上的铁路线，也需要获得国家发改委的核准。在投入商业运营前，铁路必须由按照国家规定设立的验收机构组织验收。</p>\n<p>运费   国有铁路系统按照国家发改委批准的统一货物运价费率结算运费。按照规定，公司拥有和经营的各条铁路线收取的运费也不得超过由国家发改委批准的最高运费。国家发改委制订的最高运费反映了铁路的建设成本以及合理的投资回报。任何对此最高运费的修改都必须经过国家发改委的批准。</p>\n<p>港口经营  根据 2004 年 1月1日生效的《中华人民共和国港口法》，港口设施建设项目竣工后，应当按照国家有关规定组织验收。经验收合格，方可投入使用。验收合格以后，从事港口经营的企业应当向港口行政管理部门书面申请取得港口经营许可证。交通部依据《港口法》制订的于2004年6月1日生效的《港口经营管理规定》，对港口经营涉及的港口经营许可证的申请及审批、经营管理、监督检查等方面作出了更为详细的规定。此外，依照《投资改革决定》，对于煤炭、矿石、油气的专用泊位，新建港区和年吞吐能力200万吨及以上项目的申请，均需获得国家发改委和交通部核准。</p>\n<p>电力行业主要政策法规<br>电力行业主要政策法规包括：《中华人民共和国电力法》、《关于规范电价管理有关问题的通知》、《电网调度管理条例》、《电价改革方案》、《关于调整电价的通知》、《电力安全生产监管办法》、《国家发展改革委关于东北区域电力市场上网电价改革试点有关问题的通知》、《华东电力市场监管实施办法（试行）》、《关于建立煤电价格联动机制的意见的通知》、《电力监管条例》、《上网电价管理暂行办法》、《输配电价管理暂行办法》、《销售电价管理暂行办法》、《关于华北电网实施煤电价格联动有关问题的通知》、《关于”十一五“ 深化电力体制改革的实施意见》、《新建发电机组进入商业运营管理办法（试行）》等。</p>\n<p>于1996年4月1日生效的《中华人民共和国电力法》，规定了电力行业的监管框架。国家制定《电力法》的主要目的之一是保护投资商、运营商和消费者的合法权益。《电力法》还规定，政府鼓励国内外资本投资于电力行业，并对这些投资活动实行监管。</p>\n<p>国务院于2005年2月15日颁布《电力监管条例》，该条例于2005年5月1日起生效。《电力监管条例》规定了电力行业中诸多方面的监管要求，其中包括：颁发电力业务许可证、对发电商和电网公司实施监管性质的审查，以及违反监管需求的企业的法律责任。</p>\n<p>电厂的批准<br>2004年7月前，新建电力项目和扩容的电厂，都需要按顺序经过国家发改委的三轮审批：1）项目建议书；2）可行性研究报告；3）开工报告。在《投资改革决定》生效之后，所有新建燃煤电厂均须经过国家发改委的核准，除了国家出资建设的电力项目，其它新建电力项目仅需向国家发改委提交项目申请报告，不再经过批准项目建议书、可行性研究报告和开工报告的程序。</p>\n<p>此外，国家发改委还将重大的电厂项目申请提交国务院核准。电监会目前正筹划在电力行业中实行市场准入机制。如果实施市场准入制度，发电厂将被要求取得电力经营许可证，并到电监会或其他的指定机构进行登记。</p>\n<p>定价<br>在《电力法》生效前，电价一般按照国家计划制订，发电厂的大部分发电量按政府制订的国家计划电价出售。自1996年《电力法》生效以来，《电力法》对电力价格的确定作出了原则性的规定。《电力法》规定电价应体现对发电成本的合理补偿和合理投资回报，以便能公平地分担支出并鼓励电厂建设。计划电量和超发电量的上网价格（现在的上网价格怎么定的？），都要经过国家发改委和各省物价部门的审查和批准程序。</p>\n<p>2001年4月23日，原国家发展计划委员会发布了《关于规范电价管理有关问题的通知》，该通知改变了以前上网电价的决定方法。原先定价机制是基于发电厂的成本和固定收益，而改革后的定价机制是基于电厂的经营周期和同一省级电网内的同类电厂的评价成本。对于新建的发电厂，上网电价将按照同一时期在同一地区建设的同类型的先进发电机组的社会平均成本为基础计算。这种平均成本通常考虑到各种因素，包括建设成本、经营和管理费用、维护和修理成本以及利息支出等。</p>\n<p>2003 年6月，电监会在华东和东北地区建立了试点性的区域电力市场，并且试行竞价上网。根据国务院于2003年12月制订的《东北区域电力市场暂行办法的通知》，在东北电力市场上以竞价上网方式销售的电力可以占到该市场上网总电力的 20%。根据电监会于2004年3月30日制订的《华东电力市场监管实施办法（试行）》，自2004年5月起，在华东地区电力市场上以竞价上网方式销售的电力可占到该市场上网总电力的一定比例（现在的竞价上网占比？）。迄今为止的试运行结果显示，由竞价上网确定的平均电价可能会略低于计划电量的平均电价。</p>\n<p>2003 年7月3日，国务院批准了《电价改革方案》，电价改革的长期目标是在进一步改革电力体制的基础上，将电价划分为上网电价、输电价格、配电价格和终端销售电价（现在是啥样的？）；发电、售电价格由市场竞争形成；输电、配电价格有政府指定（现在这个整体的是啥样的？）。同时，建立规范、透明的电价管理制度。2005年出台的《上网电价管理暂行办法》、《输配电价管理暂行办法》和《销售电价管理暂行办法》被作为电价改革方案实施方法。</p>\n<p>2004 年12月，经国务院批准，国家发改委发布了《关于建立煤电价格联动机制意见的通知》（这个现在有啥变化吗？），决定建立煤电价格联动机制。通知指出：为促进电力企业降低成本、提高效率，电力企业要消化 30% 的煤价上涨因素，这意味着电力公司可能通过上调上网电价的方式，向最终用户转移 70% 由于电煤涨价而造成的成本上升。（这里怎么理解 30% 和 70%）根据煤电价格联动机制的意见，国家要建立电煤价格消息系统及指标体系；原则上以不少于 6 个月为一个煤电价格联动周期，若周期内平均煤价比之前一周期变化幅度达到或超过 5%，相应调整电价；如果变化幅度不到 5%，则下一周期累计计算，直到累及变化幅度或超过 5%，进行电价调整，而30%的煤炭价格上涨将由发电企业自行消费。首次煤电价格联动以2004年5月底煤炭企业销售电煤的车板价为基础，根据此后6-11月电煤车板价的平均涨幅，按照煤电价格联动公式测算和调整发电企业上网电价和销售电价。</p>\n<p>2005 年3月28日，国家发改委发布了《上网电价管理暂行办法》（现在的上网价？），为 2003 年7月国务院批准的《电价改革方案》提供了监管准则。</p>\n<p>2005 年 4 月22日，经国务院批准，国家发展改革委员会发出《关于华北电网实施煤电价格联动有关问题的通知》，决定自2005年5月1日起在华北电网实施煤电价格联动措施，疏导突出的电价矛盾，相应调整上网电价和销售电价水平。</p>\n<p>2006 年6月，国家发改委在此调整电价，主要考虑了解决煤价上涨以及铁路运价调整对电价的影响，同时投运烟气脱硫设施导致成本增加而提高上网电价；对于 2006 年之前投产的烟气脱硫设施且尚未在上网电价中考虑脱硫成本的统调燃煤机组，经省级环保部门验收合格并经省级价格主管部门确认后，上网电价每兆瓦时提高人民币15元（含税）。公司未来如果投产新的发电机组，投产后如脱硫设施投入运行，并获省级环保部门验收及省级物价部门确认后，将获得每兆瓦时 15 元的脱硫加价（为啥要脱硫，已经影响成本？）</p>\n<p>电力调度<br>在我国，除了未接入电网的电厂所发出的电量以外，所有的电量都由电网调度，由电网公司拥有并运营的调度中心管理向电网配电。每一个调度中心都必须按照国务院发布的、于1993年11月1日生效的《电网调度管理条例》和用电计划的规定调度电力。</p>\n<p>环境保护相关政策法规<br>环境保护主要政策法规包括：《中华人民共和国环境保护法》、《海洋倾废管理条例实施办法》、《联合国气候变化框架公约》、《中华人民共和国水污染防治法》、《铁路环境保护规定》、《中华人民共和国森林法》、《建设项目环境保护管理条例》、《中华人民共和国森林法实施条例》、《中华人民共和国大气污染防治法》、《森林植被恢复费征收使用管理暂行办法》、《排污费征收使用管理条例》、《中华人民共和国环境影响评价法》、《中华人民共和国土地管理法》、《节能减排综合性工作方案》等。</p>\n<p>风险</p>\n<ul>\n<li>市场风险（煤炭价格波动；产品集中；宏观经济周期性波动）</li>\n<li>经营风险（业务发展依靠于连续有效开发煤炭储量能力的风险；煤炭安全事故的风险；煤炭和电力行业的竞争风险）</li>\n<li>煤炭和电力行业的竞争风险</li>\n<li>自然灾害和日常运营的风险</li>\n<li>长期煤炭供应合同状况和煤炭购买模式变化的风险</li>\n<li>大客户的风险</li>\n<li>运力不足的风险</li>\n<li>公司尚未获得部分土地产权证的风险</li>\n<li>成本上升的风险</li>\n</ul>\n<p>最近几个月 电力 情况（核电、风电、太阳能电发电总量增加，火电有降低的趋势）？</p>\n<p>神华集团 （73.86% 股份）</p>\n<p>煤炭行业竞争</p>\n<ul>\n<li>煤田赋存条件</li>\n<li>煤质煤种</li>\n<li>生产效率</li>\n<li>成本</li>\n<li>配煤能力</li>\n<li>品牌和服务</li>\n</ul>\n<p>电力竞争</p>\n<ul>\n<li>[2007] 五大发电集团（中国华能，中国大唐，中国国电，中国华电和中国电力投资集团）和独立发电商<br> 2006 年底 五大发电集团 总装机容量 39.1%</li>\n<li>业务规模，新项目的开发权</li>\n<li>有利的电量调度（？）和更高的上网价格（？）</li>\n</ul>\n<p>神东煤炭主要业务为煤X（石干）石发电、供暖、供水并向本公司神东矿区提供包括物业管理、环保绿化、工程建设及房地产开发、医疗服务及煤炭投资等业务。<br>神东电力主要包括煤X（石干）石发电、煤矿开采、煤化工、燃料采购及运输等配套业务。</p>\n<p>&lt;发行人的组织架构&gt; 图</p>\n<p>&lt;本公司的控股、参股子公司的情况&gt; 图</p>\n<blockquote>\n<p>本章行业概述部分，煤炭产量如不特殊注明，均指原煤产量；本章其他部分中，煤炭产量如不特殊注明均为商品煤产量。<br>涉及煤炭价格与电力价格时，如不特殊说明，均指不含增值税价格。</p>\n<p>本公司是世界领先的、立足于煤炭的综合性能源公司，专注于煤炭和电力业务。主要业务包括煤炭生产、销售，电力生产、热力生产和供应，相关铁路、港口等运输服务。</p>\n</blockquote>\n<p>Q</p>\n<ul>\n<li>为啥发行后的 A 股和发行股数不一样</li>\n<li>煤分多少种（发电用动力煤，还有其他的哪些？）</li>\n<li>电量调度是啥</li>\n<li>现在的电力上网价格怎么定的</li>\n<li>股权性质（除了国家股，还有哪些）</li>\n<li>上市时，每股 36 元，每股面值 1 元，这个怎么理解这里的 36 和 1 呢</li>\n<li>现在的母公司，子公司等情况，以及占比</li>\n<li>采矿权，这个是啥，有啥门槛之类的吗？</li>\n<li>煤炭的  产量、销量、进口量 等可以在国家统计局的数据查询</li>\n</ul>\n"},{"_content":"现在的燃料有哪些\n中国的现状（比如煤炭比较多等）\n能源行业的发展[1]\n\n2020 完成去产能，退出煤矿 5500 处，退出落后煤炭产能 10亿吨/年 以上，安置职工 100 万人左右\n\n煤炭重心向  晋陕蒙新 地区集中\n\n重组后，国家能源集团（神华与国电并重组）、晋能控股集团（山西省战略重组）、山东能源集团（山东能源+衮矿集团）、中煤能源集团（兼并重组国投、保利和中铁等），这 4 家企业煤炭产量超过 2亿吨，山西煤化工集团、山西焦煤集团等 2 家企业产量超过 1亿吨。\n\n      西部地区煤炭产量(占全国比例)    年 120 万吨以上煤矿(产量占全国）  千万吨级煤矿（总产能） 前八大企业原煤产量(占全国比例)  亿吨级以上企业煤炭产量（占全国比例) 千万吨以上企业煤炭产量（占全国比例）   原煤入洗率  矿进水综合利用率    煤矸石综合利用处置率    井下瓦斯抽采利用率    土地复垦率    大型煤矿原煤生产综合能耗   煤矸石及低热值综合利用发电装机        年利用煤矸石     全国煤炭\n2020  23.3 亿吨(59.7%)                1200 处(80%)                      52处(8.2亿吨/年)   18.55(47.6%)   16.8亿吨(43%)    30亿吨（77%）   74.1%    78.7%   72.2%   44.8%    57%     10.51千克标煤/吨   4200万千瓦     1.5亿吨\n\n\n\n\n- 原煤入洗率\n- 土地复垦率\n\n\n[1] https://news.bjx.com.cn/html/20250617/1446782.shtml\n","source":"_drafts/meitan.md","raw":"现在的燃料有哪些\n中国的现状（比如煤炭比较多等）\n能源行业的发展[1]\n\n2020 完成去产能，退出煤矿 5500 处，退出落后煤炭产能 10亿吨/年 以上，安置职工 100 万人左右\n\n煤炭重心向  晋陕蒙新 地区集中\n\n重组后，国家能源集团（神华与国电并重组）、晋能控股集团（山西省战略重组）、山东能源集团（山东能源+衮矿集团）、中煤能源集团（兼并重组国投、保利和中铁等），这 4 家企业煤炭产量超过 2亿吨，山西煤化工集团、山西焦煤集团等 2 家企业产量超过 1亿吨。\n\n      西部地区煤炭产量(占全国比例)    年 120 万吨以上煤矿(产量占全国）  千万吨级煤矿（总产能） 前八大企业原煤产量(占全国比例)  亿吨级以上企业煤炭产量（占全国比例) 千万吨以上企业煤炭产量（占全国比例）   原煤入洗率  矿进水综合利用率    煤矸石综合利用处置率    井下瓦斯抽采利用率    土地复垦率    大型煤矿原煤生产综合能耗   煤矸石及低热值综合利用发电装机        年利用煤矸石     全国煤炭\n2020  23.3 亿吨(59.7%)                1200 处(80%)                      52处(8.2亿吨/年)   18.55(47.6%)   16.8亿吨(43%)    30亿吨（77%）   74.1%    78.7%   72.2%   44.8%    57%     10.51千克标煤/吨   4200万千瓦     1.5亿吨\n\n\n\n\n- 原煤入洗率\n- 土地复垦率\n\n\n[1] https://news.bjx.com.cn/html/20250617/1446782.shtml\n","slug":"meitan","published":0,"date":"2025-11-27T01:07:34.756Z","updated":"2025-11-27T01:07:34.757Z","_id":"cmhvrxzqi0002gnmk42qvapaz","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"<p>现在的燃料有哪些<br>中国的现状（比如煤炭比较多等）<br>能源行业的发展[1]</p>\n<p>2020 完成去产能，退出煤矿 5500 处，退出落后煤炭产能 10亿吨/年 以上，安置职工 100 万人左右</p>\n<p>煤炭重心向  晋陕蒙新 地区集中</p>\n<p>重组后，国家能源集团（神华与国电并重组）、晋能控股集团（山西省战略重组）、山东能源集团（山东能源+衮矿集团）、中煤能源集团（兼并重组国投、保利和中铁等），这 4 家企业煤炭产量超过 2亿吨，山西煤化工集团、山西焦煤集团等 2 家企业产量超过 1亿吨。</p>\n<pre><code>  西部地区煤炭产量(占全国比例)    年 120 万吨以上煤矿(产量占全国）  千万吨级煤矿（总产能） 前八大企业原煤产量(占全国比例)  亿吨级以上企业煤炭产量（占全国比例) 千万吨以上企业煤炭产量（占全国比例）   原煤入洗率  矿进水综合利用率    煤矸石综合利用处置率    井下瓦斯抽采利用率    土地复垦率    大型煤矿原煤生产综合能耗   煤矸石及低热值综合利用发电装机        年利用煤矸石     全国煤炭\n</code></pre><p>2020  23.3 亿吨(59.7%)                1200 处(80%)                      52处(8.2亿吨/年)   18.55(47.6%)   16.8亿吨(43%)    30亿吨（77%）   74.1%    78.7%   72.2%   44.8%    57%     10.51千克标煤/吨   4200万千瓦     1.5亿吨</p>\n<ul>\n<li>原煤入洗率</li>\n<li>土地复垦率</li>\n</ul>\n<p>[1] <a href=\"https://news.bjx.com.cn/html/20250617/1446782.shtml\">https://news.bjx.com.cn/html/20250617/1446782.shtml</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>现在的燃料有哪些<br>中国的现状（比如煤炭比较多等）<br>能源行业的发展[1]</p>\n<p>2020 完成去产能，退出煤矿 5500 处，退出落后煤炭产能 10亿吨/年 以上，安置职工 100 万人左右</p>\n<p>煤炭重心向  晋陕蒙新 地区集中</p>\n<p>重组后，国家能源集团（神华与国电并重组）、晋能控股集团（山西省战略重组）、山东能源集团（山东能源+衮矿集团）、中煤能源集团（兼并重组国投、保利和中铁等），这 4 家企业煤炭产量超过 2亿吨，山西煤化工集团、山西焦煤集团等 2 家企业产量超过 1亿吨。</p>\n<pre><code>  西部地区煤炭产量(占全国比例)    年 120 万吨以上煤矿(产量占全国）  千万吨级煤矿（总产能） 前八大企业原煤产量(占全国比例)  亿吨级以上企业煤炭产量（占全国比例) 千万吨以上企业煤炭产量（占全国比例）   原煤入洗率  矿进水综合利用率    煤矸石综合利用处置率    井下瓦斯抽采利用率    土地复垦率    大型煤矿原煤生产综合能耗   煤矸石及低热值综合利用发电装机        年利用煤矸石     全国煤炭\n</code></pre><p>2020  23.3 亿吨(59.7%)                1200 处(80%)                      52处(8.2亿吨/年)   18.55(47.6%)   16.8亿吨(43%)    30亿吨（77%）   74.1%    78.7%   72.2%   44.8%    57%     10.51千克标煤/吨   4200万千瓦     1.5亿吨</p>\n<ul>\n<li>原煤入洗率</li>\n<li>土地复垦率</li>\n</ul>\n<p>[1] <a href=\"https://news.bjx.com.cn/html/20250617/1446782.shtml\">https://news.bjx.com.cn/html/20250617/1446782.shtml</a></p>\n"},{"_content":"好的，我将从行业分析、公司竞争力、盈利能力等方面为你全面评估中国神华的投资价值。报告的主要内容如下：\n\n· 煤炭行业竞争格局与市场空间：使用数据和表格分析煤炭行业的供需结构、政策导向和竞争态势。\n· 公司核心竞争力分析：通过表格和分级展示中国神华的一体化运营、资源储备和成本优势。\n· 未来盈利能力分析：包含盈利预测表格和情景分析，评估公司未来业绩走势。\n· 扩展参考知识：介绍价值投资中评估能源企业的关键指标和行业术语。\n· 投资价值总结与风险提示：分类整理各类风险因素并评估其影响程度。\n\n接下来，我将开始撰写报告正文：\n\n---\n\n中国神华投资价值分析：煤电一体化巨头的稳健盈利与高股息价值\n\n1 煤炭行业分析：压舱石地位的稳固与挑战\n\n煤炭作为中国能源体系的\"压舱石\"，在当前能源结构中仍占据主导地位。尽管清洁能源比重逐年提升，但煤炭在确保能源安全方面的战略价值在近年来地缘政治动荡的背景下反而愈加凸显。2025年上半年，煤炭行业经历了周期性调整，市场煤价整体呈现下行态势，部分煤矿出现亏损。根据招商证券研究，当前煤价下行业亏损面已超过60%，这从侧面反映出成本线对煤价的支撑作用日益增强。煤炭行业的进入门槛因《矿产资源法》的实施而进一步提高，该法于2025年7月1日生效，对煤矿安全生产、环保要求提出了更严格标准，相应地增加了安全生产费、环保费、复垦费等合规成本，推动了行业整体成本线上移。\n\n供需结构分析方面，短期利空与利多因素交织。利空因素主要体现为：年初煤矿复产复工早于下游行业，导致库存上升；部分库存煤因自燃掉卡问题倒逼贸易商甩卖，对煤价形成压力；乌鲁木齐铁路局下浮运费，扩宽了疆煤外输半径，可能增加整体供给量。利多因素包括：进口煤性价比下降，2025年4月中国煤炭进口量环比下降2.3%，同比降幅达16.4%，这有助于缓解市场供需宽松格局；中美关税问题引入外需不确定性，可能倒逼内需扩张，中国制造业韧性有望支撑能源消费增长。长期来看，煤炭产能门槛不断提高，行业集中度将持续提升，有利于像中国神华这样的龙头企业巩固市场地位。\n\n政策导向上，国家致力于构建新型煤炭产供储销体系，强调能源的饭碗必须端在自己手里。煤炭作为我国能源市场中最具竞争性的能源品类，其稳定供应关系到国家能源安全。在迎峰度夏、冬季供暖等能源保供关键时期，大型煤炭企业被期望发挥更为关键的支柱作用。这一政策背景为中国神华等龙头企业创造了有利的发展环境，同时也对其产能协同调度能力提出了更高要求。\n\n表：煤炭行业主要政策与市场趋势\n\n因素 现状与趋势 对行业的影响\n产能门槛 《矿产资源法》2025年7月1日生效，提高安全环保要求 中小企业退出加速，行业集中度提升\n成本结构 通胀导致运输、人工成本双增，开采条件自然恶化 成本线上移，对煤价形成支撑\n进口格局 2025年4月进口量同比降16.4%，性价比下降 国内煤炭供需关系改善\n保供政策 强调能源自主，构建新型煤炭产供储销体系 龙头企业责任加重，稳定性优于波动性\n\n2 公司核心竞争力分析\n\n2.1 煤电运化一体化运营模式\n\n中国神华作为中国煤炭行业的领军企业，其最突出的竞争优势在于全产业链一体化运营能力。公司构建了覆盖煤炭开采、铁路运输、港口转驳、航运和电力生产等多个环节的完整产业链，实现了从生产到消费终端的无缝衔接。这种一体化模式在行业景气周期波动中发挥了重要的稳定器作用，通过各业务板块之间的协同效应，有效对冲了单一产品价格波动风险。2025年上半年，在市场煤价下行背景下，公司通过成本管控和一体化经营，业绩展现出较强韧性，归母净利润同比下降12.0%，远小于行业平均水平。\n\n运输网络的战略价值构成了一体化模式的关键环节。中国神华拥有并运营着围绕“西煤东运”骨干线路的专用铁路、港口和船队，这一运输网络不仅为其煤炭流通提供了可靠保障，也形成了难以复制的天然壁垒。公司铁路分部毛利率高达40.3%，港口分部毛利率更是达到47.2%，凸显了运输资产突出的盈利能力。在2025年上半年，尽管航运货运量同比下降23.8%，但铁路和港口业务通过成本优化，利润总额仍实现同比增长1.6%和9.7%。这种跨周期盈利能力彰显了一体化模式的优越性。\n\n2.2 资源储备与资产注入\n\n中国神华的资源战略储备正通过持续的资产注入实现跨越式增长。2025年8月，公司启动大规模资产重组，拟收购控股股东国家能源集团持有的13家能源资产股权，标的范围全面覆盖煤炭开采、坑口煤电、煤制油煤制气煤化工及相关物流运输体系等产业链核心环节。这是继2025年1月完成对杭锦能源100%股权收购后的又一重要举措，此次收购使公司煤炭保有资源量增加38.2亿吨，可采储量增加24.4亿吨。\n\n此次重组将根本性改善公司与控股股东在煤炭资源开发领域的业务重叠问题，进一步巩固国内煤炭行业龙头企业的市场地位与战略价值。从资源战略布局维度看，重组的煤炭标的与中国神华现有煤炭资源形成地理空间互补，相关物流资产强化“西煤东运”通道节点功能，煤电一体化项目进一步补齐了一体化产业链条。通过建立跨区域产能协同调度机制，公司应对重点能源消费区域季节性、结构性供需波动的能力将获得全面提升，在能源保供关键时期，可依托统一管理平台高效响应国家调控需求。\n\n2.3 成本控制与长协优势\n\n在煤炭行业面临价格下行的市场环境中，中国神华展现出卓越的成本管控能力。2025年上半年，公司自产煤单位生产成本为177.7元/吨，同比下降14.9元/吨，降幅达7.7%。尤为值得一提的是，第二季度吨成本环比进一步下降30元/吨至160元/吨，这在行业普遍面临成本刚性压力的背景下显得尤为突出。成本下降主要得益于原材料、燃料及动力成本和修理费等项目的有效控制，反映出公司在精益化管理方面的深厚积淀。\n\n高比例长协是公司抵御市场波动的另一重要法宝。2025年上半年，公司煤炭销售中年度长协销量占比55.5%，价格同比仅下降5.9%；月度长协占比36.7%，现货销售占比仅为4.1%。这种销售结构使得公司煤炭销售平均价格波动远小于市场煤价波动，2025年上半年公司自产煤平均售价478元/吨，同比减少49元/吨，降幅9.3%，明显低于市场煤价的跌幅。长期稳定的合同结构为公司提供了可持续的现金流，支撑了高股息分红政策。\n\n表：中国神华核心竞争力要素分析\n\n竞争要素 具体表现 战略意义\n一体化运营 煤电运化全产业链覆盖，铁路毛利率超40% 平滑周期波动，提升协同效应\n资源储备 资产注入后资源总量跨越式增长，地理空间互补 增强保供能力，巩固龙头地位\n成本控制 2025年H1自产煤成本降7.7%，Q2环比降30元/吨 提升抗风险能力，扩大利润空间\n长协优势 年度长协占比55.5%，价格波动远小于市场 稳定现金流，支撑高股息政策\n\n3 未来盈利能力分析\n\n3.1 各业务板块盈利前景\n\n煤炭业务作为中国神华的利润基石，未来虽面临价格下行压力，但通过持续的成本优化和产能结构调整，仍将保持较强的盈利能力。根据研报预测，公司2025-2027年归母净利润分别为505.2/524.3/550.5亿元，同比变动-14%/+4%/+5%。这一预测考虑到了一体化运营对煤价下跌的对冲作用。公司现有煤矿产能充足，新街一井、二井项目用时6个月完成开工前置手续办理，杭锦能源塔然高勒井田项目已完成北部风井场地、输电线路、变电站等工程建设，为未来产能接续提供了保障。\n\n电力业务在2025年上半年表现承压，发电量987.8亿千瓦时，同比下降7.4%；售电量929.1亿千瓦时，同比下降7.3%。但值得注意的是，公司上半年获取容量电费合计25.3亿元（含税），为电力板块利润提供了有力支撑。展望未来，随着三季度高温因素及上年四季度基数偏低因素显现，预计2025年下半年用电量增速将高于上半年，公司电力业务盈利有望改善。同时，公司稳妥推动九江二期、北海二期等煤电项目建设，印尼南苏1号项目已高质量投入运营，新增对外商业运营可再生能源发电项目215兆瓦，展示了公司在能源结构转型方面的积极布局。\n\n运输与煤化工业务呈现分化趋势。2025年上半年，公司铁路和港口分部利润总额分别为70.36亿元和13.29亿元，同比分别增长1.6%和9.7%，毛利率分别提升至40.3%和47.2%。而航运分部受航运货运量同比下降23.8%影响，利润总额为1.14亿元，同比下降48.6%。煤化工板块则受益于上年同期设备检修的低基数，聚乙烯和聚丙烯销量分别增长24.2%和22.6%，实现利润总额0.76亿元，较去年同期的100万元大幅改善。这一业务结构变化反映出公司在优化利润来源方面的努力。\n\n3.2 资产注入与成长空间\n\n千亿规模的资产重组将为中国神华打开新的成长空间。根据公司公告，本次交易拟收购控股股东国家能源集团持有的13家能源资产股权，全面覆盖煤炭开采、坑口煤电、煤制油煤制气煤化工及相关物流运输体系。此次重组不仅解决长期存在的同业竞争问题，更将显著提升公司煤炭资源战略储备和一体化运营能力。重组后，上游煤炭开采主体将提供稳定资源供给保障；中下游煤制油化工技术平台提升清洁高效转化水平，煤电一体化资产强化能源梯级利用效率；运输环节的路港航资产构建自主可控物流网络，各环节协同将大幅提升“西煤东运”战略通道运转效能。\n\n资产注入带来的财务改善同样值得期待。根据券商分析，此次重组将大幅增加企业自由现金流量水平，更好回报投资者。公司在手现金充裕，截至2025H1达1615亿元，资产负债率仅31.12%，经营性净现金流458亿元大幅超越净利润。这为未来可能的并购扩张和股东回报提升提供了坚实基础。公司正在推进的包头煤制烯烃升级示范项目也已进入全面建设阶段，有望在未来贡献新的利润增长点。\n\n3.3 分红政策与投资回报\n\n中国神华长期以来坚持高比例分红政策，为股东提供稳定回报。公司拟向全体股东派发2025年中期股息每股人民币0.98元（含税），合计派发现金红利人民币194.71亿元（含税），占2025年上半年归属于公司股东净利润的79.0%。这一分红比例实际超过了2024年年度的75%，向市场释放了积极分红信号的明确意向。公司还制定了2025-2027年度股东回报规划，承诺每年现金分红不低于当年归母净利润的65%，并考虑实施中期分红。\n\n稳定的高分红凸显了公司的投资价值，特别是在当前低利率市场环境下，对长期资金具备强大吸引力。根据回溯，公司2020-2023年分红率分别为91.8%、100%、72.7%、75%，持续处于行业领先水平。以当前股价计算，公司股息率具有显著竞争力，高比例、可持续的分红政策彰显了公司对股东回报的高度重视。这种注重股东回报的文化，与价值投资理念高度契合，使中国神华成为保险、养老基金等长期资金配置的重要标的。\n\n表：中国神华2025-2027年盈利预测与业务展望\n\n财务指标 2025E 2026E 2027E 主要驱动因素\n营业收入(亿元) 2856 2879 2939 资产注入、电力业务恢复\n归母净利润(亿元) 503.94 525.07 531.75 成本控制、一体化效应\nEPS(元/股) 2.54 2.64 2.68 盈利改善、股本变动\n分红比例 ≥65% ≥65% ≥65% 回报规划承诺\n\n4 扩展参考知识\n\n4.1 价值投资视角下的能源企业评估\n\n在价值投资框架下评估能源企业时，自由现金流生成能力是核心指标之一。中国神华近年来经营性现金流持续强劲，2025年上半年达到457.94亿元，大幅超过净利润水平。这一指标的重要性在于，它反映了企业实际能够支配的真实现金流，是股息支付、资本开支和债务偿还的真正来源。与单纯看净利润相比，自由现金流更能避免会计操纵的影响，揭示企业真实的财务健康状况。作为价值投资者，应特别关注企业长期自由现金流生成能力，而不仅仅是短期盈利波动。\n\n护城河理论在能源行业分析中具有特殊重要性。中国神华的护城河主要体现在以下几个方面：一是成本优势，公司拥有优质煤炭资源，埋藏浅、煤质好、成本低、易规模化开采；二是一体化经营的协同效应，通过自有铁路、港口网络降低整体运营成本；三是规模经济，作为行业龙头在采购、生产和销售环节均享有规模优势；四是政策壁垒，煤炭行业新建产能门槛不断提高，现有龙头企业受到政策保护。这些护城河要素共同构成了企业抵御竞争、维持长期盈利的基础，是价值投资分析的关键环节。\n\n4.2 煤电行业专业术语解析\n\n· 长协机制：长协即长期协议，在煤炭行业指供需双方签订的中长期购销合同。中国神华的年度长协价格按\"基准价+浮动价\"机制形成，相对稳定。这种机制有助于平抑煤价大幅波动对供需双方的影响，提供可预期的经营环境。对发电企业而言，长协煤是稳定供应的保障；对煤炭企业而言，长协锁定了大部分销量，是应对行业周期的有效工具。中国神华高达55.5%的年度长协占比，为其业绩提供了稳定器。\n· 容量电价：容量电价是电力市场中的一种计价机制，发电企业不仅通过实际上网电量(电量电价)获取收入，还可根据其可调度的发电容量获得固定回报。2025年上半年中国神华获取容量电费合计25.3亿元（含税），这在一定程度上对冲了电量电价下滑的影响。容量电价政策保障了电力供应安全，使煤电企业在能源转型过程中保持适当的装机容量，为可再生能源提供调峰服务，同时改善了煤电企业的盈利稳定性。\n· 坑口煤电：指建设在煤矿周边的发电机组，直接利用煤矿生产的煤炭进行发电。这种模式有效降低了煤炭运输成本，提高了能源转化效率。中国神华此次资产重组特别强调坑口煤电资产的注入，这有助于进一步发挥煤电一体化协同效应。坑口电站通过直接向远方负荷中心送电，变输煤为输电，往往具有更好的经济性和环保性能，是煤炭富集区域常用的能源开发模式。\n\n5 投资价值总结与风险提示\n\n综合评估中国神华的投资价值，可以看出公司作为煤炭行业龙头，拥有全产业链一体化运营的独特优势，通过高比例长协和领先的成本管控能力，在煤价下行周期中展现了出色的业绩韧性。公司正在推进的千亿规模资产重组将进一步提升资源储备和一体化运营效率，而明确的高分红政策和充裕的在手现金则为股东回报提供了坚实保障。基于多家券商预测，公司2025-2027年归母净利润将保持在500亿元以上水平，尽管短期可能同比下滑，但中长期增长趋势明确。\n\n从投资策略角度，中国神华适合价值投资者和收益型投资者配置。公司当前估值相对合理，2025年预测PE约15.0倍，低于历史平均水平。考虑到公司持续的高分红政策以及未来资产注入带来的成长潜力，公司具备长期持有价值。特别是对于注重现金流回报的投资者，公司稳定且可持续的股息提供了有吸引力的收益来源。在能源转型背景下，公司作为煤炭行业龙头，正通过产业链整合和运营效率提升，不断增强自身竞争优势，有望在行业变革中持续引领发展。\n\n潜在风险方面\n\n· 宏观经济复苏不及预期：经济增速放缓可能导致煤炭需求疲软，进而对煤价形成持续压力。特别是制造业、房地产等下游行业若持续低迷，将直接影响能源消费需求。\n· 煤炭价格超预期下跌：虽然公司通过长协机制缓解了部分价格波动，但如果市场煤价大幅下跌，仍将对公司整体盈利能力产生负面影响。\n· 资产整合不及预期：大规模资产重组后，不同业务板块之间的整合管理存在挑战，可能产生协同效应不及预期的风险。\n· 政策变动风险：能源、环保等相关政策调整可能影响公司经营，如电价政策调整、安全生产标准提升等，都可能增加公司合规成本。\n· 行业转型风险：能源结构向清洁低碳转型的长期趋势下，煤炭行业面临转型压力，公司需在维持传统业务优势和探索新能源发展之间取得平衡。\n\n总体而言，中国神华作为中国能源行业的龙头企业，凭借其独特的煤电运化一体化模式和稳健的财务政策，在当前的市场环境下展现出了显著的投资价值，特别适合那些寻求稳定股息收益和长期价值增长的投资者。公司持续的资产注入和明确的股东回报政策进一步增强了其投资吸引力，是价值投资者在能源板块不可多得的优质标的。\n","source":"_drafts/zhong-guo-shen-hua.md","raw":"好的，我将从行业分析、公司竞争力、盈利能力等方面为你全面评估中国神华的投资价值。报告的主要内容如下：\n\n· 煤炭行业竞争格局与市场空间：使用数据和表格分析煤炭行业的供需结构、政策导向和竞争态势。\n· 公司核心竞争力分析：通过表格和分级展示中国神华的一体化运营、资源储备和成本优势。\n· 未来盈利能力分析：包含盈利预测表格和情景分析，评估公司未来业绩走势。\n· 扩展参考知识：介绍价值投资中评估能源企业的关键指标和行业术语。\n· 投资价值总结与风险提示：分类整理各类风险因素并评估其影响程度。\n\n接下来，我将开始撰写报告正文：\n\n---\n\n中国神华投资价值分析：煤电一体化巨头的稳健盈利与高股息价值\n\n1 煤炭行业分析：压舱石地位的稳固与挑战\n\n煤炭作为中国能源体系的\"压舱石\"，在当前能源结构中仍占据主导地位。尽管清洁能源比重逐年提升，但煤炭在确保能源安全方面的战略价值在近年来地缘政治动荡的背景下反而愈加凸显。2025年上半年，煤炭行业经历了周期性调整，市场煤价整体呈现下行态势，部分煤矿出现亏损。根据招商证券研究，当前煤价下行业亏损面已超过60%，这从侧面反映出成本线对煤价的支撑作用日益增强。煤炭行业的进入门槛因《矿产资源法》的实施而进一步提高，该法于2025年7月1日生效，对煤矿安全生产、环保要求提出了更严格标准，相应地增加了安全生产费、环保费、复垦费等合规成本，推动了行业整体成本线上移。\n\n供需结构分析方面，短期利空与利多因素交织。利空因素主要体现为：年初煤矿复产复工早于下游行业，导致库存上升；部分库存煤因自燃掉卡问题倒逼贸易商甩卖，对煤价形成压力；乌鲁木齐铁路局下浮运费，扩宽了疆煤外输半径，可能增加整体供给量。利多因素包括：进口煤性价比下降，2025年4月中国煤炭进口量环比下降2.3%，同比降幅达16.4%，这有助于缓解市场供需宽松格局；中美关税问题引入外需不确定性，可能倒逼内需扩张，中国制造业韧性有望支撑能源消费增长。长期来看，煤炭产能门槛不断提高，行业集中度将持续提升，有利于像中国神华这样的龙头企业巩固市场地位。\n\n政策导向上，国家致力于构建新型煤炭产供储销体系，强调能源的饭碗必须端在自己手里。煤炭作为我国能源市场中最具竞争性的能源品类，其稳定供应关系到国家能源安全。在迎峰度夏、冬季供暖等能源保供关键时期，大型煤炭企业被期望发挥更为关键的支柱作用。这一政策背景为中国神华等龙头企业创造了有利的发展环境，同时也对其产能协同调度能力提出了更高要求。\n\n表：煤炭行业主要政策与市场趋势\n\n因素 现状与趋势 对行业的影响\n产能门槛 《矿产资源法》2025年7月1日生效，提高安全环保要求 中小企业退出加速，行业集中度提升\n成本结构 通胀导致运输、人工成本双增，开采条件自然恶化 成本线上移，对煤价形成支撑\n进口格局 2025年4月进口量同比降16.4%，性价比下降 国内煤炭供需关系改善\n保供政策 强调能源自主，构建新型煤炭产供储销体系 龙头企业责任加重，稳定性优于波动性\n\n2 公司核心竞争力分析\n\n2.1 煤电运化一体化运营模式\n\n中国神华作为中国煤炭行业的领军企业，其最突出的竞争优势在于全产业链一体化运营能力。公司构建了覆盖煤炭开采、铁路运输、港口转驳、航运和电力生产等多个环节的完整产业链，实现了从生产到消费终端的无缝衔接。这种一体化模式在行业景气周期波动中发挥了重要的稳定器作用，通过各业务板块之间的协同效应，有效对冲了单一产品价格波动风险。2025年上半年，在市场煤价下行背景下，公司通过成本管控和一体化经营，业绩展现出较强韧性，归母净利润同比下降12.0%，远小于行业平均水平。\n\n运输网络的战略价值构成了一体化模式的关键环节。中国神华拥有并运营着围绕“西煤东运”骨干线路的专用铁路、港口和船队，这一运输网络不仅为其煤炭流通提供了可靠保障，也形成了难以复制的天然壁垒。公司铁路分部毛利率高达40.3%，港口分部毛利率更是达到47.2%，凸显了运输资产突出的盈利能力。在2025年上半年，尽管航运货运量同比下降23.8%，但铁路和港口业务通过成本优化，利润总额仍实现同比增长1.6%和9.7%。这种跨周期盈利能力彰显了一体化模式的优越性。\n\n2.2 资源储备与资产注入\n\n中国神华的资源战略储备正通过持续的资产注入实现跨越式增长。2025年8月，公司启动大规模资产重组，拟收购控股股东国家能源集团持有的13家能源资产股权，标的范围全面覆盖煤炭开采、坑口煤电、煤制油煤制气煤化工及相关物流运输体系等产业链核心环节。这是继2025年1月完成对杭锦能源100%股权收购后的又一重要举措，此次收购使公司煤炭保有资源量增加38.2亿吨，可采储量增加24.4亿吨。\n\n此次重组将根本性改善公司与控股股东在煤炭资源开发领域的业务重叠问题，进一步巩固国内煤炭行业龙头企业的市场地位与战略价值。从资源战略布局维度看，重组的煤炭标的与中国神华现有煤炭资源形成地理空间互补，相关物流资产强化“西煤东运”通道节点功能，煤电一体化项目进一步补齐了一体化产业链条。通过建立跨区域产能协同调度机制，公司应对重点能源消费区域季节性、结构性供需波动的能力将获得全面提升，在能源保供关键时期，可依托统一管理平台高效响应国家调控需求。\n\n2.3 成本控制与长协优势\n\n在煤炭行业面临价格下行的市场环境中，中国神华展现出卓越的成本管控能力。2025年上半年，公司自产煤单位生产成本为177.7元/吨，同比下降14.9元/吨，降幅达7.7%。尤为值得一提的是，第二季度吨成本环比进一步下降30元/吨至160元/吨，这在行业普遍面临成本刚性压力的背景下显得尤为突出。成本下降主要得益于原材料、燃料及动力成本和修理费等项目的有效控制，反映出公司在精益化管理方面的深厚积淀。\n\n高比例长协是公司抵御市场波动的另一重要法宝。2025年上半年，公司煤炭销售中年度长协销量占比55.5%，价格同比仅下降5.9%；月度长协占比36.7%，现货销售占比仅为4.1%。这种销售结构使得公司煤炭销售平均价格波动远小于市场煤价波动，2025年上半年公司自产煤平均售价478元/吨，同比减少49元/吨，降幅9.3%，明显低于市场煤价的跌幅。长期稳定的合同结构为公司提供了可持续的现金流，支撑了高股息分红政策。\n\n表：中国神华核心竞争力要素分析\n\n竞争要素 具体表现 战略意义\n一体化运营 煤电运化全产业链覆盖，铁路毛利率超40% 平滑周期波动，提升协同效应\n资源储备 资产注入后资源总量跨越式增长，地理空间互补 增强保供能力，巩固龙头地位\n成本控制 2025年H1自产煤成本降7.7%，Q2环比降30元/吨 提升抗风险能力，扩大利润空间\n长协优势 年度长协占比55.5%，价格波动远小于市场 稳定现金流，支撑高股息政策\n\n3 未来盈利能力分析\n\n3.1 各业务板块盈利前景\n\n煤炭业务作为中国神华的利润基石，未来虽面临价格下行压力，但通过持续的成本优化和产能结构调整，仍将保持较强的盈利能力。根据研报预测，公司2025-2027年归母净利润分别为505.2/524.3/550.5亿元，同比变动-14%/+4%/+5%。这一预测考虑到了一体化运营对煤价下跌的对冲作用。公司现有煤矿产能充足，新街一井、二井项目用时6个月完成开工前置手续办理，杭锦能源塔然高勒井田项目已完成北部风井场地、输电线路、变电站等工程建设，为未来产能接续提供了保障。\n\n电力业务在2025年上半年表现承压，发电量987.8亿千瓦时，同比下降7.4%；售电量929.1亿千瓦时，同比下降7.3%。但值得注意的是，公司上半年获取容量电费合计25.3亿元（含税），为电力板块利润提供了有力支撑。展望未来，随着三季度高温因素及上年四季度基数偏低因素显现，预计2025年下半年用电量增速将高于上半年，公司电力业务盈利有望改善。同时，公司稳妥推动九江二期、北海二期等煤电项目建设，印尼南苏1号项目已高质量投入运营，新增对外商业运营可再生能源发电项目215兆瓦，展示了公司在能源结构转型方面的积极布局。\n\n运输与煤化工业务呈现分化趋势。2025年上半年，公司铁路和港口分部利润总额分别为70.36亿元和13.29亿元，同比分别增长1.6%和9.7%，毛利率分别提升至40.3%和47.2%。而航运分部受航运货运量同比下降23.8%影响，利润总额为1.14亿元，同比下降48.6%。煤化工板块则受益于上年同期设备检修的低基数，聚乙烯和聚丙烯销量分别增长24.2%和22.6%，实现利润总额0.76亿元，较去年同期的100万元大幅改善。这一业务结构变化反映出公司在优化利润来源方面的努力。\n\n3.2 资产注入与成长空间\n\n千亿规模的资产重组将为中国神华打开新的成长空间。根据公司公告，本次交易拟收购控股股东国家能源集团持有的13家能源资产股权，全面覆盖煤炭开采、坑口煤电、煤制油煤制气煤化工及相关物流运输体系。此次重组不仅解决长期存在的同业竞争问题，更将显著提升公司煤炭资源战略储备和一体化运营能力。重组后，上游煤炭开采主体将提供稳定资源供给保障；中下游煤制油化工技术平台提升清洁高效转化水平，煤电一体化资产强化能源梯级利用效率；运输环节的路港航资产构建自主可控物流网络，各环节协同将大幅提升“西煤东运”战略通道运转效能。\n\n资产注入带来的财务改善同样值得期待。根据券商分析，此次重组将大幅增加企业自由现金流量水平，更好回报投资者。公司在手现金充裕，截至2025H1达1615亿元，资产负债率仅31.12%，经营性净现金流458亿元大幅超越净利润。这为未来可能的并购扩张和股东回报提升提供了坚实基础。公司正在推进的包头煤制烯烃升级示范项目也已进入全面建设阶段，有望在未来贡献新的利润增长点。\n\n3.3 分红政策与投资回报\n\n中国神华长期以来坚持高比例分红政策，为股东提供稳定回报。公司拟向全体股东派发2025年中期股息每股人民币0.98元（含税），合计派发现金红利人民币194.71亿元（含税），占2025年上半年归属于公司股东净利润的79.0%。这一分红比例实际超过了2024年年度的75%，向市场释放了积极分红信号的明确意向。公司还制定了2025-2027年度股东回报规划，承诺每年现金分红不低于当年归母净利润的65%，并考虑实施中期分红。\n\n稳定的高分红凸显了公司的投资价值，特别是在当前低利率市场环境下，对长期资金具备强大吸引力。根据回溯，公司2020-2023年分红率分别为91.8%、100%、72.7%、75%，持续处于行业领先水平。以当前股价计算，公司股息率具有显著竞争力，高比例、可持续的分红政策彰显了公司对股东回报的高度重视。这种注重股东回报的文化，与价值投资理念高度契合，使中国神华成为保险、养老基金等长期资金配置的重要标的。\n\n表：中国神华2025-2027年盈利预测与业务展望\n\n财务指标 2025E 2026E 2027E 主要驱动因素\n营业收入(亿元) 2856 2879 2939 资产注入、电力业务恢复\n归母净利润(亿元) 503.94 525.07 531.75 成本控制、一体化效应\nEPS(元/股) 2.54 2.64 2.68 盈利改善、股本变动\n分红比例 ≥65% ≥65% ≥65% 回报规划承诺\n\n4 扩展参考知识\n\n4.1 价值投资视角下的能源企业评估\n\n在价值投资框架下评估能源企业时，自由现金流生成能力是核心指标之一。中国神华近年来经营性现金流持续强劲，2025年上半年达到457.94亿元，大幅超过净利润水平。这一指标的重要性在于，它反映了企业实际能够支配的真实现金流，是股息支付、资本开支和债务偿还的真正来源。与单纯看净利润相比，自由现金流更能避免会计操纵的影响，揭示企业真实的财务健康状况。作为价值投资者，应特别关注企业长期自由现金流生成能力，而不仅仅是短期盈利波动。\n\n护城河理论在能源行业分析中具有特殊重要性。中国神华的护城河主要体现在以下几个方面：一是成本优势，公司拥有优质煤炭资源，埋藏浅、煤质好、成本低、易规模化开采；二是一体化经营的协同效应，通过自有铁路、港口网络降低整体运营成本；三是规模经济，作为行业龙头在采购、生产和销售环节均享有规模优势；四是政策壁垒，煤炭行业新建产能门槛不断提高，现有龙头企业受到政策保护。这些护城河要素共同构成了企业抵御竞争、维持长期盈利的基础，是价值投资分析的关键环节。\n\n4.2 煤电行业专业术语解析\n\n· 长协机制：长协即长期协议，在煤炭行业指供需双方签订的中长期购销合同。中国神华的年度长协价格按\"基准价+浮动价\"机制形成，相对稳定。这种机制有助于平抑煤价大幅波动对供需双方的影响，提供可预期的经营环境。对发电企业而言，长协煤是稳定供应的保障；对煤炭企业而言，长协锁定了大部分销量，是应对行业周期的有效工具。中国神华高达55.5%的年度长协占比，为其业绩提供了稳定器。\n· 容量电价：容量电价是电力市场中的一种计价机制，发电企业不仅通过实际上网电量(电量电价)获取收入，还可根据其可调度的发电容量获得固定回报。2025年上半年中国神华获取容量电费合计25.3亿元（含税），这在一定程度上对冲了电量电价下滑的影响。容量电价政策保障了电力供应安全，使煤电企业在能源转型过程中保持适当的装机容量，为可再生能源提供调峰服务，同时改善了煤电企业的盈利稳定性。\n· 坑口煤电：指建设在煤矿周边的发电机组，直接利用煤矿生产的煤炭进行发电。这种模式有效降低了煤炭运输成本，提高了能源转化效率。中国神华此次资产重组特别强调坑口煤电资产的注入，这有助于进一步发挥煤电一体化协同效应。坑口电站通过直接向远方负荷中心送电，变输煤为输电，往往具有更好的经济性和环保性能，是煤炭富集区域常用的能源开发模式。\n\n5 投资价值总结与风险提示\n\n综合评估中国神华的投资价值，可以看出公司作为煤炭行业龙头，拥有全产业链一体化运营的独特优势，通过高比例长协和领先的成本管控能力，在煤价下行周期中展现了出色的业绩韧性。公司正在推进的千亿规模资产重组将进一步提升资源储备和一体化运营效率，而明确的高分红政策和充裕的在手现金则为股东回报提供了坚实保障。基于多家券商预测，公司2025-2027年归母净利润将保持在500亿元以上水平，尽管短期可能同比下滑，但中长期增长趋势明确。\n\n从投资策略角度，中国神华适合价值投资者和收益型投资者配置。公司当前估值相对合理，2025年预测PE约15.0倍，低于历史平均水平。考虑到公司持续的高分红政策以及未来资产注入带来的成长潜力，公司具备长期持有价值。特别是对于注重现金流回报的投资者，公司稳定且可持续的股息提供了有吸引力的收益来源。在能源转型背景下，公司作为煤炭行业龙头，正通过产业链整合和运营效率提升，不断增强自身竞争优势，有望在行业变革中持续引领发展。\n\n潜在风险方面\n\n· 宏观经济复苏不及预期：经济增速放缓可能导致煤炭需求疲软，进而对煤价形成持续压力。特别是制造业、房地产等下游行业若持续低迷，将直接影响能源消费需求。\n· 煤炭价格超预期下跌：虽然公司通过长协机制缓解了部分价格波动，但如果市场煤价大幅下跌，仍将对公司整体盈利能力产生负面影响。\n· 资产整合不及预期：大规模资产重组后，不同业务板块之间的整合管理存在挑战，可能产生协同效应不及预期的风险。\n· 政策变动风险：能源、环保等相关政策调整可能影响公司经营，如电价政策调整、安全生产标准提升等，都可能增加公司合规成本。\n· 行业转型风险：能源结构向清洁低碳转型的长期趋势下，煤炭行业面临转型压力，公司需在维持传统业务优势和探索新能源发展之间取得平衡。\n\n总体而言，中国神华作为中国能源行业的龙头企业，凭借其独特的煤电运化一体化模式和稳健的财务政策，在当前的市场环境下展现出了显著的投资价值，特别适合那些寻求稳定股息收益和长期价值增长的投资者。公司持续的资产注入和明确的股东回报政策进一步增强了其投资吸引力，是价值投资者在能源板块不可多得的优质标的。\n","slug":"zhong-guo-shen-hua","published":0,"date":"2025-10-08T11:02:59.436Z","updated":"2025-10-08T11:02:59.437Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cmhvrxzqj0003gnmkbfg8b6vv","content":"<p>好的，我将从行业分析、公司竞争力、盈利能力等方面为你全面评估中国神华的投资价值。报告的主要内容如下：</p>\n<p>· 煤炭行业竞争格局与市场空间：使用数据和表格分析煤炭行业的供需结构、政策导向和竞争态势。<br>· 公司核心竞争力分析：通过表格和分级展示中国神华的一体化运营、资源储备和成本优势。<br>· 未来盈利能力分析：包含盈利预测表格和情景分析，评估公司未来业绩走势。<br>· 扩展参考知识：介绍价值投资中评估能源企业的关键指标和行业术语。<br>· 投资价值总结与风险提示：分类整理各类风险因素并评估其影响程度。</p>\n<p>接下来，我将开始撰写报告正文：</p>\n<hr>\n<p>中国神华投资价值分析：煤电一体化巨头的稳健盈利与高股息价值</p>\n<p>1 煤炭行业分析：压舱石地位的稳固与挑战</p>\n<p>煤炭作为中国能源体系的”压舱石”，在当前能源结构中仍占据主导地位。尽管清洁能源比重逐年提升，但煤炭在确保能源安全方面的战略价值在近年来地缘政治动荡的背景下反而愈加凸显。2025年上半年，煤炭行业经历了周期性调整，市场煤价整体呈现下行态势，部分煤矿出现亏损。根据招商证券研究，当前煤价下行业亏损面已超过60%，这从侧面反映出成本线对煤价的支撑作用日益增强。煤炭行业的进入门槛因《矿产资源法》的实施而进一步提高，该法于2025年7月1日生效，对煤矿安全生产、环保要求提出了更严格标准，相应地增加了安全生产费、环保费、复垦费等合规成本，推动了行业整体成本线上移。</p>\n<p>供需结构分析方面，短期利空与利多因素交织。利空因素主要体现为：年初煤矿复产复工早于下游行业，导致库存上升；部分库存煤因自燃掉卡问题倒逼贸易商甩卖，对煤价形成压力；乌鲁木齐铁路局下浮运费，扩宽了疆煤外输半径，可能增加整体供给量。利多因素包括：进口煤性价比下降，2025年4月中国煤炭进口量环比下降2.3%，同比降幅达16.4%，这有助于缓解市场供需宽松格局；中美关税问题引入外需不确定性，可能倒逼内需扩张，中国制造业韧性有望支撑能源消费增长。长期来看，煤炭产能门槛不断提高，行业集中度将持续提升，有利于像中国神华这样的龙头企业巩固市场地位。</p>\n<p>政策导向上，国家致力于构建新型煤炭产供储销体系，强调能源的饭碗必须端在自己手里。煤炭作为我国能源市场中最具竞争性的能源品类，其稳定供应关系到国家能源安全。在迎峰度夏、冬季供暖等能源保供关键时期，大型煤炭企业被期望发挥更为关键的支柱作用。这一政策背景为中国神华等龙头企业创造了有利的发展环境，同时也对其产能协同调度能力提出了更高要求。</p>\n<p>表：煤炭行业主要政策与市场趋势</p>\n<p>因素 现状与趋势 对行业的影响<br>产能门槛 《矿产资源法》2025年7月1日生效，提高安全环保要求 中小企业退出加速，行业集中度提升<br>成本结构 通胀导致运输、人工成本双增，开采条件自然恶化 成本线上移，对煤价形成支撑<br>进口格局 2025年4月进口量同比降16.4%，性价比下降 国内煤炭供需关系改善<br>保供政策 强调能源自主，构建新型煤炭产供储销体系 龙头企业责任加重，稳定性优于波动性</p>\n<p>2 公司核心竞争力分析</p>\n<p>2.1 煤电运化一体化运营模式</p>\n<p>中国神华作为中国煤炭行业的领军企业，其最突出的竞争优势在于全产业链一体化运营能力。公司构建了覆盖煤炭开采、铁路运输、港口转驳、航运和电力生产等多个环节的完整产业链，实现了从生产到消费终端的无缝衔接。这种一体化模式在行业景气周期波动中发挥了重要的稳定器作用，通过各业务板块之间的协同效应，有效对冲了单一产品价格波动风险。2025年上半年，在市场煤价下行背景下，公司通过成本管控和一体化经营，业绩展现出较强韧性，归母净利润同比下降12.0%，远小于行业平均水平。</p>\n<p>运输网络的战略价值构成了一体化模式的关键环节。中国神华拥有并运营着围绕“西煤东运”骨干线路的专用铁路、港口和船队，这一运输网络不仅为其煤炭流通提供了可靠保障，也形成了难以复制的天然壁垒。公司铁路分部毛利率高达40.3%，港口分部毛利率更是达到47.2%，凸显了运输资产突出的盈利能力。在2025年上半年，尽管航运货运量同比下降23.8%，但铁路和港口业务通过成本优化，利润总额仍实现同比增长1.6%和9.7%。这种跨周期盈利能力彰显了一体化模式的优越性。</p>\n<p>2.2 资源储备与资产注入</p>\n<p>中国神华的资源战略储备正通过持续的资产注入实现跨越式增长。2025年8月，公司启动大规模资产重组，拟收购控股股东国家能源集团持有的13家能源资产股权，标的范围全面覆盖煤炭开采、坑口煤电、煤制油煤制气煤化工及相关物流运输体系等产业链核心环节。这是继2025年1月完成对杭锦能源100%股权收购后的又一重要举措，此次收购使公司煤炭保有资源量增加38.2亿吨，可采储量增加24.4亿吨。</p>\n<p>此次重组将根本性改善公司与控股股东在煤炭资源开发领域的业务重叠问题，进一步巩固国内煤炭行业龙头企业的市场地位与战略价值。从资源战略布局维度看，重组的煤炭标的与中国神华现有煤炭资源形成地理空间互补，相关物流资产强化“西煤东运”通道节点功能，煤电一体化项目进一步补齐了一体化产业链条。通过建立跨区域产能协同调度机制，公司应对重点能源消费区域季节性、结构性供需波动的能力将获得全面提升，在能源保供关键时期，可依托统一管理平台高效响应国家调控需求。</p>\n<p>2.3 成本控制与长协优势</p>\n<p>在煤炭行业面临价格下行的市场环境中，中国神华展现出卓越的成本管控能力。2025年上半年，公司自产煤单位生产成本为177.7元/吨，同比下降14.9元/吨，降幅达7.7%。尤为值得一提的是，第二季度吨成本环比进一步下降30元/吨至160元/吨，这在行业普遍面临成本刚性压力的背景下显得尤为突出。成本下降主要得益于原材料、燃料及动力成本和修理费等项目的有效控制，反映出公司在精益化管理方面的深厚积淀。</p>\n<p>高比例长协是公司抵御市场波动的另一重要法宝。2025年上半年，公司煤炭销售中年度长协销量占比55.5%，价格同比仅下降5.9%；月度长协占比36.7%，现货销售占比仅为4.1%。这种销售结构使得公司煤炭销售平均价格波动远小于市场煤价波动，2025年上半年公司自产煤平均售价478元/吨，同比减少49元/吨，降幅9.3%，明显低于市场煤价的跌幅。长期稳定的合同结构为公司提供了可持续的现金流，支撑了高股息分红政策。</p>\n<p>表：中国神华核心竞争力要素分析</p>\n<p>竞争要素 具体表现 战略意义<br>一体化运营 煤电运化全产业链覆盖，铁路毛利率超40% 平滑周期波动，提升协同效应<br>资源储备 资产注入后资源总量跨越式增长，地理空间互补 增强保供能力，巩固龙头地位<br>成本控制 2025年H1自产煤成本降7.7%，Q2环比降30元/吨 提升抗风险能力，扩大利润空间<br>长协优势 年度长协占比55.5%，价格波动远小于市场 稳定现金流，支撑高股息政策</p>\n<p>3 未来盈利能力分析</p>\n<p>3.1 各业务板块盈利前景</p>\n<p>煤炭业务作为中国神华的利润基石，未来虽面临价格下行压力，但通过持续的成本优化和产能结构调整，仍将保持较强的盈利能力。根据研报预测，公司2025-2027年归母净利润分别为505.2/524.3/550.5亿元，同比变动-14%/+4%/+5%。这一预测考虑到了一体化运营对煤价下跌的对冲作用。公司现有煤矿产能充足，新街一井、二井项目用时6个月完成开工前置手续办理，杭锦能源塔然高勒井田项目已完成北部风井场地、输电线路、变电站等工程建设，为未来产能接续提供了保障。</p>\n<p>电力业务在2025年上半年表现承压，发电量987.8亿千瓦时，同比下降7.4%；售电量929.1亿千瓦时，同比下降7.3%。但值得注意的是，公司上半年获取容量电费合计25.3亿元（含税），为电力板块利润提供了有力支撑。展望未来，随着三季度高温因素及上年四季度基数偏低因素显现，预计2025年下半年用电量增速将高于上半年，公司电力业务盈利有望改善。同时，公司稳妥推动九江二期、北海二期等煤电项目建设，印尼南苏1号项目已高质量投入运营，新增对外商业运营可再生能源发电项目215兆瓦，展示了公司在能源结构转型方面的积极布局。</p>\n<p>运输与煤化工业务呈现分化趋势。2025年上半年，公司铁路和港口分部利润总额分别为70.36亿元和13.29亿元，同比分别增长1.6%和9.7%，毛利率分别提升至40.3%和47.2%。而航运分部受航运货运量同比下降23.8%影响，利润总额为1.14亿元，同比下降48.6%。煤化工板块则受益于上年同期设备检修的低基数，聚乙烯和聚丙烯销量分别增长24.2%和22.6%，实现利润总额0.76亿元，较去年同期的100万元大幅改善。这一业务结构变化反映出公司在优化利润来源方面的努力。</p>\n<p>3.2 资产注入与成长空间</p>\n<p>千亿规模的资产重组将为中国神华打开新的成长空间。根据公司公告，本次交易拟收购控股股东国家能源集团持有的13家能源资产股权，全面覆盖煤炭开采、坑口煤电、煤制油煤制气煤化工及相关物流运输体系。此次重组不仅解决长期存在的同业竞争问题，更将显著提升公司煤炭资源战略储备和一体化运营能力。重组后，上游煤炭开采主体将提供稳定资源供给保障；中下游煤制油化工技术平台提升清洁高效转化水平，煤电一体化资产强化能源梯级利用效率；运输环节的路港航资产构建自主可控物流网络，各环节协同将大幅提升“西煤东运”战略通道运转效能。</p>\n<p>资产注入带来的财务改善同样值得期待。根据券商分析，此次重组将大幅增加企业自由现金流量水平，更好回报投资者。公司在手现金充裕，截至2025H1达1615亿元，资产负债率仅31.12%，经营性净现金流458亿元大幅超越净利润。这为未来可能的并购扩张和股东回报提升提供了坚实基础。公司正在推进的包头煤制烯烃升级示范项目也已进入全面建设阶段，有望在未来贡献新的利润增长点。</p>\n<p>3.3 分红政策与投资回报</p>\n<p>中国神华长期以来坚持高比例分红政策，为股东提供稳定回报。公司拟向全体股东派发2025年中期股息每股人民币0.98元（含税），合计派发现金红利人民币194.71亿元（含税），占2025年上半年归属于公司股东净利润的79.0%。这一分红比例实际超过了2024年年度的75%，向市场释放了积极分红信号的明确意向。公司还制定了2025-2027年度股东回报规划，承诺每年现金分红不低于当年归母净利润的65%，并考虑实施中期分红。</p>\n<p>稳定的高分红凸显了公司的投资价值，特别是在当前低利率市场环境下，对长期资金具备强大吸引力。根据回溯，公司2020-2023年分红率分别为91.8%、100%、72.7%、75%，持续处于行业领先水平。以当前股价计算，公司股息率具有显著竞争力，高比例、可持续的分红政策彰显了公司对股东回报的高度重视。这种注重股东回报的文化，与价值投资理念高度契合，使中国神华成为保险、养老基金等长期资金配置的重要标的。</p>\n<p>表：中国神华2025-2027年盈利预测与业务展望</p>\n<p>财务指标 2025E 2026E 2027E 主要驱动因素<br>营业收入(亿元) 2856 2879 2939 资产注入、电力业务恢复<br>归母净利润(亿元) 503.94 525.07 531.75 成本控制、一体化效应<br>EPS(元/股) 2.54 2.64 2.68 盈利改善、股本变动<br>分红比例 ≥65% ≥65% ≥65% 回报规划承诺</p>\n<p>4 扩展参考知识</p>\n<p>4.1 价值投资视角下的能源企业评估</p>\n<p>在价值投资框架下评估能源企业时，自由现金流生成能力是核心指标之一。中国神华近年来经营性现金流持续强劲，2025年上半年达到457.94亿元，大幅超过净利润水平。这一指标的重要性在于，它反映了企业实际能够支配的真实现金流，是股息支付、资本开支和债务偿还的真正来源。与单纯看净利润相比，自由现金流更能避免会计操纵的影响，揭示企业真实的财务健康状况。作为价值投资者，应特别关注企业长期自由现金流生成能力，而不仅仅是短期盈利波动。</p>\n<p>护城河理论在能源行业分析中具有特殊重要性。中国神华的护城河主要体现在以下几个方面：一是成本优势，公司拥有优质煤炭资源，埋藏浅、煤质好、成本低、易规模化开采；二是一体化经营的协同效应，通过自有铁路、港口网络降低整体运营成本；三是规模经济，作为行业龙头在采购、生产和销售环节均享有规模优势；四是政策壁垒，煤炭行业新建产能门槛不断提高，现有龙头企业受到政策保护。这些护城河要素共同构成了企业抵御竞争、维持长期盈利的基础，是价值投资分析的关键环节。</p>\n<p>4.2 煤电行业专业术语解析</p>\n<p>· 长协机制：长协即长期协议，在煤炭行业指供需双方签订的中长期购销合同。中国神华的年度长协价格按”基准价+浮动价”机制形成，相对稳定。这种机制有助于平抑煤价大幅波动对供需双方的影响，提供可预期的经营环境。对发电企业而言，长协煤是稳定供应的保障；对煤炭企业而言，长协锁定了大部分销量，是应对行业周期的有效工具。中国神华高达55.5%的年度长协占比，为其业绩提供了稳定器。<br>· 容量电价：容量电价是电力市场中的一种计价机制，发电企业不仅通过实际上网电量(电量电价)获取收入，还可根据其可调度的发电容量获得固定回报。2025年上半年中国神华获取容量电费合计25.3亿元（含税），这在一定程度上对冲了电量电价下滑的影响。容量电价政策保障了电力供应安全，使煤电企业在能源转型过程中保持适当的装机容量，为可再生能源提供调峰服务，同时改善了煤电企业的盈利稳定性。<br>· 坑口煤电：指建设在煤矿周边的发电机组，直接利用煤矿生产的煤炭进行发电。这种模式有效降低了煤炭运输成本，提高了能源转化效率。中国神华此次资产重组特别强调坑口煤电资产的注入，这有助于进一步发挥煤电一体化协同效应。坑口电站通过直接向远方负荷中心送电，变输煤为输电，往往具有更好的经济性和环保性能，是煤炭富集区域常用的能源开发模式。</p>\n<p>5 投资价值总结与风险提示</p>\n<p>综合评估中国神华的投资价值，可以看出公司作为煤炭行业龙头，拥有全产业链一体化运营的独特优势，通过高比例长协和领先的成本管控能力，在煤价下行周期中展现了出色的业绩韧性。公司正在推进的千亿规模资产重组将进一步提升资源储备和一体化运营效率，而明确的高分红政策和充裕的在手现金则为股东回报提供了坚实保障。基于多家券商预测，公司2025-2027年归母净利润将保持在500亿元以上水平，尽管短期可能同比下滑，但中长期增长趋势明确。</p>\n<p>从投资策略角度，中国神华适合价值投资者和收益型投资者配置。公司当前估值相对合理，2025年预测PE约15.0倍，低于历史平均水平。考虑到公司持续的高分红政策以及未来资产注入带来的成长潜力，公司具备长期持有价值。特别是对于注重现金流回报的投资者，公司稳定且可持续的股息提供了有吸引力的收益来源。在能源转型背景下，公司作为煤炭行业龙头，正通过产业链整合和运营效率提升，不断增强自身竞争优势，有望在行业变革中持续引领发展。</p>\n<p>潜在风险方面</p>\n<p>· 宏观经济复苏不及预期：经济增速放缓可能导致煤炭需求疲软，进而对煤价形成持续压力。特别是制造业、房地产等下游行业若持续低迷，将直接影响能源消费需求。<br>· 煤炭价格超预期下跌：虽然公司通过长协机制缓解了部分价格波动，但如果市场煤价大幅下跌，仍将对公司整体盈利能力产生负面影响。<br>· 资产整合不及预期：大规模资产重组后，不同业务板块之间的整合管理存在挑战，可能产生协同效应不及预期的风险。<br>· 政策变动风险：能源、环保等相关政策调整可能影响公司经营，如电价政策调整、安全生产标准提升等，都可能增加公司合规成本。<br>· 行业转型风险：能源结构向清洁低碳转型的长期趋势下，煤炭行业面临转型压力，公司需在维持传统业务优势和探索新能源发展之间取得平衡。</p>\n<p>总体而言，中国神华作为中国能源行业的龙头企业，凭借其独特的煤电运化一体化模式和稳健的财务政策，在当前的市场环境下展现出了显著的投资价值，特别适合那些寻求稳定股息收益和长期价值增长的投资者。公司持续的资产注入和明确的股东回报政策进一步增强了其投资吸引力，是价值投资者在能源板块不可多得的优质标的。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>好的，我将从行业分析、公司竞争力、盈利能力等方面为你全面评估中国神华的投资价值。报告的主要内容如下：</p>\n<p>· 煤炭行业竞争格局与市场空间：使用数据和表格分析煤炭行业的供需结构、政策导向和竞争态势。<br>· 公司核心竞争力分析：通过表格和分级展示中国神华的一体化运营、资源储备和成本优势。<br>· 未来盈利能力分析：包含盈利预测表格和情景分析，评估公司未来业绩走势。<br>· 扩展参考知识：介绍价值投资中评估能源企业的关键指标和行业术语。<br>· 投资价值总结与风险提示：分类整理各类风险因素并评估其影响程度。</p>\n<p>接下来，我将开始撰写报告正文：</p>\n<hr>\n<p>中国神华投资价值分析：煤电一体化巨头的稳健盈利与高股息价值</p>\n<p>1 煤炭行业分析：压舱石地位的稳固与挑战</p>\n<p>煤炭作为中国能源体系的”压舱石”，在当前能源结构中仍占据主导地位。尽管清洁能源比重逐年提升，但煤炭在确保能源安全方面的战略价值在近年来地缘政治动荡的背景下反而愈加凸显。2025年上半年，煤炭行业经历了周期性调整，市场煤价整体呈现下行态势，部分煤矿出现亏损。根据招商证券研究，当前煤价下行业亏损面已超过60%，这从侧面反映出成本线对煤价的支撑作用日益增强。煤炭行业的进入门槛因《矿产资源法》的实施而进一步提高，该法于2025年7月1日生效，对煤矿安全生产、环保要求提出了更严格标准，相应地增加了安全生产费、环保费、复垦费等合规成本，推动了行业整体成本线上移。</p>\n<p>供需结构分析方面，短期利空与利多因素交织。利空因素主要体现为：年初煤矿复产复工早于下游行业，导致库存上升；部分库存煤因自燃掉卡问题倒逼贸易商甩卖，对煤价形成压力；乌鲁木齐铁路局下浮运费，扩宽了疆煤外输半径，可能增加整体供给量。利多因素包括：进口煤性价比下降，2025年4月中国煤炭进口量环比下降2.3%，同比降幅达16.4%，这有助于缓解市场供需宽松格局；中美关税问题引入外需不确定性，可能倒逼内需扩张，中国制造业韧性有望支撑能源消费增长。长期来看，煤炭产能门槛不断提高，行业集中度将持续提升，有利于像中国神华这样的龙头企业巩固市场地位。</p>\n<p>政策导向上，国家致力于构建新型煤炭产供储销体系，强调能源的饭碗必须端在自己手里。煤炭作为我国能源市场中最具竞争性的能源品类，其稳定供应关系到国家能源安全。在迎峰度夏、冬季供暖等能源保供关键时期，大型煤炭企业被期望发挥更为关键的支柱作用。这一政策背景为中国神华等龙头企业创造了有利的发展环境，同时也对其产能协同调度能力提出了更高要求。</p>\n<p>表：煤炭行业主要政策与市场趋势</p>\n<p>因素 现状与趋势 对行业的影响<br>产能门槛 《矿产资源法》2025年7月1日生效，提高安全环保要求 中小企业退出加速，行业集中度提升<br>成本结构 通胀导致运输、人工成本双增，开采条件自然恶化 成本线上移，对煤价形成支撑<br>进口格局 2025年4月进口量同比降16.4%，性价比下降 国内煤炭供需关系改善<br>保供政策 强调能源自主，构建新型煤炭产供储销体系 龙头企业责任加重，稳定性优于波动性</p>\n<p>2 公司核心竞争力分析</p>\n<p>2.1 煤电运化一体化运营模式</p>\n<p>中国神华作为中国煤炭行业的领军企业，其最突出的竞争优势在于全产业链一体化运营能力。公司构建了覆盖煤炭开采、铁路运输、港口转驳、航运和电力生产等多个环节的完整产业链，实现了从生产到消费终端的无缝衔接。这种一体化模式在行业景气周期波动中发挥了重要的稳定器作用，通过各业务板块之间的协同效应，有效对冲了单一产品价格波动风险。2025年上半年，在市场煤价下行背景下，公司通过成本管控和一体化经营，业绩展现出较强韧性，归母净利润同比下降12.0%，远小于行业平均水平。</p>\n<p>运输网络的战略价值构成了一体化模式的关键环节。中国神华拥有并运营着围绕“西煤东运”骨干线路的专用铁路、港口和船队，这一运输网络不仅为其煤炭流通提供了可靠保障，也形成了难以复制的天然壁垒。公司铁路分部毛利率高达40.3%，港口分部毛利率更是达到47.2%，凸显了运输资产突出的盈利能力。在2025年上半年，尽管航运货运量同比下降23.8%，但铁路和港口业务通过成本优化，利润总额仍实现同比增长1.6%和9.7%。这种跨周期盈利能力彰显了一体化模式的优越性。</p>\n<p>2.2 资源储备与资产注入</p>\n<p>中国神华的资源战略储备正通过持续的资产注入实现跨越式增长。2025年8月，公司启动大规模资产重组，拟收购控股股东国家能源集团持有的13家能源资产股权，标的范围全面覆盖煤炭开采、坑口煤电、煤制油煤制气煤化工及相关物流运输体系等产业链核心环节。这是继2025年1月完成对杭锦能源100%股权收购后的又一重要举措，此次收购使公司煤炭保有资源量增加38.2亿吨，可采储量增加24.4亿吨。</p>\n<p>此次重组将根本性改善公司与控股股东在煤炭资源开发领域的业务重叠问题，进一步巩固国内煤炭行业龙头企业的市场地位与战略价值。从资源战略布局维度看，重组的煤炭标的与中国神华现有煤炭资源形成地理空间互补，相关物流资产强化“西煤东运”通道节点功能，煤电一体化项目进一步补齐了一体化产业链条。通过建立跨区域产能协同调度机制，公司应对重点能源消费区域季节性、结构性供需波动的能力将获得全面提升，在能源保供关键时期，可依托统一管理平台高效响应国家调控需求。</p>\n<p>2.3 成本控制与长协优势</p>\n<p>在煤炭行业面临价格下行的市场环境中，中国神华展现出卓越的成本管控能力。2025年上半年，公司自产煤单位生产成本为177.7元/吨，同比下降14.9元/吨，降幅达7.7%。尤为值得一提的是，第二季度吨成本环比进一步下降30元/吨至160元/吨，这在行业普遍面临成本刚性压力的背景下显得尤为突出。成本下降主要得益于原材料、燃料及动力成本和修理费等项目的有效控制，反映出公司在精益化管理方面的深厚积淀。</p>\n<p>高比例长协是公司抵御市场波动的另一重要法宝。2025年上半年，公司煤炭销售中年度长协销量占比55.5%，价格同比仅下降5.9%；月度长协占比36.7%，现货销售占比仅为4.1%。这种销售结构使得公司煤炭销售平均价格波动远小于市场煤价波动，2025年上半年公司自产煤平均售价478元/吨，同比减少49元/吨，降幅9.3%，明显低于市场煤价的跌幅。长期稳定的合同结构为公司提供了可持续的现金流，支撑了高股息分红政策。</p>\n<p>表：中国神华核心竞争力要素分析</p>\n<p>竞争要素 具体表现 战略意义<br>一体化运营 煤电运化全产业链覆盖，铁路毛利率超40% 平滑周期波动，提升协同效应<br>资源储备 资产注入后资源总量跨越式增长，地理空间互补 增强保供能力，巩固龙头地位<br>成本控制 2025年H1自产煤成本降7.7%，Q2环比降30元/吨 提升抗风险能力，扩大利润空间<br>长协优势 年度长协占比55.5%，价格波动远小于市场 稳定现金流，支撑高股息政策</p>\n<p>3 未来盈利能力分析</p>\n<p>3.1 各业务板块盈利前景</p>\n<p>煤炭业务作为中国神华的利润基石，未来虽面临价格下行压力，但通过持续的成本优化和产能结构调整，仍将保持较强的盈利能力。根据研报预测，公司2025-2027年归母净利润分别为505.2/524.3/550.5亿元，同比变动-14%/+4%/+5%。这一预测考虑到了一体化运营对煤价下跌的对冲作用。公司现有煤矿产能充足，新街一井、二井项目用时6个月完成开工前置手续办理，杭锦能源塔然高勒井田项目已完成北部风井场地、输电线路、变电站等工程建设，为未来产能接续提供了保障。</p>\n<p>电力业务在2025年上半年表现承压，发电量987.8亿千瓦时，同比下降7.4%；售电量929.1亿千瓦时，同比下降7.3%。但值得注意的是，公司上半年获取容量电费合计25.3亿元（含税），为电力板块利润提供了有力支撑。展望未来，随着三季度高温因素及上年四季度基数偏低因素显现，预计2025年下半年用电量增速将高于上半年，公司电力业务盈利有望改善。同时，公司稳妥推动九江二期、北海二期等煤电项目建设，印尼南苏1号项目已高质量投入运营，新增对外商业运营可再生能源发电项目215兆瓦，展示了公司在能源结构转型方面的积极布局。</p>\n<p>运输与煤化工业务呈现分化趋势。2025年上半年，公司铁路和港口分部利润总额分别为70.36亿元和13.29亿元，同比分别增长1.6%和9.7%，毛利率分别提升至40.3%和47.2%。而航运分部受航运货运量同比下降23.8%影响，利润总额为1.14亿元，同比下降48.6%。煤化工板块则受益于上年同期设备检修的低基数，聚乙烯和聚丙烯销量分别增长24.2%和22.6%，实现利润总额0.76亿元，较去年同期的100万元大幅改善。这一业务结构变化反映出公司在优化利润来源方面的努力。</p>\n<p>3.2 资产注入与成长空间</p>\n<p>千亿规模的资产重组将为中国神华打开新的成长空间。根据公司公告，本次交易拟收购控股股东国家能源集团持有的13家能源资产股权，全面覆盖煤炭开采、坑口煤电、煤制油煤制气煤化工及相关物流运输体系。此次重组不仅解决长期存在的同业竞争问题，更将显著提升公司煤炭资源战略储备和一体化运营能力。重组后，上游煤炭开采主体将提供稳定资源供给保障；中下游煤制油化工技术平台提升清洁高效转化水平，煤电一体化资产强化能源梯级利用效率；运输环节的路港航资产构建自主可控物流网络，各环节协同将大幅提升“西煤东运”战略通道运转效能。</p>\n<p>资产注入带来的财务改善同样值得期待。根据券商分析，此次重组将大幅增加企业自由现金流量水平，更好回报投资者。公司在手现金充裕，截至2025H1达1615亿元，资产负债率仅31.12%，经营性净现金流458亿元大幅超越净利润。这为未来可能的并购扩张和股东回报提升提供了坚实基础。公司正在推进的包头煤制烯烃升级示范项目也已进入全面建设阶段，有望在未来贡献新的利润增长点。</p>\n<p>3.3 分红政策与投资回报</p>\n<p>中国神华长期以来坚持高比例分红政策，为股东提供稳定回报。公司拟向全体股东派发2025年中期股息每股人民币0.98元（含税），合计派发现金红利人民币194.71亿元（含税），占2025年上半年归属于公司股东净利润的79.0%。这一分红比例实际超过了2024年年度的75%，向市场释放了积极分红信号的明确意向。公司还制定了2025-2027年度股东回报规划，承诺每年现金分红不低于当年归母净利润的65%，并考虑实施中期分红。</p>\n<p>稳定的高分红凸显了公司的投资价值，特别是在当前低利率市场环境下，对长期资金具备强大吸引力。根据回溯，公司2020-2023年分红率分别为91.8%、100%、72.7%、75%，持续处于行业领先水平。以当前股价计算，公司股息率具有显著竞争力，高比例、可持续的分红政策彰显了公司对股东回报的高度重视。这种注重股东回报的文化，与价值投资理念高度契合，使中国神华成为保险、养老基金等长期资金配置的重要标的。</p>\n<p>表：中国神华2025-2027年盈利预测与业务展望</p>\n<p>财务指标 2025E 2026E 2027E 主要驱动因素<br>营业收入(亿元) 2856 2879 2939 资产注入、电力业务恢复<br>归母净利润(亿元) 503.94 525.07 531.75 成本控制、一体化效应<br>EPS(元/股) 2.54 2.64 2.68 盈利改善、股本变动<br>分红比例 ≥65% ≥65% ≥65% 回报规划承诺</p>\n<p>4 扩展参考知识</p>\n<p>4.1 价值投资视角下的能源企业评估</p>\n<p>在价值投资框架下评估能源企业时，自由现金流生成能力是核心指标之一。中国神华近年来经营性现金流持续强劲，2025年上半年达到457.94亿元，大幅超过净利润水平。这一指标的重要性在于，它反映了企业实际能够支配的真实现金流，是股息支付、资本开支和债务偿还的真正来源。与单纯看净利润相比，自由现金流更能避免会计操纵的影响，揭示企业真实的财务健康状况。作为价值投资者，应特别关注企业长期自由现金流生成能力，而不仅仅是短期盈利波动。</p>\n<p>护城河理论在能源行业分析中具有特殊重要性。中国神华的护城河主要体现在以下几个方面：一是成本优势，公司拥有优质煤炭资源，埋藏浅、煤质好、成本低、易规模化开采；二是一体化经营的协同效应，通过自有铁路、港口网络降低整体运营成本；三是规模经济，作为行业龙头在采购、生产和销售环节均享有规模优势；四是政策壁垒，煤炭行业新建产能门槛不断提高，现有龙头企业受到政策保护。这些护城河要素共同构成了企业抵御竞争、维持长期盈利的基础，是价值投资分析的关键环节。</p>\n<p>4.2 煤电行业专业术语解析</p>\n<p>· 长协机制：长协即长期协议，在煤炭行业指供需双方签订的中长期购销合同。中国神华的年度长协价格按”基准价+浮动价”机制形成，相对稳定。这种机制有助于平抑煤价大幅波动对供需双方的影响，提供可预期的经营环境。对发电企业而言，长协煤是稳定供应的保障；对煤炭企业而言，长协锁定了大部分销量，是应对行业周期的有效工具。中国神华高达55.5%的年度长协占比，为其业绩提供了稳定器。<br>· 容量电价：容量电价是电力市场中的一种计价机制，发电企业不仅通过实际上网电量(电量电价)获取收入，还可根据其可调度的发电容量获得固定回报。2025年上半年中国神华获取容量电费合计25.3亿元（含税），这在一定程度上对冲了电量电价下滑的影响。容量电价政策保障了电力供应安全，使煤电企业在能源转型过程中保持适当的装机容量，为可再生能源提供调峰服务，同时改善了煤电企业的盈利稳定性。<br>· 坑口煤电：指建设在煤矿周边的发电机组，直接利用煤矿生产的煤炭进行发电。这种模式有效降低了煤炭运输成本，提高了能源转化效率。中国神华此次资产重组特别强调坑口煤电资产的注入，这有助于进一步发挥煤电一体化协同效应。坑口电站通过直接向远方负荷中心送电，变输煤为输电，往往具有更好的经济性和环保性能，是煤炭富集区域常用的能源开发模式。</p>\n<p>5 投资价值总结与风险提示</p>\n<p>综合评估中国神华的投资价值，可以看出公司作为煤炭行业龙头，拥有全产业链一体化运营的独特优势，通过高比例长协和领先的成本管控能力，在煤价下行周期中展现了出色的业绩韧性。公司正在推进的千亿规模资产重组将进一步提升资源储备和一体化运营效率，而明确的高分红政策和充裕的在手现金则为股东回报提供了坚实保障。基于多家券商预测，公司2025-2027年归母净利润将保持在500亿元以上水平，尽管短期可能同比下滑，但中长期增长趋势明确。</p>\n<p>从投资策略角度，中国神华适合价值投资者和收益型投资者配置。公司当前估值相对合理，2025年预测PE约15.0倍，低于历史平均水平。考虑到公司持续的高分红政策以及未来资产注入带来的成长潜力，公司具备长期持有价值。特别是对于注重现金流回报的投资者，公司稳定且可持续的股息提供了有吸引力的收益来源。在能源转型背景下，公司作为煤炭行业龙头，正通过产业链整合和运营效率提升，不断增强自身竞争优势，有望在行业变革中持续引领发展。</p>\n<p>潜在风险方面</p>\n<p>· 宏观经济复苏不及预期：经济增速放缓可能导致煤炭需求疲软，进而对煤价形成持续压力。特别是制造业、房地产等下游行业若持续低迷，将直接影响能源消费需求。<br>· 煤炭价格超预期下跌：虽然公司通过长协机制缓解了部分价格波动，但如果市场煤价大幅下跌，仍将对公司整体盈利能力产生负面影响。<br>· 资产整合不及预期：大规模资产重组后，不同业务板块之间的整合管理存在挑战，可能产生协同效应不及预期的风险。<br>· 政策变动风险：能源、环保等相关政策调整可能影响公司经营，如电价政策调整、安全生产标准提升等，都可能增加公司合规成本。<br>· 行业转型风险：能源结构向清洁低碳转型的长期趋势下，煤炭行业面临转型压力，公司需在维持传统业务优势和探索新能源发展之间取得平衡。</p>\n<p>总体而言，中国神华作为中国能源行业的龙头企业，凭借其独特的煤电运化一体化模式和稳健的财务政策，在当前的市场环境下展现出了显著的投资价值，特别适合那些寻求稳定股息收益和长期价值增长的投资者。公司持续的资产注入和明确的股东回报政策进一步增强了其投资吸引力，是价值投资者在能源板块不可多得的优质标的。</p>\n"},{"title":"columnar-file-formats","date":"2025-11-16T02:23:32.000Z","toc":true,"_content":"\n# Background\n\n在分析场景下列存相对行存有非常大的优势，可以极大减少 IO 的开销。在 Data Page Layouts for Relational Databases on Deep Memory Hierarchies[1] 一文中，引出了 PAX 格式并与行存进行了对比。\n\n以下表数据为例\n\n| column_a | column_b | column_c |\n| -- | -- | -- |\n| 1 | abcd | 3.2 |\n| 2 | efdf | 4.7 |\n\n分别使用行存和列存写到磁盘后的格式大致如下\n\n> 为了较好展示，以 `,` 为分隔符，且省略了各种 header/footer\n\n| 存储格式 | 内容 |\n| -- | -- |\n| 行存 |1,abcd,3.2,2,efdf,4.7 |\n| 列存 |1,2,abcd,efdf,3.2,4.7 |\n\n在分析场景中，读取某一列所有的数据是常见操作，但是对于行存来说读取某一列数据，需要在文件中进行多次 IO 定位，然后读取值，而对于列存来说可以直接顺序的读取某列整体的值。比如上述示例中读取 `column_c` 的值\n\n在行存中需要\n- 定位到 3.2 的位置\n- 读取 3.2 的值\n- 定位到 4.7 的位置\n- 读取 4.7 的值\n\n在列存中需要\n- 定位到 3.2 的位置\n- 连续读取 3.2 和 4.7 的值\n\n连续读取的开销比随机读取少，也就是第二种的开销更小，因此列存在分析场景中开销更小。\n\n文献[1] 中描述列存格式可以比行存减少由于 cache miss 导致的停顿延时 75%；range selection 的查询可以快 17-25%，TPC-H 中 I/O  更重的 query 要快 11-48%。\n\n<!-- more -->\n\n# Apache Parquet\n现在工业界中的列存格式大部分场景都会使用 Apache Parquet[2] 或者 Apache ORC[3]。由于数据湖格式的兴起，Apache Iceberg/Delta 等均以 Apache Parquet[2] 为主要格式，其他一些分析型 DB 重点支持 Apache Parquet，Apache Parquet 基本成为工业界列存的事实标准。\n\nApache Parquet 定义了一套语言无关的规范，不同语言基于同一套规范进行开发。定义大致如下\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511200846927.png)\n\nParquet 的读写流程大致如下\n- 写入\n  - 将数据写入内存并记录相应的 stat\n  - 待数据足够大（满足一个 row group 大小）后写出到磁盘，并重复该步骤\n  - 整个文件写完（主动或触发条件）写入可选信息（ColumnIndex/OffsetIndex/BloomFilter 等）\n  - 写出整个 footer 完成文件的写出\n- 读取\n  - 读取 footer 信息\n    - 解析 footer 信息中的 column metadata（使用 Thrift 所以需要进行全部读取和解析）\n    - 使用 column metadata 中的 stat 对数据进行过滤 (如果有 ColumnIndex/OffsetIndex 可以读取并进行更精细的过滤)\n      - column 级别的信息是 row group 中 column 级别的信息\n      - columnIndex/offsetIndex 则是 column 中 page 级别的信息（如果没有 columnIndex 则需要读取 PageHeader 才能对 Page 进行过滤，PageHeader 保存在 Page 内部）\n  - 定位到对应的 offset 读取实际的 page\n    - 读取并反序列化 page 的内容\n    - 对内容进行过滤\n\n从读写流程可知\n- 写入\n  - 需要 buffer 整个 row group 然后整体写出, 因此：1）写入端需要较多内存；2）列的大小差异较大会导致部分列存储的数据量少，从而影响读取时的 IO (多次小 IO)。\n- 读取\n  - 对于列非常多的情况下，读取和反序列化 columnChunkMetadata 可能开销较大（部分列实际不需要，但必须要读取），在没有 ColumnIndex 的情况下，stat 信息过滤的粒度太粗，且需要读取 page header 才能对 page 进行过滤（page header 和 page data 存放在一起）\n  - 对于嵌套列（Map/List）读取不太友好（比如读取 Map 中某个 key）\n\n由于现在 AI 场景中对于宽表（列比较多）和宽列（以及嵌套列）比较多，因此问题会更突出。现在工业界和学术界都有想办法进行改进和优化。\n\n# Another FileFormat or Better Parquet\n\n对于解决 Parquet 的劣势场景，主要有两个方向：1）是造一个新的 file format；2）在 Parquet 的基础上进行迭代优化。\n\n其中前者出现了 Nimble/Lance/Vortex 等一系列 format; 后者包括 Parquet Variant[4], 优化 footer 的读写[5][6]，以及在 Parquet 之上增加纯内存的 format 作为 cache 等；\n\n## Another FileFormat\n从零开始构造一个新的 file format 满足更多的场景以及硬件是一个很直观的想法，大公司和初创公司出现较多，Google/Meta 等有自己的列存格式，Goolge 的没有开源，Meta 的 Nimble[7] 已经开源；初创公司现在有 Lance[8]/Vortex[9] 是两个新兴的 file format。Lance 由于字节在推动知名度更高一些。Lance 和 Vortex 在 IcebergSummit 2025 上也有一个相关的 talk[10]。\n\n### Lance\n从 Lance 官网[11] 可知，Lance 的结构大致如下\n\n![](https://lancedb.com/assets/blog/lance-v2/wide-columns-grouping.png)\n\nLance 以一种更扁平的方式存储文件，没有 Parquet 中的 row group 的概念，数据会包括多个 page，每列的 page 写满后即可落盘，每个 page 会包括多个 buffer。ColumnMetadata 中会记录每个 buffer 的信息，然后也会记录 Global 的 Buffer 信息（全局的信息），最终的 Footer 会记录 ColumnMetadata 的相关信息（offset/size 等）以及一些其他类似版本，校验字等信息。\n\n从格式可以知道\n- 写入的时候不需要 buffer 整个 `RowGroup` 信息，因此内存消耗会小一些\n- 随机读取的时候因为有更细粒度的 stat 和索引，所以查询会更快一点（对于定长的数据，甚至可以直接通过计算定位到具体的 row）\n\n另外 Lance table format 有一个很有意思的点, 提供了 fragement: 一个 fragement 可以包括多个文件，这些文件的数据可以属于不同的列。这样可以在不重写数据的情况下支持动态增加列，并给存量数据的新列加上值。这在需要频繁加列的情况下会很友好，不过这个属于 table format 的层面，也就是说其他像 Iceberg/Delta 等也可以支持。\n\n### Vortex\nVortex 的结构大致如下\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251118160924.png)\n\n- DataPages 记录了具体的数据\n- Zone Map 记录某一列多行（逻辑 row group）的 stat，比如 min/max/nullcount 等\n- Filestatistics 记录文件级别的列 zonemap\n- Dtype 则是文件的逻辑数据类型（类似业务视角的数据类型），也就是 schema\n- Layout 是文件的存储格式，比如文中可以理解为和 Parquet 类似的一个存储\n- Footer 记录一些可以用来做过滤的信息\n- Postscript 记录了 schema/layout/filestatistics 以及 footer 信息，每个信息都是一个 segment(包括 offset, length, alignment exponent, compression spec, encryption spec 等) \n\n- 写入\n - Vortex 内 row group 更多的是一个逻辑概念，写入不需要 buffer 整个 row group 的内容，因此内存消耗比 Parquet 也会更小。\n- 读取\n - Vortex 首先读取 footer 创建 reader，然后可以通过 zonemap 中的信息进行过滤，然后从剩下的 segment 中进行读取（可以通过 segmentId 直接定位到文件中的 offset 继续读取），然后反序列化后进行更细的过滤。\n - 对于嵌套类型（Struct），可以使用不同的 Layout 将内部数据拆开，比如上图中的 Struct 两列 Column_A 和 Column_B 可以分开存储，这样读取的时候，仅需要读取某一列，而不是整个 Struct。\n\n由于 Vortex 将逻辑数据和物理存储拆开，因此可以同样的逻辑数据使用不同的物理存储，这样也可以支持在压缩数据上进行一定的计算与过滤。Vortex 中数据类型有 Owned 和 Viewed 两种，Owned 表示内存上的数据，Viewed 则表示磁盘上数据的视图，这样可以按需加载。\n\n## Better Parquet\n\nParquet 拥有一个不错的生态，在生产环境中要从一个成熟的生态中迁移是一件较难的事情，因此在 Parquet 基础上进行迭代改进也是一个方向，包括 Variant 以及 footer 读取的优化等。\n\n### Variant\nParuqet 的 Dremel 类型对存储量更优化，但是对于 CPU 计算和内存向量化（读取吞吐）等则不那么友好\n\n比如在 paruqet 中读取 nested data 的时候, 需要\n- 根据 repetition level 和 definition level 重构整个数据\n- Filter 支持不好，因为 Parquet 的 stat 经常是 RowGroup 或者 Page 级别的，无法对 inner data 进行过滤\n- SchemaEvolution 支持不好\n- 不太好支持 SIMD\n\n现在 Parquet variant 的出现则希望解决这一问题: Variant 默认将所有数据存储到一个二进制数组中，且包括一个 metadata，这样形成自解释的数据结构，同时可以将部分数据从二进制数组中抽出来单独存储成一个物理列，这样可以更好的进行计算和过滤。\n\nVariant 大致如下所示，其中 metadata 用于解释当前 variant，value 包括了所有非进行 shred 的二进制数据，typed_value 则存储了实际被抽出来的子列。更具体的可以参考 VariantShredding[12]\n```\n- metadata\n- value\n- typed_value\n  - [value]\n  - [typed_value]\n```\n\n这样操作之后\n- 可以很好的支持 SchemaEvolution\n- 数据访问的时候，可以使用 stat 进行过滤（因为单独抽出来一列，有 stat 信息）；可以使用 SIMD 操作（因为单独一列存放在一起）\n\n### Cache & MemoryFormat\n\nParquet 是一个非常成熟，拥有良好生态的 format，所以改动会相对缓慢，因此有人提出在 Parquet 之上搭建一套纯内存的 file format, 这个 file format 相比 Parquet 更适合使用在 cache 场景，这就是 LiquidCache[13] 的想法, Cache 中存储的是“逻辑数据”，而不是原始的 Paruqet 文件，主要考虑是：纯内存的 file format 可以比 Parquet 更适合 cache，且更自由的进行更新迭代（升级成本低）；可以复用现有 Parquet 的整体生态。\n\n直接 cache Parquet 格式本身，然后进行 filter pushdown 可能无法提升速度，反而会导致速度下降，主要原因在于 Parquet 的主要开销是 decode 和 decompress（超过 90%），而 Parquet 本身也不好针对 filter pushdown 做优化。文中描述了将物理结构与逻辑结构进行解耦，这样 LiquidCache 可以将 Parquet 转换成 liquid format。Liquid format 结合了 selective decoding，late filter materialization 以及 endocing-aware predicate evaluation，可以比 Parquet 更好的支持 filter pushdown。Parquet 转换为 liquid format 则是异步进行的，可以不 block 正常的处理流程。\n\nLiquidFormat 相对 Paruqet 的优势可以从下面两种图中可以查看\n\n下图中 LiquidFormat 可以比 Paruqet 少 decode 数据（只需要 decode 实际命中的数据）\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191105278.png)\n\n下图中则是 liquid format 在多 filter 场景下，可以应用 late materialization，在前面 filter 处理后的数据上进行 decode，这样可以减少第一个 filter 中被过滤掉数据的 decode。\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119110635.png)\n\n文中有给一些结论，整体来说 liquidcache 拥有不错的性能，更详细的数据可以参考原文以及 Github 仓库\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119111018.png)\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119111040.png)\n\n# Column File Format in Academic \n\n学术界也有关于列存的研究[14][15]. 其中文献[14] 对列存进行了对比，文献[15] 则提出了一种新的列存 F3，并和已有的列存进行了对比，虽然学术界到工业界落地可能需要一段时间，但是其思路是可以参考的。\n\n## Compare between column file formats\n\n本文[14] 设计了一个 benchmark 并以 Parquet 和 ORC 为例进行了对比。\n\nBenchmark 中引入了数据分布的几个维度: NDV, NullRatio, ValueRange, Sorteness, SkewPattern 用来表示数据的不同维度。\n\n论文中从 Public BI Benchmark/Clickhouse/UCI-ML/Yelp/LOG/Geonames/IMBD 多个数据集中进行分析得到如下分布情况\n\n- 超过 80% 的 Integer，超过 60% 的 String NDV 小于 0.01, 超过 60% 的 float NDV 小于 0.1\n   - 也就是说 Dictionary Encoding 是有用处的\n- Null 的数据比较多\n- 大部分数据分布式不均匀，小于 5% 的数据是 Uniform，60-70% 的在 Gentle Zipf 分布\n   - file format 需要能同时处理热点数据和长尾数据\n- 数据要么是完全排序的，要么就是无序的\n   - 对于有序的编码部分情况有用的\n- 数据范围比想象中的要小\n   - 数值型的大小绝大部分在 1e4 以内（80%）\n   - String 80% 的长度小于 25, 60% 的长度小于 10, 90%+ 的长度小于 50\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251120111333.png)\n\n将相关数据分类后总结成如下表格\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201122186.png)\n\n在不同场景下 Parquet 和 ORC 的对比如下（绝大部分场景相差不是很大）更详细的数据可以参考论文(从这里也能看出 Decode 比 IO 耗时更多)。\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201123543.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201124790.png)\n\n## F3\n\n本文认为已有的 format 诞生时的假设已经不成立\n- 1 relative hardware performance\n- 2 workload access pattern\n\n主要原因在于\n- 最近 10 年存储和网络性能有很大的提升，但是 CPU 的性能没有成比例的增长\n- 数据湖的出现也让更多的数据存储在高吞吐高延迟的云存储中，也让整体瓶颈从 IO 转移到 CPU\n- 数据的结构也发生了很大的变化（数据越来越\"宽\" -- 表的列很多，以及列里面的数据可能很大 -- 比如 blob)，ML 场景下存储几千列的特征，以及高维向量、图片等 blob 数据已经变成越来越常见，同时应用也希望能够进行随机读取甚至对已有数据进行更新。\n\n另外文中认为 Nimble/Lance/TSFile/Bullion/BtrBlocks 这些新的 format 也和之前的 format 有一样的问题: 对硬件和数据模式有一定的假设，就算取代了之前的 format, 在未来也会被新的 format 所取代。\n\nF3 则是为了解决这些问题而诞生的，F3 的全称是 Future-proof File Format, 号称是下一代开源的 file format，拥有 interoperability，extensibility 以及 efficiency 等特性。\n\n> Eache self-describing F3 file includes both the data and meta-data, as well as WebAssembly(Wasm) binaries to decode the data. \n\nF3 的整体架构如下所示\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191116416.png)\n\n文件包括 Data 和 Metadata 两部分，其中 Data 保存数据，Metadata 保存元数据\n\nData 中的结构和 Parquet 类似，F3 的 RowGroup 是逻辑的，因为写入的时候不需要 buffer 整个 row group, 可以单独写某一个 IOUnit（对应 Parquet 中的 page)，因此没有列大小不一样导致 IO 不是最优的情况。IOUnit 包括多个 EncUnit，EncUnit 是编解码的最小单元。EncUnit is essentially an opaque byte buffer that can be interpreted by the corresponding decoding implementation.\n\nFile Metadata 的结构如下所示\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191125566.png)\n\nMetadata 包括 OptData/ColMetadata/Footer 以及 Postscript, 整体使用 flatbuffer 存储。其中\n- OptData 是一个 keyvalue 的数据结构，现在用于存储 wasm binary （可以携带编解码逻辑），后续可以用来存储 index 和 filter 等\n- ColMetadata 保存了每个 RG 中每个 column 的元数据（包括 offset/size, 以及 dictionarytype, size encoding method 等）这里也记录了类似 Parquet 中 page header 的信息，这样可以直接从 Metadata 中对数据进行过滤。\n- Footer 记录 schema 以及 optData/ColMetadata/SharedDict 等的地址\n- Postscript 记录 ColMetadata/Footer/checksum 等\n\n在 F3 中 dictionary encoding 不像 Parquet 一样固定是 row group 级别，而是可以三类：None/Local/Shared。其中 None 表示没有 dictionary encoding，local 表示在当前 IOUnit 中，Shared 则表示可以和其他 IOUnit 共享（甚至跨 Column），这样可以有更好的灵活性。\n\n对于 NestedData 的处理则使用 L&P 的格式(有 buffer 记录是否存在，然后其他的 buffer 记录具体的位置），右下角的形式\n\n\n最后 F3 最后给出的一些不同 FileFormat 上的测试数据\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191551919.png)\n\n上图展示了随着列的增加，(所有 format）元数据的 overhead 基本是线性增长。因为不管 metadata 是否支持随机访问，在 footer 中均有与列大小正相关（比如 schema）的信息。Nimble 最快是因为存的信息最少；其他使用 FlatBuffer 但比 Nimble 慢的有一部分原因在于正确性校验; F3 比其他使用 FlatBuffer 的格式更好的原因在于支持跳过特定列的 I/O; Lance 需要读取和反序列化所有的 metadata，这也是导致它是所有使用 FlatBuffer 中最慢的；Vortext 可以跳过无关 metadata 的反序列化，但是无法跳过 IO。\n\n\n文中的一些其他测试数据可以参考，更详细的可以参考原文\n\n下图比较了不同 FileFormat 中压缩比、读吞吐、随机读延迟的情况。可以看出\n- F3/Vortex 在所有的情况下都有不错的性能\n- Parquet 拥有不错的压缩比，读取吞吐也不错，但是随机读性能差\n- Orc 的压缩率不错，吞吐一般，随机读取的性能比较弱\n- Lance 压缩率很差，读吞吐一般，随机读的能力很强\n- Nimble 压缩率, 读吞吐和随机读大部分情况下都属于中等水平，少数情况下优秀\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191656466.png)\n\n下图中上面的曲线表示不同的 row group size 情况下消耗的内存大小（左右是两个不同的场景）. 其中 Parquet 对内存的消耗比其他的都要大; Lance 和 F3 都是以 IOUnit 为最小单位刷盘，因此消耗内存较小；Nimble 和 ORC 则控制了单个 row group 的物理大小, 但是这样会导致 row group 存储数据量较少；Vortex 则由 writer 控制 buffer 大小。\n\n表格则表示不同的 FileFormat 的平均 ColumnChunk 大小，可以看到 ORC/Nimble 会有比较小的 ColumnChunk，Parquet 会有比较大的 Chunk，Lance 和 F3 的则会相对平均。\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119170350.png)\n\n\n# Conclusion\n\n随着数据湖以及分析场景的广泛使用，列存的关注度也越来越高，如何在新场景，新硬件下拥有更好的性能，本文做了一些调研，总的来说 Parquet 在随机读取、SIMD 等方面较弱，其他的相对不错，这些可以有不同的优化方向；新的 FileFormat 则从不同的角度希望解决不同的问题。这些可以让我们在后续进行决策的时候提供一定的基础。\n\n# Ref\n[1] Data Page Layouts for Relational Databases on Deep Memory Hierarchies\n[2] https://parquet.apache.org\n[3] https://orc.apache.org/\n[4] https://github.com/apache/parquet-format/blob/master/VariantEncoding.md\n[5] https://lists.apache.org/thread/j9qv5vyg0r4jk6tbm6sqthltly4oztd3\n[6] https://arrow.apache.org/blog/2025/10/23/rust-parquet-metadata/\n[7] https://github.com/facebookincubator/nimble\n[8] https://github.com/lance-format/lance\n[9] https://github.com/vortex-data/vortex/\n[10] https://www.youtube.com/watch?v=p6ZKY8JViCA\n[11] https://lancedb.com/blog/lance-v2/\n[12] https://github.com/apache/parquet-format/blob/master/VariantShredding.md\n[13] https://github.com/XiangpengHao/liquid-cache/blob/main/dev/doc/liquid-cache-vldb.pdf\n[14] https://www.vldb.org/pvldb/vol17/p148-zeng.pdf\n[15] https://db.cs.cmu.edu/papers/2025/zeng-sigmod2025.pdf\n","source":"_posts/column-format-compare.md","raw":"---\ntitle: columnar-file-formats\ndate: 2025-11-16 10:23:32\ntags:\n    - file-format\n    - column-fiel-format\n    - parquet\n    - lance\n    - vortex\n    - nimble\ntoc: true\n---\n\n# Background\n\n在分析场景下列存相对行存有非常大的优势，可以极大减少 IO 的开销。在 Data Page Layouts for Relational Databases on Deep Memory Hierarchies[1] 一文中，引出了 PAX 格式并与行存进行了对比。\n\n以下表数据为例\n\n| column_a | column_b | column_c |\n| -- | -- | -- |\n| 1 | abcd | 3.2 |\n| 2 | efdf | 4.7 |\n\n分别使用行存和列存写到磁盘后的格式大致如下\n\n> 为了较好展示，以 `,` 为分隔符，且省略了各种 header/footer\n\n| 存储格式 | 内容 |\n| -- | -- |\n| 行存 |1,abcd,3.2,2,efdf,4.7 |\n| 列存 |1,2,abcd,efdf,3.2,4.7 |\n\n在分析场景中，读取某一列所有的数据是常见操作，但是对于行存来说读取某一列数据，需要在文件中进行多次 IO 定位，然后读取值，而对于列存来说可以直接顺序的读取某列整体的值。比如上述示例中读取 `column_c` 的值\n\n在行存中需要\n- 定位到 3.2 的位置\n- 读取 3.2 的值\n- 定位到 4.7 的位置\n- 读取 4.7 的值\n\n在列存中需要\n- 定位到 3.2 的位置\n- 连续读取 3.2 和 4.7 的值\n\n连续读取的开销比随机读取少，也就是第二种的开销更小，因此列存在分析场景中开销更小。\n\n文献[1] 中描述列存格式可以比行存减少由于 cache miss 导致的停顿延时 75%；range selection 的查询可以快 17-25%，TPC-H 中 I/O  更重的 query 要快 11-48%。\n\n<!-- more -->\n\n# Apache Parquet\n现在工业界中的列存格式大部分场景都会使用 Apache Parquet[2] 或者 Apache ORC[3]。由于数据湖格式的兴起，Apache Iceberg/Delta 等均以 Apache Parquet[2] 为主要格式，其他一些分析型 DB 重点支持 Apache Parquet，Apache Parquet 基本成为工业界列存的事实标准。\n\nApache Parquet 定义了一套语言无关的规范，不同语言基于同一套规范进行开发。定义大致如下\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511200846927.png)\n\nParquet 的读写流程大致如下\n- 写入\n  - 将数据写入内存并记录相应的 stat\n  - 待数据足够大（满足一个 row group 大小）后写出到磁盘，并重复该步骤\n  - 整个文件写完（主动或触发条件）写入可选信息（ColumnIndex/OffsetIndex/BloomFilter 等）\n  - 写出整个 footer 完成文件的写出\n- 读取\n  - 读取 footer 信息\n    - 解析 footer 信息中的 column metadata（使用 Thrift 所以需要进行全部读取和解析）\n    - 使用 column metadata 中的 stat 对数据进行过滤 (如果有 ColumnIndex/OffsetIndex 可以读取并进行更精细的过滤)\n      - column 级别的信息是 row group 中 column 级别的信息\n      - columnIndex/offsetIndex 则是 column 中 page 级别的信息（如果没有 columnIndex 则需要读取 PageHeader 才能对 Page 进行过滤，PageHeader 保存在 Page 内部）\n  - 定位到对应的 offset 读取实际的 page\n    - 读取并反序列化 page 的内容\n    - 对内容进行过滤\n\n从读写流程可知\n- 写入\n  - 需要 buffer 整个 row group 然后整体写出, 因此：1）写入端需要较多内存；2）列的大小差异较大会导致部分列存储的数据量少，从而影响读取时的 IO (多次小 IO)。\n- 读取\n  - 对于列非常多的情况下，读取和反序列化 columnChunkMetadata 可能开销较大（部分列实际不需要，但必须要读取），在没有 ColumnIndex 的情况下，stat 信息过滤的粒度太粗，且需要读取 page header 才能对 page 进行过滤（page header 和 page data 存放在一起）\n  - 对于嵌套列（Map/List）读取不太友好（比如读取 Map 中某个 key）\n\n由于现在 AI 场景中对于宽表（列比较多）和宽列（以及嵌套列）比较多，因此问题会更突出。现在工业界和学术界都有想办法进行改进和优化。\n\n# Another FileFormat or Better Parquet\n\n对于解决 Parquet 的劣势场景，主要有两个方向：1）是造一个新的 file format；2）在 Parquet 的基础上进行迭代优化。\n\n其中前者出现了 Nimble/Lance/Vortex 等一系列 format; 后者包括 Parquet Variant[4], 优化 footer 的读写[5][6]，以及在 Parquet 之上增加纯内存的 format 作为 cache 等；\n\n## Another FileFormat\n从零开始构造一个新的 file format 满足更多的场景以及硬件是一个很直观的想法，大公司和初创公司出现较多，Google/Meta 等有自己的列存格式，Goolge 的没有开源，Meta 的 Nimble[7] 已经开源；初创公司现在有 Lance[8]/Vortex[9] 是两个新兴的 file format。Lance 由于字节在推动知名度更高一些。Lance 和 Vortex 在 IcebergSummit 2025 上也有一个相关的 talk[10]。\n\n### Lance\n从 Lance 官网[11] 可知，Lance 的结构大致如下\n\n![](https://lancedb.com/assets/blog/lance-v2/wide-columns-grouping.png)\n\nLance 以一种更扁平的方式存储文件，没有 Parquet 中的 row group 的概念，数据会包括多个 page，每列的 page 写满后即可落盘，每个 page 会包括多个 buffer。ColumnMetadata 中会记录每个 buffer 的信息，然后也会记录 Global 的 Buffer 信息（全局的信息），最终的 Footer 会记录 ColumnMetadata 的相关信息（offset/size 等）以及一些其他类似版本，校验字等信息。\n\n从格式可以知道\n- 写入的时候不需要 buffer 整个 `RowGroup` 信息，因此内存消耗会小一些\n- 随机读取的时候因为有更细粒度的 stat 和索引，所以查询会更快一点（对于定长的数据，甚至可以直接通过计算定位到具体的 row）\n\n另外 Lance table format 有一个很有意思的点, 提供了 fragement: 一个 fragement 可以包括多个文件，这些文件的数据可以属于不同的列。这样可以在不重写数据的情况下支持动态增加列，并给存量数据的新列加上值。这在需要频繁加列的情况下会很友好，不过这个属于 table format 的层面，也就是说其他像 Iceberg/Delta 等也可以支持。\n\n### Vortex\nVortex 的结构大致如下\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251118160924.png)\n\n- DataPages 记录了具体的数据\n- Zone Map 记录某一列多行（逻辑 row group）的 stat，比如 min/max/nullcount 等\n- Filestatistics 记录文件级别的列 zonemap\n- Dtype 则是文件的逻辑数据类型（类似业务视角的数据类型），也就是 schema\n- Layout 是文件的存储格式，比如文中可以理解为和 Parquet 类似的一个存储\n- Footer 记录一些可以用来做过滤的信息\n- Postscript 记录了 schema/layout/filestatistics 以及 footer 信息，每个信息都是一个 segment(包括 offset, length, alignment exponent, compression spec, encryption spec 等) \n\n- 写入\n - Vortex 内 row group 更多的是一个逻辑概念，写入不需要 buffer 整个 row group 的内容，因此内存消耗比 Parquet 也会更小。\n- 读取\n - Vortex 首先读取 footer 创建 reader，然后可以通过 zonemap 中的信息进行过滤，然后从剩下的 segment 中进行读取（可以通过 segmentId 直接定位到文件中的 offset 继续读取），然后反序列化后进行更细的过滤。\n - 对于嵌套类型（Struct），可以使用不同的 Layout 将内部数据拆开，比如上图中的 Struct 两列 Column_A 和 Column_B 可以分开存储，这样读取的时候，仅需要读取某一列，而不是整个 Struct。\n\n由于 Vortex 将逻辑数据和物理存储拆开，因此可以同样的逻辑数据使用不同的物理存储，这样也可以支持在压缩数据上进行一定的计算与过滤。Vortex 中数据类型有 Owned 和 Viewed 两种，Owned 表示内存上的数据，Viewed 则表示磁盘上数据的视图，这样可以按需加载。\n\n## Better Parquet\n\nParquet 拥有一个不错的生态，在生产环境中要从一个成熟的生态中迁移是一件较难的事情，因此在 Parquet 基础上进行迭代改进也是一个方向，包括 Variant 以及 footer 读取的优化等。\n\n### Variant\nParuqet 的 Dremel 类型对存储量更优化，但是对于 CPU 计算和内存向量化（读取吞吐）等则不那么友好\n\n比如在 paruqet 中读取 nested data 的时候, 需要\n- 根据 repetition level 和 definition level 重构整个数据\n- Filter 支持不好，因为 Parquet 的 stat 经常是 RowGroup 或者 Page 级别的，无法对 inner data 进行过滤\n- SchemaEvolution 支持不好\n- 不太好支持 SIMD\n\n现在 Parquet variant 的出现则希望解决这一问题: Variant 默认将所有数据存储到一个二进制数组中，且包括一个 metadata，这样形成自解释的数据结构，同时可以将部分数据从二进制数组中抽出来单独存储成一个物理列，这样可以更好的进行计算和过滤。\n\nVariant 大致如下所示，其中 metadata 用于解释当前 variant，value 包括了所有非进行 shred 的二进制数据，typed_value 则存储了实际被抽出来的子列。更具体的可以参考 VariantShredding[12]\n```\n- metadata\n- value\n- typed_value\n  - [value]\n  - [typed_value]\n```\n\n这样操作之后\n- 可以很好的支持 SchemaEvolution\n- 数据访问的时候，可以使用 stat 进行过滤（因为单独抽出来一列，有 stat 信息）；可以使用 SIMD 操作（因为单独一列存放在一起）\n\n### Cache & MemoryFormat\n\nParquet 是一个非常成熟，拥有良好生态的 format，所以改动会相对缓慢，因此有人提出在 Parquet 之上搭建一套纯内存的 file format, 这个 file format 相比 Parquet 更适合使用在 cache 场景，这就是 LiquidCache[13] 的想法, Cache 中存储的是“逻辑数据”，而不是原始的 Paruqet 文件，主要考虑是：纯内存的 file format 可以比 Parquet 更适合 cache，且更自由的进行更新迭代（升级成本低）；可以复用现有 Parquet 的整体生态。\n\n直接 cache Parquet 格式本身，然后进行 filter pushdown 可能无法提升速度，反而会导致速度下降，主要原因在于 Parquet 的主要开销是 decode 和 decompress（超过 90%），而 Parquet 本身也不好针对 filter pushdown 做优化。文中描述了将物理结构与逻辑结构进行解耦，这样 LiquidCache 可以将 Parquet 转换成 liquid format。Liquid format 结合了 selective decoding，late filter materialization 以及 endocing-aware predicate evaluation，可以比 Parquet 更好的支持 filter pushdown。Parquet 转换为 liquid format 则是异步进行的，可以不 block 正常的处理流程。\n\nLiquidFormat 相对 Paruqet 的优势可以从下面两种图中可以查看\n\n下图中 LiquidFormat 可以比 Paruqet 少 decode 数据（只需要 decode 实际命中的数据）\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191105278.png)\n\n下图中则是 liquid format 在多 filter 场景下，可以应用 late materialization，在前面 filter 处理后的数据上进行 decode，这样可以减少第一个 filter 中被过滤掉数据的 decode。\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119110635.png)\n\n文中有给一些结论，整体来说 liquidcache 拥有不错的性能，更详细的数据可以参考原文以及 Github 仓库\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119111018.png)\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119111040.png)\n\n# Column File Format in Academic \n\n学术界也有关于列存的研究[14][15]. 其中文献[14] 对列存进行了对比，文献[15] 则提出了一种新的列存 F3，并和已有的列存进行了对比，虽然学术界到工业界落地可能需要一段时间，但是其思路是可以参考的。\n\n## Compare between column file formats\n\n本文[14] 设计了一个 benchmark 并以 Parquet 和 ORC 为例进行了对比。\n\nBenchmark 中引入了数据分布的几个维度: NDV, NullRatio, ValueRange, Sorteness, SkewPattern 用来表示数据的不同维度。\n\n论文中从 Public BI Benchmark/Clickhouse/UCI-ML/Yelp/LOG/Geonames/IMBD 多个数据集中进行分析得到如下分布情况\n\n- 超过 80% 的 Integer，超过 60% 的 String NDV 小于 0.01, 超过 60% 的 float NDV 小于 0.1\n   - 也就是说 Dictionary Encoding 是有用处的\n- Null 的数据比较多\n- 大部分数据分布式不均匀，小于 5% 的数据是 Uniform，60-70% 的在 Gentle Zipf 分布\n   - file format 需要能同时处理热点数据和长尾数据\n- 数据要么是完全排序的，要么就是无序的\n   - 对于有序的编码部分情况有用的\n- 数据范围比想象中的要小\n   - 数值型的大小绝大部分在 1e4 以内（80%）\n   - String 80% 的长度小于 25, 60% 的长度小于 10, 90%+ 的长度小于 50\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251120111333.png)\n\n将相关数据分类后总结成如下表格\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201122186.png)\n\n在不同场景下 Parquet 和 ORC 的对比如下（绝大部分场景相差不是很大）更详细的数据可以参考论文(从这里也能看出 Decode 比 IO 耗时更多)。\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201123543.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201124790.png)\n\n## F3\n\n本文认为已有的 format 诞生时的假设已经不成立\n- 1 relative hardware performance\n- 2 workload access pattern\n\n主要原因在于\n- 最近 10 年存储和网络性能有很大的提升，但是 CPU 的性能没有成比例的增长\n- 数据湖的出现也让更多的数据存储在高吞吐高延迟的云存储中，也让整体瓶颈从 IO 转移到 CPU\n- 数据的结构也发生了很大的变化（数据越来越\"宽\" -- 表的列很多，以及列里面的数据可能很大 -- 比如 blob)，ML 场景下存储几千列的特征，以及高维向量、图片等 blob 数据已经变成越来越常见，同时应用也希望能够进行随机读取甚至对已有数据进行更新。\n\n另外文中认为 Nimble/Lance/TSFile/Bullion/BtrBlocks 这些新的 format 也和之前的 format 有一样的问题: 对硬件和数据模式有一定的假设，就算取代了之前的 format, 在未来也会被新的 format 所取代。\n\nF3 则是为了解决这些问题而诞生的，F3 的全称是 Future-proof File Format, 号称是下一代开源的 file format，拥有 interoperability，extensibility 以及 efficiency 等特性。\n\n> Eache self-describing F3 file includes both the data and meta-data, as well as WebAssembly(Wasm) binaries to decode the data. \n\nF3 的整体架构如下所示\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191116416.png)\n\n文件包括 Data 和 Metadata 两部分，其中 Data 保存数据，Metadata 保存元数据\n\nData 中的结构和 Parquet 类似，F3 的 RowGroup 是逻辑的，因为写入的时候不需要 buffer 整个 row group, 可以单独写某一个 IOUnit（对应 Parquet 中的 page)，因此没有列大小不一样导致 IO 不是最优的情况。IOUnit 包括多个 EncUnit，EncUnit 是编解码的最小单元。EncUnit is essentially an opaque byte buffer that can be interpreted by the corresponding decoding implementation.\n\nFile Metadata 的结构如下所示\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191125566.png)\n\nMetadata 包括 OptData/ColMetadata/Footer 以及 Postscript, 整体使用 flatbuffer 存储。其中\n- OptData 是一个 keyvalue 的数据结构，现在用于存储 wasm binary （可以携带编解码逻辑），后续可以用来存储 index 和 filter 等\n- ColMetadata 保存了每个 RG 中每个 column 的元数据（包括 offset/size, 以及 dictionarytype, size encoding method 等）这里也记录了类似 Parquet 中 page header 的信息，这样可以直接从 Metadata 中对数据进行过滤。\n- Footer 记录 schema 以及 optData/ColMetadata/SharedDict 等的地址\n- Postscript 记录 ColMetadata/Footer/checksum 等\n\n在 F3 中 dictionary encoding 不像 Parquet 一样固定是 row group 级别，而是可以三类：None/Local/Shared。其中 None 表示没有 dictionary encoding，local 表示在当前 IOUnit 中，Shared 则表示可以和其他 IOUnit 共享（甚至跨 Column），这样可以有更好的灵活性。\n\n对于 NestedData 的处理则使用 L&P 的格式(有 buffer 记录是否存在，然后其他的 buffer 记录具体的位置），右下角的形式\n\n\n最后 F3 最后给出的一些不同 FileFormat 上的测试数据\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191551919.png)\n\n上图展示了随着列的增加，(所有 format）元数据的 overhead 基本是线性增长。因为不管 metadata 是否支持随机访问，在 footer 中均有与列大小正相关（比如 schema）的信息。Nimble 最快是因为存的信息最少；其他使用 FlatBuffer 但比 Nimble 慢的有一部分原因在于正确性校验; F3 比其他使用 FlatBuffer 的格式更好的原因在于支持跳过特定列的 I/O; Lance 需要读取和反序列化所有的 metadata，这也是导致它是所有使用 FlatBuffer 中最慢的；Vortext 可以跳过无关 metadata 的反序列化，但是无法跳过 IO。\n\n\n文中的一些其他测试数据可以参考，更详细的可以参考原文\n\n下图比较了不同 FileFormat 中压缩比、读吞吐、随机读延迟的情况。可以看出\n- F3/Vortex 在所有的情况下都有不错的性能\n- Parquet 拥有不错的压缩比，读取吞吐也不错，但是随机读性能差\n- Orc 的压缩率不错，吞吐一般，随机读取的性能比较弱\n- Lance 压缩率很差，读吞吐一般，随机读的能力很强\n- Nimble 压缩率, 读吞吐和随机读大部分情况下都属于中等水平，少数情况下优秀\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191656466.png)\n\n下图中上面的曲线表示不同的 row group size 情况下消耗的内存大小（左右是两个不同的场景）. 其中 Parquet 对内存的消耗比其他的都要大; Lance 和 F3 都是以 IOUnit 为最小单位刷盘，因此消耗内存较小；Nimble 和 ORC 则控制了单个 row group 的物理大小, 但是这样会导致 row group 存储数据量较少；Vortex 则由 writer 控制 buffer 大小。\n\n表格则表示不同的 FileFormat 的平均 ColumnChunk 大小，可以看到 ORC/Nimble 会有比较小的 ColumnChunk，Parquet 会有比较大的 Chunk，Lance 和 F3 的则会相对平均。\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119170350.png)\n\n\n# Conclusion\n\n随着数据湖以及分析场景的广泛使用，列存的关注度也越来越高，如何在新场景，新硬件下拥有更好的性能，本文做了一些调研，总的来说 Parquet 在随机读取、SIMD 等方面较弱，其他的相对不错，这些可以有不同的优化方向；新的 FileFormat 则从不同的角度希望解决不同的问题。这些可以让我们在后续进行决策的时候提供一定的基础。\n\n# Ref\n[1] Data Page Layouts for Relational Databases on Deep Memory Hierarchies\n[2] https://parquet.apache.org\n[3] https://orc.apache.org/\n[4] https://github.com/apache/parquet-format/blob/master/VariantEncoding.md\n[5] https://lists.apache.org/thread/j9qv5vyg0r4jk6tbm6sqthltly4oztd3\n[6] https://arrow.apache.org/blog/2025/10/23/rust-parquet-metadata/\n[7] https://github.com/facebookincubator/nimble\n[8] https://github.com/lance-format/lance\n[9] https://github.com/vortex-data/vortex/\n[10] https://www.youtube.com/watch?v=p6ZKY8JViCA\n[11] https://lancedb.com/blog/lance-v2/\n[12] https://github.com/apache/parquet-format/blob/master/VariantShredding.md\n[13] https://github.com/XiangpengHao/liquid-cache/blob/main/dev/doc/liquid-cache-vldb.pdf\n[14] https://www.vldb.org/pvldb/vol17/p148-zeng.pdf\n[15] https://db.cs.cmu.edu/papers/2025/zeng-sigmod2025.pdf\n","slug":"column-format-compare","published":1,"updated":"2025-11-21T02:18:07.633Z","_id":"cmi87ko2q000spwmk6zatebak","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h1><p>在分析场景下列存相对行存有非常大的优势，可以极大减少 IO 的开销。在 Data Page Layouts for Relational Databases on Deep Memory Hierarchies[1] 一文中，引出了 PAX 格式并与行存进行了对比。</p>\n<p>以下表数据为例</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>column_a</th>\n<th>column_b</th>\n<th>column_c</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>abcd</td>\n<td>3.2</td>\n</tr>\n<tr>\n<td>2</td>\n<td>efdf</td>\n<td>4.7</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>分别使用行存和列存写到磁盘后的格式大致如下</p>\n<blockquote>\n<p>为了较好展示，以 <code>,</code> 为分隔符，且省略了各种 header/footer</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>存储格式</th>\n<th>内容</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>行存</td>\n<td>1,abcd,3.2,2,efdf,4.7</td>\n</tr>\n<tr>\n<td>列存</td>\n<td>1,2,abcd,efdf,3.2,4.7</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>在分析场景中，读取某一列所有的数据是常见操作，但是对于行存来说读取某一列数据，需要在文件中进行多次 IO 定位，然后读取值，而对于列存来说可以直接顺序的读取某列整体的值。比如上述示例中读取 <code>column_c</code> 的值</p>\n<p>在行存中需要</p>\n<ul>\n<li>定位到 3.2 的位置</li>\n<li>读取 3.2 的值</li>\n<li>定位到 4.7 的位置</li>\n<li>读取 4.7 的值</li>\n</ul>\n<p>在列存中需要</p>\n<ul>\n<li>定位到 3.2 的位置</li>\n<li>连续读取 3.2 和 4.7 的值</li>\n</ul>\n<p>连续读取的开销比随机读取少，也就是第二种的开销更小，因此列存在分析场景中开销更小。</p>\n<p>文献[1] 中描述列存格式可以比行存减少由于 cache miss 导致的停顿延时 75%；range selection 的查询可以快 17-25%，TPC-H 中 I/O  更重的 query 要快 11-48%。</p>\n<span id=\"more\"></span>\n<h1 id=\"Apache-Parquet\"><a href=\"#Apache-Parquet\" class=\"headerlink\" title=\"Apache Parquet\"></a>Apache Parquet</h1><p>现在工业界中的列存格式大部分场景都会使用 Apache Parquet[2] 或者 Apache ORC[3]。由于数据湖格式的兴起，Apache Iceberg/Delta 等均以 Apache Parquet[2] 为主要格式，其他一些分析型 DB 重点支持 Apache Parquet，Apache Parquet 基本成为工业界列存的事实标准。</p>\n<p>Apache Parquet 定义了一套语言无关的规范，不同语言基于同一套规范进行开发。定义大致如下</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511200846927.png\" alt=\"\"></p>\n<p>Parquet 的读写流程大致如下</p>\n<ul>\n<li>写入<ul>\n<li>将数据写入内存并记录相应的 stat</li>\n<li>待数据足够大（满足一个 row group 大小）后写出到磁盘，并重复该步骤</li>\n<li>整个文件写完（主动或触发条件）写入可选信息（ColumnIndex/OffsetIndex/BloomFilter 等）</li>\n<li>写出整个 footer 完成文件的写出</li>\n</ul>\n</li>\n<li>读取<ul>\n<li>读取 footer 信息<ul>\n<li>解析 footer 信息中的 column metadata（使用 Thrift 所以需要进行全部读取和解析）</li>\n<li>使用 column metadata 中的 stat 对数据进行过滤 (如果有 ColumnIndex/OffsetIndex 可以读取并进行更精细的过滤)<ul>\n<li>column 级别的信息是 row group 中 column 级别的信息</li>\n<li>columnIndex/offsetIndex 则是 column 中 page 级别的信息（如果没有 columnIndex 则需要读取 PageHeader 才能对 Page 进行过滤，PageHeader 保存在 Page 内部）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>定位到对应的 offset 读取实际的 page<ul>\n<li>读取并反序列化 page 的内容</li>\n<li>对内容进行过滤</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>从读写流程可知</p>\n<ul>\n<li>写入<ul>\n<li>需要 buffer 整个 row group 然后整体写出, 因此：1）写入端需要较多内存；2）列的大小差异较大会导致部分列存储的数据量少，从而影响读取时的 IO (多次小 IO)。</li>\n</ul>\n</li>\n<li>读取<ul>\n<li>对于列非常多的情况下，读取和反序列化 columnChunkMetadata 可能开销较大（部分列实际不需要，但必须要读取），在没有 ColumnIndex 的情况下，stat 信息过滤的粒度太粗，且需要读取 page header 才能对 page 进行过滤（page header 和 page data 存放在一起）</li>\n<li>对于嵌套列（Map/List）读取不太友好（比如读取 Map 中某个 key）</li>\n</ul>\n</li>\n</ul>\n<p>由于现在 AI 场景中对于宽表（列比较多）和宽列（以及嵌套列）比较多，因此问题会更突出。现在工业界和学术界都有想办法进行改进和优化。</p>\n<h1 id=\"Another-FileFormat-or-Better-Parquet\"><a href=\"#Another-FileFormat-or-Better-Parquet\" class=\"headerlink\" title=\"Another FileFormat or Better Parquet\"></a>Another FileFormat or Better Parquet</h1><p>对于解决 Parquet 的劣势场景，主要有两个方向：1）是造一个新的 file format；2）在 Parquet 的基础上进行迭代优化。</p>\n<p>其中前者出现了 Nimble/Lance/Vortex 等一系列 format; 后者包括 Parquet Variant[4], 优化 footer 的读写[5][6]，以及在 Parquet 之上增加纯内存的 format 作为 cache 等；</p>\n<h2 id=\"Another-FileFormat\"><a href=\"#Another-FileFormat\" class=\"headerlink\" title=\"Another FileFormat\"></a>Another FileFormat</h2><p>从零开始构造一个新的 file format 满足更多的场景以及硬件是一个很直观的想法，大公司和初创公司出现较多，Google/Meta 等有自己的列存格式，Goolge 的没有开源，Meta 的 Nimble[7] 已经开源；初创公司现在有 Lance[8]/Vortex[9] 是两个新兴的 file format。Lance 由于字节在推动知名度更高一些。Lance 和 Vortex 在 IcebergSummit 2025 上也有一个相关的 talk[10]。</p>\n<h3 id=\"Lance\"><a href=\"#Lance\" class=\"headerlink\" title=\"Lance\"></a>Lance</h3><p>从 Lance 官网[11] 可知，Lance 的结构大致如下</p>\n<p><img src=\"https://lancedb.com/assets/blog/lance-v2/wide-columns-grouping.png\" alt=\"\"></p>\n<p>Lance 以一种更扁平的方式存储文件，没有 Parquet 中的 row group 的概念，数据会包括多个 page，每列的 page 写满后即可落盘，每个 page 会包括多个 buffer。ColumnMetadata 中会记录每个 buffer 的信息，然后也会记录 Global 的 Buffer 信息（全局的信息），最终的 Footer 会记录 ColumnMetadata 的相关信息（offset/size 等）以及一些其他类似版本，校验字等信息。</p>\n<p>从格式可以知道</p>\n<ul>\n<li>写入的时候不需要 buffer 整个 <code>RowGroup</code> 信息，因此内存消耗会小一些</li>\n<li>随机读取的时候因为有更细粒度的 stat 和索引，所以查询会更快一点（对于定长的数据，甚至可以直接通过计算定位到具体的 row）</li>\n</ul>\n<p>另外 Lance table format 有一个很有意思的点, 提供了 fragement: 一个 fragement 可以包括多个文件，这些文件的数据可以属于不同的列。这样可以在不重写数据的情况下支持动态增加列，并给存量数据的新列加上值。这在需要频繁加列的情况下会很友好，不过这个属于 table format 的层面，也就是说其他像 Iceberg/Delta 等也可以支持。</p>\n<h3 id=\"Vortex\"><a href=\"#Vortex\" class=\"headerlink\" title=\"Vortex\"></a>Vortex</h3><p>Vortex 的结构大致如下</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251118160924.png\" alt=\"\"></p>\n<ul>\n<li>DataPages 记录了具体的数据</li>\n<li>Zone Map 记录某一列多行（逻辑 row group）的 stat，比如 min/max/nullcount 等</li>\n<li>Filestatistics 记录文件级别的列 zonemap</li>\n<li>Dtype 则是文件的逻辑数据类型（类似业务视角的数据类型），也就是 schema</li>\n<li>Layout 是文件的存储格式，比如文中可以理解为和 Parquet 类似的一个存储</li>\n<li>Footer 记录一些可以用来做过滤的信息</li>\n<li><p>Postscript 记录了 schema/layout/filestatistics 以及 footer 信息，每个信息都是一个 segment(包括 offset, length, alignment exponent, compression spec, encryption spec 等) </p>\n</li>\n<li><p>写入</p>\n<ul>\n<li>Vortex 内 row group 更多的是一个逻辑概念，写入不需要 buffer 整个 row group 的内容，因此内存消耗比 Parquet 也会更小。</li>\n</ul>\n</li>\n<li>读取<ul>\n<li>Vortex 首先读取 footer 创建 reader，然后可以通过 zonemap 中的信息进行过滤，然后从剩下的 segment 中进行读取（可以通过 segmentId 直接定位到文件中的 offset 继续读取），然后反序列化后进行更细的过滤。</li>\n<li>对于嵌套类型（Struct），可以使用不同的 Layout 将内部数据拆开，比如上图中的 Struct 两列 Column_A 和 Column_B 可以分开存储，这样读取的时候，仅需要读取某一列，而不是整个 Struct。</li>\n</ul>\n</li>\n</ul>\n<p>由于 Vortex 将逻辑数据和物理存储拆开，因此可以同样的逻辑数据使用不同的物理存储，这样也可以支持在压缩数据上进行一定的计算与过滤。Vortex 中数据类型有 Owned 和 Viewed 两种，Owned 表示内存上的数据，Viewed 则表示磁盘上数据的视图，这样可以按需加载。</p>\n<h2 id=\"Better-Parquet\"><a href=\"#Better-Parquet\" class=\"headerlink\" title=\"Better Parquet\"></a>Better Parquet</h2><p>Parquet 拥有一个不错的生态，在生产环境中要从一个成熟的生态中迁移是一件较难的事情，因此在 Parquet 基础上进行迭代改进也是一个方向，包括 Variant 以及 footer 读取的优化等。</p>\n<h3 id=\"Variant\"><a href=\"#Variant\" class=\"headerlink\" title=\"Variant\"></a>Variant</h3><p>Paruqet 的 Dremel 类型对存储量更优化，但是对于 CPU 计算和内存向量化（读取吞吐）等则不那么友好</p>\n<p>比如在 paruqet 中读取 nested data 的时候, 需要</p>\n<ul>\n<li>根据 repetition level 和 definition level 重构整个数据</li>\n<li>Filter 支持不好，因为 Parquet 的 stat 经常是 RowGroup 或者 Page 级别的，无法对 inner data 进行过滤</li>\n<li>SchemaEvolution 支持不好</li>\n<li>不太好支持 SIMD</li>\n</ul>\n<p>现在 Parquet variant 的出现则希望解决这一问题: Variant 默认将所有数据存储到一个二进制数组中，且包括一个 metadata，这样形成自解释的数据结构，同时可以将部分数据从二进制数组中抽出来单独存储成一个物理列，这样可以更好的进行计算和过滤。</p>\n<p>Variant 大致如下所示，其中 metadata 用于解释当前 variant，value 包括了所有非进行 shred 的二进制数据，typed_value 则存储了实际被抽出来的子列。更具体的可以参考 VariantShredding[12]<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- metadata</span><br><span class=\"line\">- value</span><br><span class=\"line\">- typed_value</span><br><span class=\"line\">  - [value]</span><br><span class=\"line\">  - [typed_value]</span><br></pre></td></tr></table></figure></p>\n<p>这样操作之后</p>\n<ul>\n<li>可以很好的支持 SchemaEvolution</li>\n<li>数据访问的时候，可以使用 stat 进行过滤（因为单独抽出来一列，有 stat 信息）；可以使用 SIMD 操作（因为单独一列存放在一起）</li>\n</ul>\n<h3 id=\"Cache-amp-MemoryFormat\"><a href=\"#Cache-amp-MemoryFormat\" class=\"headerlink\" title=\"Cache &amp; MemoryFormat\"></a>Cache &amp; MemoryFormat</h3><p>Parquet 是一个非常成熟，拥有良好生态的 format，所以改动会相对缓慢，因此有人提出在 Parquet 之上搭建一套纯内存的 file format, 这个 file format 相比 Parquet 更适合使用在 cache 场景，这就是 LiquidCache[13] 的想法, Cache 中存储的是“逻辑数据”，而不是原始的 Paruqet 文件，主要考虑是：纯内存的 file format 可以比 Parquet 更适合 cache，且更自由的进行更新迭代（升级成本低）；可以复用现有 Parquet 的整体生态。</p>\n<p>直接 cache Parquet 格式本身，然后进行 filter pushdown 可能无法提升速度，反而会导致速度下降，主要原因在于 Parquet 的主要开销是 decode 和 decompress（超过 90%），而 Parquet 本身也不好针对 filter pushdown 做优化。文中描述了将物理结构与逻辑结构进行解耦，这样 LiquidCache 可以将 Parquet 转换成 liquid format。Liquid format 结合了 selective decoding，late filter materialization 以及 endocing-aware predicate evaluation，可以比 Parquet 更好的支持 filter pushdown。Parquet 转换为 liquid format 则是异步进行的，可以不 block 正常的处理流程。</p>\n<p>LiquidFormat 相对 Paruqet 的优势可以从下面两种图中可以查看</p>\n<p>下图中 LiquidFormat 可以比 Paruqet 少 decode 数据（只需要 decode 实际命中的数据）<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191105278.png\" alt=\"\"></p>\n<p>下图中则是 liquid format 在多 filter 场景下，可以应用 late materialization，在前面 filter 处理后的数据上进行 decode，这样可以减少第一个 filter 中被过滤掉数据的 decode。<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119110635.png\" alt=\"\"></p>\n<p>文中有给一些结论，整体来说 liquidcache 拥有不错的性能，更详细的数据可以参考原文以及 Github 仓库</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119111018.png\" alt=\"\"><br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119111040.png\" alt=\"\"></p>\n<h1 id=\"Column-File-Format-in-Academic\"><a href=\"#Column-File-Format-in-Academic\" class=\"headerlink\" title=\"Column File Format in Academic\"></a>Column File Format in Academic</h1><p>学术界也有关于列存的研究[14][15]. 其中文献[14] 对列存进行了对比，文献[15] 则提出了一种新的列存 F3，并和已有的列存进行了对比，虽然学术界到工业界落地可能需要一段时间，但是其思路是可以参考的。</p>\n<h2 id=\"Compare-between-column-file-formats\"><a href=\"#Compare-between-column-file-formats\" class=\"headerlink\" title=\"Compare between column file formats\"></a>Compare between column file formats</h2><p>本文[14] 设计了一个 benchmark 并以 Parquet 和 ORC 为例进行了对比。</p>\n<p>Benchmark 中引入了数据分布的几个维度: NDV, NullRatio, ValueRange, Sorteness, SkewPattern 用来表示数据的不同维度。</p>\n<p>论文中从 Public BI Benchmark/Clickhouse/UCI-ML/Yelp/LOG/Geonames/IMBD 多个数据集中进行分析得到如下分布情况</p>\n<ul>\n<li>超过 80% 的 Integer，超过 60% 的 String NDV 小于 0.01, 超过 60% 的 float NDV 小于 0.1<ul>\n<li>也就是说 Dictionary Encoding 是有用处的</li>\n</ul>\n</li>\n<li>Null 的数据比较多</li>\n<li>大部分数据分布式不均匀，小于 5% 的数据是 Uniform，60-70% 的在 Gentle Zipf 分布<ul>\n<li>file format 需要能同时处理热点数据和长尾数据</li>\n</ul>\n</li>\n<li>数据要么是完全排序的，要么就是无序的<ul>\n<li>对于有序的编码部分情况有用的</li>\n</ul>\n</li>\n<li>数据范围比想象中的要小<ul>\n<li>数值型的大小绝大部分在 1e4 以内（80%）</li>\n<li>String 80% 的长度小于 25, 60% 的长度小于 10, 90%+ 的长度小于 50</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251120111333.png\" alt=\"\"></p>\n<p>将相关数据分类后总结成如下表格</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201122186.png\" alt=\"\"></p>\n<p>在不同场景下 Parquet 和 ORC 的对比如下（绝大部分场景相差不是很大）更详细的数据可以参考论文(从这里也能看出 Decode 比 IO 耗时更多)。</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201123543.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201124790.png\" alt=\"\"></p>\n<h2 id=\"F3\"><a href=\"#F3\" class=\"headerlink\" title=\"F3\"></a>F3</h2><p>本文认为已有的 format 诞生时的假设已经不成立</p>\n<ul>\n<li>1 relative hardware performance</li>\n<li>2 workload access pattern</li>\n</ul>\n<p>主要原因在于</p>\n<ul>\n<li>最近 10 年存储和网络性能有很大的提升，但是 CPU 的性能没有成比例的增长</li>\n<li>数据湖的出现也让更多的数据存储在高吞吐高延迟的云存储中，也让整体瓶颈从 IO 转移到 CPU</li>\n<li>数据的结构也发生了很大的变化（数据越来越”宽” — 表的列很多，以及列里面的数据可能很大 — 比如 blob)，ML 场景下存储几千列的特征，以及高维向量、图片等 blob 数据已经变成越来越常见，同时应用也希望能够进行随机读取甚至对已有数据进行更新。</li>\n</ul>\n<p>另外文中认为 Nimble/Lance/TSFile/Bullion/BtrBlocks 这些新的 format 也和之前的 format 有一样的问题: 对硬件和数据模式有一定的假设，就算取代了之前的 format, 在未来也会被新的 format 所取代。</p>\n<p>F3 则是为了解决这些问题而诞生的，F3 的全称是 Future-proof File Format, 号称是下一代开源的 file format，拥有 interoperability，extensibility 以及 efficiency 等特性。</p>\n<blockquote>\n<p>Eache self-describing F3 file includes both the data and meta-data, as well as WebAssembly(Wasm) binaries to decode the data. </p>\n</blockquote>\n<p>F3 的整体架构如下所示</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191116416.png\" alt=\"\"></p>\n<p>文件包括 Data 和 Metadata 两部分，其中 Data 保存数据，Metadata 保存元数据</p>\n<p>Data 中的结构和 Parquet 类似，F3 的 RowGroup 是逻辑的，因为写入的时候不需要 buffer 整个 row group, 可以单独写某一个 IOUnit（对应 Parquet 中的 page)，因此没有列大小不一样导致 IO 不是最优的情况。IOUnit 包括多个 EncUnit，EncUnit 是编解码的最小单元。EncUnit is essentially an opaque byte buffer that can be interpreted by the corresponding decoding implementation.</p>\n<p>File Metadata 的结构如下所示</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191125566.png\" alt=\"\"></p>\n<p>Metadata 包括 OptData/ColMetadata/Footer 以及 Postscript, 整体使用 flatbuffer 存储。其中</p>\n<ul>\n<li>OptData 是一个 keyvalue 的数据结构，现在用于存储 wasm binary （可以携带编解码逻辑），后续可以用来存储 index 和 filter 等</li>\n<li>ColMetadata 保存了每个 RG 中每个 column 的元数据（包括 offset/size, 以及 dictionarytype, size encoding method 等）这里也记录了类似 Parquet 中 page header 的信息，这样可以直接从 Metadata 中对数据进行过滤。</li>\n<li>Footer 记录 schema 以及 optData/ColMetadata/SharedDict 等的地址</li>\n<li>Postscript 记录 ColMetadata/Footer/checksum 等</li>\n</ul>\n<p>在 F3 中 dictionary encoding 不像 Parquet 一样固定是 row group 级别，而是可以三类：None/Local/Shared。其中 None 表示没有 dictionary encoding，local 表示在当前 IOUnit 中，Shared 则表示可以和其他 IOUnit 共享（甚至跨 Column），这样可以有更好的灵活性。</p>\n<p>对于 NestedData 的处理则使用 L&amp;P 的格式(有 buffer 记录是否存在，然后其他的 buffer 记录具体的位置），右下角的形式</p>\n<p>最后 F3 最后给出的一些不同 FileFormat 上的测试数据</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191551919.png\" alt=\"\"></p>\n<p>上图展示了随着列的增加，(所有 format）元数据的 overhead 基本是线性增长。因为不管 metadata 是否支持随机访问，在 footer 中均有与列大小正相关（比如 schema）的信息。Nimble 最快是因为存的信息最少；其他使用 FlatBuffer 但比 Nimble 慢的有一部分原因在于正确性校验; F3 比其他使用 FlatBuffer 的格式更好的原因在于支持跳过特定列的 I/O; Lance 需要读取和反序列化所有的 metadata，这也是导致它是所有使用 FlatBuffer 中最慢的；Vortext 可以跳过无关 metadata 的反序列化，但是无法跳过 IO。</p>\n<p>文中的一些其他测试数据可以参考，更详细的可以参考原文</p>\n<p>下图比较了不同 FileFormat 中压缩比、读吞吐、随机读延迟的情况。可以看出</p>\n<ul>\n<li>F3/Vortex 在所有的情况下都有不错的性能</li>\n<li>Parquet 拥有不错的压缩比，读取吞吐也不错，但是随机读性能差</li>\n<li>Orc 的压缩率不错，吞吐一般，随机读取的性能比较弱</li>\n<li>Lance 压缩率很差，读吞吐一般，随机读的能力很强</li>\n<li>Nimble 压缩率, 读吞吐和随机读大部分情况下都属于中等水平，少数情况下优秀</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191656466.png\" alt=\"\"></p>\n<p>下图中上面的曲线表示不同的 row group size 情况下消耗的内存大小（左右是两个不同的场景）. 其中 Parquet 对内存的消耗比其他的都要大; Lance 和 F3 都是以 IOUnit 为最小单位刷盘，因此消耗内存较小；Nimble 和 ORC 则控制了单个 row group 的物理大小, 但是这样会导致 row group 存储数据量较少；Vortex 则由 writer 控制 buffer 大小。</p>\n<p>表格则表示不同的 FileFormat 的平均 ColumnChunk 大小，可以看到 ORC/Nimble 会有比较小的 ColumnChunk，Parquet 会有比较大的 Chunk，Lance 和 F3 的则会相对平均。</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119170350.png\" alt=\"\"></p>\n<h1 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h1><p>随着数据湖以及分析场景的广泛使用，列存的关注度也越来越高，如何在新场景，新硬件下拥有更好的性能，本文做了一些调研，总的来说 Parquet 在随机读取、SIMD 等方面较弱，其他的相对不错，这些可以有不同的优化方向；新的 FileFormat 则从不同的角度希望解决不同的问题。这些可以让我们在后续进行决策的时候提供一定的基础。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] Data Page Layouts for Relational Databases on Deep Memory Hierarchies<br>[2] <a href=\"https://parquet.apache.org\">https://parquet.apache.org</a><br>[3] <a href=\"https://orc.apache.org/\">https://orc.apache.org/</a><br>[4] <a href=\"https://github.com/apache/parquet-format/blob/master/VariantEncoding.md\">https://github.com/apache/parquet-format/blob/master/VariantEncoding.md</a><br>[5] <a href=\"https://lists.apache.org/thread/j9qv5vyg0r4jk6tbm6sqthltly4oztd3\">https://lists.apache.org/thread/j9qv5vyg0r4jk6tbm6sqthltly4oztd3</a><br>[6] <a href=\"https://arrow.apache.org/blog/2025/10/23/rust-parquet-metadata/\">https://arrow.apache.org/blog/2025/10/23/rust-parquet-metadata/</a><br>[7] <a href=\"https://github.com/facebookincubator/nimble\">https://github.com/facebookincubator/nimble</a><br>[8] <a href=\"https://github.com/lance-format/lance\">https://github.com/lance-format/lance</a><br>[9] <a href=\"https://github.com/vortex-data/vortex/\">https://github.com/vortex-data/vortex/</a><br>[10] <a href=\"https://www.youtube.com/watch?v=p6ZKY8JViCA\">https://www.youtube.com/watch?v=p6ZKY8JViCA</a><br>[11] <a href=\"https://lancedb.com/blog/lance-v2/\">https://lancedb.com/blog/lance-v2/</a><br>[12] <a href=\"https://github.com/apache/parquet-format/blob/master/VariantShredding.md\">https://github.com/apache/parquet-format/blob/master/VariantShredding.md</a><br>[13] <a href=\"https://github.com/XiangpengHao/liquid-cache/blob/main/dev/doc/liquid-cache-vldb.pdf\">https://github.com/XiangpengHao/liquid-cache/blob/main/dev/doc/liquid-cache-vldb.pdf</a><br>[14] <a href=\"https://www.vldb.org/pvldb/vol17/p148-zeng.pdf\">https://www.vldb.org/pvldb/vol17/p148-zeng.pdf</a><br>[15] <a href=\"https://db.cs.cmu.edu/papers/2025/zeng-sigmod2025.pdf\">https://db.cs.cmu.edu/papers/2025/zeng-sigmod2025.pdf</a></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h1><p>在分析场景下列存相对行存有非常大的优势，可以极大减少 IO 的开销。在 Data Page Layouts for Relational Databases on Deep Memory Hierarchies[1] 一文中，引出了 PAX 格式并与行存进行了对比。</p>\n<p>以下表数据为例</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>column_a</th>\n<th>column_b</th>\n<th>column_c</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>abcd</td>\n<td>3.2</td>\n</tr>\n<tr>\n<td>2</td>\n<td>efdf</td>\n<td>4.7</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>分别使用行存和列存写到磁盘后的格式大致如下</p>\n<blockquote>\n<p>为了较好展示，以 <code>,</code> 为分隔符，且省略了各种 header/footer</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>存储格式</th>\n<th>内容</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>行存</td>\n<td>1,abcd,3.2,2,efdf,4.7</td>\n</tr>\n<tr>\n<td>列存</td>\n<td>1,2,abcd,efdf,3.2,4.7</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>在分析场景中，读取某一列所有的数据是常见操作，但是对于行存来说读取某一列数据，需要在文件中进行多次 IO 定位，然后读取值，而对于列存来说可以直接顺序的读取某列整体的值。比如上述示例中读取 <code>column_c</code> 的值</p>\n<p>在行存中需要</p>\n<ul>\n<li>定位到 3.2 的位置</li>\n<li>读取 3.2 的值</li>\n<li>定位到 4.7 的位置</li>\n<li>读取 4.7 的值</li>\n</ul>\n<p>在列存中需要</p>\n<ul>\n<li>定位到 3.2 的位置</li>\n<li>连续读取 3.2 和 4.7 的值</li>\n</ul>\n<p>连续读取的开销比随机读取少，也就是第二种的开销更小，因此列存在分析场景中开销更小。</p>\n<p>文献[1] 中描述列存格式可以比行存减少由于 cache miss 导致的停顿延时 75%；range selection 的查询可以快 17-25%，TPC-H 中 I/O  更重的 query 要快 11-48%。</p>","more":"<h1 id=\"Apache-Parquet\"><a href=\"#Apache-Parquet\" class=\"headerlink\" title=\"Apache Parquet\"></a>Apache Parquet</h1><p>现在工业界中的列存格式大部分场景都会使用 Apache Parquet[2] 或者 Apache ORC[3]。由于数据湖格式的兴起，Apache Iceberg/Delta 等均以 Apache Parquet[2] 为主要格式，其他一些分析型 DB 重点支持 Apache Parquet，Apache Parquet 基本成为工业界列存的事实标准。</p>\n<p>Apache Parquet 定义了一套语言无关的规范，不同语言基于同一套规范进行开发。定义大致如下</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511200846927.png\" alt=\"\"></p>\n<p>Parquet 的读写流程大致如下</p>\n<ul>\n<li>写入<ul>\n<li>将数据写入内存并记录相应的 stat</li>\n<li>待数据足够大（满足一个 row group 大小）后写出到磁盘，并重复该步骤</li>\n<li>整个文件写完（主动或触发条件）写入可选信息（ColumnIndex/OffsetIndex/BloomFilter 等）</li>\n<li>写出整个 footer 完成文件的写出</li>\n</ul>\n</li>\n<li>读取<ul>\n<li>读取 footer 信息<ul>\n<li>解析 footer 信息中的 column metadata（使用 Thrift 所以需要进行全部读取和解析）</li>\n<li>使用 column metadata 中的 stat 对数据进行过滤 (如果有 ColumnIndex/OffsetIndex 可以读取并进行更精细的过滤)<ul>\n<li>column 级别的信息是 row group 中 column 级别的信息</li>\n<li>columnIndex/offsetIndex 则是 column 中 page 级别的信息（如果没有 columnIndex 则需要读取 PageHeader 才能对 Page 进行过滤，PageHeader 保存在 Page 内部）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>定位到对应的 offset 读取实际的 page<ul>\n<li>读取并反序列化 page 的内容</li>\n<li>对内容进行过滤</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>从读写流程可知</p>\n<ul>\n<li>写入<ul>\n<li>需要 buffer 整个 row group 然后整体写出, 因此：1）写入端需要较多内存；2）列的大小差异较大会导致部分列存储的数据量少，从而影响读取时的 IO (多次小 IO)。</li>\n</ul>\n</li>\n<li>读取<ul>\n<li>对于列非常多的情况下，读取和反序列化 columnChunkMetadata 可能开销较大（部分列实际不需要，但必须要读取），在没有 ColumnIndex 的情况下，stat 信息过滤的粒度太粗，且需要读取 page header 才能对 page 进行过滤（page header 和 page data 存放在一起）</li>\n<li>对于嵌套列（Map/List）读取不太友好（比如读取 Map 中某个 key）</li>\n</ul>\n</li>\n</ul>\n<p>由于现在 AI 场景中对于宽表（列比较多）和宽列（以及嵌套列）比较多，因此问题会更突出。现在工业界和学术界都有想办法进行改进和优化。</p>\n<h1 id=\"Another-FileFormat-or-Better-Parquet\"><a href=\"#Another-FileFormat-or-Better-Parquet\" class=\"headerlink\" title=\"Another FileFormat or Better Parquet\"></a>Another FileFormat or Better Parquet</h1><p>对于解决 Parquet 的劣势场景，主要有两个方向：1）是造一个新的 file format；2）在 Parquet 的基础上进行迭代优化。</p>\n<p>其中前者出现了 Nimble/Lance/Vortex 等一系列 format; 后者包括 Parquet Variant[4], 优化 footer 的读写[5][6]，以及在 Parquet 之上增加纯内存的 format 作为 cache 等；</p>\n<h2 id=\"Another-FileFormat\"><a href=\"#Another-FileFormat\" class=\"headerlink\" title=\"Another FileFormat\"></a>Another FileFormat</h2><p>从零开始构造一个新的 file format 满足更多的场景以及硬件是一个很直观的想法，大公司和初创公司出现较多，Google/Meta 等有自己的列存格式，Goolge 的没有开源，Meta 的 Nimble[7] 已经开源；初创公司现在有 Lance[8]/Vortex[9] 是两个新兴的 file format。Lance 由于字节在推动知名度更高一些。Lance 和 Vortex 在 IcebergSummit 2025 上也有一个相关的 talk[10]。</p>\n<h3 id=\"Lance\"><a href=\"#Lance\" class=\"headerlink\" title=\"Lance\"></a>Lance</h3><p>从 Lance 官网[11] 可知，Lance 的结构大致如下</p>\n<p><img src=\"https://lancedb.com/assets/blog/lance-v2/wide-columns-grouping.png\" alt=\"\"></p>\n<p>Lance 以一种更扁平的方式存储文件，没有 Parquet 中的 row group 的概念，数据会包括多个 page，每列的 page 写满后即可落盘，每个 page 会包括多个 buffer。ColumnMetadata 中会记录每个 buffer 的信息，然后也会记录 Global 的 Buffer 信息（全局的信息），最终的 Footer 会记录 ColumnMetadata 的相关信息（offset/size 等）以及一些其他类似版本，校验字等信息。</p>\n<p>从格式可以知道</p>\n<ul>\n<li>写入的时候不需要 buffer 整个 <code>RowGroup</code> 信息，因此内存消耗会小一些</li>\n<li>随机读取的时候因为有更细粒度的 stat 和索引，所以查询会更快一点（对于定长的数据，甚至可以直接通过计算定位到具体的 row）</li>\n</ul>\n<p>另外 Lance table format 有一个很有意思的点, 提供了 fragement: 一个 fragement 可以包括多个文件，这些文件的数据可以属于不同的列。这样可以在不重写数据的情况下支持动态增加列，并给存量数据的新列加上值。这在需要频繁加列的情况下会很友好，不过这个属于 table format 的层面，也就是说其他像 Iceberg/Delta 等也可以支持。</p>\n<h3 id=\"Vortex\"><a href=\"#Vortex\" class=\"headerlink\" title=\"Vortex\"></a>Vortex</h3><p>Vortex 的结构大致如下</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251118160924.png\" alt=\"\"></p>\n<ul>\n<li>DataPages 记录了具体的数据</li>\n<li>Zone Map 记录某一列多行（逻辑 row group）的 stat，比如 min/max/nullcount 等</li>\n<li>Filestatistics 记录文件级别的列 zonemap</li>\n<li>Dtype 则是文件的逻辑数据类型（类似业务视角的数据类型），也就是 schema</li>\n<li>Layout 是文件的存储格式，比如文中可以理解为和 Parquet 类似的一个存储</li>\n<li>Footer 记录一些可以用来做过滤的信息</li>\n<li><p>Postscript 记录了 schema/layout/filestatistics 以及 footer 信息，每个信息都是一个 segment(包括 offset, length, alignment exponent, compression spec, encryption spec 等) </p>\n</li>\n<li><p>写入</p>\n<ul>\n<li>Vortex 内 row group 更多的是一个逻辑概念，写入不需要 buffer 整个 row group 的内容，因此内存消耗比 Parquet 也会更小。</li>\n</ul>\n</li>\n<li>读取<ul>\n<li>Vortex 首先读取 footer 创建 reader，然后可以通过 zonemap 中的信息进行过滤，然后从剩下的 segment 中进行读取（可以通过 segmentId 直接定位到文件中的 offset 继续读取），然后反序列化后进行更细的过滤。</li>\n<li>对于嵌套类型（Struct），可以使用不同的 Layout 将内部数据拆开，比如上图中的 Struct 两列 Column_A 和 Column_B 可以分开存储，这样读取的时候，仅需要读取某一列，而不是整个 Struct。</li>\n</ul>\n</li>\n</ul>\n<p>由于 Vortex 将逻辑数据和物理存储拆开，因此可以同样的逻辑数据使用不同的物理存储，这样也可以支持在压缩数据上进行一定的计算与过滤。Vortex 中数据类型有 Owned 和 Viewed 两种，Owned 表示内存上的数据，Viewed 则表示磁盘上数据的视图，这样可以按需加载。</p>\n<h2 id=\"Better-Parquet\"><a href=\"#Better-Parquet\" class=\"headerlink\" title=\"Better Parquet\"></a>Better Parquet</h2><p>Parquet 拥有一个不错的生态，在生产环境中要从一个成熟的生态中迁移是一件较难的事情，因此在 Parquet 基础上进行迭代改进也是一个方向，包括 Variant 以及 footer 读取的优化等。</p>\n<h3 id=\"Variant\"><a href=\"#Variant\" class=\"headerlink\" title=\"Variant\"></a>Variant</h3><p>Paruqet 的 Dremel 类型对存储量更优化，但是对于 CPU 计算和内存向量化（读取吞吐）等则不那么友好</p>\n<p>比如在 paruqet 中读取 nested data 的时候, 需要</p>\n<ul>\n<li>根据 repetition level 和 definition level 重构整个数据</li>\n<li>Filter 支持不好，因为 Parquet 的 stat 经常是 RowGroup 或者 Page 级别的，无法对 inner data 进行过滤</li>\n<li>SchemaEvolution 支持不好</li>\n<li>不太好支持 SIMD</li>\n</ul>\n<p>现在 Parquet variant 的出现则希望解决这一问题: Variant 默认将所有数据存储到一个二进制数组中，且包括一个 metadata，这样形成自解释的数据结构，同时可以将部分数据从二进制数组中抽出来单独存储成一个物理列，这样可以更好的进行计算和过滤。</p>\n<p>Variant 大致如下所示，其中 metadata 用于解释当前 variant，value 包括了所有非进行 shred 的二进制数据，typed_value 则存储了实际被抽出来的子列。更具体的可以参考 VariantShredding[12]<br><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- metadata</span><br><span class=\"line\">- value</span><br><span class=\"line\">- typed_value</span><br><span class=\"line\">  - [value]</span><br><span class=\"line\">  - [typed_value]</span><br></pre></td></tr></table></figure></p>\n<p>这样操作之后</p>\n<ul>\n<li>可以很好的支持 SchemaEvolution</li>\n<li>数据访问的时候，可以使用 stat 进行过滤（因为单独抽出来一列，有 stat 信息）；可以使用 SIMD 操作（因为单独一列存放在一起）</li>\n</ul>\n<h3 id=\"Cache-amp-MemoryFormat\"><a href=\"#Cache-amp-MemoryFormat\" class=\"headerlink\" title=\"Cache &amp; MemoryFormat\"></a>Cache &amp; MemoryFormat</h3><p>Parquet 是一个非常成熟，拥有良好生态的 format，所以改动会相对缓慢，因此有人提出在 Parquet 之上搭建一套纯内存的 file format, 这个 file format 相比 Parquet 更适合使用在 cache 场景，这就是 LiquidCache[13] 的想法, Cache 中存储的是“逻辑数据”，而不是原始的 Paruqet 文件，主要考虑是：纯内存的 file format 可以比 Parquet 更适合 cache，且更自由的进行更新迭代（升级成本低）；可以复用现有 Parquet 的整体生态。</p>\n<p>直接 cache Parquet 格式本身，然后进行 filter pushdown 可能无法提升速度，反而会导致速度下降，主要原因在于 Parquet 的主要开销是 decode 和 decompress（超过 90%），而 Parquet 本身也不好针对 filter pushdown 做优化。文中描述了将物理结构与逻辑结构进行解耦，这样 LiquidCache 可以将 Parquet 转换成 liquid format。Liquid format 结合了 selective decoding，late filter materialization 以及 endocing-aware predicate evaluation，可以比 Parquet 更好的支持 filter pushdown。Parquet 转换为 liquid format 则是异步进行的，可以不 block 正常的处理流程。</p>\n<p>LiquidFormat 相对 Paruqet 的优势可以从下面两种图中可以查看</p>\n<p>下图中 LiquidFormat 可以比 Paruqet 少 decode 数据（只需要 decode 实际命中的数据）<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191105278.png\" alt=\"\"></p>\n<p>下图中则是 liquid format 在多 filter 场景下，可以应用 late materialization，在前面 filter 处理后的数据上进行 decode，这样可以减少第一个 filter 中被过滤掉数据的 decode。<br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119110635.png\" alt=\"\"></p>\n<p>文中有给一些结论，整体来说 liquidcache 拥有不错的性能，更详细的数据可以参考原文以及 Github 仓库</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119111018.png\" alt=\"\"><br><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119111040.png\" alt=\"\"></p>\n<h1 id=\"Column-File-Format-in-Academic\"><a href=\"#Column-File-Format-in-Academic\" class=\"headerlink\" title=\"Column File Format in Academic\"></a>Column File Format in Academic</h1><p>学术界也有关于列存的研究[14][15]. 其中文献[14] 对列存进行了对比，文献[15] 则提出了一种新的列存 F3，并和已有的列存进行了对比，虽然学术界到工业界落地可能需要一段时间，但是其思路是可以参考的。</p>\n<h2 id=\"Compare-between-column-file-formats\"><a href=\"#Compare-between-column-file-formats\" class=\"headerlink\" title=\"Compare between column file formats\"></a>Compare between column file formats</h2><p>本文[14] 设计了一个 benchmark 并以 Parquet 和 ORC 为例进行了对比。</p>\n<p>Benchmark 中引入了数据分布的几个维度: NDV, NullRatio, ValueRange, Sorteness, SkewPattern 用来表示数据的不同维度。</p>\n<p>论文中从 Public BI Benchmark/Clickhouse/UCI-ML/Yelp/LOG/Geonames/IMBD 多个数据集中进行分析得到如下分布情况</p>\n<ul>\n<li>超过 80% 的 Integer，超过 60% 的 String NDV 小于 0.01, 超过 60% 的 float NDV 小于 0.1<ul>\n<li>也就是说 Dictionary Encoding 是有用处的</li>\n</ul>\n</li>\n<li>Null 的数据比较多</li>\n<li>大部分数据分布式不均匀，小于 5% 的数据是 Uniform，60-70% 的在 Gentle Zipf 分布<ul>\n<li>file format 需要能同时处理热点数据和长尾数据</li>\n</ul>\n</li>\n<li>数据要么是完全排序的，要么就是无序的<ul>\n<li>对于有序的编码部分情况有用的</li>\n</ul>\n</li>\n<li>数据范围比想象中的要小<ul>\n<li>数值型的大小绝大部分在 1e4 以内（80%）</li>\n<li>String 80% 的长度小于 25, 60% 的长度小于 10, 90%+ 的长度小于 50</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251120111333.png\" alt=\"\"></p>\n<p>将相关数据分类后总结成如下表格</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201122186.png\" alt=\"\"></p>\n<p>在不同场景下 Parquet 和 ORC 的对比如下（绝大部分场景相差不是很大）更详细的数据可以参考论文(从这里也能看出 Decode 比 IO 耗时更多)。</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201123543.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511201124790.png\" alt=\"\"></p>\n<h2 id=\"F3\"><a href=\"#F3\" class=\"headerlink\" title=\"F3\"></a>F3</h2><p>本文认为已有的 format 诞生时的假设已经不成立</p>\n<ul>\n<li>1 relative hardware performance</li>\n<li>2 workload access pattern</li>\n</ul>\n<p>主要原因在于</p>\n<ul>\n<li>最近 10 年存储和网络性能有很大的提升，但是 CPU 的性能没有成比例的增长</li>\n<li>数据湖的出现也让更多的数据存储在高吞吐高延迟的云存储中，也让整体瓶颈从 IO 转移到 CPU</li>\n<li>数据的结构也发生了很大的变化（数据越来越”宽” — 表的列很多，以及列里面的数据可能很大 — 比如 blob)，ML 场景下存储几千列的特征，以及高维向量、图片等 blob 数据已经变成越来越常见，同时应用也希望能够进行随机读取甚至对已有数据进行更新。</li>\n</ul>\n<p>另外文中认为 Nimble/Lance/TSFile/Bullion/BtrBlocks 这些新的 format 也和之前的 format 有一样的问题: 对硬件和数据模式有一定的假设，就算取代了之前的 format, 在未来也会被新的 format 所取代。</p>\n<p>F3 则是为了解决这些问题而诞生的，F3 的全称是 Future-proof File Format, 号称是下一代开源的 file format，拥有 interoperability，extensibility 以及 efficiency 等特性。</p>\n<blockquote>\n<p>Eache self-describing F3 file includes both the data and meta-data, as well as WebAssembly(Wasm) binaries to decode the data. </p>\n</blockquote>\n<p>F3 的整体架构如下所示</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191116416.png\" alt=\"\"></p>\n<p>文件包括 Data 和 Metadata 两部分，其中 Data 保存数据，Metadata 保存元数据</p>\n<p>Data 中的结构和 Parquet 类似，F3 的 RowGroup 是逻辑的，因为写入的时候不需要 buffer 整个 row group, 可以单独写某一个 IOUnit（对应 Parquet 中的 page)，因此没有列大小不一样导致 IO 不是最优的情况。IOUnit 包括多个 EncUnit，EncUnit 是编解码的最小单元。EncUnit is essentially an opaque byte buffer that can be interpreted by the corresponding decoding implementation.</p>\n<p>File Metadata 的结构如下所示</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191125566.png\" alt=\"\"></p>\n<p>Metadata 包括 OptData/ColMetadata/Footer 以及 Postscript, 整体使用 flatbuffer 存储。其中</p>\n<ul>\n<li>OptData 是一个 keyvalue 的数据结构，现在用于存储 wasm binary （可以携带编解码逻辑），后续可以用来存储 index 和 filter 等</li>\n<li>ColMetadata 保存了每个 RG 中每个 column 的元数据（包括 offset/size, 以及 dictionarytype, size encoding method 等）这里也记录了类似 Parquet 中 page header 的信息，这样可以直接从 Metadata 中对数据进行过滤。</li>\n<li>Footer 记录 schema 以及 optData/ColMetadata/SharedDict 等的地址</li>\n<li>Postscript 记录 ColMetadata/Footer/checksum 等</li>\n</ul>\n<p>在 F3 中 dictionary encoding 不像 Parquet 一样固定是 row group 级别，而是可以三类：None/Local/Shared。其中 None 表示没有 dictionary encoding，local 表示在当前 IOUnit 中，Shared 则表示可以和其他 IOUnit 共享（甚至跨 Column），这样可以有更好的灵活性。</p>\n<p>对于 NestedData 的处理则使用 L&amp;P 的格式(有 buffer 记录是否存在，然后其他的 buffer 记录具体的位置），右下角的形式</p>\n<p>最后 F3 最后给出的一些不同 FileFormat 上的测试数据</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191551919.png\" alt=\"\"></p>\n<p>上图展示了随着列的增加，(所有 format）元数据的 overhead 基本是线性增长。因为不管 metadata 是否支持随机访问，在 footer 中均有与列大小正相关（比如 schema）的信息。Nimble 最快是因为存的信息最少；其他使用 FlatBuffer 但比 Nimble 慢的有一部分原因在于正确性校验; F3 比其他使用 FlatBuffer 的格式更好的原因在于支持跳过特定列的 I/O; Lance 需要读取和反序列化所有的 metadata，这也是导致它是所有使用 FlatBuffer 中最慢的；Vortext 可以跳过无关 metadata 的反序列化，但是无法跳过 IO。</p>\n<p>文中的一些其他测试数据可以参考，更详细的可以参考原文</p>\n<p>下图比较了不同 FileFormat 中压缩比、读吞吐、随机读延迟的情况。可以看出</p>\n<ul>\n<li>F3/Vortex 在所有的情况下都有不错的性能</li>\n<li>Parquet 拥有不错的压缩比，读取吞吐也不错，但是随机读性能差</li>\n<li>Orc 的压缩率不错，吞吐一般，随机读取的性能比较弱</li>\n<li>Lance 压缩率很差，读吞吐一般，随机读的能力很强</li>\n<li>Nimble 压缩率, 读吞吐和随机读大部分情况下都属于中等水平，少数情况下优秀</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202511191656466.png\" alt=\"\"></p>\n<p>下图中上面的曲线表示不同的 row group size 情况下消耗的内存大小（左右是两个不同的场景）. 其中 Parquet 对内存的消耗比其他的都要大; Lance 和 F3 都是以 IOUnit 为最小单位刷盘，因此消耗内存较小；Nimble 和 ORC 则控制了单个 row group 的物理大小, 但是这样会导致 row group 存储数据量较少；Vortex 则由 writer 控制 buffer 大小。</p>\n<p>表格则表示不同的 FileFormat 的平均 ColumnChunk 大小，可以看到 ORC/Nimble 会有比较小的 ColumnChunk，Parquet 会有比较大的 Chunk，Lance 和 F3 的则会相对平均。</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20251119170350.png\" alt=\"\"></p>\n<h1 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h1><p>随着数据湖以及分析场景的广泛使用，列存的关注度也越来越高，如何在新场景，新硬件下拥有更好的性能，本文做了一些调研，总的来说 Parquet 在随机读取、SIMD 等方面较弱，其他的相对不错，这些可以有不同的优化方向；新的 FileFormat 则从不同的角度希望解决不同的问题。这些可以让我们在后续进行决策的时候提供一定的基础。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] Data Page Layouts for Relational Databases on Deep Memory Hierarchies<br>[2] <a href=\"https://parquet.apache.org\">https://parquet.apache.org</a><br>[3] <a href=\"https://orc.apache.org/\">https://orc.apache.org/</a><br>[4] <a href=\"https://github.com/apache/parquet-format/blob/master/VariantEncoding.md\">https://github.com/apache/parquet-format/blob/master/VariantEncoding.md</a><br>[5] <a href=\"https://lists.apache.org/thread/j9qv5vyg0r4jk6tbm6sqthltly4oztd3\">https://lists.apache.org/thread/j9qv5vyg0r4jk6tbm6sqthltly4oztd3</a><br>[6] <a href=\"https://arrow.apache.org/blog/2025/10/23/rust-parquet-metadata/\">https://arrow.apache.org/blog/2025/10/23/rust-parquet-metadata/</a><br>[7] <a href=\"https://github.com/facebookincubator/nimble\">https://github.com/facebookincubator/nimble</a><br>[8] <a href=\"https://github.com/lance-format/lance\">https://github.com/lance-format/lance</a><br>[9] <a href=\"https://github.com/vortex-data/vortex/\">https://github.com/vortex-data/vortex/</a><br>[10] <a href=\"https://www.youtube.com/watch?v=p6ZKY8JViCA\">https://www.youtube.com/watch?v=p6ZKY8JViCA</a><br>[11] <a href=\"https://lancedb.com/blog/lance-v2/\">https://lancedb.com/blog/lance-v2/</a><br>[12] <a href=\"https://github.com/apache/parquet-format/blob/master/VariantShredding.md\">https://github.com/apache/parquet-format/blob/master/VariantShredding.md</a><br>[13] <a href=\"https://github.com/XiangpengHao/liquid-cache/blob/main/dev/doc/liquid-cache-vldb.pdf\">https://github.com/XiangpengHao/liquid-cache/blob/main/dev/doc/liquid-cache-vldb.pdf</a><br>[14] <a href=\"https://www.vldb.org/pvldb/vol17/p148-zeng.pdf\">https://www.vldb.org/pvldb/vol17/p148-zeng.pdf</a><br>[15] <a href=\"https://db.cs.cmu.edu/papers/2025/zeng-sigmod2025.pdf\">https://db.cs.cmu.edu/papers/2025/zeng-sigmod2025.pdf</a></p>"},{"_content":"腾讯的\n\n收入\n支出\n\n然后尽量进行一些拆解\n","source":"_drafts/tencent.md","raw":"腾讯的\n\n收入\n支出\n\n然后尽量进行一些拆解\n","slug":"tencent","published":0,"date":"2025-11-24T03:43:39.709Z","updated":"2025-11-24T03:43:39.709Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cmj89f2z500007qmkd8kg9gk5","content":"<p>腾讯的</p>\n<p>收入<br>支出</p>\n<p>然后尽量进行一些拆解</p>\n","site":{"data":{}},"excerpt":"","more":"<p>腾讯的</p>\n<p>收入<br>支出</p>\n<p>然后尽量进行一些拆解</p>\n"},{"_content":"读写角\n\n目的：能够能够的帮助自己（别人），过上更好的生活\n\n我们都知道吃的东西，会影响身体，但是对了解的知识会影响自己了解（不多）\n\n可视化可以帮助我们了解这些事情\n\n> If your do see the truth clearly, you can't unsee it.\n\n写作的好处\n- 能够帮助自己梳理思路\n- 能够将自己的想法显性化，这样可以更好的调整\n> 我们大脑会有很多自动化的行为，这些行为是为了让我们能够更好的生活而存在的 -- 比如可以观察让小朋友拿旁边的水杯这件事，这件事包括了很多的行为：1）需要能够理解这句话，2）能够操作自己的手，3）能够准确的拿到杯子。这里每一步对于刚开始学习的小朋友都是一件不容易的事情，但是对于大人来说却是那么“顺其自然”。同样对于其他事情的处理，我们也会有一些自动化的处理，比如遇到了一些事情，然后自己有一些行为，比如选择，比如情绪等。但是这些这些不一定那么容易“看清楚”，所以写下来是一个能够帮助自己了解自己“行为逻辑” -- 这里是自己为什么会这么做-- 的一个可行方案。而且读书和写作这些都是比较能够自己获得的。\n\n自己成长终究能在某个地方获利\n- 比如投资\n- 比如选择\n\n但是只写作，不输入，会导致枯竭，所以需要看书。\n\n是否会显示加重自己平时生活的负担：不太会，这个每天只需要 10 分钟左右即可。\n\n对于如果持续做一件事情，我有一些经验：\n- 暂停实验室的设计模式\n- 我自己阅读的经验\n  - 设置一个较小的门坑（主要是希望自己能够持续的做下去）\n  - 有一些外界刺激，比如使用一些软件记录自己持续行动的时间\n  - 允许自己有状态不好的时候\n    - 比如允许自己某天休息\n    - 如果某些记录系统不支持，那么支持自己“作弊” -- 比如看不下去书，那么就打开读书软件，能看多少看多少，看不了，就一直打开让软件记录上“阅读时长“\n\n写作\n","source":"_drafts/read-write-group.md","raw":"读写角\n\n目的：能够能够的帮助自己（别人），过上更好的生活\n\n我们都知道吃的东西，会影响身体，但是对了解的知识会影响自己了解（不多）\n\n可视化可以帮助我们了解这些事情\n\n> If your do see the truth clearly, you can't unsee it.\n\n写作的好处\n- 能够帮助自己梳理思路\n- 能够将自己的想法显性化，这样可以更好的调整\n> 我们大脑会有很多自动化的行为，这些行为是为了让我们能够更好的生活而存在的 -- 比如可以观察让小朋友拿旁边的水杯这件事，这件事包括了很多的行为：1）需要能够理解这句话，2）能够操作自己的手，3）能够准确的拿到杯子。这里每一步对于刚开始学习的小朋友都是一件不容易的事情，但是对于大人来说却是那么“顺其自然”。同样对于其他事情的处理，我们也会有一些自动化的处理，比如遇到了一些事情，然后自己有一些行为，比如选择，比如情绪等。但是这些这些不一定那么容易“看清楚”，所以写下来是一个能够帮助自己了解自己“行为逻辑” -- 这里是自己为什么会这么做-- 的一个可行方案。而且读书和写作这些都是比较能够自己获得的。\n\n自己成长终究能在某个地方获利\n- 比如投资\n- 比如选择\n\n但是只写作，不输入，会导致枯竭，所以需要看书。\n\n是否会显示加重自己平时生活的负担：不太会，这个每天只需要 10 分钟左右即可。\n\n对于如果持续做一件事情，我有一些经验：\n- 暂停实验室的设计模式\n- 我自己阅读的经验\n  - 设置一个较小的门坑（主要是希望自己能够持续的做下去）\n  - 有一些外界刺激，比如使用一些软件记录自己持续行动的时间\n  - 允许自己有状态不好的时候\n    - 比如允许自己某天休息\n    - 如果某些记录系统不支持，那么支持自己“作弊” -- 比如看不下去书，那么就打开读书软件，能看多少看多少，看不了，就一直打开让软件记录上“阅读时长“\n\n写作\n","slug":"read-write-group","published":0,"date":"2025-12-13T10:11:58.963Z","updated":"2025-12-13T10:11:58.963Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cmj89f2z600017qmkc6m32swk","content":"<p>读写角</p>\n<p>目的：能够能够的帮助自己（别人），过上更好的生活</p>\n<p>我们都知道吃的东西，会影响身体，但是对了解的知识会影响自己了解（不多）</p>\n<p>可视化可以帮助我们了解这些事情</p>\n<blockquote>\n<p>If your do see the truth clearly, you can’t unsee it.</p>\n</blockquote>\n<p>写作的好处</p>\n<ul>\n<li>能够帮助自己梳理思路</li>\n<li>能够将自己的想法显性化，这样可以更好的调整<blockquote>\n<p>我们大脑会有很多自动化的行为，这些行为是为了让我们能够更好的生活而存在的 — 比如可以观察让小朋友拿旁边的水杯这件事，这件事包括了很多的行为：1）需要能够理解这句话，2）能够操作自己的手，3）能够准确的拿到杯子。这里每一步对于刚开始学习的小朋友都是一件不容易的事情，但是对于大人来说却是那么“顺其自然”。同样对于其他事情的处理，我们也会有一些自动化的处理，比如遇到了一些事情，然后自己有一些行为，比如选择，比如情绪等。但是这些这些不一定那么容易“看清楚”，所以写下来是一个能够帮助自己了解自己“行为逻辑” — 这里是自己为什么会这么做— 的一个可行方案。而且读书和写作这些都是比较能够自己获得的。</p>\n</blockquote>\n</li>\n</ul>\n<p>自己成长终究能在某个地方获利</p>\n<ul>\n<li>比如投资</li>\n<li>比如选择</li>\n</ul>\n<p>但是只写作，不输入，会导致枯竭，所以需要看书。</p>\n<p>是否会显示加重自己平时生活的负担：不太会，这个每天只需要 10 分钟左右即可。</p>\n<p>对于如果持续做一件事情，我有一些经验：</p>\n<ul>\n<li>暂停实验室的设计模式</li>\n<li>我自己阅读的经验<ul>\n<li>设置一个较小的门坑（主要是希望自己能够持续的做下去）</li>\n<li>有一些外界刺激，比如使用一些软件记录自己持续行动的时间</li>\n<li>允许自己有状态不好的时候<ul>\n<li>比如允许自己某天休息</li>\n<li>如果某些记录系统不支持，那么支持自己“作弊” — 比如看不下去书，那么就打开读书软件，能看多少看多少，看不了，就一直打开让软件记录上“阅读时长“</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>写作</p>\n","site":{"data":{}},"excerpt":"","more":"<p>读写角</p>\n<p>目的：能够能够的帮助自己（别人），过上更好的生活</p>\n<p>我们都知道吃的东西，会影响身体，但是对了解的知识会影响自己了解（不多）</p>\n<p>可视化可以帮助我们了解这些事情</p>\n<blockquote>\n<p>If your do see the truth clearly, you can’t unsee it.</p>\n</blockquote>\n<p>写作的好处</p>\n<ul>\n<li>能够帮助自己梳理思路</li>\n<li>能够将自己的想法显性化，这样可以更好的调整<blockquote>\n<p>我们大脑会有很多自动化的行为，这些行为是为了让我们能够更好的生活而存在的 — 比如可以观察让小朋友拿旁边的水杯这件事，这件事包括了很多的行为：1）需要能够理解这句话，2）能够操作自己的手，3）能够准确的拿到杯子。这里每一步对于刚开始学习的小朋友都是一件不容易的事情，但是对于大人来说却是那么“顺其自然”。同样对于其他事情的处理，我们也会有一些自动化的处理，比如遇到了一些事情，然后自己有一些行为，比如选择，比如情绪等。但是这些这些不一定那么容易“看清楚”，所以写下来是一个能够帮助自己了解自己“行为逻辑” — 这里是自己为什么会这么做— 的一个可行方案。而且读书和写作这些都是比较能够自己获得的。</p>\n</blockquote>\n</li>\n</ul>\n<p>自己成长终究能在某个地方获利</p>\n<ul>\n<li>比如投资</li>\n<li>比如选择</li>\n</ul>\n<p>但是只写作，不输入，会导致枯竭，所以需要看书。</p>\n<p>是否会显示加重自己平时生活的负担：不太会，这个每天只需要 10 分钟左右即可。</p>\n<p>对于如果持续做一件事情，我有一些经验：</p>\n<ul>\n<li>暂停实验室的设计模式</li>\n<li>我自己阅读的经验<ul>\n<li>设置一个较小的门坑（主要是希望自己能够持续的做下去）</li>\n<li>有一些外界刺激，比如使用一些软件记录自己持续行动的时间</li>\n<li>允许自己有状态不好的时候<ul>\n<li>比如允许自己某天休息</li>\n<li>如果某些记录系统不支持，那么支持自己“作弊” — 比如看不下去书，那么就打开读书软件，能看多少看多少，看不了，就一直打开让软件记录上“阅读时长“</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>写作</p>\n"},{"_content":"AI 行业是未来整体的方向\n\n但是 AI  行业会包括方方面面，本文希望对这个行业有一些稍微的了解\n\nAI 不仅仅包括 LLM（也就是大模型），但是最吸引眼球的是 LLM\n\n本文希望能探索 AI 整个行业，从上游到下游可能的产业，公司等，由于能力有限，难免会有错漏，算是一个快照吧。\n\n> 部分由 LLM 产生的结构，后面需要确认或者调整\n\n1. 上游：硬件与基础设施（支持 LLM 训练与推理）\n上游聚焦计算资源和制造，支持 LLM 的海量参数处理（当前 LLM 参数量已超 5000 亿）。 关键链路包括半导体制造 → 芯片设计 → GPU/加速器 → 数据中心基础设施。供应链瓶颈（如 TSMC 产能）是主要挑战。\n\n链路,标杆公司,标杆产品,产品特色,竞争力\n\"半导体制造（晶圆代工）\n（基础硅片加工，先进节点如 3nm/2nm）\",TSMC（台积电）,N3E/N2 工艺节点,支持高密度集成，EUV 光刻技术降低功耗；产量高，适用于多芯片模块 (MCM) 封装。,全球 90% 先进节点份额；客户多样化（NVIDIA、AMD、Apple），抗风险强；但地缘政治依赖台湾。\n\"芯片设计工具 & IP 核心\n（EDA 软件与神经网络 IP）\",Synopsys / Cadence,Fusion Compiler / Cerebrus AI 工具,AI 优化设计流程，自动化布局布线；集成 IP 如 Arm Neoverse 核心，支持并行计算。,高切换成本（知识产权壁垒）；加速设计周期 20-30%；与 TSMC 深度合作，提升供应链效率。\n\"GPU/加速器设计\n（AI 专用芯片，处理 LLM 并行计算）\",NVIDIA,H100 / B200 GPU（Blackwell 架构）,每瓦性能领先，支持 NVLink 互联；CUDA 生态优化 LLM 训练，处理万亿参数模型。,90% AI GPU 市场份额；软件锁定（CUDA 如 iOS）；年迭代快，2025 年出货超 500 万片。\n,AMD,MI300X / MI325X,高带宽内存 (HBM3e) 集成，性价比高；支持 ROCm 开源软件栈。,作为 NVIDIA 备选，价格低 20-30%；LLM 开发者青睐多样化供应；CEO Lisa Su 领导下快速追赶。\n,Intel,Gaudi 3 / Xeon 6,FPGA 基加速器，集成 AI 引擎；支持混合 CPU-GPU 工作负载。,Foundry 服务重建中，与 NVIDIA 合作嵌入 GPU；边缘 AI 强，成本低但性能落后 10-20%。\n\"数据中心基础设施\n（服务器、冷却、网络）\",Dell / HPE,PowerEdge XE9680 / ProLiant DL380,液冷支持 8x GPU 集群；模块化设计，易扩展到 PB 级存储。,端到端集成，OEM 定制强；液冷降低能耗 40%，适应 AI 高密度负载。\n,Broadcom,Tomahawk 5 交换芯片,InfiniBand 支持非阻塞互联；带宽达 51.2 Tbps。,网络占数据中心支出 15-20%；NVIDIA 备选，降低锁定风险。\n\"云基础设施\n（ hyperscaler，提供 GPU 云服务）\",AWS / Azure / Google Cloud,EC2 P5 / Azure NDv5 / Vertex AI,按需 GPU 集群；集成安全合规工具。,规模经济，AWS 占 31% 云市场；Azure 与 OpenAI 深度绑定。\n\n\n下游强调 LLM 在企业场景的落地，如自动化和个性化。2025 年，企业 LLM 采用率达 78%，市场规模超 1300 亿美元      https://aloa.co/ai/comparisons/llm-comparison/best-enterprise-llm-solutions\n\n\n\n总结：建设一个 AI 数据中心需要的“购物清单”\n核心系统\t具体需求\t关键上游组件\t全球/行业标杆供应商\n电力\t稳定、高密度供电\t变压器、中高压开关\tSchneider, Eaton, ABB\n\t\tUPS、备用电池\tVertiv, Tesla (Megapack)\n制冷\t液冷 (AI 核心趋势)\t冷板、CDU (分配单元)\tVertiv, CoolIT, nVent, 英维克\n\t\t快接头、冷却液\tParker, 3M, Shell\n网络 (内)\tGPU 间高速互联\t800G/1.6T 光模块\tInnolight (中际旭创), Coherent, Finisar\n\t\t光芯片 (激光器/DSP)\tLumentum, Broadcom, Marvell\n\t\t光纤光缆\tCorning, CommScope\n集成\t服务器组装\tAI 服务器/整机柜\tFoxconn (工业富联), Quanta, Supermicro\n\n一句话投资/关注逻辑：\n目前最紧俏、技术迭代最快、与 AI 算力增长呈强正相关的环节是 液冷温控（Vertiv） 和 高速光互联（光模块/Innolight）。因为 GPU 越多，卡越热，通信需求越大。\n\n\n中际旭创（InnoLight）和新易盛这样的光模块厂商，本质上是高端精密组装与集成商。\n\n光模块的成本结构中，上游芯片（光芯片 + 电芯片）占据了 60%-70% 的成本。这些上游供应商掌握着极强的话语权。\n\n我们可以把光模块拆开，看看里面最值钱的零件是谁造的：\n- 第一层：电芯片（The Brains）—— 利润的大头\n      竞争态势： 中际旭创和新易盛主要是在给 Broadcom 和 Marvell 打工。谁能更早拿到 Broadcom 的最新 5nm/3nm DSP 芯片，谁就能更早出货光模块。\n- 第二层：光芯片（The Heart）—— 物理的极限\n  发射端芯片      EML：800G 的主流，技术难。     Lumentum (全球龙头，苹果也是客户)、Coherent (自产自销)、Mitsubishi (三菱电机)、Sumitomo (住友电工)。<br>国产突破： 源杰科技 (Yuanjie)（正在攻克高端 EML）。\n                  VCSEL（短距离/多模）：用于机柜内部连接   Broadcom/Lumentun 长关华芯\n- 第三层：无源器件与精密件（The Skeleton）—— 隐形冠军的聚集地\n- 第四层：PCB 与 外壳（The Body）\n\n\n如果把 AI 产业链 比作一家餐厅：\n\n    NVIDIA (食客)： 点菜的人，而且只吃最贵的（H100/GB200）。\n\n    中际旭创 (主厨)： 负责把菜做出来（组装光模块），通过 NVIDIA 的口味测试。\n\n    Broadcom/Marvell (顶级食材商)： 卖顶级牛肉（DSP 芯片）的，垄断货源，价格死贵，主厨没它不行。\n\n    Lumentum/Coherent (生鲜供应商)： 卖海鲜（光芯片）的，技术含量高。\n\n    天孚通信 (刀具与摆盘供应商)： 提供顶级厨具（精密光器件）的，虽然不卖肉，但主厨离不开它的精密工具，而且它利润很高。\n  接收端芯片       PD                        Hamamatsu    Kyosemi\n","source":"_drafts/AI-and-others.md","raw":"AI 行业是未来整体的方向\n\n但是 AI  行业会包括方方面面，本文希望对这个行业有一些稍微的了解\n\nAI 不仅仅包括 LLM（也就是大模型），但是最吸引眼球的是 LLM\n\n本文希望能探索 AI 整个行业，从上游到下游可能的产业，公司等，由于能力有限，难免会有错漏，算是一个快照吧。\n\n> 部分由 LLM 产生的结构，后面需要确认或者调整\n\n1. 上游：硬件与基础设施（支持 LLM 训练与推理）\n上游聚焦计算资源和制造，支持 LLM 的海量参数处理（当前 LLM 参数量已超 5000 亿）。 关键链路包括半导体制造 → 芯片设计 → GPU/加速器 → 数据中心基础设施。供应链瓶颈（如 TSMC 产能）是主要挑战。\n\n链路,标杆公司,标杆产品,产品特色,竞争力\n\"半导体制造（晶圆代工）\n（基础硅片加工，先进节点如 3nm/2nm）\",TSMC（台积电）,N3E/N2 工艺节点,支持高密度集成，EUV 光刻技术降低功耗；产量高，适用于多芯片模块 (MCM) 封装。,全球 90% 先进节点份额；客户多样化（NVIDIA、AMD、Apple），抗风险强；但地缘政治依赖台湾。\n\"芯片设计工具 & IP 核心\n（EDA 软件与神经网络 IP）\",Synopsys / Cadence,Fusion Compiler / Cerebrus AI 工具,AI 优化设计流程，自动化布局布线；集成 IP 如 Arm Neoverse 核心，支持并行计算。,高切换成本（知识产权壁垒）；加速设计周期 20-30%；与 TSMC 深度合作，提升供应链效率。\n\"GPU/加速器设计\n（AI 专用芯片，处理 LLM 并行计算）\",NVIDIA,H100 / B200 GPU（Blackwell 架构）,每瓦性能领先，支持 NVLink 互联；CUDA 生态优化 LLM 训练，处理万亿参数模型。,90% AI GPU 市场份额；软件锁定（CUDA 如 iOS）；年迭代快，2025 年出货超 500 万片。\n,AMD,MI300X / MI325X,高带宽内存 (HBM3e) 集成，性价比高；支持 ROCm 开源软件栈。,作为 NVIDIA 备选，价格低 20-30%；LLM 开发者青睐多样化供应；CEO Lisa Su 领导下快速追赶。\n,Intel,Gaudi 3 / Xeon 6,FPGA 基加速器，集成 AI 引擎；支持混合 CPU-GPU 工作负载。,Foundry 服务重建中，与 NVIDIA 合作嵌入 GPU；边缘 AI 强，成本低但性能落后 10-20%。\n\"数据中心基础设施\n（服务器、冷却、网络）\",Dell / HPE,PowerEdge XE9680 / ProLiant DL380,液冷支持 8x GPU 集群；模块化设计，易扩展到 PB 级存储。,端到端集成，OEM 定制强；液冷降低能耗 40%，适应 AI 高密度负载。\n,Broadcom,Tomahawk 5 交换芯片,InfiniBand 支持非阻塞互联；带宽达 51.2 Tbps。,网络占数据中心支出 15-20%；NVIDIA 备选，降低锁定风险。\n\"云基础设施\n（ hyperscaler，提供 GPU 云服务）\",AWS / Azure / Google Cloud,EC2 P5 / Azure NDv5 / Vertex AI,按需 GPU 集群；集成安全合规工具。,规模经济，AWS 占 31% 云市场；Azure 与 OpenAI 深度绑定。\n\n\n下游强调 LLM 在企业场景的落地，如自动化和个性化。2025 年，企业 LLM 采用率达 78%，市场规模超 1300 亿美元      https://aloa.co/ai/comparisons/llm-comparison/best-enterprise-llm-solutions\n\n\n\n总结：建设一个 AI 数据中心需要的“购物清单”\n核心系统\t具体需求\t关键上游组件\t全球/行业标杆供应商\n电力\t稳定、高密度供电\t变压器、中高压开关\tSchneider, Eaton, ABB\n\t\tUPS、备用电池\tVertiv, Tesla (Megapack)\n制冷\t液冷 (AI 核心趋势)\t冷板、CDU (分配单元)\tVertiv, CoolIT, nVent, 英维克\n\t\t快接头、冷却液\tParker, 3M, Shell\n网络 (内)\tGPU 间高速互联\t800G/1.6T 光模块\tInnolight (中际旭创), Coherent, Finisar\n\t\t光芯片 (激光器/DSP)\tLumentum, Broadcom, Marvell\n\t\t光纤光缆\tCorning, CommScope\n集成\t服务器组装\tAI 服务器/整机柜\tFoxconn (工业富联), Quanta, Supermicro\n\n一句话投资/关注逻辑：\n目前最紧俏、技术迭代最快、与 AI 算力增长呈强正相关的环节是 液冷温控（Vertiv） 和 高速光互联（光模块/Innolight）。因为 GPU 越多，卡越热，通信需求越大。\n\n\n中际旭创（InnoLight）和新易盛这样的光模块厂商，本质上是高端精密组装与集成商。\n\n光模块的成本结构中，上游芯片（光芯片 + 电芯片）占据了 60%-70% 的成本。这些上游供应商掌握着极强的话语权。\n\n我们可以把光模块拆开，看看里面最值钱的零件是谁造的：\n- 第一层：电芯片（The Brains）—— 利润的大头\n      竞争态势： 中际旭创和新易盛主要是在给 Broadcom 和 Marvell 打工。谁能更早拿到 Broadcom 的最新 5nm/3nm DSP 芯片，谁就能更早出货光模块。\n- 第二层：光芯片（The Heart）—— 物理的极限\n  发射端芯片      EML：800G 的主流，技术难。     Lumentum (全球龙头，苹果也是客户)、Coherent (自产自销)、Mitsubishi (三菱电机)、Sumitomo (住友电工)。<br>国产突破： 源杰科技 (Yuanjie)（正在攻克高端 EML）。\n                  VCSEL（短距离/多模）：用于机柜内部连接   Broadcom/Lumentun 长关华芯\n- 第三层：无源器件与精密件（The Skeleton）—— 隐形冠军的聚集地\n- 第四层：PCB 与 外壳（The Body）\n\n\n如果把 AI 产业链 比作一家餐厅：\n\n    NVIDIA (食客)： 点菜的人，而且只吃最贵的（H100/GB200）。\n\n    中际旭创 (主厨)： 负责把菜做出来（组装光模块），通过 NVIDIA 的口味测试。\n\n    Broadcom/Marvell (顶级食材商)： 卖顶级牛肉（DSP 芯片）的，垄断货源，价格死贵，主厨没它不行。\n\n    Lumentum/Coherent (生鲜供应商)： 卖海鲜（光芯片）的，技术含量高。\n\n    天孚通信 (刀具与摆盘供应商)： 提供顶级厨具（精密光器件）的，虽然不卖肉，但主厨离不开它的精密工具，而且它利润很高。\n  接收端芯片       PD                        Hamamatsu    Kyosemi\n","slug":"AI-and-others","published":0,"date":"2025-11-26T03:14:43.946Z","updated":"2025-11-26T03:14:43.947Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cmj89f2z600027qmk73e846yc","content":"<p>AI 行业是未来整体的方向</p>\n<p>但是 AI  行业会包括方方面面，本文希望对这个行业有一些稍微的了解</p>\n<p>AI 不仅仅包括 LLM（也就是大模型），但是最吸引眼球的是 LLM</p>\n<p>本文希望能探索 AI 整个行业，从上游到下游可能的产业，公司等，由于能力有限，难免会有错漏，算是一个快照吧。</p>\n<blockquote>\n<p>部分由 LLM 产生的结构，后面需要确认或者调整</p>\n</blockquote>\n<ol>\n<li>上游：硬件与基础设施（支持 LLM 训练与推理）<br>上游聚焦计算资源和制造，支持 LLM 的海量参数处理（当前 LLM 参数量已超 5000 亿）。 关键链路包括半导体制造 → 芯片设计 → GPU/加速器 → 数据中心基础设施。供应链瓶颈（如 TSMC 产能）是主要挑战。</li>\n</ol>\n<p>链路,标杆公司,标杆产品,产品特色,竞争力<br>“半导体制造（晶圆代工）<br>（基础硅片加工，先进节点如 3nm/2nm）”,TSMC（台积电）,N3E/N2 工艺节点,支持高密度集成，EUV 光刻技术降低功耗；产量高，适用于多芯片模块 (MCM) 封装。,全球 90% 先进节点份额；客户多样化（NVIDIA、AMD、Apple），抗风险强；但地缘政治依赖台湾。<br>“芯片设计工具 &amp; IP 核心<br>（EDA 软件与神经网络 IP）”,Synopsys / Cadence,Fusion Compiler / Cerebrus AI 工具,AI 优化设计流程，自动化布局布线；集成 IP 如 Arm Neoverse 核心，支持并行计算。,高切换成本（知识产权壁垒）；加速设计周期 20-30%；与 TSMC 深度合作，提升供应链效率。<br>“GPU/加速器设计<br>（AI 专用芯片，处理 LLM 并行计算）”,NVIDIA,H100 / B200 GPU（Blackwell 架构）,每瓦性能领先，支持 NVLink 互联；CUDA 生态优化 LLM 训练，处理万亿参数模型。,90% AI GPU 市场份额；软件锁定（CUDA 如 iOS）；年迭代快，2025 年出货超 500 万片。<br>,AMD,MI300X / MI325X,高带宽内存 (HBM3e) 集成，性价比高；支持 ROCm 开源软件栈。,作为 NVIDIA 备选，价格低 20-30%；LLM 开发者青睐多样化供应；CEO Lisa Su 领导下快速追赶。<br>,Intel,Gaudi 3 / Xeon 6,FPGA 基加速器，集成 AI 引擎；支持混合 CPU-GPU 工作负载。,Foundry 服务重建中，与 NVIDIA 合作嵌入 GPU；边缘 AI 强，成本低但性能落后 10-20%。<br>“数据中心基础设施<br>（服务器、冷却、网络）”,Dell / HPE,PowerEdge XE9680 / ProLiant DL380,液冷支持 8x GPU 集群；模块化设计，易扩展到 PB 级存储。,端到端集成，OEM 定制强；液冷降低能耗 40%，适应 AI 高密度负载。<br>,Broadcom,Tomahawk 5 交换芯片,InfiniBand 支持非阻塞互联；带宽达 51.2 Tbps。,网络占数据中心支出 15-20%；NVIDIA 备选，降低锁定风险。<br>“云基础设施<br>（ hyperscaler，提供 GPU 云服务）”,AWS / Azure / Google Cloud,EC2 P5 / Azure NDv5 / Vertex AI,按需 GPU 集群；集成安全合规工具。,规模经济，AWS 占 31% 云市场；Azure 与 OpenAI 深度绑定。</p>\n<p>下游强调 LLM 在企业场景的落地，如自动化和个性化。2025 年，企业 LLM 采用率达 78%，市场规模超 1300 亿美元      <a href=\"https://aloa.co/ai/comparisons/llm-comparison/best-enterprise-llm-solutions\">https://aloa.co/ai/comparisons/llm-comparison/best-enterprise-llm-solutions</a></p>\n<p>总结：建设一个 AI 数据中心需要的“购物清单”<br>核心系统    具体需求    关键上游组件    全球/行业标杆供应商<br>电力    稳定、高密度供电    变压器、中高压开关    Schneider, Eaton, ABB<br>        UPS、备用电池    Vertiv, Tesla (Megapack)<br>制冷    液冷 (AI 核心趋势)    冷板、CDU (分配单元)    Vertiv, CoolIT, nVent, 英维克<br>        快接头、冷却液    Parker, 3M, Shell<br>网络 (内)    GPU 间高速互联    800G/1.6T 光模块    Innolight (中际旭创), Coherent, Finisar<br>        光芯片 (激光器/DSP)    Lumentum, Broadcom, Marvell<br>        光纤光缆    Corning, CommScope<br>集成    服务器组装    AI 服务器/整机柜    Foxconn (工业富联), Quanta, Supermicro</p>\n<p>一句话投资/关注逻辑：<br>目前最紧俏、技术迭代最快、与 AI 算力增长呈强正相关的环节是 液冷温控（Vertiv） 和 高速光互联（光模块/Innolight）。因为 GPU 越多，卡越热，通信需求越大。</p>\n<p>中际旭创（InnoLight）和新易盛这样的光模块厂商，本质上是高端精密组装与集成商。</p>\n<p>光模块的成本结构中，上游芯片（光芯片 + 电芯片）占据了 60%-70% 的成本。这些上游供应商掌握着极强的话语权。</p>\n<p>我们可以把光模块拆开，看看里面最值钱的零件是谁造的：</p>\n<ul>\n<li>第一层：电芯片（The Brains）—— 利润的大头<pre><code>竞争态势： 中际旭创和新易盛主要是在给 Broadcom 和 Marvell 打工。谁能更早拿到 Broadcom 的最新 5nm/3nm DSP 芯片，谁就能更早出货光模块。\n</code></pre></li>\n<li>第二层：光芯片（The Heart）—— 物理的极限<br>发射端芯片      EML：800G 的主流，技术难。     Lumentum (全球龙头，苹果也是客户)、Coherent (自产自销)、Mitsubishi (三菱电机)、Sumitomo (住友电工)。<br>国产突破： 源杰科技 (Yuanjie)（正在攻克高端 EML）。<pre><code>            VCSEL（短距离/多模）：用于机柜内部连接   Broadcom/Lumentun 长关华芯\n</code></pre></li>\n<li>第三层：无源器件与精密件（The Skeleton）—— 隐形冠军的聚集地</li>\n<li>第四层：PCB 与 外壳（The Body）</li>\n</ul>\n<p>如果把 AI 产业链 比作一家餐厅：</p>\n<pre><code>NVIDIA (食客)： 点菜的人，而且只吃最贵的（H100/GB200）。\n\n中际旭创 (主厨)： 负责把菜做出来（组装光模块），通过 NVIDIA 的口味测试。\n\nBroadcom/Marvell (顶级食材商)： 卖顶级牛肉（DSP 芯片）的，垄断货源，价格死贵，主厨没它不行。\n\nLumentum/Coherent (生鲜供应商)： 卖海鲜（光芯片）的，技术含量高。\n\n天孚通信 (刀具与摆盘供应商)： 提供顶级厨具（精密光器件）的，虽然不卖肉，但主厨离不开它的精密工具，而且它利润很高。\n</code></pre><p>  接收端芯片       PD                        Hamamatsu    Kyosemi</p>\n","site":{"data":{}},"excerpt":"","more":"<p>AI 行业是未来整体的方向</p>\n<p>但是 AI  行业会包括方方面面，本文希望对这个行业有一些稍微的了解</p>\n<p>AI 不仅仅包括 LLM（也就是大模型），但是最吸引眼球的是 LLM</p>\n<p>本文希望能探索 AI 整个行业，从上游到下游可能的产业，公司等，由于能力有限，难免会有错漏，算是一个快照吧。</p>\n<blockquote>\n<p>部分由 LLM 产生的结构，后面需要确认或者调整</p>\n</blockquote>\n<ol>\n<li>上游：硬件与基础设施（支持 LLM 训练与推理）<br>上游聚焦计算资源和制造，支持 LLM 的海量参数处理（当前 LLM 参数量已超 5000 亿）。 关键链路包括半导体制造 → 芯片设计 → GPU/加速器 → 数据中心基础设施。供应链瓶颈（如 TSMC 产能）是主要挑战。</li>\n</ol>\n<p>链路,标杆公司,标杆产品,产品特色,竞争力<br>“半导体制造（晶圆代工）<br>（基础硅片加工，先进节点如 3nm/2nm）”,TSMC（台积电）,N3E/N2 工艺节点,支持高密度集成，EUV 光刻技术降低功耗；产量高，适用于多芯片模块 (MCM) 封装。,全球 90% 先进节点份额；客户多样化（NVIDIA、AMD、Apple），抗风险强；但地缘政治依赖台湾。<br>“芯片设计工具 &amp; IP 核心<br>（EDA 软件与神经网络 IP）”,Synopsys / Cadence,Fusion Compiler / Cerebrus AI 工具,AI 优化设计流程，自动化布局布线；集成 IP 如 Arm Neoverse 核心，支持并行计算。,高切换成本（知识产权壁垒）；加速设计周期 20-30%；与 TSMC 深度合作，提升供应链效率。<br>“GPU/加速器设计<br>（AI 专用芯片，处理 LLM 并行计算）”,NVIDIA,H100 / B200 GPU（Blackwell 架构）,每瓦性能领先，支持 NVLink 互联；CUDA 生态优化 LLM 训练，处理万亿参数模型。,90% AI GPU 市场份额；软件锁定（CUDA 如 iOS）；年迭代快，2025 年出货超 500 万片。<br>,AMD,MI300X / MI325X,高带宽内存 (HBM3e) 集成，性价比高；支持 ROCm 开源软件栈。,作为 NVIDIA 备选，价格低 20-30%；LLM 开发者青睐多样化供应；CEO Lisa Su 领导下快速追赶。<br>,Intel,Gaudi 3 / Xeon 6,FPGA 基加速器，集成 AI 引擎；支持混合 CPU-GPU 工作负载。,Foundry 服务重建中，与 NVIDIA 合作嵌入 GPU；边缘 AI 强，成本低但性能落后 10-20%。<br>“数据中心基础设施<br>（服务器、冷却、网络）”,Dell / HPE,PowerEdge XE9680 / ProLiant DL380,液冷支持 8x GPU 集群；模块化设计，易扩展到 PB 级存储。,端到端集成，OEM 定制强；液冷降低能耗 40%，适应 AI 高密度负载。<br>,Broadcom,Tomahawk 5 交换芯片,InfiniBand 支持非阻塞互联；带宽达 51.2 Tbps。,网络占数据中心支出 15-20%；NVIDIA 备选，降低锁定风险。<br>“云基础设施<br>（ hyperscaler，提供 GPU 云服务）”,AWS / Azure / Google Cloud,EC2 P5 / Azure NDv5 / Vertex AI,按需 GPU 集群；集成安全合规工具。,规模经济，AWS 占 31% 云市场；Azure 与 OpenAI 深度绑定。</p>\n<p>下游强调 LLM 在企业场景的落地，如自动化和个性化。2025 年，企业 LLM 采用率达 78%，市场规模超 1300 亿美元      <a href=\"https://aloa.co/ai/comparisons/llm-comparison/best-enterprise-llm-solutions\">https://aloa.co/ai/comparisons/llm-comparison/best-enterprise-llm-solutions</a></p>\n<p>总结：建设一个 AI 数据中心需要的“购物清单”<br>核心系统    具体需求    关键上游组件    全球/行业标杆供应商<br>电力    稳定、高密度供电    变压器、中高压开关    Schneider, Eaton, ABB<br>        UPS、备用电池    Vertiv, Tesla (Megapack)<br>制冷    液冷 (AI 核心趋势)    冷板、CDU (分配单元)    Vertiv, CoolIT, nVent, 英维克<br>        快接头、冷却液    Parker, 3M, Shell<br>网络 (内)    GPU 间高速互联    800G/1.6T 光模块    Innolight (中际旭创), Coherent, Finisar<br>        光芯片 (激光器/DSP)    Lumentum, Broadcom, Marvell<br>        光纤光缆    Corning, CommScope<br>集成    服务器组装    AI 服务器/整机柜    Foxconn (工业富联), Quanta, Supermicro</p>\n<p>一句话投资/关注逻辑：<br>目前最紧俏、技术迭代最快、与 AI 算力增长呈强正相关的环节是 液冷温控（Vertiv） 和 高速光互联（光模块/Innolight）。因为 GPU 越多，卡越热，通信需求越大。</p>\n<p>中际旭创（InnoLight）和新易盛这样的光模块厂商，本质上是高端精密组装与集成商。</p>\n<p>光模块的成本结构中，上游芯片（光芯片 + 电芯片）占据了 60%-70% 的成本。这些上游供应商掌握着极强的话语权。</p>\n<p>我们可以把光模块拆开，看看里面最值钱的零件是谁造的：</p>\n<ul>\n<li>第一层：电芯片（The Brains）—— 利润的大头<pre><code>竞争态势： 中际旭创和新易盛主要是在给 Broadcom 和 Marvell 打工。谁能更早拿到 Broadcom 的最新 5nm/3nm DSP 芯片，谁就能更早出货光模块。\n</code></pre></li>\n<li>第二层：光芯片（The Heart）—— 物理的极限<br>发射端芯片      EML：800G 的主流，技术难。     Lumentum (全球龙头，苹果也是客户)、Coherent (自产自销)、Mitsubishi (三菱电机)、Sumitomo (住友电工)。<br>国产突破： 源杰科技 (Yuanjie)（正在攻克高端 EML）。<pre><code>            VCSEL（短距离/多模）：用于机柜内部连接   Broadcom/Lumentun 长关华芯\n</code></pre></li>\n<li>第三层：无源器件与精密件（The Skeleton）—— 隐形冠军的聚集地</li>\n<li>第四层：PCB 与 外壳（The Body）</li>\n</ul>\n<p>如果把 AI 产业链 比作一家餐厅：</p>\n<pre><code>NVIDIA (食客)： 点菜的人，而且只吃最贵的（H100/GB200）。\n\n中际旭创 (主厨)： 负责把菜做出来（组装光模块），通过 NVIDIA 的口味测试。\n\nBroadcom/Marvell (顶级食材商)： 卖顶级牛肉（DSP 芯片）的，垄断货源，价格死贵，主厨没它不行。\n\nLumentum/Coherent (生鲜供应商)： 卖海鲜（光芯片）的，技术含量高。\n\n天孚通信 (刀具与摆盘供应商)： 提供顶级厨具（精密光器件）的，虽然不卖肉，但主厨离不开它的精密工具，而且它利润很高。\n</code></pre><p>  接收端芯片       PD                        Hamamatsu    Kyosemi</p>\n"},{"_content":"供需曲线\n\n供给弹性\n需求弹性\n\n卖家的总收益 (书中的小麦）\n> 整体好，和 个体好可能不一样：比如小麦的产率提高了\n\n可以沉淀一些结论（比如在什么情况下，总收益会变好，会变差），然后总的需求走向等\n","source":"_drafts/demand-supply-curve-andelasticity.md","raw":"供需曲线\n\n供给弹性\n需求弹性\n\n卖家的总收益 (书中的小麦）\n> 整体好，和 个体好可能不一样：比如小麦的产率提高了\n\n可以沉淀一些结论（比如在什么情况下，总收益会变好，会变差），然后总的需求走向等\n","slug":"demand-supply-curve-andelasticity","published":0,"date":"2026-01-17T01:18:10.558Z","updated":"2026-01-17T01:18:10.558Z","_id":"cmkgc54oy0000cjmk7178eyjm","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"<p>供需曲线</p>\n<p>供给弹性<br>需求弹性</p>\n<p>卖家的总收益 (书中的小麦）</p>\n<blockquote>\n<p>整体好，和 个体好可能不一样：比如小麦的产率提高了</p>\n</blockquote>\n<p>可以沉淀一些结论（比如在什么情况下，总收益会变好，会变差），然后总的需求走向等</p>\n","site":{"data":{}},"excerpt":"","more":"<p>供需曲线</p>\n<p>供给弹性<br>需求弹性</p>\n<p>卖家的总收益 (书中的小麦）</p>\n<blockquote>\n<p>整体好，和 个体好可能不一样：比如小麦的产率提高了</p>\n</blockquote>\n<p>可以沉淀一些结论（比如在什么情况下，总收益会变好，会变差），然后总的需求走向等</p>\n"},{"_content":"关键词\nDeepseek 分的大类\n- 资源与开采\n- 生产与运营\n- 市场与贸易\n- 电力生产与运营\n- 电网与输配\n- 市场与交易\n- 政策与监管\n- 技术与创新\n- 财务与投资\n\n\nGrok 分的维度\n- 采矿操作\n- 煤炭加工\n- 发电生产\n- 环境可持续\n- 安全健康\n- 基础设施\n- 能源转型替代\n- 政策法规\n- 市场经济\n- 需求供给管理\n- 技术与创新\n\n上面的视角是典型的“全产业链价值链”视角，Grok 的更像是“运营指标与战略议题”的混合体。\n方案一，非常符合麦肯锡的 Value Chain Analysis（价值链分析）。它顺着煤炭从地下挖出来，一直到变成电能传送到千家万户的物理流向进行拆解。\n建议优化后的结构\n- 上游（煤炭篇）\n- 中游（物流贸易）\n- 下游（电力端）\n- 电网层\n- 横向支撑层\n\n方案二更像一个管理仪表盘，它把“安全”，“环境”，“需求管理”等具体课题提炼出来\n优点：痛点导向，缺点：不 MECC\n\n建议\n第一步搭建纵向价值链\n- 煤炭供给层：产能分布，采掘技术，成本曲线\n- 能源转换层：火电效率，煤电联动机制，碳捕捉技术（CCUS）\n- 电力交付层：特高压输电，配电侧改革\n\n第二步 叠加横向驱动力（驱动因素分析）\n- 上述每个环节，都要用以下四个维度去“切”一遍\n- 政策驱动：“双碳”政策，长协煤价限制\n- 技术驱动：智能化采矿，灵活性改造\n- 经济驱动：供需平衡、煤电价差（度电成本 LCOE）\n- 环境驱动：碳交易市场（ETS）的影响\n\n\n\n煤炭端的成本分析，通常会使用成本曲线（Cost Curve）和全成本构成分析（Total cost of ownership/operation)\n\n在煤炭行业，成本控制不是简单的“省钱”，而是通过规模效应，地质条件的抵消以及技术效率来实现\n\n- 煤炭端成本的深度拆解（MECE 原则）\n完全成本（Full Cost）体系\n\n| 成本维度 | 具体构成要素 | 核心影响因子 |\n| -- | -- | -- |\n| 生产成本 | 人工、材料（支护、炸药），电力，燃料，外包工程费 | 采掘机械化程度，地质条件 |\n| 洗选与加工 | 洗煤厂折旧、药剂消耗、洗选煤损 | 精煤回收率 |\n| 物流运输 | 坑口费、铁路运输费（长协、市场），港口杂费、短驳费 | 距离消费地的半径（煤炭是典型的物流敏感型行业）|\n| 期间费用与税费 | 资源税， 安全生产费， 维简费，管理/财务费用| 政策性规费、负债率|\n| 环境与碳成本 | 矿山修复基金、碳排放权配额购买（未来趋势）| 环保监管力度、ESG 达标 |\n\n成本控制的关键驱动因素\n1. 地质条件与采掘比（Geological Efficiency）\n- 露天矿与井工矿：露天矿的玻璃比是核心，玻璃一吨煤需要移走多少土方，直接决定了油耗和机械折旧\n- 井工矿：关注工作面长度和断层频率\n- 控制手段：通过精准勘探减少无效掘进\n2.智能化与自动化（Smart mining）\n煤炭行业目前最大的成本变量\n- 无人化采掘：减少高海拔或危险环境下高昂人工成本\n- 预测性维护：利用传感器检测采煤机、皮带机的运行状态。公式参考：维护成本 C_maint 与非计划停机损失 L_downtime 的平衡\n- 控制手段：提高设备综合效率（OEE）\n3.供应链与采购优化（Strategic Sourcing）\n- 煤机设备零件、大型轮胎、燃油（柴油）的集中采购\n- 控制手段：建立供应商管理体系，利用规模效应压低采购单价\n\n成本领先战略的评估工具：成本曲线\n在行业分析中，我需要将所有矿进按离岸/到岸现价成本从低到高排列\n- 第一分位矿进（lowest cost）：拥有天然的地质优势（如鄂尔多斯/神府矿区）抗风险能力极强\n- 边际生产商：成本接近市场价，通常是控制成本的重点监测对象，也是市场下行时首批减产的对象。\n\n针对煤电一体化的特殊视角\n 如果你关注煤炭成本是为了给电力端服务，那么核心在于“内部转移定价”\n1.热值比价：控制“单位发热量成本”（Cost per kcall），而非简单的“吨煤成本”\n2.长协履约率：在煤炭端，稳定的长协供应是电力端最大的成本保障\n\n\n在煤炭行业，“出矿价”并不决定竞争力，“到厂价”才决定生死。同时，智能化则是当前煤企跨越“地质边际成本”陷阱的唯一路径。\n\n一、物流路径优化：从“坑口”到“炉口”的成本压缩\n煤炭物流具有“重载、长距离、高损耗”的特点。优化物流不仅是省运费，更是为了降低综合持有成本。\n1.运输方式的效能对比\n通常情况下，不同运输方式的单位成本差异巨大\n- 铁路：最具经济性，适合 500km 以上长距离\n- 水运（海运/内河）：单价最低，但受地理位置限制\n- 公路：灵活性高，但单价通常是铁路的 2-3倍，且受环保政策限制（公转铁）\n\n2.核心优化策略：一体化与多式联运\n- “公转铁”与专线建设：建设矿区专用线直接接入铁路干线，可减少二次装卸费用约 15-30元/吨，并大幅降低煤炭破碎和流失（约1%的损耗）\n- 中长期合同（长协）锁定运力：煤电企业通过与国铁集团签订年度协议，在运力紧张期确保“保供价”，避免寻找社会车辆带来的溢价\n- 坑口电价模式：终极优化方案。直接在矿区建电厂，通过皮带运输（成本几乎忽略不计），彻底消除长途运输费用\n\n二 智能化矿山：具体的成本降温与数据表现\n智能化不仅仅是“炫技”，其核心是“减人、增效、降耗”，以下是根据行业标杆企业（如国家能源集团、红柳林矿等）总结的经典数据\n1.人工成本的直接削减\n- 表现：综采工作面从传统的 15 - 20 人减至 3-5 人，甚至实现无人操作\n- 数据：万吨用工数可下降 30% -50%。在用人成本占比逐年攀升的背景下，这是控制全成本最有效的手段。\n2. 设备综合效率（OEE）的提升\n- 表现：通过远程诊断和预测性维护，减少意外停机时间\n- 数据：设备故障可降低 20%，设备寿命延长的 15%\n3.数据开采带来的增值\n- 表现：自动截割技术减少了采煤时的“掺矸率”（即不小心挖到石头）\n- 数据：原煤灰可降低 1%-2%，直接提升了洗选回收率，相当于变相增加了 3%-5%的有效产能\n\n智能化投入产出对比表\n\n| 项目 | 传统矿山 | 智能化矿山 | 成本影响 |\n| -- | -- | -- | -- |\n| 单产效率 | 较低、受体力限制 | 24 小时连续高产 | 单位折旧成本稀释 |\n| 电力消耗 | 峰谷不分，空转多 | 智能变频、按需供 | 电费下降约 10% |\n| 安全投入 | 事故风险高、保费高 | 风险预警、本质安全 | 间接成本大幅降低 |\n\n三总结：分析闭环\n要深入探讨煤炭端成本，你可以建立这样一个分析模型\n1. 基本面：确定该矿点的地质基础成本（刚性）\n2. 变量 A（物流）：计算通过“专用线+多式联运”能挤出多少利润空间\n3. 变量 B（技术）：评估当前智能化水平处于哪个阶段（L1-L4），预测未来 3 年的减人空间\n\n\n当前电力市场和能源转型的背景下，煤电厂的角色正从“电量供应主体”向“调节性电源”转变。灵活性改造是煤电厂在煤价高企、发电亏损压力下，实现深度止损甚至增收的核心战略。\n\n煤电厂如何通过灵活性改造实现“成本抵消”与“收益增收”\n一：什么是灵活性改造？（技术内核）\n煤电厂设计的初衷是“基荷运行”（即平稳发电）。灵活性改造主要包括：\n1. 深度调峰能力：将最低稳定负荷从额定的 50% 降低至 20% - 30% 甚至更低\n2. 快速启停与爬坡：提高响应速度，以匹配风电、光伏波动。\n3. 供热改造：实现热电解耦，在保证供热的同时具备大幅调节电功率的能力。\n\n二、灵活性改造如何“抵消”高昂煤炭成本？\n在高煤价时代，发的越多可能亏得越多，灵活性改造通过“优化发电结构”来对冲成本\n1. 规避“高价煤、低价电”的亏损区间\n- 逻辑：当现货市场电价低于煤电边际成本（主要是煤耗成本）时，通过深度调峰减少出力，少发少亏。\n- 价值：灵活性改造让电厂具备了“选择性发电”的权利，通过在峰谷时段灵活切换，将有限的长协煤用在电价最高的时段\n\n2. 提升煤电联动下的边际贡献\n- 逻辑：通过改造提升中低负荷下的热效率（降低分摊后的煤耗）\n- 数据：虽然低负荷运行会增加单位煤耗，但通过精细化热力系统改造，可降低负荷下的热耗率降幅提升约 3%-5%，从而在边际上减少燃煤浪费\n\n三 获取“辅助服务收益”：新的利润增长极\n在新型电力系统中，“灵活性”本身就是一种稀缺商品。煤电厂通过提供辅助服务获取额外补偿，这部分收益往往能覆盖煤炭成本的上涨。\n\n1.深度调峰补偿（Peak Shaving）\n- 机制：电网为鼓励煤电厂释放空间给新能源，会对提供 30% 以下负荷调节的电厂给予高额补偿。\n- 收益：在部分省份（如东北、华北），深度调峰补偿收益可达 0.4-1.0 元/千瓦时，远高于普通上网电价，这直接变成了电厂的纯利润。\n\n2. 调频服务(Frequency Regulation)\n- 机制：利用灵活性改造后的快速响应能力（通常配合“火电+储能”），参与电网调频\n- 价值：调频收益取决于响应速度和精度。灵活性好的机组在电力辅助服务市场中具有极高的“中标率”，收益非常稳健\n\n3. 备用容量补偿（Capacity Market）\n- 机制：即使不发电，只要机组处于随时可启用的状态，电网就支付“容量电价”\n- 趋势：随着容量电价机制在全国推广，灵活性改造后的煤电厂即时发电量减少，也能通过“买保险”的方式获得稳定的现金流，有效抵御煤价波动风险\n\n财务分析模型：改造前后的收益对比\n\n| 维度 | 改造前（基荷模式） | 改造后（灵活性模式） | 对利润的影响 |\n| -- | -- | -- |\n| 运营策略 | 满负荷，长时间运行 | 峰发电，谷调峰 | 减少高煤价期的无效燃料消耗 |\n| 主要收入 | 仅电量电价（kWh）| 电量电价 + 辅助服务补偿 + 容量电价 | 收入多元化，抗风险能力增强 |\n| 燃料成本 | 线性增长，压力大| 通过调峰避峰，优化单位煤炭成本| 边际效应提升 |\n| 设备损耗 | 较低| 频繁波动导致疲劳损耗增加 | 需通过智能化监控抵消维护成本 |\n\n需要对具体电厂进行评估，可以关注以下三个指标\n- 最小负荷率：是否能稳在 30% 以下？（决定了调峰收益门槛）\n- 爬坡速率：每分钟能调节多少万千瓦？（决定了调频收益）\n- 度电调节成本：提供一次辅助服务的综合折旧成本是多少？\n\n\n\n“煤电一体化 + 储能”的组合，在行业内被称为“火储联合调频”或“火储一体化电站”，如果说灵活性改造是给煤电厂换一颗“强心脏”，那么配建储能就是给这颗心脏装了一个“超级电容器”\n\n这种模式通过“收益叠加（Revenue Stacking） 在三个维度上显著放大收益\n\n1. 调频收益的“质变级”放大（核心盈利点）\n这是目前火电配储能最主要的收益来源\n- 痛点：传统火电机组（即时经过改造）响应电网调度指令时，存在延迟（秒级）和调节偏差。电网的调频补偿系数（K_p）直接挂钩调节精度\n- 储能放大效应：电化学储能（如锂电池）具有毫秒级的响应速度。当储能与火电机组联合时，系统整体的 K_p 值通常能从 1.0 左右提升到 3.0 以上\n- 由于 K_p 值成倍提升，在同样的调频指令下，电厂获得的补偿金额往往能翻 2-4 倍\n\n2. 释放“隐藏”的发电容量（容量价值）\n- 痛点：煤电厂为了留出一定的容量应对瞬时的频率调节，通常不能“满功率发电”，这部分被预留的容量被称为“旋转备用”，是不产生电量收益的。\n- 储能放大效应：由储能承担瞬时的调频任务，煤电机组就可以在电价高位端更加“顶峰发电”。\n- 收益：相当于变相增加了电厂的有效发点小时数，在现货市场高电价时段，这部分电量利润非常可观\n\n3. 利用“容量电价机制”获取保底收益\n- 最新政策导向：根据 2024 - 2025 年最新的政策，中国已全面推行煤电两部制电价（容量电价 + 电量电价）\n- 放大逻辑\n  - 容量补偿：煤电厂只要保持可用状态，每年每千瓦可获得约 100-165 元的固定容量电价支付\n  - 储能加持：储能系统可以辅助机组更快地从冷态/温态启动，确保在电网需要时“随叫随到”，规避因响应失败导致的容量费扣减处罚（最高肯梦扣除当月 50% - 100% 的容量费）\n\n“煤电+储能”收益叠加模型\n\n| 收益层级 | 来源 | 放大机制 | 财务影响 |\n| -- | -- | -- | -- |\n| 基础层(Base) | 现货电量收益 | 储能代行调频，火电多发高价电 | 提升边际贡献 5% - 10% |\n| 溢价层（Premium） | 调频辅助服务 | 显著提升 K_p 指标 | 调频结算金额提升 200%+ |\n| 保障层 (Safety) | 容量电价补偿 | 降低响应失败风险，确保拿足补偿 | 锁定每年每 kw 百元以上的现金流 |\n\n\n4. 关键财务门槛：投资回收期\n虽然受益放大了，但储能系统（BESS）的初投成本较高。\n- 行业基准：在调频补偿机制完善的省份（如广东、山西、蒙西），“火储联合”项目的内部收益率（IRR）可达 12%-18%，通常 3-5 年即可收回储能投资\n- 风险点：需警惕地方辅助服务市场政策的“退坡”风险，即随着储能电厂变多，单次调频的价格可能会下降。\n\nRef\n- [容量电价](https://www.ndrc.gov.cn/xxgk/zcfb/tz/202311/t20231110_1361897.html)\n","source":"_drafts/keywords-in-mine-and-electric.md","raw":"关键词\nDeepseek 分的大类\n- 资源与开采\n- 生产与运营\n- 市场与贸易\n- 电力生产与运营\n- 电网与输配\n- 市场与交易\n- 政策与监管\n- 技术与创新\n- 财务与投资\n\n\nGrok 分的维度\n- 采矿操作\n- 煤炭加工\n- 发电生产\n- 环境可持续\n- 安全健康\n- 基础设施\n- 能源转型替代\n- 政策法规\n- 市场经济\n- 需求供给管理\n- 技术与创新\n\n上面的视角是典型的“全产业链价值链”视角，Grok 的更像是“运营指标与战略议题”的混合体。\n方案一，非常符合麦肯锡的 Value Chain Analysis（价值链分析）。它顺着煤炭从地下挖出来，一直到变成电能传送到千家万户的物理流向进行拆解。\n建议优化后的结构\n- 上游（煤炭篇）\n- 中游（物流贸易）\n- 下游（电力端）\n- 电网层\n- 横向支撑层\n\n方案二更像一个管理仪表盘，它把“安全”，“环境”，“需求管理”等具体课题提炼出来\n优点：痛点导向，缺点：不 MECC\n\n建议\n第一步搭建纵向价值链\n- 煤炭供给层：产能分布，采掘技术，成本曲线\n- 能源转换层：火电效率，煤电联动机制，碳捕捉技术（CCUS）\n- 电力交付层：特高压输电，配电侧改革\n\n第二步 叠加横向驱动力（驱动因素分析）\n- 上述每个环节，都要用以下四个维度去“切”一遍\n- 政策驱动：“双碳”政策，长协煤价限制\n- 技术驱动：智能化采矿，灵活性改造\n- 经济驱动：供需平衡、煤电价差（度电成本 LCOE）\n- 环境驱动：碳交易市场（ETS）的影响\n\n\n\n煤炭端的成本分析，通常会使用成本曲线（Cost Curve）和全成本构成分析（Total cost of ownership/operation)\n\n在煤炭行业，成本控制不是简单的“省钱”，而是通过规模效应，地质条件的抵消以及技术效率来实现\n\n- 煤炭端成本的深度拆解（MECE 原则）\n完全成本（Full Cost）体系\n\n| 成本维度 | 具体构成要素 | 核心影响因子 |\n| -- | -- | -- |\n| 生产成本 | 人工、材料（支护、炸药），电力，燃料，外包工程费 | 采掘机械化程度，地质条件 |\n| 洗选与加工 | 洗煤厂折旧、药剂消耗、洗选煤损 | 精煤回收率 |\n| 物流运输 | 坑口费、铁路运输费（长协、市场），港口杂费、短驳费 | 距离消费地的半径（煤炭是典型的物流敏感型行业）|\n| 期间费用与税费 | 资源税， 安全生产费， 维简费，管理/财务费用| 政策性规费、负债率|\n| 环境与碳成本 | 矿山修复基金、碳排放权配额购买（未来趋势）| 环保监管力度、ESG 达标 |\n\n成本控制的关键驱动因素\n1. 地质条件与采掘比（Geological Efficiency）\n- 露天矿与井工矿：露天矿的玻璃比是核心，玻璃一吨煤需要移走多少土方，直接决定了油耗和机械折旧\n- 井工矿：关注工作面长度和断层频率\n- 控制手段：通过精准勘探减少无效掘进\n2.智能化与自动化（Smart mining）\n煤炭行业目前最大的成本变量\n- 无人化采掘：减少高海拔或危险环境下高昂人工成本\n- 预测性维护：利用传感器检测采煤机、皮带机的运行状态。公式参考：维护成本 C_maint 与非计划停机损失 L_downtime 的平衡\n- 控制手段：提高设备综合效率（OEE）\n3.供应链与采购优化（Strategic Sourcing）\n- 煤机设备零件、大型轮胎、燃油（柴油）的集中采购\n- 控制手段：建立供应商管理体系，利用规模效应压低采购单价\n\n成本领先战略的评估工具：成本曲线\n在行业分析中，我需要将所有矿进按离岸/到岸现价成本从低到高排列\n- 第一分位矿进（lowest cost）：拥有天然的地质优势（如鄂尔多斯/神府矿区）抗风险能力极强\n- 边际生产商：成本接近市场价，通常是控制成本的重点监测对象，也是市场下行时首批减产的对象。\n\n针对煤电一体化的特殊视角\n 如果你关注煤炭成本是为了给电力端服务，那么核心在于“内部转移定价”\n1.热值比价：控制“单位发热量成本”（Cost per kcall），而非简单的“吨煤成本”\n2.长协履约率：在煤炭端，稳定的长协供应是电力端最大的成本保障\n\n\n在煤炭行业，“出矿价”并不决定竞争力，“到厂价”才决定生死。同时，智能化则是当前煤企跨越“地质边际成本”陷阱的唯一路径。\n\n一、物流路径优化：从“坑口”到“炉口”的成本压缩\n煤炭物流具有“重载、长距离、高损耗”的特点。优化物流不仅是省运费，更是为了降低综合持有成本。\n1.运输方式的效能对比\n通常情况下，不同运输方式的单位成本差异巨大\n- 铁路：最具经济性，适合 500km 以上长距离\n- 水运（海运/内河）：单价最低，但受地理位置限制\n- 公路：灵活性高，但单价通常是铁路的 2-3倍，且受环保政策限制（公转铁）\n\n2.核心优化策略：一体化与多式联运\n- “公转铁”与专线建设：建设矿区专用线直接接入铁路干线，可减少二次装卸费用约 15-30元/吨，并大幅降低煤炭破碎和流失（约1%的损耗）\n- 中长期合同（长协）锁定运力：煤电企业通过与国铁集团签订年度协议，在运力紧张期确保“保供价”，避免寻找社会车辆带来的溢价\n- 坑口电价模式：终极优化方案。直接在矿区建电厂，通过皮带运输（成本几乎忽略不计），彻底消除长途运输费用\n\n二 智能化矿山：具体的成本降温与数据表现\n智能化不仅仅是“炫技”，其核心是“减人、增效、降耗”，以下是根据行业标杆企业（如国家能源集团、红柳林矿等）总结的经典数据\n1.人工成本的直接削减\n- 表现：综采工作面从传统的 15 - 20 人减至 3-5 人，甚至实现无人操作\n- 数据：万吨用工数可下降 30% -50%。在用人成本占比逐年攀升的背景下，这是控制全成本最有效的手段。\n2. 设备综合效率（OEE）的提升\n- 表现：通过远程诊断和预测性维护，减少意外停机时间\n- 数据：设备故障可降低 20%，设备寿命延长的 15%\n3.数据开采带来的增值\n- 表现：自动截割技术减少了采煤时的“掺矸率”（即不小心挖到石头）\n- 数据：原煤灰可降低 1%-2%，直接提升了洗选回收率，相当于变相增加了 3%-5%的有效产能\n\n智能化投入产出对比表\n\n| 项目 | 传统矿山 | 智能化矿山 | 成本影响 |\n| -- | -- | -- | -- |\n| 单产效率 | 较低、受体力限制 | 24 小时连续高产 | 单位折旧成本稀释 |\n| 电力消耗 | 峰谷不分，空转多 | 智能变频、按需供 | 电费下降约 10% |\n| 安全投入 | 事故风险高、保费高 | 风险预警、本质安全 | 间接成本大幅降低 |\n\n三总结：分析闭环\n要深入探讨煤炭端成本，你可以建立这样一个分析模型\n1. 基本面：确定该矿点的地质基础成本（刚性）\n2. 变量 A（物流）：计算通过“专用线+多式联运”能挤出多少利润空间\n3. 变量 B（技术）：评估当前智能化水平处于哪个阶段（L1-L4），预测未来 3 年的减人空间\n\n\n当前电力市场和能源转型的背景下，煤电厂的角色正从“电量供应主体”向“调节性电源”转变。灵活性改造是煤电厂在煤价高企、发电亏损压力下，实现深度止损甚至增收的核心战略。\n\n煤电厂如何通过灵活性改造实现“成本抵消”与“收益增收”\n一：什么是灵活性改造？（技术内核）\n煤电厂设计的初衷是“基荷运行”（即平稳发电）。灵活性改造主要包括：\n1. 深度调峰能力：将最低稳定负荷从额定的 50% 降低至 20% - 30% 甚至更低\n2. 快速启停与爬坡：提高响应速度，以匹配风电、光伏波动。\n3. 供热改造：实现热电解耦，在保证供热的同时具备大幅调节电功率的能力。\n\n二、灵活性改造如何“抵消”高昂煤炭成本？\n在高煤价时代，发的越多可能亏得越多，灵活性改造通过“优化发电结构”来对冲成本\n1. 规避“高价煤、低价电”的亏损区间\n- 逻辑：当现货市场电价低于煤电边际成本（主要是煤耗成本）时，通过深度调峰减少出力，少发少亏。\n- 价值：灵活性改造让电厂具备了“选择性发电”的权利，通过在峰谷时段灵活切换，将有限的长协煤用在电价最高的时段\n\n2. 提升煤电联动下的边际贡献\n- 逻辑：通过改造提升中低负荷下的热效率（降低分摊后的煤耗）\n- 数据：虽然低负荷运行会增加单位煤耗，但通过精细化热力系统改造，可降低负荷下的热耗率降幅提升约 3%-5%，从而在边际上减少燃煤浪费\n\n三 获取“辅助服务收益”：新的利润增长极\n在新型电力系统中，“灵活性”本身就是一种稀缺商品。煤电厂通过提供辅助服务获取额外补偿，这部分收益往往能覆盖煤炭成本的上涨。\n\n1.深度调峰补偿（Peak Shaving）\n- 机制：电网为鼓励煤电厂释放空间给新能源，会对提供 30% 以下负荷调节的电厂给予高额补偿。\n- 收益：在部分省份（如东北、华北），深度调峰补偿收益可达 0.4-1.0 元/千瓦时，远高于普通上网电价，这直接变成了电厂的纯利润。\n\n2. 调频服务(Frequency Regulation)\n- 机制：利用灵活性改造后的快速响应能力（通常配合“火电+储能”），参与电网调频\n- 价值：调频收益取决于响应速度和精度。灵活性好的机组在电力辅助服务市场中具有极高的“中标率”，收益非常稳健\n\n3. 备用容量补偿（Capacity Market）\n- 机制：即使不发电，只要机组处于随时可启用的状态，电网就支付“容量电价”\n- 趋势：随着容量电价机制在全国推广，灵活性改造后的煤电厂即时发电量减少，也能通过“买保险”的方式获得稳定的现金流，有效抵御煤价波动风险\n\n财务分析模型：改造前后的收益对比\n\n| 维度 | 改造前（基荷模式） | 改造后（灵活性模式） | 对利润的影响 |\n| -- | -- | -- |\n| 运营策略 | 满负荷，长时间运行 | 峰发电，谷调峰 | 减少高煤价期的无效燃料消耗 |\n| 主要收入 | 仅电量电价（kWh）| 电量电价 + 辅助服务补偿 + 容量电价 | 收入多元化，抗风险能力增强 |\n| 燃料成本 | 线性增长，压力大| 通过调峰避峰，优化单位煤炭成本| 边际效应提升 |\n| 设备损耗 | 较低| 频繁波动导致疲劳损耗增加 | 需通过智能化监控抵消维护成本 |\n\n需要对具体电厂进行评估，可以关注以下三个指标\n- 最小负荷率：是否能稳在 30% 以下？（决定了调峰收益门槛）\n- 爬坡速率：每分钟能调节多少万千瓦？（决定了调频收益）\n- 度电调节成本：提供一次辅助服务的综合折旧成本是多少？\n\n\n\n“煤电一体化 + 储能”的组合，在行业内被称为“火储联合调频”或“火储一体化电站”，如果说灵活性改造是给煤电厂换一颗“强心脏”，那么配建储能就是给这颗心脏装了一个“超级电容器”\n\n这种模式通过“收益叠加（Revenue Stacking） 在三个维度上显著放大收益\n\n1. 调频收益的“质变级”放大（核心盈利点）\n这是目前火电配储能最主要的收益来源\n- 痛点：传统火电机组（即时经过改造）响应电网调度指令时，存在延迟（秒级）和调节偏差。电网的调频补偿系数（K_p）直接挂钩调节精度\n- 储能放大效应：电化学储能（如锂电池）具有毫秒级的响应速度。当储能与火电机组联合时，系统整体的 K_p 值通常能从 1.0 左右提升到 3.0 以上\n- 由于 K_p 值成倍提升，在同样的调频指令下，电厂获得的补偿金额往往能翻 2-4 倍\n\n2. 释放“隐藏”的发电容量（容量价值）\n- 痛点：煤电厂为了留出一定的容量应对瞬时的频率调节，通常不能“满功率发电”，这部分被预留的容量被称为“旋转备用”，是不产生电量收益的。\n- 储能放大效应：由储能承担瞬时的调频任务，煤电机组就可以在电价高位端更加“顶峰发电”。\n- 收益：相当于变相增加了电厂的有效发点小时数，在现货市场高电价时段，这部分电量利润非常可观\n\n3. 利用“容量电价机制”获取保底收益\n- 最新政策导向：根据 2024 - 2025 年最新的政策，中国已全面推行煤电两部制电价（容量电价 + 电量电价）\n- 放大逻辑\n  - 容量补偿：煤电厂只要保持可用状态，每年每千瓦可获得约 100-165 元的固定容量电价支付\n  - 储能加持：储能系统可以辅助机组更快地从冷态/温态启动，确保在电网需要时“随叫随到”，规避因响应失败导致的容量费扣减处罚（最高肯梦扣除当月 50% - 100% 的容量费）\n\n“煤电+储能”收益叠加模型\n\n| 收益层级 | 来源 | 放大机制 | 财务影响 |\n| -- | -- | -- | -- |\n| 基础层(Base) | 现货电量收益 | 储能代行调频，火电多发高价电 | 提升边际贡献 5% - 10% |\n| 溢价层（Premium） | 调频辅助服务 | 显著提升 K_p 指标 | 调频结算金额提升 200%+ |\n| 保障层 (Safety) | 容量电价补偿 | 降低响应失败风险，确保拿足补偿 | 锁定每年每 kw 百元以上的现金流 |\n\n\n4. 关键财务门槛：投资回收期\n虽然受益放大了，但储能系统（BESS）的初投成本较高。\n- 行业基准：在调频补偿机制完善的省份（如广东、山西、蒙西），“火储联合”项目的内部收益率（IRR）可达 12%-18%，通常 3-5 年即可收回储能投资\n- 风险点：需警惕地方辅助服务市场政策的“退坡”风险，即随着储能电厂变多，单次调频的价格可能会下降。\n\nRef\n- [容量电价](https://www.ndrc.gov.cn/xxgk/zcfb/tz/202311/t20231110_1361897.html)\n","slug":"keywords-in-mine-and-electric","published":0,"date":"2025-12-29T01:09:18.333Z","updated":"2025-12-29T01:09:18.333Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cmkgc54p10001cjmk3eyogkvc","content":"<p>关键词<br>Deepseek 分的大类</p>\n<ul>\n<li>资源与开采</li>\n<li>生产与运营</li>\n<li>市场与贸易</li>\n<li>电力生产与运营</li>\n<li>电网与输配</li>\n<li>市场与交易</li>\n<li>政策与监管</li>\n<li>技术与创新</li>\n<li>财务与投资</li>\n</ul>\n<p>Grok 分的维度</p>\n<ul>\n<li>采矿操作</li>\n<li>煤炭加工</li>\n<li>发电生产</li>\n<li>环境可持续</li>\n<li>安全健康</li>\n<li>基础设施</li>\n<li>能源转型替代</li>\n<li>政策法规</li>\n<li>市场经济</li>\n<li>需求供给管理</li>\n<li>技术与创新</li>\n</ul>\n<p>上面的视角是典型的“全产业链价值链”视角，Grok 的更像是“运营指标与战略议题”的混合体。<br>方案一，非常符合麦肯锡的 Value Chain Analysis（价值链分析）。它顺着煤炭从地下挖出来，一直到变成电能传送到千家万户的物理流向进行拆解。<br>建议优化后的结构</p>\n<ul>\n<li>上游（煤炭篇）</li>\n<li>中游（物流贸易）</li>\n<li>下游（电力端）</li>\n<li>电网层</li>\n<li>横向支撑层</li>\n</ul>\n<p>方案二更像一个管理仪表盘，它把“安全”，“环境”，“需求管理”等具体课题提炼出来<br>优点：痛点导向，缺点：不 MECC</p>\n<p>建议<br>第一步搭建纵向价值链</p>\n<ul>\n<li>煤炭供给层：产能分布，采掘技术，成本曲线</li>\n<li>能源转换层：火电效率，煤电联动机制，碳捕捉技术（CCUS）</li>\n<li>电力交付层：特高压输电，配电侧改革</li>\n</ul>\n<p>第二步 叠加横向驱动力（驱动因素分析）</p>\n<ul>\n<li>上述每个环节，都要用以下四个维度去“切”一遍</li>\n<li>政策驱动：“双碳”政策，长协煤价限制</li>\n<li>技术驱动：智能化采矿，灵活性改造</li>\n<li>经济驱动：供需平衡、煤电价差（度电成本 LCOE）</li>\n<li>环境驱动：碳交易市场（ETS）的影响</li>\n</ul>\n<p>煤炭端的成本分析，通常会使用成本曲线（Cost Curve）和全成本构成分析（Total cost of ownership/operation)</p>\n<p>在煤炭行业，成本控制不是简单的“省钱”，而是通过规模效应，地质条件的抵消以及技术效率来实现</p>\n<ul>\n<li>煤炭端成本的深度拆解（MECE 原则）<br>完全成本（Full Cost）体系</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>成本维度</th>\n<th>具体构成要素</th>\n<th>核心影响因子</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>生产成本</td>\n<td>人工、材料（支护、炸药），电力，燃料，外包工程费</td>\n<td>采掘机械化程度，地质条件</td>\n</tr>\n<tr>\n<td>洗选与加工</td>\n<td>洗煤厂折旧、药剂消耗、洗选煤损</td>\n<td>精煤回收率</td>\n</tr>\n<tr>\n<td>物流运输</td>\n<td>坑口费、铁路运输费（长协、市场），港口杂费、短驳费</td>\n<td>距离消费地的半径（煤炭是典型的物流敏感型行业）</td>\n</tr>\n<tr>\n<td>期间费用与税费</td>\n<td>资源税， 安全生产费， 维简费，管理/财务费用</td>\n<td>政策性规费、负债率</td>\n</tr>\n<tr>\n<td>环境与碳成本</td>\n<td>矿山修复基金、碳排放权配额购买（未来趋势）</td>\n<td>环保监管力度、ESG 达标</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>成本控制的关键驱动因素</p>\n<ol>\n<li>地质条件与采掘比（Geological Efficiency）</li>\n</ol>\n<ul>\n<li>露天矿与井工矿：露天矿的玻璃比是核心，玻璃一吨煤需要移走多少土方，直接决定了油耗和机械折旧</li>\n<li>井工矿：关注工作面长度和断层频率</li>\n<li>控制手段：通过精准勘探减少无效掘进<br>2.智能化与自动化（Smart mining）<br>煤炭行业目前最大的成本变量</li>\n<li>无人化采掘：减少高海拔或危险环境下高昂人工成本</li>\n<li>预测性维护：利用传感器检测采煤机、皮带机的运行状态。公式参考：维护成本 C_maint 与非计划停机损失 L_downtime 的平衡</li>\n<li>控制手段：提高设备综合效率（OEE）<br>3.供应链与采购优化（Strategic Sourcing）</li>\n<li>煤机设备零件、大型轮胎、燃油（柴油）的集中采购</li>\n<li>控制手段：建立供应商管理体系，利用规模效应压低采购单价</li>\n</ul>\n<p>成本领先战略的评估工具：成本曲线<br>在行业分析中，我需要将所有矿进按离岸/到岸现价成本从低到高排列</p>\n<ul>\n<li>第一分位矿进（lowest cost）：拥有天然的地质优势（如鄂尔多斯/神府矿区）抗风险能力极强</li>\n<li>边际生产商：成本接近市场价，通常是控制成本的重点监测对象，也是市场下行时首批减产的对象。</li>\n</ul>\n<p>针对煤电一体化的特殊视角<br> 如果你关注煤炭成本是为了给电力端服务，那么核心在于“内部转移定价”<br>1.热值比价：控制“单位发热量成本”（Cost per kcall），而非简单的“吨煤成本”<br>2.长协履约率：在煤炭端，稳定的长协供应是电力端最大的成本保障</p>\n<p>在煤炭行业，“出矿价”并不决定竞争力，“到厂价”才决定生死。同时，智能化则是当前煤企跨越“地质边际成本”陷阱的唯一路径。</p>\n<p>一、物流路径优化：从“坑口”到“炉口”的成本压缩<br>煤炭物流具有“重载、长距离、高损耗”的特点。优化物流不仅是省运费，更是为了降低综合持有成本。<br>1.运输方式的效能对比<br>通常情况下，不同运输方式的单位成本差异巨大</p>\n<ul>\n<li>铁路：最具经济性，适合 500km 以上长距离</li>\n<li>水运（海运/内河）：单价最低，但受地理位置限制</li>\n<li>公路：灵活性高，但单价通常是铁路的 2-3倍，且受环保政策限制（公转铁）</li>\n</ul>\n<p>2.核心优化策略：一体化与多式联运</p>\n<ul>\n<li>“公转铁”与专线建设：建设矿区专用线直接接入铁路干线，可减少二次装卸费用约 15-30元/吨，并大幅降低煤炭破碎和流失（约1%的损耗）</li>\n<li>中长期合同（长协）锁定运力：煤电企业通过与国铁集团签订年度协议，在运力紧张期确保“保供价”，避免寻找社会车辆带来的溢价</li>\n<li>坑口电价模式：终极优化方案。直接在矿区建电厂，通过皮带运输（成本几乎忽略不计），彻底消除长途运输费用</li>\n</ul>\n<p>二 智能化矿山：具体的成本降温与数据表现<br>智能化不仅仅是“炫技”，其核心是“减人、增效、降耗”，以下是根据行业标杆企业（如国家能源集团、红柳林矿等）总结的经典数据<br>1.人工成本的直接削减</p>\n<ul>\n<li>表现：综采工作面从传统的 15 - 20 人减至 3-5 人，甚至实现无人操作</li>\n<li>数据：万吨用工数可下降 30% -50%。在用人成本占比逐年攀升的背景下，这是控制全成本最有效的手段。</li>\n</ul>\n<ol>\n<li>设备综合效率（OEE）的提升</li>\n</ol>\n<ul>\n<li>表现：通过远程诊断和预测性维护，减少意外停机时间</li>\n<li>数据：设备故障可降低 20%，设备寿命延长的 15%<br>3.数据开采带来的增值</li>\n<li>表现：自动截割技术减少了采煤时的“掺矸率”（即不小心挖到石头）</li>\n<li>数据：原煤灰可降低 1%-2%，直接提升了洗选回收率，相当于变相增加了 3%-5%的有效产能</li>\n</ul>\n<p>智能化投入产出对比表</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>传统矿山</th>\n<th>智能化矿山</th>\n<th>成本影响</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>单产效率</td>\n<td>较低、受体力限制</td>\n<td>24 小时连续高产</td>\n<td>单位折旧成本稀释</td>\n</tr>\n<tr>\n<td>电力消耗</td>\n<td>峰谷不分，空转多</td>\n<td>智能变频、按需供</td>\n<td>电费下降约 10%</td>\n</tr>\n<tr>\n<td>安全投入</td>\n<td>事故风险高、保费高</td>\n<td>风险预警、本质安全</td>\n<td>间接成本大幅降低</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>三总结：分析闭环<br>要深入探讨煤炭端成本，你可以建立这样一个分析模型</p>\n<ol>\n<li>基本面：确定该矿点的地质基础成本（刚性）</li>\n<li>变量 A（物流）：计算通过“专用线+多式联运”能挤出多少利润空间</li>\n<li>变量 B（技术）：评估当前智能化水平处于哪个阶段（L1-L4），预测未来 3 年的减人空间</li>\n</ol>\n<p>当前电力市场和能源转型的背景下，煤电厂的角色正从“电量供应主体”向“调节性电源”转变。灵活性改造是煤电厂在煤价高企、发电亏损压力下，实现深度止损甚至增收的核心战略。</p>\n<p>煤电厂如何通过灵活性改造实现“成本抵消”与“收益增收”<br>一：什么是灵活性改造？（技术内核）<br>煤电厂设计的初衷是“基荷运行”（即平稳发电）。灵活性改造主要包括：</p>\n<ol>\n<li>深度调峰能力：将最低稳定负荷从额定的 50% 降低至 20% - 30% 甚至更低</li>\n<li>快速启停与爬坡：提高响应速度，以匹配风电、光伏波动。</li>\n<li>供热改造：实现热电解耦，在保证供热的同时具备大幅调节电功率的能力。</li>\n</ol>\n<p>二、灵活性改造如何“抵消”高昂煤炭成本？<br>在高煤价时代，发的越多可能亏得越多，灵活性改造通过“优化发电结构”来对冲成本</p>\n<ol>\n<li>规避“高价煤、低价电”的亏损区间</li>\n</ol>\n<ul>\n<li>逻辑：当现货市场电价低于煤电边际成本（主要是煤耗成本）时，通过深度调峰减少出力，少发少亏。</li>\n<li>价值：灵活性改造让电厂具备了“选择性发电”的权利，通过在峰谷时段灵活切换，将有限的长协煤用在电价最高的时段</li>\n</ul>\n<ol>\n<li>提升煤电联动下的边际贡献</li>\n</ol>\n<ul>\n<li>逻辑：通过改造提升中低负荷下的热效率（降低分摊后的煤耗）</li>\n<li>数据：虽然低负荷运行会增加单位煤耗，但通过精细化热力系统改造，可降低负荷下的热耗率降幅提升约 3%-5%，从而在边际上减少燃煤浪费</li>\n</ul>\n<p>三 获取“辅助服务收益”：新的利润增长极<br>在新型电力系统中，“灵活性”本身就是一种稀缺商品。煤电厂通过提供辅助服务获取额外补偿，这部分收益往往能覆盖煤炭成本的上涨。</p>\n<p>1.深度调峰补偿（Peak Shaving）</p>\n<ul>\n<li>机制：电网为鼓励煤电厂释放空间给新能源，会对提供 30% 以下负荷调节的电厂给予高额补偿。</li>\n<li>收益：在部分省份（如东北、华北），深度调峰补偿收益可达 0.4-1.0 元/千瓦时，远高于普通上网电价，这直接变成了电厂的纯利润。</li>\n</ul>\n<ol>\n<li>调频服务(Frequency Regulation)</li>\n</ol>\n<ul>\n<li>机制：利用灵活性改造后的快速响应能力（通常配合“火电+储能”），参与电网调频</li>\n<li>价值：调频收益取决于响应速度和精度。灵活性好的机组在电力辅助服务市场中具有极高的“中标率”，收益非常稳健</li>\n</ul>\n<ol>\n<li>备用容量补偿（Capacity Market）</li>\n</ol>\n<ul>\n<li>机制：即使不发电，只要机组处于随时可启用的状态，电网就支付“容量电价”</li>\n<li>趋势：随着容量电价机制在全国推广，灵活性改造后的煤电厂即时发电量减少，也能通过“买保险”的方式获得稳定的现金流，有效抵御煤价波动风险</li>\n</ul>\n<p>财务分析模型：改造前后的收益对比</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>改造前（基荷模式）</th>\n<th>改造后（灵活性模式）</th>\n<th>对利润的影响</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>运营策略</td>\n<td>满负荷，长时间运行</td>\n<td>峰发电，谷调峰</td>\n<td>减少高煤价期的无效燃料消耗</td>\n</tr>\n<tr>\n<td>主要收入</td>\n<td>仅电量电价（kWh）</td>\n<td>电量电价 + 辅助服务补偿 + 容量电价</td>\n<td>收入多元化，抗风险能力增强</td>\n</tr>\n<tr>\n<td>燃料成本</td>\n<td>线性增长，压力大</td>\n<td>通过调峰避峰，优化单位煤炭成本</td>\n<td>边际效应提升</td>\n</tr>\n<tr>\n<td>设备损耗</td>\n<td>较低</td>\n<td>频繁波动导致疲劳损耗增加</td>\n<td>需通过智能化监控抵消维护成本</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>需要对具体电厂进行评估，可以关注以下三个指标</p>\n<ul>\n<li>最小负荷率：是否能稳在 30% 以下？（决定了调峰收益门槛）</li>\n<li>爬坡速率：每分钟能调节多少万千瓦？（决定了调频收益）</li>\n<li>度电调节成本：提供一次辅助服务的综合折旧成本是多少？</li>\n</ul>\n<p>“煤电一体化 + 储能”的组合，在行业内被称为“火储联合调频”或“火储一体化电站”，如果说灵活性改造是给煤电厂换一颗“强心脏”，那么配建储能就是给这颗心脏装了一个“超级电容器”</p>\n<p>这种模式通过“收益叠加（Revenue Stacking） 在三个维度上显著放大收益</p>\n<ol>\n<li>调频收益的“质变级”放大（核心盈利点）<br>这是目前火电配储能最主要的收益来源</li>\n</ol>\n<ul>\n<li>痛点：传统火电机组（即时经过改造）响应电网调度指令时，存在延迟（秒级）和调节偏差。电网的调频补偿系数（K_p）直接挂钩调节精度</li>\n<li>储能放大效应：电化学储能（如锂电池）具有毫秒级的响应速度。当储能与火电机组联合时，系统整体的 K_p 值通常能从 1.0 左右提升到 3.0 以上</li>\n<li>由于 K_p 值成倍提升，在同样的调频指令下，电厂获得的补偿金额往往能翻 2-4 倍</li>\n</ul>\n<ol>\n<li>释放“隐藏”的发电容量（容量价值）</li>\n</ol>\n<ul>\n<li>痛点：煤电厂为了留出一定的容量应对瞬时的频率调节，通常不能“满功率发电”，这部分被预留的容量被称为“旋转备用”，是不产生电量收益的。</li>\n<li>储能放大效应：由储能承担瞬时的调频任务，煤电机组就可以在电价高位端更加“顶峰发电”。</li>\n<li>收益：相当于变相增加了电厂的有效发点小时数，在现货市场高电价时段，这部分电量利润非常可观</li>\n</ul>\n<ol>\n<li>利用“容量电价机制”获取保底收益</li>\n</ol>\n<ul>\n<li>最新政策导向：根据 2024 - 2025 年最新的政策，中国已全面推行煤电两部制电价（容量电价 + 电量电价）</li>\n<li>放大逻辑<ul>\n<li>容量补偿：煤电厂只要保持可用状态，每年每千瓦可获得约 100-165 元的固定容量电价支付</li>\n<li>储能加持：储能系统可以辅助机组更快地从冷态/温态启动，确保在电网需要时“随叫随到”，规避因响应失败导致的容量费扣减处罚（最高肯梦扣除当月 50% - 100% 的容量费）</li>\n</ul>\n</li>\n</ul>\n<p>“煤电+储能”收益叠加模型</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>收益层级</th>\n<th>来源</th>\n<th>放大机制</th>\n<th>财务影响</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>基础层(Base)</td>\n<td>现货电量收益</td>\n<td>储能代行调频，火电多发高价电</td>\n<td>提升边际贡献 5% - 10%</td>\n</tr>\n<tr>\n<td>溢价层（Premium）</td>\n<td>调频辅助服务</td>\n<td>显著提升 K_p 指标</td>\n<td>调频结算金额提升 200%+</td>\n</tr>\n<tr>\n<td>保障层 (Safety)</td>\n<td>容量电价补偿</td>\n<td>降低响应失败风险，确保拿足补偿</td>\n<td>锁定每年每 kw 百元以上的现金流</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ol>\n<li>关键财务门槛：投资回收期<br>虽然受益放大了，但储能系统（BESS）的初投成本较高。</li>\n</ol>\n<ul>\n<li>行业基准：在调频补偿机制完善的省份（如广东、山西、蒙西），“火储联合”项目的内部收益率（IRR）可达 12%-18%，通常 3-5 年即可收回储能投资</li>\n<li>风险点：需警惕地方辅助服务市场政策的“退坡”风险，即随着储能电厂变多，单次调频的价格可能会下降。</li>\n</ul>\n<p>Ref</p>\n<ul>\n<li><a href=\"https://www.ndrc.gov.cn/xxgk/zcfb/tz/202311/t20231110_1361897.html\">容量电价</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>关键词<br>Deepseek 分的大类</p>\n<ul>\n<li>资源与开采</li>\n<li>生产与运营</li>\n<li>市场与贸易</li>\n<li>电力生产与运营</li>\n<li>电网与输配</li>\n<li>市场与交易</li>\n<li>政策与监管</li>\n<li>技术与创新</li>\n<li>财务与投资</li>\n</ul>\n<p>Grok 分的维度</p>\n<ul>\n<li>采矿操作</li>\n<li>煤炭加工</li>\n<li>发电生产</li>\n<li>环境可持续</li>\n<li>安全健康</li>\n<li>基础设施</li>\n<li>能源转型替代</li>\n<li>政策法规</li>\n<li>市场经济</li>\n<li>需求供给管理</li>\n<li>技术与创新</li>\n</ul>\n<p>上面的视角是典型的“全产业链价值链”视角，Grok 的更像是“运营指标与战略议题”的混合体。<br>方案一，非常符合麦肯锡的 Value Chain Analysis（价值链分析）。它顺着煤炭从地下挖出来，一直到变成电能传送到千家万户的物理流向进行拆解。<br>建议优化后的结构</p>\n<ul>\n<li>上游（煤炭篇）</li>\n<li>中游（物流贸易）</li>\n<li>下游（电力端）</li>\n<li>电网层</li>\n<li>横向支撑层</li>\n</ul>\n<p>方案二更像一个管理仪表盘，它把“安全”，“环境”，“需求管理”等具体课题提炼出来<br>优点：痛点导向，缺点：不 MECC</p>\n<p>建议<br>第一步搭建纵向价值链</p>\n<ul>\n<li>煤炭供给层：产能分布，采掘技术，成本曲线</li>\n<li>能源转换层：火电效率，煤电联动机制，碳捕捉技术（CCUS）</li>\n<li>电力交付层：特高压输电，配电侧改革</li>\n</ul>\n<p>第二步 叠加横向驱动力（驱动因素分析）</p>\n<ul>\n<li>上述每个环节，都要用以下四个维度去“切”一遍</li>\n<li>政策驱动：“双碳”政策，长协煤价限制</li>\n<li>技术驱动：智能化采矿，灵活性改造</li>\n<li>经济驱动：供需平衡、煤电价差（度电成本 LCOE）</li>\n<li>环境驱动：碳交易市场（ETS）的影响</li>\n</ul>\n<p>煤炭端的成本分析，通常会使用成本曲线（Cost Curve）和全成本构成分析（Total cost of ownership/operation)</p>\n<p>在煤炭行业，成本控制不是简单的“省钱”，而是通过规模效应，地质条件的抵消以及技术效率来实现</p>\n<ul>\n<li>煤炭端成本的深度拆解（MECE 原则）<br>完全成本（Full Cost）体系</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>成本维度</th>\n<th>具体构成要素</th>\n<th>核心影响因子</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>生产成本</td>\n<td>人工、材料（支护、炸药），电力，燃料，外包工程费</td>\n<td>采掘机械化程度，地质条件</td>\n</tr>\n<tr>\n<td>洗选与加工</td>\n<td>洗煤厂折旧、药剂消耗、洗选煤损</td>\n<td>精煤回收率</td>\n</tr>\n<tr>\n<td>物流运输</td>\n<td>坑口费、铁路运输费（长协、市场），港口杂费、短驳费</td>\n<td>距离消费地的半径（煤炭是典型的物流敏感型行业）</td>\n</tr>\n<tr>\n<td>期间费用与税费</td>\n<td>资源税， 安全生产费， 维简费，管理/财务费用</td>\n<td>政策性规费、负债率</td>\n</tr>\n<tr>\n<td>环境与碳成本</td>\n<td>矿山修复基金、碳排放权配额购买（未来趋势）</td>\n<td>环保监管力度、ESG 达标</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>成本控制的关键驱动因素</p>\n<ol>\n<li>地质条件与采掘比（Geological Efficiency）</li>\n</ol>\n<ul>\n<li>露天矿与井工矿：露天矿的玻璃比是核心，玻璃一吨煤需要移走多少土方，直接决定了油耗和机械折旧</li>\n<li>井工矿：关注工作面长度和断层频率</li>\n<li>控制手段：通过精准勘探减少无效掘进<br>2.智能化与自动化（Smart mining）<br>煤炭行业目前最大的成本变量</li>\n<li>无人化采掘：减少高海拔或危险环境下高昂人工成本</li>\n<li>预测性维护：利用传感器检测采煤机、皮带机的运行状态。公式参考：维护成本 C_maint 与非计划停机损失 L_downtime 的平衡</li>\n<li>控制手段：提高设备综合效率（OEE）<br>3.供应链与采购优化（Strategic Sourcing）</li>\n<li>煤机设备零件、大型轮胎、燃油（柴油）的集中采购</li>\n<li>控制手段：建立供应商管理体系，利用规模效应压低采购单价</li>\n</ul>\n<p>成本领先战略的评估工具：成本曲线<br>在行业分析中，我需要将所有矿进按离岸/到岸现价成本从低到高排列</p>\n<ul>\n<li>第一分位矿进（lowest cost）：拥有天然的地质优势（如鄂尔多斯/神府矿区）抗风险能力极强</li>\n<li>边际生产商：成本接近市场价，通常是控制成本的重点监测对象，也是市场下行时首批减产的对象。</li>\n</ul>\n<p>针对煤电一体化的特殊视角<br> 如果你关注煤炭成本是为了给电力端服务，那么核心在于“内部转移定价”<br>1.热值比价：控制“单位发热量成本”（Cost per kcall），而非简单的“吨煤成本”<br>2.长协履约率：在煤炭端，稳定的长协供应是电力端最大的成本保障</p>\n<p>在煤炭行业，“出矿价”并不决定竞争力，“到厂价”才决定生死。同时，智能化则是当前煤企跨越“地质边际成本”陷阱的唯一路径。</p>\n<p>一、物流路径优化：从“坑口”到“炉口”的成本压缩<br>煤炭物流具有“重载、长距离、高损耗”的特点。优化物流不仅是省运费，更是为了降低综合持有成本。<br>1.运输方式的效能对比<br>通常情况下，不同运输方式的单位成本差异巨大</p>\n<ul>\n<li>铁路：最具经济性，适合 500km 以上长距离</li>\n<li>水运（海运/内河）：单价最低，但受地理位置限制</li>\n<li>公路：灵活性高，但单价通常是铁路的 2-3倍，且受环保政策限制（公转铁）</li>\n</ul>\n<p>2.核心优化策略：一体化与多式联运</p>\n<ul>\n<li>“公转铁”与专线建设：建设矿区专用线直接接入铁路干线，可减少二次装卸费用约 15-30元/吨，并大幅降低煤炭破碎和流失（约1%的损耗）</li>\n<li>中长期合同（长协）锁定运力：煤电企业通过与国铁集团签订年度协议，在运力紧张期确保“保供价”，避免寻找社会车辆带来的溢价</li>\n<li>坑口电价模式：终极优化方案。直接在矿区建电厂，通过皮带运输（成本几乎忽略不计），彻底消除长途运输费用</li>\n</ul>\n<p>二 智能化矿山：具体的成本降温与数据表现<br>智能化不仅仅是“炫技”，其核心是“减人、增效、降耗”，以下是根据行业标杆企业（如国家能源集团、红柳林矿等）总结的经典数据<br>1.人工成本的直接削减</p>\n<ul>\n<li>表现：综采工作面从传统的 15 - 20 人减至 3-5 人，甚至实现无人操作</li>\n<li>数据：万吨用工数可下降 30% -50%。在用人成本占比逐年攀升的背景下，这是控制全成本最有效的手段。</li>\n</ul>\n<ol>\n<li>设备综合效率（OEE）的提升</li>\n</ol>\n<ul>\n<li>表现：通过远程诊断和预测性维护，减少意外停机时间</li>\n<li>数据：设备故障可降低 20%，设备寿命延长的 15%<br>3.数据开采带来的增值</li>\n<li>表现：自动截割技术减少了采煤时的“掺矸率”（即不小心挖到石头）</li>\n<li>数据：原煤灰可降低 1%-2%，直接提升了洗选回收率，相当于变相增加了 3%-5%的有效产能</li>\n</ul>\n<p>智能化投入产出对比表</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>传统矿山</th>\n<th>智能化矿山</th>\n<th>成本影响</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>单产效率</td>\n<td>较低、受体力限制</td>\n<td>24 小时连续高产</td>\n<td>单位折旧成本稀释</td>\n</tr>\n<tr>\n<td>电力消耗</td>\n<td>峰谷不分，空转多</td>\n<td>智能变频、按需供</td>\n<td>电费下降约 10%</td>\n</tr>\n<tr>\n<td>安全投入</td>\n<td>事故风险高、保费高</td>\n<td>风险预警、本质安全</td>\n<td>间接成本大幅降低</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>三总结：分析闭环<br>要深入探讨煤炭端成本，你可以建立这样一个分析模型</p>\n<ol>\n<li>基本面：确定该矿点的地质基础成本（刚性）</li>\n<li>变量 A（物流）：计算通过“专用线+多式联运”能挤出多少利润空间</li>\n<li>变量 B（技术）：评估当前智能化水平处于哪个阶段（L1-L4），预测未来 3 年的减人空间</li>\n</ol>\n<p>当前电力市场和能源转型的背景下，煤电厂的角色正从“电量供应主体”向“调节性电源”转变。灵活性改造是煤电厂在煤价高企、发电亏损压力下，实现深度止损甚至增收的核心战略。</p>\n<p>煤电厂如何通过灵活性改造实现“成本抵消”与“收益增收”<br>一：什么是灵活性改造？（技术内核）<br>煤电厂设计的初衷是“基荷运行”（即平稳发电）。灵活性改造主要包括：</p>\n<ol>\n<li>深度调峰能力：将最低稳定负荷从额定的 50% 降低至 20% - 30% 甚至更低</li>\n<li>快速启停与爬坡：提高响应速度，以匹配风电、光伏波动。</li>\n<li>供热改造：实现热电解耦，在保证供热的同时具备大幅调节电功率的能力。</li>\n</ol>\n<p>二、灵活性改造如何“抵消”高昂煤炭成本？<br>在高煤价时代，发的越多可能亏得越多，灵活性改造通过“优化发电结构”来对冲成本</p>\n<ol>\n<li>规避“高价煤、低价电”的亏损区间</li>\n</ol>\n<ul>\n<li>逻辑：当现货市场电价低于煤电边际成本（主要是煤耗成本）时，通过深度调峰减少出力，少发少亏。</li>\n<li>价值：灵活性改造让电厂具备了“选择性发电”的权利，通过在峰谷时段灵活切换，将有限的长协煤用在电价最高的时段</li>\n</ul>\n<ol>\n<li>提升煤电联动下的边际贡献</li>\n</ol>\n<ul>\n<li>逻辑：通过改造提升中低负荷下的热效率（降低分摊后的煤耗）</li>\n<li>数据：虽然低负荷运行会增加单位煤耗，但通过精细化热力系统改造，可降低负荷下的热耗率降幅提升约 3%-5%，从而在边际上减少燃煤浪费</li>\n</ul>\n<p>三 获取“辅助服务收益”：新的利润增长极<br>在新型电力系统中，“灵活性”本身就是一种稀缺商品。煤电厂通过提供辅助服务获取额外补偿，这部分收益往往能覆盖煤炭成本的上涨。</p>\n<p>1.深度调峰补偿（Peak Shaving）</p>\n<ul>\n<li>机制：电网为鼓励煤电厂释放空间给新能源，会对提供 30% 以下负荷调节的电厂给予高额补偿。</li>\n<li>收益：在部分省份（如东北、华北），深度调峰补偿收益可达 0.4-1.0 元/千瓦时，远高于普通上网电价，这直接变成了电厂的纯利润。</li>\n</ul>\n<ol>\n<li>调频服务(Frequency Regulation)</li>\n</ol>\n<ul>\n<li>机制：利用灵活性改造后的快速响应能力（通常配合“火电+储能”），参与电网调频</li>\n<li>价值：调频收益取决于响应速度和精度。灵活性好的机组在电力辅助服务市场中具有极高的“中标率”，收益非常稳健</li>\n</ul>\n<ol>\n<li>备用容量补偿（Capacity Market）</li>\n</ol>\n<ul>\n<li>机制：即使不发电，只要机组处于随时可启用的状态，电网就支付“容量电价”</li>\n<li>趋势：随着容量电价机制在全国推广，灵活性改造后的煤电厂即时发电量减少，也能通过“买保险”的方式获得稳定的现金流，有效抵御煤价波动风险</li>\n</ul>\n<p>财务分析模型：改造前后的收益对比</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>改造前（基荷模式）</th>\n<th>改造后（灵活性模式）</th>\n<th>对利润的影响</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>运营策略</td>\n<td>满负荷，长时间运行</td>\n<td>峰发电，谷调峰</td>\n<td>减少高煤价期的无效燃料消耗</td>\n</tr>\n<tr>\n<td>主要收入</td>\n<td>仅电量电价（kWh）</td>\n<td>电量电价 + 辅助服务补偿 + 容量电价</td>\n<td>收入多元化，抗风险能力增强</td>\n</tr>\n<tr>\n<td>燃料成本</td>\n<td>线性增长，压力大</td>\n<td>通过调峰避峰，优化单位煤炭成本</td>\n<td>边际效应提升</td>\n</tr>\n<tr>\n<td>设备损耗</td>\n<td>较低</td>\n<td>频繁波动导致疲劳损耗增加</td>\n<td>需通过智能化监控抵消维护成本</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>需要对具体电厂进行评估，可以关注以下三个指标</p>\n<ul>\n<li>最小负荷率：是否能稳在 30% 以下？（决定了调峰收益门槛）</li>\n<li>爬坡速率：每分钟能调节多少万千瓦？（决定了调频收益）</li>\n<li>度电调节成本：提供一次辅助服务的综合折旧成本是多少？</li>\n</ul>\n<p>“煤电一体化 + 储能”的组合，在行业内被称为“火储联合调频”或“火储一体化电站”，如果说灵活性改造是给煤电厂换一颗“强心脏”，那么配建储能就是给这颗心脏装了一个“超级电容器”</p>\n<p>这种模式通过“收益叠加（Revenue Stacking） 在三个维度上显著放大收益</p>\n<ol>\n<li>调频收益的“质变级”放大（核心盈利点）<br>这是目前火电配储能最主要的收益来源</li>\n</ol>\n<ul>\n<li>痛点：传统火电机组（即时经过改造）响应电网调度指令时，存在延迟（秒级）和调节偏差。电网的调频补偿系数（K_p）直接挂钩调节精度</li>\n<li>储能放大效应：电化学储能（如锂电池）具有毫秒级的响应速度。当储能与火电机组联合时，系统整体的 K_p 值通常能从 1.0 左右提升到 3.0 以上</li>\n<li>由于 K_p 值成倍提升，在同样的调频指令下，电厂获得的补偿金额往往能翻 2-4 倍</li>\n</ul>\n<ol>\n<li>释放“隐藏”的发电容量（容量价值）</li>\n</ol>\n<ul>\n<li>痛点：煤电厂为了留出一定的容量应对瞬时的频率调节，通常不能“满功率发电”，这部分被预留的容量被称为“旋转备用”，是不产生电量收益的。</li>\n<li>储能放大效应：由储能承担瞬时的调频任务，煤电机组就可以在电价高位端更加“顶峰发电”。</li>\n<li>收益：相当于变相增加了电厂的有效发点小时数，在现货市场高电价时段，这部分电量利润非常可观</li>\n</ul>\n<ol>\n<li>利用“容量电价机制”获取保底收益</li>\n</ol>\n<ul>\n<li>最新政策导向：根据 2024 - 2025 年最新的政策，中国已全面推行煤电两部制电价（容量电价 + 电量电价）</li>\n<li>放大逻辑<ul>\n<li>容量补偿：煤电厂只要保持可用状态，每年每千瓦可获得约 100-165 元的固定容量电价支付</li>\n<li>储能加持：储能系统可以辅助机组更快地从冷态/温态启动，确保在电网需要时“随叫随到”，规避因响应失败导致的容量费扣减处罚（最高肯梦扣除当月 50% - 100% 的容量费）</li>\n</ul>\n</li>\n</ul>\n<p>“煤电+储能”收益叠加模型</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>收益层级</th>\n<th>来源</th>\n<th>放大机制</th>\n<th>财务影响</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>基础层(Base)</td>\n<td>现货电量收益</td>\n<td>储能代行调频，火电多发高价电</td>\n<td>提升边际贡献 5% - 10%</td>\n</tr>\n<tr>\n<td>溢价层（Premium）</td>\n<td>调频辅助服务</td>\n<td>显著提升 K_p 指标</td>\n<td>调频结算金额提升 200%+</td>\n</tr>\n<tr>\n<td>保障层 (Safety)</td>\n<td>容量电价补偿</td>\n<td>降低响应失败风险，确保拿足补偿</td>\n<td>锁定每年每 kw 百元以上的现金流</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ol>\n<li>关键财务门槛：投资回收期<br>虽然受益放大了，但储能系统（BESS）的初投成本较高。</li>\n</ol>\n<ul>\n<li>行业基准：在调频补偿机制完善的省份（如广东、山西、蒙西），“火储联合”项目的内部收益率（IRR）可达 12%-18%，通常 3-5 年即可收回储能投资</li>\n<li>风险点：需警惕地方辅助服务市场政策的“退坡”风险，即随着储能电厂变多，单次调频的价格可能会下降。</li>\n</ul>\n<p>Ref</p>\n<ul>\n<li><a href=\"https://www.ndrc.gov.cn/xxgk/zcfb/tz/202311/t20231110_1361897.html\">容量电价</a></li>\n</ul>\n"},{"_content":"> 求真，求善，求美\n- 求真：理解，接受 真实的世界\n- 求善：求善，可以让自己被善包围\n- 求美：求美，可以让自己被美包围\n\n理性想长远\n - 有一种情况，没个月，或者每个季度都是有增长的，但是从整年的维度看，是没有增长的\n - 这就是没有长远的指标看\n\n最终要回答一个问题：我是谁。最重要回到自己，其他的都是空的。但是怎么给自己定位，以及怎么做的更好，需要进行学习\n\n可视化很重要\n- 随着年龄的增长，我们会有各种习惯 -- 用于加速我们处理，因此需要能够有一套流程增加新的流程替换到之前的流程，从而改变习惯\n  - 可以思考“XX，你帮我拿一下你旁边的杯子” 这句话，听到之后，自己是不是就会直接跳到“行动”，但是这句话会包括很多流程：\n    - 第一听到 XX 表示有人在叫你\n    - 第二我们听到了“你帮我拿一下你旁边的杯子”  我们知道了需要“我”做一件事，这件事是“拿旁边的杯子”\n    - 第三步在完全理解这句话的意思之后，我们需要指挥我们的手去拿到杯子，在这之前我们需要转动头并且通过眼睛找到杯子所在的地方\n    - 第四步手伸到杯子的地方，然后拿起来交给我\n    - 当然这些步骤由于我们做的太多了，导致已经信手拈来，不需要思考。可以观察一下刚学交流的小孩是怎么做这件事的\n      - 这个带出一个问题，不管是小孩还是大人，可能有些事情比我们想象中的要复杂，因为我们会了/熟悉了，但是对方没有。这个过程对方的整个行动就会显得“慢”，“不协调”等，但是这是一个必经的过程 -- 可年龄无关，甚至和年龄是负相关，因为年龄越大越有一些其他的“习惯”可能阻碍当前的事情 -- 这也是不太好改变的一个原因。\n\n不要变的更差\n- 我们在任何时候都处在某个 status\n- 我们每次决策/行动，可能会让我们所处的 status 变好/不变/变差\n- 每个人都会犯错（也就是都会变差等）\n- 不变差就变是减少犯错，从长远来看，这个犯错少，积累的就多\n   - 这个涉及到复利，复利就是在上次的基础上进行叠加\n   - 犯错相当于回撤，也就是下一次的 base 变低\n\n这个会导致有些变化会相对很慢（我们在分析公司有些事情的时候也需要考虑 -- 公司不做改变，可能不是它不想做改变，而是没有更好的办法，然后这个事情也不是那么紧急，所以就先维持现状）。这个来自于我的一个想法：\n- 我想在团队内做一个改变（取消晨会），虽然我主持晨会，但是我想取消掉。但是一直没有实施，是因为我担心后面由于各种原因又需要再进行，导致来回的变动，我没有想清楚这个事情，所以就一直没有进行调整。\n\n慢就稳 ，稳就快\n\n觉得压力是因为想要的和实际的可能有冲突，焦虑是因为压力太多太大。但是我们只看到了表面上的焦虑/压力，没有看到实际情况下的冲突。如果想根本性的解决，就需要解决冲突。写作是一个相对比较好的手段，可以让我们看到冲突。\n\n长远的事情要从根本上解决，一次性解决问题，自己的事情要从根本上解决，但是对于工作来说不一定要完全一次性解决，一次性解决可能别人看不到你的功劳，可以捡重要的解决，然后自己能适当的放松，这样也能给其他人成长。\n\n\n\nAI 影响\n- AI 相当于是一个很厉害的助手，但是不会帮助自己做行为改变（可能给一些指示），但是具体的改变还是关于自己内化的，所以 AI 是一个很厉害的，但也不会那么那么厉害，最后还是看自己\n- AI 是用零壹这种表示，那么肯定有无法表达的（或者说电脑这种表达是稀疏的）\n- AI 现在说的强化学习，听起来感觉像鸡娃，那么能否非常强就有待商榷\n- 但是上面的不是说 AI 不行，AI 就算没法到达顶尖，那么达到一定阶段，也能够解决很多问题\n- 所以 AI 一定会改变很多事情，但是 AI 有自己的上限，这个上限可能比很多人会更强（不管是否不是有幻觉），如果自己要想能够有一定的安全，那么要怎么办呢？\n\nAI 是一个聪明的人（记忆力强，然后有一定的关联能力 -- 理解能力），但是“聪明真的重要吗？” \n- 聪明重要\n- 但更重要的是智慧\n- 而且 AI 是泛化的，统一的，人是特化的，有自己独特的个性，但是这样就需要找自己的特性了\n\nAI 可以会导致现在的流程发生变化\n- 需要接受并使用\n- 不要过于依赖（尽可能保留一些锻炼自己的方式）\n  - 如果仅接受 AI 的输出，然后自己做判断，那么时间久了，可能会导致判断力下降\n\n工作、投资和写作\n\n工作是一定的反馈，也可以有收入，但是工作来说对于大部分人可能会限于“螺丝钉”角色，导致无法看到整个大的 picture\n投资可以更好的理解世界运行，而且能够很好的进行验证 -- 这里设计到真金白银的决策\n- 投资用反人性的决策，选择顺人性的投资标的\n- 投资标的：定价权，差异化竞争性能力。更多的是要想办法对投资标的了解的足够深入，这里面可能也涉及到产品/公司的权力构建\n- 投资没有想象中的难，回报在 5% - 10% 的还是有不少，也相对比较稳，但是想赚大钱，就需要下大注，下大注来自于对「非共识」的正确理解，所以对自己的要求也相对比较高，当然汇报也会相对比较好\n  - 没有想象中的难，跑赢十年期国债的稳定投资标的还是比较多的，但是这个不能保证跑赢 CPI + GDP\n  - 换另外一个看法，GDP 是所有公司的营收平均值，然后有部分公司是上市了，那么找这些上市公司中营收前面的，一定是能跑赢 GDP 的，但是如果要赚大钱，就回到了对「非共识」的正确理解上，这一点要求高\n\n资产（asset）是未来能增值的，费用（cost）是会逐渐减值的，assert 和 cost 是可以进行转换的，怎么区分和转换 assert 以及 cost 是一个 ROI 很高的事情。\n\n写作可以帮助自己梳理想法, 相当于把下意识的东西暴露出来，让自己有可能做改变\n\n三者相辅相成\n\n如果对真实世界理解更深，那么一定能够活的更好，更自由。但是“真实世界理解更深”这个不是那么容易，而且需要是“真实”的，所以需要有验证 -- 有验证有调整。\n- 起点重要，更重要的是速度，也就是斜率，\n\n每个人活的足够久，就能够发现“智慧”，但是“智慧”没法通过语言等传递，只能自己发现\n要尊重常识，不要挑战常识，让自己尽可能做到“不败”\n\n\n正反馈很重要\n- 正反馈能帮助自己坚定的走一条路 -- 如果在未得到足够正反馈的情况下，有人能推着走也是一种不错的，但是这种不能强求\n- 有正反馈，能够不断的调整，然后继续\n\n一定程度能区分 自己了解，和不了解 的东西，能跟多的说「我不知道」\n","source":"_drafts/review-2025.md","raw":"> 求真，求善，求美\n- 求真：理解，接受 真实的世界\n- 求善：求善，可以让自己被善包围\n- 求美：求美，可以让自己被美包围\n\n理性想长远\n - 有一种情况，没个月，或者每个季度都是有增长的，但是从整年的维度看，是没有增长的\n - 这就是没有长远的指标看\n\n最终要回答一个问题：我是谁。最重要回到自己，其他的都是空的。但是怎么给自己定位，以及怎么做的更好，需要进行学习\n\n可视化很重要\n- 随着年龄的增长，我们会有各种习惯 -- 用于加速我们处理，因此需要能够有一套流程增加新的流程替换到之前的流程，从而改变习惯\n  - 可以思考“XX，你帮我拿一下你旁边的杯子” 这句话，听到之后，自己是不是就会直接跳到“行动”，但是这句话会包括很多流程：\n    - 第一听到 XX 表示有人在叫你\n    - 第二我们听到了“你帮我拿一下你旁边的杯子”  我们知道了需要“我”做一件事，这件事是“拿旁边的杯子”\n    - 第三步在完全理解这句话的意思之后，我们需要指挥我们的手去拿到杯子，在这之前我们需要转动头并且通过眼睛找到杯子所在的地方\n    - 第四步手伸到杯子的地方，然后拿起来交给我\n    - 当然这些步骤由于我们做的太多了，导致已经信手拈来，不需要思考。可以观察一下刚学交流的小孩是怎么做这件事的\n      - 这个带出一个问题，不管是小孩还是大人，可能有些事情比我们想象中的要复杂，因为我们会了/熟悉了，但是对方没有。这个过程对方的整个行动就会显得“慢”，“不协调”等，但是这是一个必经的过程 -- 可年龄无关，甚至和年龄是负相关，因为年龄越大越有一些其他的“习惯”可能阻碍当前的事情 -- 这也是不太好改变的一个原因。\n\n不要变的更差\n- 我们在任何时候都处在某个 status\n- 我们每次决策/行动，可能会让我们所处的 status 变好/不变/变差\n- 每个人都会犯错（也就是都会变差等）\n- 不变差就变是减少犯错，从长远来看，这个犯错少，积累的就多\n   - 这个涉及到复利，复利就是在上次的基础上进行叠加\n   - 犯错相当于回撤，也就是下一次的 base 变低\n\n这个会导致有些变化会相对很慢（我们在分析公司有些事情的时候也需要考虑 -- 公司不做改变，可能不是它不想做改变，而是没有更好的办法，然后这个事情也不是那么紧急，所以就先维持现状）。这个来自于我的一个想法：\n- 我想在团队内做一个改变（取消晨会），虽然我主持晨会，但是我想取消掉。但是一直没有实施，是因为我担心后面由于各种原因又需要再进行，导致来回的变动，我没有想清楚这个事情，所以就一直没有进行调整。\n\n慢就稳 ，稳就快\n\n觉得压力是因为想要的和实际的可能有冲突，焦虑是因为压力太多太大。但是我们只看到了表面上的焦虑/压力，没有看到实际情况下的冲突。如果想根本性的解决，就需要解决冲突。写作是一个相对比较好的手段，可以让我们看到冲突。\n\n长远的事情要从根本上解决，一次性解决问题，自己的事情要从根本上解决，但是对于工作来说不一定要完全一次性解决，一次性解决可能别人看不到你的功劳，可以捡重要的解决，然后自己能适当的放松，这样也能给其他人成长。\n\n\n\nAI 影响\n- AI 相当于是一个很厉害的助手，但是不会帮助自己做行为改变（可能给一些指示），但是具体的改变还是关于自己内化的，所以 AI 是一个很厉害的，但也不会那么那么厉害，最后还是看自己\n- AI 是用零壹这种表示，那么肯定有无法表达的（或者说电脑这种表达是稀疏的）\n- AI 现在说的强化学习，听起来感觉像鸡娃，那么能否非常强就有待商榷\n- 但是上面的不是说 AI 不行，AI 就算没法到达顶尖，那么达到一定阶段，也能够解决很多问题\n- 所以 AI 一定会改变很多事情，但是 AI 有自己的上限，这个上限可能比很多人会更强（不管是否不是有幻觉），如果自己要想能够有一定的安全，那么要怎么办呢？\n\nAI 是一个聪明的人（记忆力强，然后有一定的关联能力 -- 理解能力），但是“聪明真的重要吗？” \n- 聪明重要\n- 但更重要的是智慧\n- 而且 AI 是泛化的，统一的，人是特化的，有自己独特的个性，但是这样就需要找自己的特性了\n\nAI 可以会导致现在的流程发生变化\n- 需要接受并使用\n- 不要过于依赖（尽可能保留一些锻炼自己的方式）\n  - 如果仅接受 AI 的输出，然后自己做判断，那么时间久了，可能会导致判断力下降\n\n工作、投资和写作\n\n工作是一定的反馈，也可以有收入，但是工作来说对于大部分人可能会限于“螺丝钉”角色，导致无法看到整个大的 picture\n投资可以更好的理解世界运行，而且能够很好的进行验证 -- 这里设计到真金白银的决策\n- 投资用反人性的决策，选择顺人性的投资标的\n- 投资标的：定价权，差异化竞争性能力。更多的是要想办法对投资标的了解的足够深入，这里面可能也涉及到产品/公司的权力构建\n- 投资没有想象中的难，回报在 5% - 10% 的还是有不少，也相对比较稳，但是想赚大钱，就需要下大注，下大注来自于对「非共识」的正确理解，所以对自己的要求也相对比较高，当然汇报也会相对比较好\n  - 没有想象中的难，跑赢十年期国债的稳定投资标的还是比较多的，但是这个不能保证跑赢 CPI + GDP\n  - 换另外一个看法，GDP 是所有公司的营收平均值，然后有部分公司是上市了，那么找这些上市公司中营收前面的，一定是能跑赢 GDP 的，但是如果要赚大钱，就回到了对「非共识」的正确理解上，这一点要求高\n\n资产（asset）是未来能增值的，费用（cost）是会逐渐减值的，assert 和 cost 是可以进行转换的，怎么区分和转换 assert 以及 cost 是一个 ROI 很高的事情。\n\n写作可以帮助自己梳理想法, 相当于把下意识的东西暴露出来，让自己有可能做改变\n\n三者相辅相成\n\n如果对真实世界理解更深，那么一定能够活的更好，更自由。但是“真实世界理解更深”这个不是那么容易，而且需要是“真实”的，所以需要有验证 -- 有验证有调整。\n- 起点重要，更重要的是速度，也就是斜率，\n\n每个人活的足够久，就能够发现“智慧”，但是“智慧”没法通过语言等传递，只能自己发现\n要尊重常识，不要挑战常识，让自己尽可能做到“不败”\n\n\n正反馈很重要\n- 正反馈能帮助自己坚定的走一条路 -- 如果在未得到足够正反馈的情况下，有人能推着走也是一种不错的，但是这种不能强求\n- 有正反馈，能够不断的调整，然后继续\n\n一定程度能区分 自己了解，和不了解 的东西，能跟多的说「我不知道」\n","slug":"review-2025","published":0,"date":"2026-01-16T06:56:48.694Z","updated":"2026-01-16T06:56:48.694Z","_id":"cmkgc54p20002cjmkeheo1ya9","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>求真，求善，求美</p>\n<ul>\n<li>求真：理解，接受 真实的世界</li>\n<li>求善：求善，可以让自己被善包围</li>\n<li>求美：求美，可以让自己被美包围</li>\n</ul>\n</blockquote>\n<p>理性想长远</p>\n<ul>\n<li>有一种情况，没个月，或者每个季度都是有增长的，但是从整年的维度看，是没有增长的</li>\n<li>这就是没有长远的指标看</li>\n</ul>\n<p>最终要回答一个问题：我是谁。最重要回到自己，其他的都是空的。但是怎么给自己定位，以及怎么做的更好，需要进行学习</p>\n<p>可视化很重要</p>\n<ul>\n<li>随着年龄的增长，我们会有各种习惯 — 用于加速我们处理，因此需要能够有一套流程增加新的流程替换到之前的流程，从而改变习惯<ul>\n<li>可以思考“XX，你帮我拿一下你旁边的杯子” 这句话，听到之后，自己是不是就会直接跳到“行动”，但是这句话会包括很多流程：<ul>\n<li>第一听到 XX 表示有人在叫你</li>\n<li>第二我们听到了“你帮我拿一下你旁边的杯子”  我们知道了需要“我”做一件事，这件事是“拿旁边的杯子”</li>\n<li>第三步在完全理解这句话的意思之后，我们需要指挥我们的手去拿到杯子，在这之前我们需要转动头并且通过眼睛找到杯子所在的地方</li>\n<li>第四步手伸到杯子的地方，然后拿起来交给我</li>\n<li>当然这些步骤由于我们做的太多了，导致已经信手拈来，不需要思考。可以观察一下刚学交流的小孩是怎么做这件事的<ul>\n<li>这个带出一个问题，不管是小孩还是大人，可能有些事情比我们想象中的要复杂，因为我们会了/熟悉了，但是对方没有。这个过程对方的整个行动就会显得“慢”，“不协调”等，但是这是一个必经的过程 — 可年龄无关，甚至和年龄是负相关，因为年龄越大越有一些其他的“习惯”可能阻碍当前的事情 — 这也是不太好改变的一个原因。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>不要变的更差</p>\n<ul>\n<li>我们在任何时候都处在某个 status</li>\n<li>我们每次决策/行动，可能会让我们所处的 status 变好/不变/变差</li>\n<li>每个人都会犯错（也就是都会变差等）</li>\n<li>不变差就变是减少犯错，从长远来看，这个犯错少，积累的就多<ul>\n<li>这个涉及到复利，复利就是在上次的基础上进行叠加</li>\n<li>犯错相当于回撤，也就是下一次的 base 变低</li>\n</ul>\n</li>\n</ul>\n<p>这个会导致有些变化会相对很慢（我们在分析公司有些事情的时候也需要考虑 — 公司不做改变，可能不是它不想做改变，而是没有更好的办法，然后这个事情也不是那么紧急，所以就先维持现状）。这个来自于我的一个想法：</p>\n<ul>\n<li>我想在团队内做一个改变（取消晨会），虽然我主持晨会，但是我想取消掉。但是一直没有实施，是因为我担心后面由于各种原因又需要再进行，导致来回的变动，我没有想清楚这个事情，所以就一直没有进行调整。</li>\n</ul>\n<p>慢就稳 ，稳就快</p>\n<p>觉得压力是因为想要的和实际的可能有冲突，焦虑是因为压力太多太大。但是我们只看到了表面上的焦虑/压力，没有看到实际情况下的冲突。如果想根本性的解决，就需要解决冲突。写作是一个相对比较好的手段，可以让我们看到冲突。</p>\n<p>长远的事情要从根本上解决，一次性解决问题，自己的事情要从根本上解决，但是对于工作来说不一定要完全一次性解决，一次性解决可能别人看不到你的功劳，可以捡重要的解决，然后自己能适当的放松，这样也能给其他人成长。</p>\n<p>AI 影响</p>\n<ul>\n<li>AI 相当于是一个很厉害的助手，但是不会帮助自己做行为改变（可能给一些指示），但是具体的改变还是关于自己内化的，所以 AI 是一个很厉害的，但也不会那么那么厉害，最后还是看自己</li>\n<li>AI 是用零壹这种表示，那么肯定有无法表达的（或者说电脑这种表达是稀疏的）</li>\n<li>AI 现在说的强化学习，听起来感觉像鸡娃，那么能否非常强就有待商榷</li>\n<li>但是上面的不是说 AI 不行，AI 就算没法到达顶尖，那么达到一定阶段，也能够解决很多问题</li>\n<li>所以 AI 一定会改变很多事情，但是 AI 有自己的上限，这个上限可能比很多人会更强（不管是否不是有幻觉），如果自己要想能够有一定的安全，那么要怎么办呢？</li>\n</ul>\n<p>AI 是一个聪明的人（记忆力强，然后有一定的关联能力 — 理解能力），但是“聪明真的重要吗？” </p>\n<ul>\n<li>聪明重要</li>\n<li>但更重要的是智慧</li>\n<li>而且 AI 是泛化的，统一的，人是特化的，有自己独特的个性，但是这样就需要找自己的特性了</li>\n</ul>\n<p>AI 可以会导致现在的流程发生变化</p>\n<ul>\n<li>需要接受并使用</li>\n<li>不要过于依赖（尽可能保留一些锻炼自己的方式）<ul>\n<li>如果仅接受 AI 的输出，然后自己做判断，那么时间久了，可能会导致判断力下降</li>\n</ul>\n</li>\n</ul>\n<p>工作、投资和写作</p>\n<p>工作是一定的反馈，也可以有收入，但是工作来说对于大部分人可能会限于“螺丝钉”角色，导致无法看到整个大的 picture<br>投资可以更好的理解世界运行，而且能够很好的进行验证 — 这里设计到真金白银的决策</p>\n<ul>\n<li>投资用反人性的决策，选择顺人性的投资标的</li>\n<li>投资标的：定价权，差异化竞争性能力。更多的是要想办法对投资标的了解的足够深入，这里面可能也涉及到产品/公司的权力构建</li>\n<li>投资没有想象中的难，回报在 5% - 10% 的还是有不少，也相对比较稳，但是想赚大钱，就需要下大注，下大注来自于对「非共识」的正确理解，所以对自己的要求也相对比较高，当然汇报也会相对比较好<ul>\n<li>没有想象中的难，跑赢十年期国债的稳定投资标的还是比较多的，但是这个不能保证跑赢 CPI + GDP</li>\n<li>换另外一个看法，GDP 是所有公司的营收平均值，然后有部分公司是上市了，那么找这些上市公司中营收前面的，一定是能跑赢 GDP 的，但是如果要赚大钱，就回到了对「非共识」的正确理解上，这一点要求高</li>\n</ul>\n</li>\n</ul>\n<p>资产（asset）是未来能增值的，费用（cost）是会逐渐减值的，assert 和 cost 是可以进行转换的，怎么区分和转换 assert 以及 cost 是一个 ROI 很高的事情。</p>\n<p>写作可以帮助自己梳理想法, 相当于把下意识的东西暴露出来，让自己有可能做改变</p>\n<p>三者相辅相成</p>\n<p>如果对真实世界理解更深，那么一定能够活的更好，更自由。但是“真实世界理解更深”这个不是那么容易，而且需要是“真实”的，所以需要有验证 — 有验证有调整。</p>\n<ul>\n<li>起点重要，更重要的是速度，也就是斜率，</li>\n</ul>\n<p>每个人活的足够久，就能够发现“智慧”，但是“智慧”没法通过语言等传递，只能自己发现<br>要尊重常识，不要挑战常识，让自己尽可能做到“不败”</p>\n<p>正反馈很重要</p>\n<ul>\n<li>正反馈能帮助自己坚定的走一条路 — 如果在未得到足够正反馈的情况下，有人能推着走也是一种不错的，但是这种不能强求</li>\n<li>有正反馈，能够不断的调整，然后继续</li>\n</ul>\n<p>一定程度能区分 自己了解，和不了解 的东西，能跟多的说「我不知道」</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>求真，求善，求美</p>\n<ul>\n<li>求真：理解，接受 真实的世界</li>\n<li>求善：求善，可以让自己被善包围</li>\n<li>求美：求美，可以让自己被美包围</li>\n</ul>\n</blockquote>\n<p>理性想长远</p>\n<ul>\n<li>有一种情况，没个月，或者每个季度都是有增长的，但是从整年的维度看，是没有增长的</li>\n<li>这就是没有长远的指标看</li>\n</ul>\n<p>最终要回答一个问题：我是谁。最重要回到自己，其他的都是空的。但是怎么给自己定位，以及怎么做的更好，需要进行学习</p>\n<p>可视化很重要</p>\n<ul>\n<li>随着年龄的增长，我们会有各种习惯 — 用于加速我们处理，因此需要能够有一套流程增加新的流程替换到之前的流程，从而改变习惯<ul>\n<li>可以思考“XX，你帮我拿一下你旁边的杯子” 这句话，听到之后，自己是不是就会直接跳到“行动”，但是这句话会包括很多流程：<ul>\n<li>第一听到 XX 表示有人在叫你</li>\n<li>第二我们听到了“你帮我拿一下你旁边的杯子”  我们知道了需要“我”做一件事，这件事是“拿旁边的杯子”</li>\n<li>第三步在完全理解这句话的意思之后，我们需要指挥我们的手去拿到杯子，在这之前我们需要转动头并且通过眼睛找到杯子所在的地方</li>\n<li>第四步手伸到杯子的地方，然后拿起来交给我</li>\n<li>当然这些步骤由于我们做的太多了，导致已经信手拈来，不需要思考。可以观察一下刚学交流的小孩是怎么做这件事的<ul>\n<li>这个带出一个问题，不管是小孩还是大人，可能有些事情比我们想象中的要复杂，因为我们会了/熟悉了，但是对方没有。这个过程对方的整个行动就会显得“慢”，“不协调”等，但是这是一个必经的过程 — 可年龄无关，甚至和年龄是负相关，因为年龄越大越有一些其他的“习惯”可能阻碍当前的事情 — 这也是不太好改变的一个原因。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>不要变的更差</p>\n<ul>\n<li>我们在任何时候都处在某个 status</li>\n<li>我们每次决策/行动，可能会让我们所处的 status 变好/不变/变差</li>\n<li>每个人都会犯错（也就是都会变差等）</li>\n<li>不变差就变是减少犯错，从长远来看，这个犯错少，积累的就多<ul>\n<li>这个涉及到复利，复利就是在上次的基础上进行叠加</li>\n<li>犯错相当于回撤，也就是下一次的 base 变低</li>\n</ul>\n</li>\n</ul>\n<p>这个会导致有些变化会相对很慢（我们在分析公司有些事情的时候也需要考虑 — 公司不做改变，可能不是它不想做改变，而是没有更好的办法，然后这个事情也不是那么紧急，所以就先维持现状）。这个来自于我的一个想法：</p>\n<ul>\n<li>我想在团队内做一个改变（取消晨会），虽然我主持晨会，但是我想取消掉。但是一直没有实施，是因为我担心后面由于各种原因又需要再进行，导致来回的变动，我没有想清楚这个事情，所以就一直没有进行调整。</li>\n</ul>\n<p>慢就稳 ，稳就快</p>\n<p>觉得压力是因为想要的和实际的可能有冲突，焦虑是因为压力太多太大。但是我们只看到了表面上的焦虑/压力，没有看到实际情况下的冲突。如果想根本性的解决，就需要解决冲突。写作是一个相对比较好的手段，可以让我们看到冲突。</p>\n<p>长远的事情要从根本上解决，一次性解决问题，自己的事情要从根本上解决，但是对于工作来说不一定要完全一次性解决，一次性解决可能别人看不到你的功劳，可以捡重要的解决，然后自己能适当的放松，这样也能给其他人成长。</p>\n<p>AI 影响</p>\n<ul>\n<li>AI 相当于是一个很厉害的助手，但是不会帮助自己做行为改变（可能给一些指示），但是具体的改变还是关于自己内化的，所以 AI 是一个很厉害的，但也不会那么那么厉害，最后还是看自己</li>\n<li>AI 是用零壹这种表示，那么肯定有无法表达的（或者说电脑这种表达是稀疏的）</li>\n<li>AI 现在说的强化学习，听起来感觉像鸡娃，那么能否非常强就有待商榷</li>\n<li>但是上面的不是说 AI 不行，AI 就算没法到达顶尖，那么达到一定阶段，也能够解决很多问题</li>\n<li>所以 AI 一定会改变很多事情，但是 AI 有自己的上限，这个上限可能比很多人会更强（不管是否不是有幻觉），如果自己要想能够有一定的安全，那么要怎么办呢？</li>\n</ul>\n<p>AI 是一个聪明的人（记忆力强，然后有一定的关联能力 — 理解能力），但是“聪明真的重要吗？” </p>\n<ul>\n<li>聪明重要</li>\n<li>但更重要的是智慧</li>\n<li>而且 AI 是泛化的，统一的，人是特化的，有自己独特的个性，但是这样就需要找自己的特性了</li>\n</ul>\n<p>AI 可以会导致现在的流程发生变化</p>\n<ul>\n<li>需要接受并使用</li>\n<li>不要过于依赖（尽可能保留一些锻炼自己的方式）<ul>\n<li>如果仅接受 AI 的输出，然后自己做判断，那么时间久了，可能会导致判断力下降</li>\n</ul>\n</li>\n</ul>\n<p>工作、投资和写作</p>\n<p>工作是一定的反馈，也可以有收入，但是工作来说对于大部分人可能会限于“螺丝钉”角色，导致无法看到整个大的 picture<br>投资可以更好的理解世界运行，而且能够很好的进行验证 — 这里设计到真金白银的决策</p>\n<ul>\n<li>投资用反人性的决策，选择顺人性的投资标的</li>\n<li>投资标的：定价权，差异化竞争性能力。更多的是要想办法对投资标的了解的足够深入，这里面可能也涉及到产品/公司的权力构建</li>\n<li>投资没有想象中的难，回报在 5% - 10% 的还是有不少，也相对比较稳，但是想赚大钱，就需要下大注，下大注来自于对「非共识」的正确理解，所以对自己的要求也相对比较高，当然汇报也会相对比较好<ul>\n<li>没有想象中的难，跑赢十年期国债的稳定投资标的还是比较多的，但是这个不能保证跑赢 CPI + GDP</li>\n<li>换另外一个看法，GDP 是所有公司的营收平均值，然后有部分公司是上市了，那么找这些上市公司中营收前面的，一定是能跑赢 GDP 的，但是如果要赚大钱，就回到了对「非共识」的正确理解上，这一点要求高</li>\n</ul>\n</li>\n</ul>\n<p>资产（asset）是未来能增值的，费用（cost）是会逐渐减值的，assert 和 cost 是可以进行转换的，怎么区分和转换 assert 以及 cost 是一个 ROI 很高的事情。</p>\n<p>写作可以帮助自己梳理想法, 相当于把下意识的东西暴露出来，让自己有可能做改变</p>\n<p>三者相辅相成</p>\n<p>如果对真实世界理解更深，那么一定能够活的更好，更自由。但是“真实世界理解更深”这个不是那么容易，而且需要是“真实”的，所以需要有验证 — 有验证有调整。</p>\n<ul>\n<li>起点重要，更重要的是速度，也就是斜率，</li>\n</ul>\n<p>每个人活的足够久，就能够发现“智慧”，但是“智慧”没法通过语言等传递，只能自己发现<br>要尊重常识，不要挑战常识，让自己尽可能做到“不败”</p>\n<p>正反馈很重要</p>\n<ul>\n<li>正反馈能帮助自己坚定的走一条路 — 如果在未得到足够正反馈的情况下，有人能推着走也是一种不错的，但是这种不能强求</li>\n<li>有正反馈，能够不断的调整，然后继续</li>\n</ul>\n<p>一定程度能区分 自己了解，和不了解 的东西，能跟多的说「我不知道」</p>\n"},{"_content":"储能的现状，要求，前沿技术等等\n\n以及整个产业\n\nAI 算力等\n","source":"_drafts/chu-neng.md","raw":"储能的现状，要求，前沿技术等等\n\n以及整个产业\n\nAI 算力等\n","slug":"chu-neng","published":0,"date":"2026-01-15T08:38:32.159Z","updated":"2026-01-15T08:38:32.160Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cmkgc54p80004cjmk897qfg3n","content":"<p>储能的现状，要求，前沿技术等等</p>\n<p>以及整个产业</p>\n<p>AI 算力等</p>\n","site":{"data":{}},"excerpt":"","more":"<p>储能的现状，要求，前沿技术等等</p>\n<p>以及整个产业</p>\n<p>AI 算力等</p>\n"},{"title":"中国神华公司初步分析","date":"2026-01-18T02:23:32.000Z","toc":true,"_content":"\n> 中国神华的情况，数据主要以 2024 年年报为主\n\n# 股东以及相关关系\n\n整体的控股关系如下图所示\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151952893.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151953271.png)\n\n<!-- more -->\n\n# 业务基本情况\n\n公司包括多个部门，煤炭生产→煤炭运输 （铁路、 港口、 航运） →煤炭转化 （发\n电及煤化工）的一体化产业链，各分部之间存在业务往来，比如本公司的煤炭供给给发电部门，然后途中会使用本公司的铁路/航运等进行运行。\n\n其中按照 2024 年的情况，不同分部的营收毛利如下所示\n\n| 分行业 | 营业收入（百万）| 营业成本（百万) | 毛利率(%) | 营业收入比上年增减(%) | 营业成本比上年增减 (%) | 毛利率比上年增减(%)|\n| -- | -- | --  | -- |-- | -- | --|\n| 煤炭 | 268618 | 188066 | 30.0 | (1.7) | 1.2 | (2.0)|\n| 发电 | 94217 | 78832 | 16.3 | 2.0 | 2.7 | (0.6) |\n| 铁路 | 43115 | 26819 | 37.8 | 0.4 | (0.9) | 0.8 |\n| 港口 | 6842 | 4058 | 40.7 | 1.4 | 8.1 | (3.7) |\n| 航运 | 4996 | 4457 | 10.8 | 3.3 | (3.0) | 5.8 |\n| 煤化工 | 5633 | 5305 | 5.8 | (7.6) | (2.0) | (5.4) |\n\n可以看到其中煤炭占比最多，营业收入占 63.4%，发电占 22.25%，铁路占 10.18% 其他的占 5% 左右。\n\n公司不同分部之间也有交易，比如煤炭分部会卖煤给发电部门，同时会使用自己铁路分部的铁路进行运输等，\n\n20204 年的分部间交易如下\n\n| 分部业绩 | 煤炭 | 发电 | 铁路 | 港口 |\n| -- | -- | -- | --  | -- |\n| 对外交易收入 | 223753 | 94012 | 11120 | 1796 |\n| 分部间交易收入 | 44865 | 205 | 31995 | 5046 |\n\n可以看出来，煤炭供给给内部 16.7%(其中电力部门 16%，煤化工分部 0.7%)，外部占比 83.3% 主要还是销往外部；发电部门供给给内部占 0.2% 基本可以忽略，铁路部分供给给内部占 74.2% 外部占 25.8%，港口内部占 73.7% 外部占比 26.3%； 可以看出，煤炭、发电主要是供给外部，运输（铁路/港口）主要还是内部使用。\n\n## 煤炭\n> 煤炭行业来看，我国经济增长将持续拉动能源需求，煤炭作为全球最重要的能源来源之一， 尽管面临着可再生能源、 低碳发展和环保要求的多重挑战， 在可预见的未来市场中依旧扮演着关键角色。 预计电力和化工用煤是煤炭消费的主要增量来源。 煤炭产量预计总体保持稳定。进口煤价格优势缩小，进口煤量或小幅减少。总体来看，2025年煤炭市场供需向平衡偏宽松方向发展， 市场煤占比增加， 煤炭市场价格中枢或小幅下降，稳定在合理区间。受季节性波动、突发事件等因素影响，局部地区、部分时段可能出现供应偏紧的局面\n\n煤炭现在有两类销售：第一个是通过销售集团销售，主要是第一个，共有三种：年度长协，月度长协，以及现货；第二个就是煤矿坑口直接销售，整体占比 5% 以内。其中\n\n2024 年不同类型的销售情况如下\n\n| 类型 | 销售量(百万吨) | 占比 (%) | 价格(不含税) | \n| -- | -- | -- | -- |\n| 年度长协 | 246.4 | 53.6 | 491 |\n| 月度长协 | 154.8 | 33.7 | 705 |\n| 现货 | 36.2 | 7.9 | 627 |\n\n现在的煤炭包括自产煤，以及外购煤，成本包括：采掘成本，销售成本，运输成本，加工和管理，热值换算等成本。\n其中 2024 年的自产煤采掘成本是 179 元/吨，然后根据 [1] 预测的完全成本，中国神华（蒙西坑口到秦皇岛）完全成本是 640 元/吨左右（其中运费估算 250元/吨，陕西动力煤的运费成本在 200 元/吨左右，陕西动力煤的运输成本在 230 元/吨左右），由于中国神华的运输会使用自己的铁路/港口等，因此运费会更低一些，按照煤炭分部的运输成本计算，则平均运输成本 = 总平均运输成本/总销量 = 55180百万/459.3百万吨 = 120.13934248 元/吨，可见神华的平均运输成本比市场要便宜大几十/吨。\n\n其中热值换算，是因为中国煤的情况：北多南少，西多东少，然后从北方运往其他地方的时候，一般会用秦皇岛港口，所以市场往往会以秦皇岛 5500 大卡的价格计算，但是如果煤的热力值和 5500 不同，就需要进行换算\n\n煤炭的采掘量以及储量如下所示，2024 年产量 327.1 百万吨，销售 459.3 百万吨，对前五大外部煤炭客户销售量为 192.4 百万吨，占煤炭销售总量的 41.9%，其中对最大客户国家能源接团的煤炭销售为 164.9 百万吨，占煤炭销售总量的 35.9%，整体储量如下所示\n\n| 内外部客户 | 销售量(百万吨) | 占销售量比例 (%) | 价格(不含税) 元/ 吨 |\n| -- | -- | -- | -- |\n| 对外部客户销售 | 381.2| 83.0 | 573 |\n| 对内部发电分部销售 | 73.5 | 16.0 | 523 |\n| 对内部煤化工分部销售 | 4.6 | 1.0 | 424 |\n| 销售量合计/平均价格（不含税) | 459.3 | 100 | 564 |\n\n从这里看电力部分消耗内部煤炭 16%\n\n煤炭的保有量 343.6 亿吨，较上一年增加 17.8 亿吨，煤炭保有可采储量 150.9 亿吨，较上一年增加 17.1 亿吨；JORC 标准下本集团的煤炭可售储量为 105.1 亿吨，较上一年增加 10.3 亿吨，不同矿区的保有量，以及相关信息如下\n\n| 矿区 | 保有资源量（中国标准）| 保有可采储量（中国标准） |证实储量（中国标准）|可信储量（中国标准）|煤炭可售储量（JORC标准）|主要煤种|主要商品煤的发热量（千克/千克) | 硫分(%) | 灰分(%) | \n| -- | -- | -- | -- | -- | -- | -- | -- | --|\n| 神东矿区 |158.0 | 89.7 | 18.7 | 36.6 | 65.4 | 长焰煤/不粘煤 | 4720-5730 | 0.2-0.6 | 8.4-19.4|\n| 新街台格庙矿区 | 110.1 | 14.0 | 6.2 | 4.5 | 9.4 | - | - | - | - |\n| 准格尔矿区 | 40.3 | 29.2 | 8.9 | 9.7 | 21.3 | 长焰煤 | 4409 -4744 | 0.4-0.6 | 25.0-29.8|\n| 胜利矿区 | 22.3 | 10.2 | 2.2 | 5.4 | 1.9 | 褐煤 | 2980 | 1.1 | 23.8 |\n| 宝日希勒矿区 | 12.5 | 7.5 | 1.4 | 4.2 | 7.0 | 褐煤 | 3551 | 0.2 | 13.9 |\n| 包头矿区 | 0.4 | 0.3 | 0.1 | 0.0 | 0.1 | 长焰煤/不粘煤 | 4073-4399 | 0.5-1.0 | 14.1 -18.3 |\n\n\n## 电力\n\n> 电力行业来看，综合考虑我国目前阶段经济增长潜力、“十四五”规划和国家宏观调控政策措施等因素，根据中国电力企业联合会预测结果，预计 2025 年全国全社会用电量同比增长 6%左右。新能源装机持续增长，部分地区新能源消纳压力凸显。预计2025 年底煤电占总装机比重将降至三分之一。综合考虑电力消费需求增长、电源投产等情况，预计 2025 年迎峰度夏等用电高峰期部分地区电力供需形势紧平衡\n\n全年总售电量 210.28 十亿千瓦时，占同期占社会用电量 98521 亿千瓦时的 2.1%， 其中市场交易电量达 205.20 十亿千瓦时，占总售电量的 97.6%；平均售电价格 403元/兆瓦时（2023 年 414 元/兆瓦时），本集团享有获取容量电费资格的国内煤电机组共 68 台，约占本集团国内煤电机组总数的 94%，2024 年共获取容量电费约 50 亿元（含税）。\n\n本集团火电供电标准煤耗降至 292.9 可/千瓦时（2023 年 294.9 克/千瓦时）\n\n本集团加大可再生能源项目开发和产业基金投资。本集团充分利用露天矿排土场、复垦区、铁路沿线闲置用地等土地资源投资建设光伏项目，2024 年新增对外商业运营的光伏发电装机容量合计 366 兆瓦。\n\n本集团发电机组总装机容量 46264 兆瓦，其中燃煤发电机组总装机容量 43184 兆瓦，约占全国煤电发电装机容量 11.9 亿千瓦的 3.6%。\n\n不同类型的电源情况如下所示\n\n| 电源种类 | 2024 年 12 月 31 日总装机容量 | 2023 年 12 月 31 日 总装机容量 | 新增 |\n| -- | -- | -- | -- |\n| 燃煤发电 | 43184 | 43164 | 20 |\n| 燃气发电 | 2194 | 950 | 1244 |\n| 水电 | 125 | 125 | 0 |\n| 光伏发电 | 761 | 395 | 366 |\n| 合计 | 46264 | 44634 | 1630 |\n\n\n本集团燃煤发电机组平均利用小时达 5030 小时，同比减少 191 小时，比全国 6000 千瓦及以上的电厂燃煤发电设备平均利用小时数 4628 小时高 402 小时，利用小时比平均高，表示有一定的调度优先级（后续可以持续观察利用小时数于平均利用小时数的相对情况）。另外2024 年整体的「6000 千瓦及以上电厂发电设备利用小时」 3442（全年累计），同比减少 157 小时，全国线路损失率 4.37%，同比减少 0.17%\n\n本集团具体发电利用小时如下\n\n| 电源种类  | 平均利用小时(2024) | 平均利用小时(2023) | 变动 (%) | 发电厂用电率(%)(2024) | 发电厂用电率(203) | 变动 |\n| -- | -- | -- | -- | -- | -- |--|\n| 燃煤发电(含矸石电厂) | 5030 | 5221 | (3.7) | 5.07 | 5.20 | 下降 0.13 个百分点|\n| 燃气发电 | 4151 | 4152 | (0.0) | 1.66 | 1.56 | 上升 0.10 个百分点 |\n| 水电 | 5097 | 5228 | (2.5) | 0.63 | 0.28 | 上升 0.35 个百分点 |\n| 光伏发电 | 1317 | 905 | 45.5 | 1.03 | / | / |\n| 加权平均 | 4960 | 5167 | (4.0) | 4.98 | 5.11 | 下降 0.13 个百分点 |\n\n\n电力市场化交易 \n\n| 项目 | 2024 | 2023 | 变动 (%) |\n| -- | -- | -- | -- |\n| 市场化交易的总电量(十亿千瓦时) | 205.2 | 194.56 | 5.5 |\n| 总上网电量（十亿千瓦时) | 210.28 | 199.75 | 5.3 |\n| 市场化交易电量占比 (%) | 97.6 | 97.4 | 上升 0.2 个百分点|\n\n2024 年 发电分部共耗本集团内部销售的煤炭（包括本集团自产煤和采购没）73.6 百万吨（2023 年 73.2 百万吨) 同比增长 0.5%，发电分部耗用本集团内部销售的煤炭量占发电分部耗煤总量 96.5 百万吨的 76.3%，消耗煤炭的绝大部分已经从内部供给。\n\n## 铁路\n\n铁路分部紧密服务一体化运营和产业链发展，进一步拓展”大一体化”优势，建立高效协同的运输生产生态系统，本集团2024 年自由铁路运输周转量达 312.1 十亿吨公里（2023 年：309.4 十亿吨公里），同比增长 0.9%。  神朔铁路 3 亿吨扩能改造工程有序推进，成功研制出氢能源动力调车机车和氢能源动力接触网作业车等核心装备。巴准铁路暖水集运站铁路专用线、三道渠铁路专用线顺利开通，设计装车能力 2000 万吨/年。\n\n2024 年，本集团完成金属矿石、化工品等非煤货物运量 24.5 百万吨（2023 年：22.3 百万吨），同比增长 9.9%，其中反向非煤货物运输 18.8 百万吨。\n\n营业情况\n\n| 项目 | 2024 | 2023 | 变动(%) | 主要变动原因 |\n| -- | -- | -- | -- | -- |\n| 营业收入(百万) | 43115 | 42961 | 0.4 | 自有铁路运输周转量增长 |\n| 营业成本(百万) | 26819 | 27059 | (0.9) | 受检修计划影响，修理费同比减少 |\n| 毛利率(%) | 37.8 | 37.0 | 上升 0.8 个百分点 | |\n| 利润总额(百万) | 12562 | 11039 | 13.8 | 资产减值损失同比减少 |\n\n2024 年，铁路分部单位运输成本为 0.081 元/吨公里（2023 年：0.085 元/吨公里），同比下降 4.7%，主要原因是受检修计划影响，修理费同比减少\n\n## 港口\n\n本集团港口分部深化内外协同合作，完善港航协同联动机制，精简装卸流程，报销组织生产。2024 年，黄骅港完成装船量 214.4 百万吨（2023:209.5 百万吨），同比增长 2.3%，连续 6 年位居“北煤南运”港口首位，散杂货吞吐量完成 8.2 百万吨，创开港以来最好水平。天津煤码头完成装船量 44.0 百万吨（2023 年：45.8 百万吨），同比下降 3.9%。\n\n加快推进多功能、综合性、现代化港口建设。黄骅港（煤炭港区）五期工程（规划煤炭下水量 5,000 万吨/年）、天津港务二期工程（设计年通过能力煤炭 3,500 万吨、矿石 1,800 万吨）获得核准批复；黄骅港（煤炭港区）油品码头工程、珠海港高栏港区国能散货码头工程开工建设；珠海港务 2 号、3 号卸船泊位升级，满足 15 万吨级船舶满载通航条件\n\n黄骅港构建覆盖煤港生产全过程的长效抑尘系统、生态环境智能管控系统及“两湖三湿地”生态水循环系统，抑尘率达到 98%，年节约淡水 400 万立方米以上；\n\n经营成果\n\n| 项目 | 2024 | 2023 | 变动(%)| 主要变动原因 |\n| -- | -- | -- | -- | -- |\n| 营业收入(百万) | 6842 | 6749 | 1.4 | 港口装船量增长 |\n| 营业成本(百万) | 4058 | 3754 | 8.1  | 航道疏浚费等增长；港口装船量增长 |\n| 毛利率(%) | 40.7 | 44.4  | 下降 3.7 个百分点 | |\n| 利润总额(百万) | 2122 | 2301 | (7.8) | |\n\n2024 年港口分部单位运输成本为 13.1 元/吨（2023 年：12.5 元/吨），同比增长 4.8%，主要原因是航道疏浚费等增长。\n\n## 航运\n\n2024 年完成航运货运量 129.9 百万吨（2023年：152.9百万吨），同比下降 15%，完成航运周转量 149.4 十亿吨海里（2023年：164.7十亿吨海里），同比下降 9.3%，完成非煤运输量 4.4 百万吨（2023 年：3.7 百万吨），同比增长 18.9%\n\n经营成果\n\n| 项目 | 2024 | 2023 | 变动(%)| 主要变动原因 |\n| -- | -- | -- | -- | -- |\n| 营业收入(百万) | 4996 | 4836 | 3.3 | 平均海运价格增长 |\n| 营业成本(百万) | 4457 | 4594 | (3.0)  | 业务结构调整导致航运周转量下降 |\n| 毛利率(%) | 10.8 | 5.0  | 下降 5.8 个百分点 | |\n| 利润总额(百万) | 260 | 100 | 160.0 | |\n\n2024 年航运分部单位运输成本为 0.030 元/吨海里（2023 年：0.028 元/吨海里），同比增长 7.1%，主要原因是航运周转量下降。从数字上看 运输总量少了，利润多了。\n\n## 煤化工\n\n本集团煤化工分部为包头煤化工煤制烯烃项目，主要产品包括聚乙烯（生产能力约 30万吨/年），聚丙烯（生产能力约 30万吨/年）及少量副产品（包括工业硫磺、混合碳五、工业丙烷、混合碳四、工业用甲醇、精甲醇等）。2024 年，包头煤化工煤制烯烃升级示范项目（生产能力 75万吨/年）建设有序推进。\n\n| 物品 | 2024 销售量(千吨) | 2024 价格(元/吨) | 2023 销售量(千吨) | 2023 价格（元/吨) | 销售量变动(%) | 价格变动(%) |\n| -- | -- | -- | -- | -- | -- | -- |\n| 聚乙烯 | 332.2 | 6645 | 364.4 | 6446 | (8.8) | 3.1 |\n| 聚丙烯 | 313.6 | 5896 | 341.5 | 5908 | (8.2) | (0.2) |\n\n经营成果\n\n| 项目 | 2024 | 2023 | 变动(%)| 主要变动原因 |\n| -- | -- | -- | -- | -- |\n| 营业收入(百万) | 5633 | 6098 | (7.6) | 煤制烯烃生产设备按计划检修，聚烯烃产品产量及销量下降 |\n| 营业成本(百万) | 5305 | 5412 | (2.0)  | 同上 |\n| 毛利率(%) | 5.8 | 11.2  | 下降 5.4 个百分点 | |\n| 利润总额(百万) | 37 | 190 | (80.5)| |\n\n2024 年，煤化工部共耗煤 4.6 百万吨（2023 年 4.9 百万吨），同步下降 6.1%,全部本集团内销售的煤炭（包括资产和采购）\n\n## 煤电结合\n\n公司本身有煤，也有火电，因此会有内部销售的情况，2024 年，发电分部共耗用本集团内部销售的煤炭（包括本集团自产煤和采购煤）73.6 百万吨（2023 年：73.2 百万吨），同比增长 0.5%。发电分部耗用本集团内部销售的煤炭量占发电分部耗煤总量 96.5 百万吨的 76.3%。  由于使用内部煤炭进行发电，在煤价波动或者电价波动的时候，可以有一定的缓冲。\n\n另外内部电厂和煤矿具体较近，因此运费成本也相对较低，自己的铁路运输自己的煤炭，整体的成本也更低。这里可能有几个原因：1）使用自有的运输路线，2）部分电厂和煤矿相对比较近。\n\n从年报中可知，煤矿和电厂的分布如下\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142515.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142515.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142704.png)\n\n\n运输成本如下所示\n> 其中自有成本包括铁路和港口，航运暂时没找到，这里计算的成本较实际可能偏高，由于航运整体的收入和成本不大，所以暂时不做进一步细化\n\n| 项目 | 2024 | 2023 | 2022 | 2021  | 2020 |\n| -- | -- | -- | -- | -- | -- | \n| 运输成本 | 55180(100%) | 52236(100%) | 50094(100%) | 58027(100%) | 51557(100%) | \n| 自有成本* | 37041(67.12%) | 34681(66.39%) | 33226(66.32%) | 39319(67.75%) | 38304(74.29%) |\n| 外部成本 | 18139(32.87%) | 17555(33.60%) | 16868(33.67%) | 18708(32.24%) | 13253(25.70%) |\n\n可以看到，自有运输成本占 66% 以上，这部分在成本计算的时候会按照市价进行计算，但是实际不需要花这么多钱，仅需要花费运输路线的成本即可，因此整体的运输成本相对较低。 粗略估算整体的运输成本比其他公司要少 66% * (37% -- 铁路的毛利率) ~ 24% 也就是卖同样的煤，单位运输成本可能会减少 20% 左右，这部分会成为整个公司的利润。\n\n接下来可以对比自产煤的利润率和外购煤的利润率，如下所示\n> 由于 2022 年以前，年报暂无外购煤和自产煤相关详细数据 -- 2021 年报描述公司暂无法区分自产煤和外购煤相关数据，因此暂不纳入计算\n\n| 项目 | 2024 | 2023 | 2022 | \n| -- | -- | -- | -- | -- | -- | \n| 自产煤（销售量） | 327 | 325.4 | 316.2 | \n| 外购煤（销售量） | 132 | 124.6 | 101.6 |\n| 自产煤（销售收入) | 172442 | 178242 | 188818 | \n| 外购煤（销售收入) | 86373 | 84626 | 80178 | \n| 自产煤（销售成本) | 95642 | 95250 | 93150 |\n| 外购煤（销售收入) | 86373 | 84626 | 80178 |\n| 外购煤（销售成本) | 84797 | 82617 | 77627 | \n| 自产煤（毛利率) | 44.5% | 46.6% | 50.7% |\n| 外购煤（毛利率） | 1.8% | 2.4% | 3.2% |\n\n可以看到自产煤的毛利率远大于外购煤的毛利率，另外这部分既然不赚钱，为啥还要做生意呢？或许是为了维持运输线路，运输路线只要能同正常流转就能够赚钱（运输自己的煤可以减少开支，运输其他公司物品可以赚利润）\n\n\n从发电分部来说，现在有两个政策对火电相对较好：1）容量电价[2]；2）电价浮动[3]。第一个是说只要保证有相关的能力，就能有一定的收入（不管是否发电） -- 但是需要电的时候要能保证提供，否则会扣费，甚至取消相关资格；第二个是电价会按市场需要波动，低峰更便宜，高峰更贵。\n\n由于公司内部有煤，有电，然后有容量电价，以及电价的浮动，那么在煤炭价格进行波动的时候，可以内部进行一定的缓冲，比如煤炭价格下跌的时候，可以适当的给内部发电部门供应更多的煤炭（这个有上限），然后发电分部可以通过多发电（甚至在高峰期多发电 -- 这个查看调度优先级），这样可以把一部分由于煤炭降价导致收入转移到电力下游，一定程度的对冲价格的波动，整体的收入和利润会更平衡一些。后文我们会对具体的波动数值进行一个推演。\n\n这里可以分为 \n\n| 项目 | 煤炭上涨 |煤价不变 | 煤炭下跌|\n| -- | -- | -- |\n| 电价上涨 | (1) | (2) | (3) |\n| 电价不变 | (4) | (5) | (6) |\n| 电价下跌 | (7) | (8) | (9) |\n\n这里我们需要重点关注的是 (9) 这个位置，也就是煤价和电价都下跌的情况，后续我们会对这个进行一些具体的推演\n\n# 经营情况\n## 现金流量以及分红\n\n公司业务挣的钱，可能会有一些资本开支，也可能会有分红，接下来我们看看业务收入，以及现金流量净额的流向如何\n\n2024 年经营活动产生的现金流净额 93348 百万，「购建固定资产、无形资产和其他长期资产支付的现金」是 37032 百万，两者剩余 56316 百万，预计分红 44903 百万，占净利润的 76.5%（2023 年 75.2%），可以看到现金流量是足够分红支出的。另外公司承诺 25-27 年承诺每年以现金方式分配的利润不少于本公司当年实现的归属本公司股东净利润的 65%，实际最近 3 年都高于 70%(2024 年 76.5%， 2023 年 75.2%，2022 年 72.8%)。 2022 - 2024 的三年股东回报规划，承诺以现金方式分配的利润不少于公司当年实现归母净利的 60%，\n\n公司 24 年经营现金流和 固定资产、无形资产等支持，分红的情况如下所示（单位百万）\n\n| 项目 | 2024 | 2023 | 2022 | 2021 | 2020|\n| -- | -- | -- | -- | -- | -- |\n| 经营活动产生的现金流量净额 | 93348 | 89687 | 109734 | 94575 | 81289 |\n| 购建固定资产、无形资产和其他长期资产支付的现金 | 37032(39.67%) |  37084(41.34%) | 28684(26.13%) | 23863(25.23%) | 20673(25.43%) |\n| 分红 | 44903(48.10%) | 44903(50.06%) | 50665(46.17%) | 50466(53.36%) | 35962(44.23%) |\n| 剩余 | 11413(12.22%) | 7700(8.58%) | 30385(27.68%) | 20246(21.40%) | 24654(30.32%) |\n\n可以从上表看出，经营活动的现金流净额减去固定资产、无形资产的投资后，是足够分红的（也就是「剩余」一栏都是正数），可见公司是有钱分红的。 从年报可以分析 2023 年「购建固定资产、无形资产和其他长期资产支付的现金」增加是因为有发电厂投产，2024 年「购建固定资产、无形资产和其他长期资产支付的现金」增加是因为在建工程的投入更多，后续可以持续观察看看，这部分看是否会有大幅度的投入。\n\n## 合同负债和应收款\n\n我们来看看公司的合同负债，以及应收账款，这两部分表示公司已经收到下游的钱还未交付，或者已经交付还未收到钱。一定程度可以看出公司的议价权。\n\n| 项目 | 2024 | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 合同负债 | 4045 | 7208 | 5597 | 6864 | 5256 |\n| 应收账款 | 12466 | 11875 |  10968 | 10258 | 7798 |\n\n可以看到公司既有合同负债，又有应收账款，然后查看应收账款的相应情况如下\n\n按性质分\n\n| 项目 | 2024  | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 售电款 | 7869 | 7539 | 6475 | 4480 | 3619 | \n| 售煤款 | 2182 | 2003 | 1802 | 3380 | 1982 |\n| 售热款 | 267 | 319 | 280 | 217 | 262 |\n| 其他 | 3292 | 3209 | 3632 | 3458 | 3234 |\n\n按账龄分析\n\n| 账龄 | 2024 | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 1 年以内 | 12125(89%) | 11497(87%) | 10646(87%) | 9648(84%) | 7009(78%) |\n| 1-2 年 | 182(1%) | 253(2%)| 165(1%) | 155(1%) | 131(1%) |\n| 2-3 年 | 136(1%) | 56(1%) | 30(1%) | 87(1%) | 93(1%) |\n| > 3年 | 1167(9%) | 1264(10%) | 1348(11%) | 1645(14%) | 1864(20%) |\n\n应收账款金额前五的单位\n\n- 2024 ![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151023782.png)\n- 2023 ![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115102144.png)\n- 2022 ![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115102413.png)\n- 2021  ![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151018170.png)\n- 2020 ![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115101901.png)\n\n可以看到应收账款主要在「售电」，主要是电力公司，主要在一年以内，这个应该是和结算周期有关，可以推测煤炭分部有一定的合同负债，从这个来看，相对来说煤炭分部有一定的议价权\n\n接下来我们单独看煤炭分部的应收账款于营业收入的比值，一定程度看议价能力的变动，如果「应收账款」/「营业收入」变大，表示议价能力变弱，否则变高\n\n| 项目 | 2024 | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 应收账款 | 2182 | 2003 | 1802 | 3380 | 1982 |\n| 营业收入 | 268618 | 273306 | 277474 | 292661 | 292661 |\n| 比值 |  0.81% | 0.73% | 0.64% | 1.15% | 0.67% |\n\n可以看出来 2021 年的比值超过 1%，其他几年都低于 1%。搜了下，发现 2021 年刚好是煤炭价格下跌的一年，这个能对应上，煤炭下跌，行情不好，应收账款变的更多了。\n\n## 和煤炭公司，电力公司的部分对比\n\n中国神华在于煤电、运输等一体化运营，我们也来对比下和煤炭公司、电力公司在不同指标上的情况，有一个直观的对比和了解。我们选择 毛利率、ROE 以及资产负债率这三个指标，其中毛利率表示生意模式是否优秀，ROE 表示资产回报率，资产负债率则表示抗极限风险的能力。\n\n毛利率\n\n|   公司       | 2016 | 2017 | 2018 | 2019 | 2020 | 2021 | 2022 | 2023 | 2024 |\n| -- | --  | -- | -- | -- | -- | -- | -- | -- | -- |\n| 陕西煤业 | 43.39 | 55.40 | 48.69 | 40.93 | 27.46 | 35.84 | 44.99 | 37.86 | 32.69|\n| 华能国际 | 21.43 | 11.31 | 11.30 | 12.5 | 14.5 | 17.4 | -0.33 | 3.04 | 12.11|\n| 中国神华 | 39.5 | 42.1 | 41.1 | 36.7 | 36.4 | 32.9 | 39.03 | 35.89 | 34.04 |\n\nROE\n\n| 公司 | 2021 | 2022 | 2023 | 2024 |\n| -- | -- | -- | -- | -- |\n| 陕西煤业 | 24.03 | 33.3 | 20.64 | 21.32 |\n| 华能国际 | -10.29 | -8.92 | 4.28 | 5.14 |\n| 中国神华 | 13.82 | 18.77 | 15.99 | 14.97 |\n\n资产负债率\n\n| 公司 | 2020 | 2021 | 2022 | 2023 | 2024 |\n| -- | -- | -- | -- | -- | -- |\n| 陕西煤业 | 39.78%  | 60.82% | 60.19% | 62.99% | 63.35% |\n| 华能国际 | 67.71% | 74.68% | 74.82% | 68.33% | 65.40% |\n| 中国神华 | 23.9% | 26.6% |26.1% | 24.1% | 23.4% |\n\n\n对于 ROE 这一项，我们可以再继续进行细分，查看「销售净利率」、「资产周转率」以及「权益系数」的相关数值，其中「销售净利率」表示赚钱多狠，资产周转率表示公司跑的多块，权益系数表示杠杆有多高\n\n销售净利率\n\n| 公司 | 2024 | 2023 | 2022 | 2021 | 2020|\n| -- | -- | -- | -- | -- | -- |\n| 神华 | 17.3 | 17.3 | 20.2 | 14.9 | 16.7 |\n| 陕西煤业 | 12.14 | 6.2 | 21 | 14 | 15.6 |\n\n资产周转率\n\n| 公司 | 2024 | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 神华 | 52.53 | 54.80 | 56.08 | 57.52 | 41.76 |\n| 陕西煤业 | 79.28 | 72.99 | 79.91 | 91.02 | 68.5 |\n\n\n权益乘数\n> 使用公式 = 1/ (1 - 资产负债率)\n\n| 公司 | 2024 | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 神华 | 1.3 | 1.31 | 1.35 | 1.36 | 1.31 |\n| 陕西煤业 | 2.7 | 2.7 | 2.51 | 2.55 |  2.51 |\n\n\n可以从上面的图表中看到，神华和陕西煤业比较，销售净利率相对还是比较好的，资产周转率不如，，然后杠杆率比较低。其中对于杠杆率来说，虽然可能借到很便宜的钱，杠杆可以放大收益，但是在行情不好的时候，风险也会被放大，因此这个也变相的体现抗风险能力\n\n# 风险\n对于神华来说，针对不同的业务，会有不同的风险，比如\n- 对于煤炭生意来说：1）最大的风险在于新能源的推广，这块由于现在储能上还不太能跟上，因此煤炭作为资源压舱石还一直在使用，但是未来如果储能有重大进展的话，则新能源可能会大幅替代火电；2）是否可能对煤炭企业或者火电企业收取「碳」相关的税，从而促进能源转型；3）作为国企，在煤炭涨价的时候，是否需要承受更多的社会责任，对本公司的利益是否有影响。\n- 对于电力生意来说：1）火电是否会被新能源发电去掉；2）现在的电价方式是否会发生变化\n- 对于铁路来说：如果不需要允许这么多煤，那么能否比较快速的转运其他非煤物品\n\n我们可以知道这些都和火电有关，那么我们通过国家能源官网[4]的装机信息来看，不同类系发电的装机情况，火电的装机情况暂时还行，斜率是往上的\n\n\n2025 全国不同类型装机容量新增数，可以用 (1-3) - (1-2) 获得 3 月新增\n\n| 项目(万千瓦) | 1-2 | 1-3月 | 1-4 月 | 1-5 | 1-6 | 1-7 | 1-8 | 1-9 | 1-10 | 1-11 |\n| -- | -- |-- | -- | -- | -- | -- | -- | -- | -- | -- |\n| 水电 | 191 | 213 | 265 | 325 | 393 |589 | 684 | 716 | 835 | 912 |\n| 火电 | 388 | 925 | 1298 | 1755 | 2578 | 4198 | 4987 | 5668 | 6508 | 7752 |\n| 核电 | 0 | 0 | 0 | 0 |  0 | 0 | 0| 0 | 153 | 153 |\n| 风电 | 928 | 1462 | 1996 | 4628 | 5139 | 5367 | 5784 | 6109 | 7001 | 8250 |\n| 太阳能发电 | 3947 | 5971 | 10493 | 19785 | 21221 | 22325 | 23061 | 24027 | 25287 | 27489 |\n\n相关图形如下所示（可以观察斜率表示增长率）\n\n{% echarts 85% 400 %}\noption = {\n  title: {\n    text: '新增装机量'\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  legend: {\n    data: ['水电', '火电', '核电', '风电', '太阳能']\n  },\n  grid: {\n    left: '3%',\n    right: '4%',\n    bottom: '3%',\n    containLabel: true\n  },\n  toolbox: {\n    feature: {\n      saveAsImage: {}\n    }\n  },\n  xAxis: {\n    type: 'category',\n    boundaryGap: false,\n    data: ['2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n  },\n  yAxis: {\n    type: 'value'\n  },\n  series: [\n    {\n      name: '水电',\n      type: 'line',\n\n      data: [191, 213, 265, 325, 393, 589, 684, 716, 835, 912]\n    },\n    {\n      name: '火电',\n      type: 'line',\n\n      data: [388, 925, 1298, 1755, 2578, 4198, 4987, 5668, 6500, 7752]\n    },\n    {\n      name: '核电',\n      type: 'line',\n\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 153, 153]\n    },\n    {\n      name: '风电',\n      type: 'line',\n\n      data: [928, 1462, 1996, 4628, 5139, 5367, 5784, 6109, 7001, 8250]\n    },\n    {\n      name: '太阳能',\n      type: 'line',\n\n      data: [3947, 5971, 10493, 19785, 21221, 22325, 23061, 24027, 25287, 27489]\n    }\n  ]\n};\n{% endecharts %}\n\n\n# 神华自己的价值\n\n首先我们对神华进行公司的价值估算，这样可以和现在的市值进行比较。我们根据不同业务的综合进行估值\n\n- 其中煤炭现在保有量 343.6 亿吨，按照现在均价 584 元/吨，总价在 20 万亿。如果按照 300 百万吨一年的销量，大概一年营收 1755 亿，然后按照 5% 左右的折旧率，以及计算 50 年的话，大概总价值 3万亿，按照 30% 的利润率，则总价在在 1万亿左右。\n- 现在铁路总共 2408 公里，按照修建铁路 1 公里的成本大约在 1.5 亿左右，就算不再使用，也可以进行售卖，这块的价值 3600 亿左右\n- 电厂的价值估算，现在总共有 4万兆瓦的装机容量，目前新建的成本大概在 3500 元/千瓦，则重估的价值等于 1400 亿\n- 另外还有港口和航运等这些资产\n\n可以发现整个神华的资产是肯定超过现在的市值 8300 亿的。因此现在的市值是相对比较便宜的。\n\n\n# Ref\n[1] 华源证券 煤炭行业中期策略报告 (2025.06.27)\n[2] https://www.ndrc.gov.cn/xxgk/zcfb/tz/202311/t20231110_1361897.html\n[3] https://www.ndrc.gov.cn/xxgk/zcfb/tz/202110/t20211012_1299461.html\n[4] https://www.nea.gov.cn/20251026/70d3b88f62f1401bbe47a8212e06ad8e/c.html\n","source":"_posts/601088-company-ana.md","raw":"---\ntitle: 中国神华公司初步分析\ndate: 2026-01-18 10:23:32\ntags:\n    - investment\n    - 601088\n    - company-analysis\n\ntoc: true\n---\n\n> 中国神华的情况，数据主要以 2024 年年报为主\n\n# 股东以及相关关系\n\n整体的控股关系如下图所示\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151952893.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151953271.png)\n\n<!-- more -->\n\n# 业务基本情况\n\n公司包括多个部门，煤炭生产→煤炭运输 （铁路、 港口、 航运） →煤炭转化 （发\n电及煤化工）的一体化产业链，各分部之间存在业务往来，比如本公司的煤炭供给给发电部门，然后途中会使用本公司的铁路/航运等进行运行。\n\n其中按照 2024 年的情况，不同分部的营收毛利如下所示\n\n| 分行业 | 营业收入（百万）| 营业成本（百万) | 毛利率(%) | 营业收入比上年增减(%) | 营业成本比上年增减 (%) | 毛利率比上年增减(%)|\n| -- | -- | --  | -- |-- | -- | --|\n| 煤炭 | 268618 | 188066 | 30.0 | (1.7) | 1.2 | (2.0)|\n| 发电 | 94217 | 78832 | 16.3 | 2.0 | 2.7 | (0.6) |\n| 铁路 | 43115 | 26819 | 37.8 | 0.4 | (0.9) | 0.8 |\n| 港口 | 6842 | 4058 | 40.7 | 1.4 | 8.1 | (3.7) |\n| 航运 | 4996 | 4457 | 10.8 | 3.3 | (3.0) | 5.8 |\n| 煤化工 | 5633 | 5305 | 5.8 | (7.6) | (2.0) | (5.4) |\n\n可以看到其中煤炭占比最多，营业收入占 63.4%，发电占 22.25%，铁路占 10.18% 其他的占 5% 左右。\n\n公司不同分部之间也有交易，比如煤炭分部会卖煤给发电部门，同时会使用自己铁路分部的铁路进行运输等，\n\n20204 年的分部间交易如下\n\n| 分部业绩 | 煤炭 | 发电 | 铁路 | 港口 |\n| -- | -- | -- | --  | -- |\n| 对外交易收入 | 223753 | 94012 | 11120 | 1796 |\n| 分部间交易收入 | 44865 | 205 | 31995 | 5046 |\n\n可以看出来，煤炭供给给内部 16.7%(其中电力部门 16%，煤化工分部 0.7%)，外部占比 83.3% 主要还是销往外部；发电部门供给给内部占 0.2% 基本可以忽略，铁路部分供给给内部占 74.2% 外部占 25.8%，港口内部占 73.7% 外部占比 26.3%； 可以看出，煤炭、发电主要是供给外部，运输（铁路/港口）主要还是内部使用。\n\n## 煤炭\n> 煤炭行业来看，我国经济增长将持续拉动能源需求，煤炭作为全球最重要的能源来源之一， 尽管面临着可再生能源、 低碳发展和环保要求的多重挑战， 在可预见的未来市场中依旧扮演着关键角色。 预计电力和化工用煤是煤炭消费的主要增量来源。 煤炭产量预计总体保持稳定。进口煤价格优势缩小，进口煤量或小幅减少。总体来看，2025年煤炭市场供需向平衡偏宽松方向发展， 市场煤占比增加， 煤炭市场价格中枢或小幅下降，稳定在合理区间。受季节性波动、突发事件等因素影响，局部地区、部分时段可能出现供应偏紧的局面\n\n煤炭现在有两类销售：第一个是通过销售集团销售，主要是第一个，共有三种：年度长协，月度长协，以及现货；第二个就是煤矿坑口直接销售，整体占比 5% 以内。其中\n\n2024 年不同类型的销售情况如下\n\n| 类型 | 销售量(百万吨) | 占比 (%) | 价格(不含税) | \n| -- | -- | -- | -- |\n| 年度长协 | 246.4 | 53.6 | 491 |\n| 月度长协 | 154.8 | 33.7 | 705 |\n| 现货 | 36.2 | 7.9 | 627 |\n\n现在的煤炭包括自产煤，以及外购煤，成本包括：采掘成本，销售成本，运输成本，加工和管理，热值换算等成本。\n其中 2024 年的自产煤采掘成本是 179 元/吨，然后根据 [1] 预测的完全成本，中国神华（蒙西坑口到秦皇岛）完全成本是 640 元/吨左右（其中运费估算 250元/吨，陕西动力煤的运费成本在 200 元/吨左右，陕西动力煤的运输成本在 230 元/吨左右），由于中国神华的运输会使用自己的铁路/港口等，因此运费会更低一些，按照煤炭分部的运输成本计算，则平均运输成本 = 总平均运输成本/总销量 = 55180百万/459.3百万吨 = 120.13934248 元/吨，可见神华的平均运输成本比市场要便宜大几十/吨。\n\n其中热值换算，是因为中国煤的情况：北多南少，西多东少，然后从北方运往其他地方的时候，一般会用秦皇岛港口，所以市场往往会以秦皇岛 5500 大卡的价格计算，但是如果煤的热力值和 5500 不同，就需要进行换算\n\n煤炭的采掘量以及储量如下所示，2024 年产量 327.1 百万吨，销售 459.3 百万吨，对前五大外部煤炭客户销售量为 192.4 百万吨，占煤炭销售总量的 41.9%，其中对最大客户国家能源接团的煤炭销售为 164.9 百万吨，占煤炭销售总量的 35.9%，整体储量如下所示\n\n| 内外部客户 | 销售量(百万吨) | 占销售量比例 (%) | 价格(不含税) 元/ 吨 |\n| -- | -- | -- | -- |\n| 对外部客户销售 | 381.2| 83.0 | 573 |\n| 对内部发电分部销售 | 73.5 | 16.0 | 523 |\n| 对内部煤化工分部销售 | 4.6 | 1.0 | 424 |\n| 销售量合计/平均价格（不含税) | 459.3 | 100 | 564 |\n\n从这里看电力部分消耗内部煤炭 16%\n\n煤炭的保有量 343.6 亿吨，较上一年增加 17.8 亿吨，煤炭保有可采储量 150.9 亿吨，较上一年增加 17.1 亿吨；JORC 标准下本集团的煤炭可售储量为 105.1 亿吨，较上一年增加 10.3 亿吨，不同矿区的保有量，以及相关信息如下\n\n| 矿区 | 保有资源量（中国标准）| 保有可采储量（中国标准） |证实储量（中国标准）|可信储量（中国标准）|煤炭可售储量（JORC标准）|主要煤种|主要商品煤的发热量（千克/千克) | 硫分(%) | 灰分(%) | \n| -- | -- | -- | -- | -- | -- | -- | -- | --|\n| 神东矿区 |158.0 | 89.7 | 18.7 | 36.6 | 65.4 | 长焰煤/不粘煤 | 4720-5730 | 0.2-0.6 | 8.4-19.4|\n| 新街台格庙矿区 | 110.1 | 14.0 | 6.2 | 4.5 | 9.4 | - | - | - | - |\n| 准格尔矿区 | 40.3 | 29.2 | 8.9 | 9.7 | 21.3 | 长焰煤 | 4409 -4744 | 0.4-0.6 | 25.0-29.8|\n| 胜利矿区 | 22.3 | 10.2 | 2.2 | 5.4 | 1.9 | 褐煤 | 2980 | 1.1 | 23.8 |\n| 宝日希勒矿区 | 12.5 | 7.5 | 1.4 | 4.2 | 7.0 | 褐煤 | 3551 | 0.2 | 13.9 |\n| 包头矿区 | 0.4 | 0.3 | 0.1 | 0.0 | 0.1 | 长焰煤/不粘煤 | 4073-4399 | 0.5-1.0 | 14.1 -18.3 |\n\n\n## 电力\n\n> 电力行业来看，综合考虑我国目前阶段经济增长潜力、“十四五”规划和国家宏观调控政策措施等因素，根据中国电力企业联合会预测结果，预计 2025 年全国全社会用电量同比增长 6%左右。新能源装机持续增长，部分地区新能源消纳压力凸显。预计2025 年底煤电占总装机比重将降至三分之一。综合考虑电力消费需求增长、电源投产等情况，预计 2025 年迎峰度夏等用电高峰期部分地区电力供需形势紧平衡\n\n全年总售电量 210.28 十亿千瓦时，占同期占社会用电量 98521 亿千瓦时的 2.1%， 其中市场交易电量达 205.20 十亿千瓦时，占总售电量的 97.6%；平均售电价格 403元/兆瓦时（2023 年 414 元/兆瓦时），本集团享有获取容量电费资格的国内煤电机组共 68 台，约占本集团国内煤电机组总数的 94%，2024 年共获取容量电费约 50 亿元（含税）。\n\n本集团火电供电标准煤耗降至 292.9 可/千瓦时（2023 年 294.9 克/千瓦时）\n\n本集团加大可再生能源项目开发和产业基金投资。本集团充分利用露天矿排土场、复垦区、铁路沿线闲置用地等土地资源投资建设光伏项目，2024 年新增对外商业运营的光伏发电装机容量合计 366 兆瓦。\n\n本集团发电机组总装机容量 46264 兆瓦，其中燃煤发电机组总装机容量 43184 兆瓦，约占全国煤电发电装机容量 11.9 亿千瓦的 3.6%。\n\n不同类型的电源情况如下所示\n\n| 电源种类 | 2024 年 12 月 31 日总装机容量 | 2023 年 12 月 31 日 总装机容量 | 新增 |\n| -- | -- | -- | -- |\n| 燃煤发电 | 43184 | 43164 | 20 |\n| 燃气发电 | 2194 | 950 | 1244 |\n| 水电 | 125 | 125 | 0 |\n| 光伏发电 | 761 | 395 | 366 |\n| 合计 | 46264 | 44634 | 1630 |\n\n\n本集团燃煤发电机组平均利用小时达 5030 小时，同比减少 191 小时，比全国 6000 千瓦及以上的电厂燃煤发电设备平均利用小时数 4628 小时高 402 小时，利用小时比平均高，表示有一定的调度优先级（后续可以持续观察利用小时数于平均利用小时数的相对情况）。另外2024 年整体的「6000 千瓦及以上电厂发电设备利用小时」 3442（全年累计），同比减少 157 小时，全国线路损失率 4.37%，同比减少 0.17%\n\n本集团具体发电利用小时如下\n\n| 电源种类  | 平均利用小时(2024) | 平均利用小时(2023) | 变动 (%) | 发电厂用电率(%)(2024) | 发电厂用电率(203) | 变动 |\n| -- | -- | -- | -- | -- | -- |--|\n| 燃煤发电(含矸石电厂) | 5030 | 5221 | (3.7) | 5.07 | 5.20 | 下降 0.13 个百分点|\n| 燃气发电 | 4151 | 4152 | (0.0) | 1.66 | 1.56 | 上升 0.10 个百分点 |\n| 水电 | 5097 | 5228 | (2.5) | 0.63 | 0.28 | 上升 0.35 个百分点 |\n| 光伏发电 | 1317 | 905 | 45.5 | 1.03 | / | / |\n| 加权平均 | 4960 | 5167 | (4.0) | 4.98 | 5.11 | 下降 0.13 个百分点 |\n\n\n电力市场化交易 \n\n| 项目 | 2024 | 2023 | 变动 (%) |\n| -- | -- | -- | -- |\n| 市场化交易的总电量(十亿千瓦时) | 205.2 | 194.56 | 5.5 |\n| 总上网电量（十亿千瓦时) | 210.28 | 199.75 | 5.3 |\n| 市场化交易电量占比 (%) | 97.6 | 97.4 | 上升 0.2 个百分点|\n\n2024 年 发电分部共耗本集团内部销售的煤炭（包括本集团自产煤和采购没）73.6 百万吨（2023 年 73.2 百万吨) 同比增长 0.5%，发电分部耗用本集团内部销售的煤炭量占发电分部耗煤总量 96.5 百万吨的 76.3%，消耗煤炭的绝大部分已经从内部供给。\n\n## 铁路\n\n铁路分部紧密服务一体化运营和产业链发展，进一步拓展”大一体化”优势，建立高效协同的运输生产生态系统，本集团2024 年自由铁路运输周转量达 312.1 十亿吨公里（2023 年：309.4 十亿吨公里），同比增长 0.9%。  神朔铁路 3 亿吨扩能改造工程有序推进，成功研制出氢能源动力调车机车和氢能源动力接触网作业车等核心装备。巴准铁路暖水集运站铁路专用线、三道渠铁路专用线顺利开通，设计装车能力 2000 万吨/年。\n\n2024 年，本集团完成金属矿石、化工品等非煤货物运量 24.5 百万吨（2023 年：22.3 百万吨），同比增长 9.9%，其中反向非煤货物运输 18.8 百万吨。\n\n营业情况\n\n| 项目 | 2024 | 2023 | 变动(%) | 主要变动原因 |\n| -- | -- | -- | -- | -- |\n| 营业收入(百万) | 43115 | 42961 | 0.4 | 自有铁路运输周转量增长 |\n| 营业成本(百万) | 26819 | 27059 | (0.9) | 受检修计划影响，修理费同比减少 |\n| 毛利率(%) | 37.8 | 37.0 | 上升 0.8 个百分点 | |\n| 利润总额(百万) | 12562 | 11039 | 13.8 | 资产减值损失同比减少 |\n\n2024 年，铁路分部单位运输成本为 0.081 元/吨公里（2023 年：0.085 元/吨公里），同比下降 4.7%，主要原因是受检修计划影响，修理费同比减少\n\n## 港口\n\n本集团港口分部深化内外协同合作，完善港航协同联动机制，精简装卸流程，报销组织生产。2024 年，黄骅港完成装船量 214.4 百万吨（2023:209.5 百万吨），同比增长 2.3%，连续 6 年位居“北煤南运”港口首位，散杂货吞吐量完成 8.2 百万吨，创开港以来最好水平。天津煤码头完成装船量 44.0 百万吨（2023 年：45.8 百万吨），同比下降 3.9%。\n\n加快推进多功能、综合性、现代化港口建设。黄骅港（煤炭港区）五期工程（规划煤炭下水量 5,000 万吨/年）、天津港务二期工程（设计年通过能力煤炭 3,500 万吨、矿石 1,800 万吨）获得核准批复；黄骅港（煤炭港区）油品码头工程、珠海港高栏港区国能散货码头工程开工建设；珠海港务 2 号、3 号卸船泊位升级，满足 15 万吨级船舶满载通航条件\n\n黄骅港构建覆盖煤港生产全过程的长效抑尘系统、生态环境智能管控系统及“两湖三湿地”生态水循环系统，抑尘率达到 98%，年节约淡水 400 万立方米以上；\n\n经营成果\n\n| 项目 | 2024 | 2023 | 变动(%)| 主要变动原因 |\n| -- | -- | -- | -- | -- |\n| 营业收入(百万) | 6842 | 6749 | 1.4 | 港口装船量增长 |\n| 营业成本(百万) | 4058 | 3754 | 8.1  | 航道疏浚费等增长；港口装船量增长 |\n| 毛利率(%) | 40.7 | 44.4  | 下降 3.7 个百分点 | |\n| 利润总额(百万) | 2122 | 2301 | (7.8) | |\n\n2024 年港口分部单位运输成本为 13.1 元/吨（2023 年：12.5 元/吨），同比增长 4.8%，主要原因是航道疏浚费等增长。\n\n## 航运\n\n2024 年完成航运货运量 129.9 百万吨（2023年：152.9百万吨），同比下降 15%，完成航运周转量 149.4 十亿吨海里（2023年：164.7十亿吨海里），同比下降 9.3%，完成非煤运输量 4.4 百万吨（2023 年：3.7 百万吨），同比增长 18.9%\n\n经营成果\n\n| 项目 | 2024 | 2023 | 变动(%)| 主要变动原因 |\n| -- | -- | -- | -- | -- |\n| 营业收入(百万) | 4996 | 4836 | 3.3 | 平均海运价格增长 |\n| 营业成本(百万) | 4457 | 4594 | (3.0)  | 业务结构调整导致航运周转量下降 |\n| 毛利率(%) | 10.8 | 5.0  | 下降 5.8 个百分点 | |\n| 利润总额(百万) | 260 | 100 | 160.0 | |\n\n2024 年航运分部单位运输成本为 0.030 元/吨海里（2023 年：0.028 元/吨海里），同比增长 7.1%，主要原因是航运周转量下降。从数字上看 运输总量少了，利润多了。\n\n## 煤化工\n\n本集团煤化工分部为包头煤化工煤制烯烃项目，主要产品包括聚乙烯（生产能力约 30万吨/年），聚丙烯（生产能力约 30万吨/年）及少量副产品（包括工业硫磺、混合碳五、工业丙烷、混合碳四、工业用甲醇、精甲醇等）。2024 年，包头煤化工煤制烯烃升级示范项目（生产能力 75万吨/年）建设有序推进。\n\n| 物品 | 2024 销售量(千吨) | 2024 价格(元/吨) | 2023 销售量(千吨) | 2023 价格（元/吨) | 销售量变动(%) | 价格变动(%) |\n| -- | -- | -- | -- | -- | -- | -- |\n| 聚乙烯 | 332.2 | 6645 | 364.4 | 6446 | (8.8) | 3.1 |\n| 聚丙烯 | 313.6 | 5896 | 341.5 | 5908 | (8.2) | (0.2) |\n\n经营成果\n\n| 项目 | 2024 | 2023 | 变动(%)| 主要变动原因 |\n| -- | -- | -- | -- | -- |\n| 营业收入(百万) | 5633 | 6098 | (7.6) | 煤制烯烃生产设备按计划检修，聚烯烃产品产量及销量下降 |\n| 营业成本(百万) | 5305 | 5412 | (2.0)  | 同上 |\n| 毛利率(%) | 5.8 | 11.2  | 下降 5.4 个百分点 | |\n| 利润总额(百万) | 37 | 190 | (80.5)| |\n\n2024 年，煤化工部共耗煤 4.6 百万吨（2023 年 4.9 百万吨），同步下降 6.1%,全部本集团内销售的煤炭（包括资产和采购）\n\n## 煤电结合\n\n公司本身有煤，也有火电，因此会有内部销售的情况，2024 年，发电分部共耗用本集团内部销售的煤炭（包括本集团自产煤和采购煤）73.6 百万吨（2023 年：73.2 百万吨），同比增长 0.5%。发电分部耗用本集团内部销售的煤炭量占发电分部耗煤总量 96.5 百万吨的 76.3%。  由于使用内部煤炭进行发电，在煤价波动或者电价波动的时候，可以有一定的缓冲。\n\n另外内部电厂和煤矿具体较近，因此运费成本也相对较低，自己的铁路运输自己的煤炭，整体的成本也更低。这里可能有几个原因：1）使用自有的运输路线，2）部分电厂和煤矿相对比较近。\n\n从年报中可知，煤矿和电厂的分布如下\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142515.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142515.png)\n\n![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142704.png)\n\n\n运输成本如下所示\n> 其中自有成本包括铁路和港口，航运暂时没找到，这里计算的成本较实际可能偏高，由于航运整体的收入和成本不大，所以暂时不做进一步细化\n\n| 项目 | 2024 | 2023 | 2022 | 2021  | 2020 |\n| -- | -- | -- | -- | -- | -- | \n| 运输成本 | 55180(100%) | 52236(100%) | 50094(100%) | 58027(100%) | 51557(100%) | \n| 自有成本* | 37041(67.12%) | 34681(66.39%) | 33226(66.32%) | 39319(67.75%) | 38304(74.29%) |\n| 外部成本 | 18139(32.87%) | 17555(33.60%) | 16868(33.67%) | 18708(32.24%) | 13253(25.70%) |\n\n可以看到，自有运输成本占 66% 以上，这部分在成本计算的时候会按照市价进行计算，但是实际不需要花这么多钱，仅需要花费运输路线的成本即可，因此整体的运输成本相对较低。 粗略估算整体的运输成本比其他公司要少 66% * (37% -- 铁路的毛利率) ~ 24% 也就是卖同样的煤，单位运输成本可能会减少 20% 左右，这部分会成为整个公司的利润。\n\n接下来可以对比自产煤的利润率和外购煤的利润率，如下所示\n> 由于 2022 年以前，年报暂无外购煤和自产煤相关详细数据 -- 2021 年报描述公司暂无法区分自产煤和外购煤相关数据，因此暂不纳入计算\n\n| 项目 | 2024 | 2023 | 2022 | \n| -- | -- | -- | -- | -- | -- | \n| 自产煤（销售量） | 327 | 325.4 | 316.2 | \n| 外购煤（销售量） | 132 | 124.6 | 101.6 |\n| 自产煤（销售收入) | 172442 | 178242 | 188818 | \n| 外购煤（销售收入) | 86373 | 84626 | 80178 | \n| 自产煤（销售成本) | 95642 | 95250 | 93150 |\n| 外购煤（销售收入) | 86373 | 84626 | 80178 |\n| 外购煤（销售成本) | 84797 | 82617 | 77627 | \n| 自产煤（毛利率) | 44.5% | 46.6% | 50.7% |\n| 外购煤（毛利率） | 1.8% | 2.4% | 3.2% |\n\n可以看到自产煤的毛利率远大于外购煤的毛利率，另外这部分既然不赚钱，为啥还要做生意呢？或许是为了维持运输线路，运输路线只要能同正常流转就能够赚钱（运输自己的煤可以减少开支，运输其他公司物品可以赚利润）\n\n\n从发电分部来说，现在有两个政策对火电相对较好：1）容量电价[2]；2）电价浮动[3]。第一个是说只要保证有相关的能力，就能有一定的收入（不管是否发电） -- 但是需要电的时候要能保证提供，否则会扣费，甚至取消相关资格；第二个是电价会按市场需要波动，低峰更便宜，高峰更贵。\n\n由于公司内部有煤，有电，然后有容量电价，以及电价的浮动，那么在煤炭价格进行波动的时候，可以内部进行一定的缓冲，比如煤炭价格下跌的时候，可以适当的给内部发电部门供应更多的煤炭（这个有上限），然后发电分部可以通过多发电（甚至在高峰期多发电 -- 这个查看调度优先级），这样可以把一部分由于煤炭降价导致收入转移到电力下游，一定程度的对冲价格的波动，整体的收入和利润会更平衡一些。后文我们会对具体的波动数值进行一个推演。\n\n这里可以分为 \n\n| 项目 | 煤炭上涨 |煤价不变 | 煤炭下跌|\n| -- | -- | -- |\n| 电价上涨 | (1) | (2) | (3) |\n| 电价不变 | (4) | (5) | (6) |\n| 电价下跌 | (7) | (8) | (9) |\n\n这里我们需要重点关注的是 (9) 这个位置，也就是煤价和电价都下跌的情况，后续我们会对这个进行一些具体的推演\n\n# 经营情况\n## 现金流量以及分红\n\n公司业务挣的钱，可能会有一些资本开支，也可能会有分红，接下来我们看看业务收入，以及现金流量净额的流向如何\n\n2024 年经营活动产生的现金流净额 93348 百万，「购建固定资产、无形资产和其他长期资产支付的现金」是 37032 百万，两者剩余 56316 百万，预计分红 44903 百万，占净利润的 76.5%（2023 年 75.2%），可以看到现金流量是足够分红支出的。另外公司承诺 25-27 年承诺每年以现金方式分配的利润不少于本公司当年实现的归属本公司股东净利润的 65%，实际最近 3 年都高于 70%(2024 年 76.5%， 2023 年 75.2%，2022 年 72.8%)。 2022 - 2024 的三年股东回报规划，承诺以现金方式分配的利润不少于公司当年实现归母净利的 60%，\n\n公司 24 年经营现金流和 固定资产、无形资产等支持，分红的情况如下所示（单位百万）\n\n| 项目 | 2024 | 2023 | 2022 | 2021 | 2020|\n| -- | -- | -- | -- | -- | -- |\n| 经营活动产生的现金流量净额 | 93348 | 89687 | 109734 | 94575 | 81289 |\n| 购建固定资产、无形资产和其他长期资产支付的现金 | 37032(39.67%) |  37084(41.34%) | 28684(26.13%) | 23863(25.23%) | 20673(25.43%) |\n| 分红 | 44903(48.10%) | 44903(50.06%) | 50665(46.17%) | 50466(53.36%) | 35962(44.23%) |\n| 剩余 | 11413(12.22%) | 7700(8.58%) | 30385(27.68%) | 20246(21.40%) | 24654(30.32%) |\n\n可以从上表看出，经营活动的现金流净额减去固定资产、无形资产的投资后，是足够分红的（也就是「剩余」一栏都是正数），可见公司是有钱分红的。 从年报可以分析 2023 年「购建固定资产、无形资产和其他长期资产支付的现金」增加是因为有发电厂投产，2024 年「购建固定资产、无形资产和其他长期资产支付的现金」增加是因为在建工程的投入更多，后续可以持续观察看看，这部分看是否会有大幅度的投入。\n\n## 合同负债和应收款\n\n我们来看看公司的合同负债，以及应收账款，这两部分表示公司已经收到下游的钱还未交付，或者已经交付还未收到钱。一定程度可以看出公司的议价权。\n\n| 项目 | 2024 | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 合同负债 | 4045 | 7208 | 5597 | 6864 | 5256 |\n| 应收账款 | 12466 | 11875 |  10968 | 10258 | 7798 |\n\n可以看到公司既有合同负债，又有应收账款，然后查看应收账款的相应情况如下\n\n按性质分\n\n| 项目 | 2024  | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 售电款 | 7869 | 7539 | 6475 | 4480 | 3619 | \n| 售煤款 | 2182 | 2003 | 1802 | 3380 | 1982 |\n| 售热款 | 267 | 319 | 280 | 217 | 262 |\n| 其他 | 3292 | 3209 | 3632 | 3458 | 3234 |\n\n按账龄分析\n\n| 账龄 | 2024 | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 1 年以内 | 12125(89%) | 11497(87%) | 10646(87%) | 9648(84%) | 7009(78%) |\n| 1-2 年 | 182(1%) | 253(2%)| 165(1%) | 155(1%) | 131(1%) |\n| 2-3 年 | 136(1%) | 56(1%) | 30(1%) | 87(1%) | 93(1%) |\n| > 3年 | 1167(9%) | 1264(10%) | 1348(11%) | 1645(14%) | 1864(20%) |\n\n应收账款金额前五的单位\n\n- 2024 ![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151023782.png)\n- 2023 ![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115102144.png)\n- 2022 ![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115102413.png)\n- 2021  ![](https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151018170.png)\n- 2020 ![](https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115101901.png)\n\n可以看到应收账款主要在「售电」，主要是电力公司，主要在一年以内，这个应该是和结算周期有关，可以推测煤炭分部有一定的合同负债，从这个来看，相对来说煤炭分部有一定的议价权\n\n接下来我们单独看煤炭分部的应收账款于营业收入的比值，一定程度看议价能力的变动，如果「应收账款」/「营业收入」变大，表示议价能力变弱，否则变高\n\n| 项目 | 2024 | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 应收账款 | 2182 | 2003 | 1802 | 3380 | 1982 |\n| 营业收入 | 268618 | 273306 | 277474 | 292661 | 292661 |\n| 比值 |  0.81% | 0.73% | 0.64% | 1.15% | 0.67% |\n\n可以看出来 2021 年的比值超过 1%，其他几年都低于 1%。搜了下，发现 2021 年刚好是煤炭价格下跌的一年，这个能对应上，煤炭下跌，行情不好，应收账款变的更多了。\n\n## 和煤炭公司，电力公司的部分对比\n\n中国神华在于煤电、运输等一体化运营，我们也来对比下和煤炭公司、电力公司在不同指标上的情况，有一个直观的对比和了解。我们选择 毛利率、ROE 以及资产负债率这三个指标，其中毛利率表示生意模式是否优秀，ROE 表示资产回报率，资产负债率则表示抗极限风险的能力。\n\n毛利率\n\n|   公司       | 2016 | 2017 | 2018 | 2019 | 2020 | 2021 | 2022 | 2023 | 2024 |\n| -- | --  | -- | -- | -- | -- | -- | -- | -- | -- |\n| 陕西煤业 | 43.39 | 55.40 | 48.69 | 40.93 | 27.46 | 35.84 | 44.99 | 37.86 | 32.69|\n| 华能国际 | 21.43 | 11.31 | 11.30 | 12.5 | 14.5 | 17.4 | -0.33 | 3.04 | 12.11|\n| 中国神华 | 39.5 | 42.1 | 41.1 | 36.7 | 36.4 | 32.9 | 39.03 | 35.89 | 34.04 |\n\nROE\n\n| 公司 | 2021 | 2022 | 2023 | 2024 |\n| -- | -- | -- | -- | -- |\n| 陕西煤业 | 24.03 | 33.3 | 20.64 | 21.32 |\n| 华能国际 | -10.29 | -8.92 | 4.28 | 5.14 |\n| 中国神华 | 13.82 | 18.77 | 15.99 | 14.97 |\n\n资产负债率\n\n| 公司 | 2020 | 2021 | 2022 | 2023 | 2024 |\n| -- | -- | -- | -- | -- | -- |\n| 陕西煤业 | 39.78%  | 60.82% | 60.19% | 62.99% | 63.35% |\n| 华能国际 | 67.71% | 74.68% | 74.82% | 68.33% | 65.40% |\n| 中国神华 | 23.9% | 26.6% |26.1% | 24.1% | 23.4% |\n\n\n对于 ROE 这一项，我们可以再继续进行细分，查看「销售净利率」、「资产周转率」以及「权益系数」的相关数值，其中「销售净利率」表示赚钱多狠，资产周转率表示公司跑的多块，权益系数表示杠杆有多高\n\n销售净利率\n\n| 公司 | 2024 | 2023 | 2022 | 2021 | 2020|\n| -- | -- | -- | -- | -- | -- |\n| 神华 | 17.3 | 17.3 | 20.2 | 14.9 | 16.7 |\n| 陕西煤业 | 12.14 | 6.2 | 21 | 14 | 15.6 |\n\n资产周转率\n\n| 公司 | 2024 | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 神华 | 52.53 | 54.80 | 56.08 | 57.52 | 41.76 |\n| 陕西煤业 | 79.28 | 72.99 | 79.91 | 91.02 | 68.5 |\n\n\n权益乘数\n> 使用公式 = 1/ (1 - 资产负债率)\n\n| 公司 | 2024 | 2023 | 2022 | 2021 | 2020 |\n| -- | -- | -- | -- | -- | -- |\n| 神华 | 1.3 | 1.31 | 1.35 | 1.36 | 1.31 |\n| 陕西煤业 | 2.7 | 2.7 | 2.51 | 2.55 |  2.51 |\n\n\n可以从上面的图表中看到，神华和陕西煤业比较，销售净利率相对还是比较好的，资产周转率不如，，然后杠杆率比较低。其中对于杠杆率来说，虽然可能借到很便宜的钱，杠杆可以放大收益，但是在行情不好的时候，风险也会被放大，因此这个也变相的体现抗风险能力\n\n# 风险\n对于神华来说，针对不同的业务，会有不同的风险，比如\n- 对于煤炭生意来说：1）最大的风险在于新能源的推广，这块由于现在储能上还不太能跟上，因此煤炭作为资源压舱石还一直在使用，但是未来如果储能有重大进展的话，则新能源可能会大幅替代火电；2）是否可能对煤炭企业或者火电企业收取「碳」相关的税，从而促进能源转型；3）作为国企，在煤炭涨价的时候，是否需要承受更多的社会责任，对本公司的利益是否有影响。\n- 对于电力生意来说：1）火电是否会被新能源发电去掉；2）现在的电价方式是否会发生变化\n- 对于铁路来说：如果不需要允许这么多煤，那么能否比较快速的转运其他非煤物品\n\n我们可以知道这些都和火电有关，那么我们通过国家能源官网[4]的装机信息来看，不同类系发电的装机情况，火电的装机情况暂时还行，斜率是往上的\n\n\n2025 全国不同类型装机容量新增数，可以用 (1-3) - (1-2) 获得 3 月新增\n\n| 项目(万千瓦) | 1-2 | 1-3月 | 1-4 月 | 1-5 | 1-6 | 1-7 | 1-8 | 1-9 | 1-10 | 1-11 |\n| -- | -- |-- | -- | -- | -- | -- | -- | -- | -- | -- |\n| 水电 | 191 | 213 | 265 | 325 | 393 |589 | 684 | 716 | 835 | 912 |\n| 火电 | 388 | 925 | 1298 | 1755 | 2578 | 4198 | 4987 | 5668 | 6508 | 7752 |\n| 核电 | 0 | 0 | 0 | 0 |  0 | 0 | 0| 0 | 153 | 153 |\n| 风电 | 928 | 1462 | 1996 | 4628 | 5139 | 5367 | 5784 | 6109 | 7001 | 8250 |\n| 太阳能发电 | 3947 | 5971 | 10493 | 19785 | 21221 | 22325 | 23061 | 24027 | 25287 | 27489 |\n\n相关图形如下所示（可以观察斜率表示增长率）\n\n{% echarts 85% 400 %}\noption = {\n  title: {\n    text: '新增装机量'\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  legend: {\n    data: ['水电', '火电', '核电', '风电', '太阳能']\n  },\n  grid: {\n    left: '3%',\n    right: '4%',\n    bottom: '3%',\n    containLabel: true\n  },\n  toolbox: {\n    feature: {\n      saveAsImage: {}\n    }\n  },\n  xAxis: {\n    type: 'category',\n    boundaryGap: false,\n    data: ['2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n  },\n  yAxis: {\n    type: 'value'\n  },\n  series: [\n    {\n      name: '水电',\n      type: 'line',\n\n      data: [191, 213, 265, 325, 393, 589, 684, 716, 835, 912]\n    },\n    {\n      name: '火电',\n      type: 'line',\n\n      data: [388, 925, 1298, 1755, 2578, 4198, 4987, 5668, 6500, 7752]\n    },\n    {\n      name: '核电',\n      type: 'line',\n\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 153, 153]\n    },\n    {\n      name: '风电',\n      type: 'line',\n\n      data: [928, 1462, 1996, 4628, 5139, 5367, 5784, 6109, 7001, 8250]\n    },\n    {\n      name: '太阳能',\n      type: 'line',\n\n      data: [3947, 5971, 10493, 19785, 21221, 22325, 23061, 24027, 25287, 27489]\n    }\n  ]\n};\n{% endecharts %}\n\n\n# 神华自己的价值\n\n首先我们对神华进行公司的价值估算，这样可以和现在的市值进行比较。我们根据不同业务的综合进行估值\n\n- 其中煤炭现在保有量 343.6 亿吨，按照现在均价 584 元/吨，总价在 20 万亿。如果按照 300 百万吨一年的销量，大概一年营收 1755 亿，然后按照 5% 左右的折旧率，以及计算 50 年的话，大概总价值 3万亿，按照 30% 的利润率，则总价在在 1万亿左右。\n- 现在铁路总共 2408 公里，按照修建铁路 1 公里的成本大约在 1.5 亿左右，就算不再使用，也可以进行售卖，这块的价值 3600 亿左右\n- 电厂的价值估算，现在总共有 4万兆瓦的装机容量，目前新建的成本大概在 3500 元/千瓦，则重估的价值等于 1400 亿\n- 另外还有港口和航运等这些资产\n\n可以发现整个神华的资产是肯定超过现在的市值 8300 亿的。因此现在的市值是相对比较便宜的。\n\n\n# Ref\n[1] 华源证券 煤炭行业中期策略报告 (2025.06.27)\n[2] https://www.ndrc.gov.cn/xxgk/zcfb/tz/202311/t20231110_1361897.html\n[3] https://www.ndrc.gov.cn/xxgk/zcfb/tz/202110/t20211012_1299461.html\n[4] https://www.nea.gov.cn/20251026/70d3b88f62f1401bbe47a8212e06ad8e/c.html\n","slug":"601088-company-ana","published":1,"updated":"2026-01-17T06:36:57.387Z","_id":"cmkgimn3a000fdgmkef45144z","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>中国神华的情况，数据主要以 2024 年年报为主</p>\n</blockquote>\n<h1 id=\"股东以及相关关系\"><a href=\"#股东以及相关关系\" class=\"headerlink\" title=\"股东以及相关关系\"></a>股东以及相关关系</h1><p>整体的控股关系如下图所示</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151952893.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151953271.png\" alt=\"\"></p>\n<span id=\"more\"></span>\n<h1 id=\"业务基本情况\"><a href=\"#业务基本情况\" class=\"headerlink\" title=\"业务基本情况\"></a>业务基本情况</h1><p>公司包括多个部门，煤炭生产→煤炭运输 （铁路、 港口、 航运） →煤炭转化 （发<br>电及煤化工）的一体化产业链，各分部之间存在业务往来，比如本公司的煤炭供给给发电部门，然后途中会使用本公司的铁路/航运等进行运行。</p>\n<p>其中按照 2024 年的情况，不同分部的营收毛利如下所示</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>分行业</th>\n<th>营业收入（百万）</th>\n<th>营业成本（百万)</th>\n<th>毛利率(%)</th>\n<th>营业收入比上年增减(%)</th>\n<th>营业成本比上年增减 (%)</th>\n<th>毛利率比上年增减(%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>煤炭</td>\n<td>268618</td>\n<td>188066</td>\n<td>30.0</td>\n<td>(1.7)</td>\n<td>1.2</td>\n<td>(2.0)</td>\n</tr>\n<tr>\n<td>发电</td>\n<td>94217</td>\n<td>78832</td>\n<td>16.3</td>\n<td>2.0</td>\n<td>2.7</td>\n<td>(0.6)</td>\n</tr>\n<tr>\n<td>铁路</td>\n<td>43115</td>\n<td>26819</td>\n<td>37.8</td>\n<td>0.4</td>\n<td>(0.9)</td>\n<td>0.8</td>\n</tr>\n<tr>\n<td>港口</td>\n<td>6842</td>\n<td>4058</td>\n<td>40.7</td>\n<td>1.4</td>\n<td>8.1</td>\n<td>(3.7)</td>\n</tr>\n<tr>\n<td>航运</td>\n<td>4996</td>\n<td>4457</td>\n<td>10.8</td>\n<td>3.3</td>\n<td>(3.0)</td>\n<td>5.8</td>\n</tr>\n<tr>\n<td>煤化工</td>\n<td>5633</td>\n<td>5305</td>\n<td>5.8</td>\n<td>(7.6)</td>\n<td>(2.0)</td>\n<td>(5.4)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到其中煤炭占比最多，营业收入占 63.4%，发电占 22.25%，铁路占 10.18% 其他的占 5% 左右。</p>\n<p>公司不同分部之间也有交易，比如煤炭分部会卖煤给发电部门，同时会使用自己铁路分部的铁路进行运输等，</p>\n<p>20204 年的分部间交易如下</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>分部业绩</th>\n<th>煤炭</th>\n<th>发电</th>\n<th>铁路</th>\n<th>港口</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>对外交易收入</td>\n<td>223753</td>\n<td>94012</td>\n<td>11120</td>\n<td>1796</td>\n</tr>\n<tr>\n<td>分部间交易收入</td>\n<td>44865</td>\n<td>205</td>\n<td>31995</td>\n<td>5046</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看出来，煤炭供给给内部 16.7%(其中电力部门 16%，煤化工分部 0.7%)，外部占比 83.3% 主要还是销往外部；发电部门供给给内部占 0.2% 基本可以忽略，铁路部分供给给内部占 74.2% 外部占 25.8%，港口内部占 73.7% 外部占比 26.3%； 可以看出，煤炭、发电主要是供给外部，运输（铁路/港口）主要还是内部使用。</p>\n<h2 id=\"煤炭\"><a href=\"#煤炭\" class=\"headerlink\" title=\"煤炭\"></a>煤炭</h2><blockquote>\n<p>煤炭行业来看，我国经济增长将持续拉动能源需求，煤炭作为全球最重要的能源来源之一， 尽管面临着可再生能源、 低碳发展和环保要求的多重挑战， 在可预见的未来市场中依旧扮演着关键角色。 预计电力和化工用煤是煤炭消费的主要增量来源。 煤炭产量预计总体保持稳定。进口煤价格优势缩小，进口煤量或小幅减少。总体来看，2025年煤炭市场供需向平衡偏宽松方向发展， 市场煤占比增加， 煤炭市场价格中枢或小幅下降，稳定在合理区间。受季节性波动、突发事件等因素影响，局部地区、部分时段可能出现供应偏紧的局面</p>\n</blockquote>\n<p>煤炭现在有两类销售：第一个是通过销售集团销售，主要是第一个，共有三种：年度长协，月度长协，以及现货；第二个就是煤矿坑口直接销售，整体占比 5% 以内。其中</p>\n<p>2024 年不同类型的销售情况如下</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>销售量(百万吨)</th>\n<th>占比 (%)</th>\n<th>价格(不含税)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>年度长协</td>\n<td>246.4</td>\n<td>53.6</td>\n<td>491</td>\n</tr>\n<tr>\n<td>月度长协</td>\n<td>154.8</td>\n<td>33.7</td>\n<td>705</td>\n</tr>\n<tr>\n<td>现货</td>\n<td>36.2</td>\n<td>7.9</td>\n<td>627</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>现在的煤炭包括自产煤，以及外购煤，成本包括：采掘成本，销售成本，运输成本，加工和管理，热值换算等成本。<br>其中 2024 年的自产煤采掘成本是 179 元/吨，然后根据 [1] 预测的完全成本，中国神华（蒙西坑口到秦皇岛）完全成本是 640 元/吨左右（其中运费估算 250元/吨，陕西动力煤的运费成本在 200 元/吨左右，陕西动力煤的运输成本在 230 元/吨左右），由于中国神华的运输会使用自己的铁路/港口等，因此运费会更低一些，按照煤炭分部的运输成本计算，则平均运输成本 = 总平均运输成本/总销量 = 55180百万/459.3百万吨 = 120.13934248 元/吨，可见神华的平均运输成本比市场要便宜大几十/吨。</p>\n<p>其中热值换算，是因为中国煤的情况：北多南少，西多东少，然后从北方运往其他地方的时候，一般会用秦皇岛港口，所以市场往往会以秦皇岛 5500 大卡的价格计算，但是如果煤的热力值和 5500 不同，就需要进行换算</p>\n<p>煤炭的采掘量以及储量如下所示，2024 年产量 327.1 百万吨，销售 459.3 百万吨，对前五大外部煤炭客户销售量为 192.4 百万吨，占煤炭销售总量的 41.9%，其中对最大客户国家能源接团的煤炭销售为 164.9 百万吨，占煤炭销售总量的 35.9%，整体储量如下所示</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>内外部客户</th>\n<th>销售量(百万吨)</th>\n<th>占销售量比例 (%)</th>\n<th>价格(不含税) 元/ 吨</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>对外部客户销售</td>\n<td>381.2</td>\n<td>83.0</td>\n<td>573</td>\n</tr>\n<tr>\n<td>对内部发电分部销售</td>\n<td>73.5</td>\n<td>16.0</td>\n<td>523</td>\n</tr>\n<tr>\n<td>对内部煤化工分部销售</td>\n<td>4.6</td>\n<td>1.0</td>\n<td>424</td>\n</tr>\n<tr>\n<td>销售量合计/平均价格（不含税)</td>\n<td>459.3</td>\n<td>100</td>\n<td>564</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>从这里看电力部分消耗内部煤炭 16%</p>\n<p>煤炭的保有量 343.6 亿吨，较上一年增加 17.8 亿吨，煤炭保有可采储量 150.9 亿吨，较上一年增加 17.1 亿吨；JORC 标准下本集团的煤炭可售储量为 105.1 亿吨，较上一年增加 10.3 亿吨，不同矿区的保有量，以及相关信息如下</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>矿区</th>\n<th>保有资源量（中国标准）</th>\n<th>保有可采储量（中国标准）</th>\n<th>证实储量（中国标准）</th>\n<th>可信储量（中国标准）</th>\n<th>煤炭可售储量（JORC标准）</th>\n<th>主要煤种</th>\n<th>主要商品煤的发热量（千克/千克)</th>\n<th>硫分(%)</th>\n<th>灰分(%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>神东矿区</td>\n<td>158.0</td>\n<td>89.7</td>\n<td>18.7</td>\n<td>36.6</td>\n<td>65.4</td>\n<td>长焰煤/不粘煤</td>\n<td>4720-5730</td>\n<td>0.2-0.6</td>\n<td>8.4-19.4</td>\n</tr>\n<tr>\n<td>新街台格庙矿区</td>\n<td>110.1</td>\n<td>14.0</td>\n<td>6.2</td>\n<td>4.5</td>\n<td>9.4</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>准格尔矿区</td>\n<td>40.3</td>\n<td>29.2</td>\n<td>8.9</td>\n<td>9.7</td>\n<td>21.3</td>\n<td>长焰煤</td>\n<td>4409 -4744</td>\n<td>0.4-0.6</td>\n<td>25.0-29.8</td>\n</tr>\n<tr>\n<td>胜利矿区</td>\n<td>22.3</td>\n<td>10.2</td>\n<td>2.2</td>\n<td>5.4</td>\n<td>1.9</td>\n<td>褐煤</td>\n<td>2980</td>\n<td>1.1</td>\n<td>23.8</td>\n</tr>\n<tr>\n<td>宝日希勒矿区</td>\n<td>12.5</td>\n<td>7.5</td>\n<td>1.4</td>\n<td>4.2</td>\n<td>7.0</td>\n<td>褐煤</td>\n<td>3551</td>\n<td>0.2</td>\n<td>13.9</td>\n</tr>\n<tr>\n<td>包头矿区</td>\n<td>0.4</td>\n<td>0.3</td>\n<td>0.1</td>\n<td>0.0</td>\n<td>0.1</td>\n<td>长焰煤/不粘煤</td>\n<td>4073-4399</td>\n<td>0.5-1.0</td>\n<td>14.1 -18.3</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"电力\"><a href=\"#电力\" class=\"headerlink\" title=\"电力\"></a>电力</h2><blockquote>\n<p>电力行业来看，综合考虑我国目前阶段经济增长潜力、“十四五”规划和国家宏观调控政策措施等因素，根据中国电力企业联合会预测结果，预计 2025 年全国全社会用电量同比增长 6%左右。新能源装机持续增长，部分地区新能源消纳压力凸显。预计2025 年底煤电占总装机比重将降至三分之一。综合考虑电力消费需求增长、电源投产等情况，预计 2025 年迎峰度夏等用电高峰期部分地区电力供需形势紧平衡</p>\n</blockquote>\n<p>全年总售电量 210.28 十亿千瓦时，占同期占社会用电量 98521 亿千瓦时的 2.1%， 其中市场交易电量达 205.20 十亿千瓦时，占总售电量的 97.6%；平均售电价格 403元/兆瓦时（2023 年 414 元/兆瓦时），本集团享有获取容量电费资格的国内煤电机组共 68 台，约占本集团国内煤电机组总数的 94%，2024 年共获取容量电费约 50 亿元（含税）。</p>\n<p>本集团火电供电标准煤耗降至 292.9 可/千瓦时（2023 年 294.9 克/千瓦时）</p>\n<p>本集团加大可再生能源项目开发和产业基金投资。本集团充分利用露天矿排土场、复垦区、铁路沿线闲置用地等土地资源投资建设光伏项目，2024 年新增对外商业运营的光伏发电装机容量合计 366 兆瓦。</p>\n<p>本集团发电机组总装机容量 46264 兆瓦，其中燃煤发电机组总装机容量 43184 兆瓦，约占全国煤电发电装机容量 11.9 亿千瓦的 3.6%。</p>\n<p>不同类型的电源情况如下所示</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>电源种类</th>\n<th>2024 年 12 月 31 日总装机容量</th>\n<th>2023 年 12 月 31 日 总装机容量</th>\n<th>新增</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>燃煤发电</td>\n<td>43184</td>\n<td>43164</td>\n<td>20</td>\n</tr>\n<tr>\n<td>燃气发电</td>\n<td>2194</td>\n<td>950</td>\n<td>1244</td>\n</tr>\n<tr>\n<td>水电</td>\n<td>125</td>\n<td>125</td>\n<td>0</td>\n</tr>\n<tr>\n<td>光伏发电</td>\n<td>761</td>\n<td>395</td>\n<td>366</td>\n</tr>\n<tr>\n<td>合计</td>\n<td>46264</td>\n<td>44634</td>\n<td>1630</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>本集团燃煤发电机组平均利用小时达 5030 小时，同比减少 191 小时，比全国 6000 千瓦及以上的电厂燃煤发电设备平均利用小时数 4628 小时高 402 小时，利用小时比平均高，表示有一定的调度优先级（后续可以持续观察利用小时数于平均利用小时数的相对情况）。另外2024 年整体的「6000 千瓦及以上电厂发电设备利用小时」 3442（全年累计），同比减少 157 小时，全国线路损失率 4.37%，同比减少 0.17%</p>\n<p>本集团具体发电利用小时如下</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>电源种类</th>\n<th>平均利用小时(2024)</th>\n<th>平均利用小时(2023)</th>\n<th>变动 (%)</th>\n<th>发电厂用电率(%)(2024)</th>\n<th>发电厂用电率(203)</th>\n<th>变动</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>燃煤发电(含矸石电厂)</td>\n<td>5030</td>\n<td>5221</td>\n<td>(3.7)</td>\n<td>5.07</td>\n<td>5.20</td>\n<td>下降 0.13 个百分点</td>\n</tr>\n<tr>\n<td>燃气发电</td>\n<td>4151</td>\n<td>4152</td>\n<td>(0.0)</td>\n<td>1.66</td>\n<td>1.56</td>\n<td>上升 0.10 个百分点</td>\n</tr>\n<tr>\n<td>水电</td>\n<td>5097</td>\n<td>5228</td>\n<td>(2.5)</td>\n<td>0.63</td>\n<td>0.28</td>\n<td>上升 0.35 个百分点</td>\n</tr>\n<tr>\n<td>光伏发电</td>\n<td>1317</td>\n<td>905</td>\n<td>45.5</td>\n<td>1.03</td>\n<td>/</td>\n<td>/</td>\n</tr>\n<tr>\n<td>加权平均</td>\n<td>4960</td>\n<td>5167</td>\n<td>(4.0)</td>\n<td>4.98</td>\n<td>5.11</td>\n<td>下降 0.13 个百分点</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>电力市场化交易 </p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>变动 (%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>市场化交易的总电量(十亿千瓦时)</td>\n<td>205.2</td>\n<td>194.56</td>\n<td>5.5</td>\n</tr>\n<tr>\n<td>总上网电量（十亿千瓦时)</td>\n<td>210.28</td>\n<td>199.75</td>\n<td>5.3</td>\n</tr>\n<tr>\n<td>市场化交易电量占比 (%)</td>\n<td>97.6</td>\n<td>97.4</td>\n<td>上升 0.2 个百分点</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2024 年 发电分部共耗本集团内部销售的煤炭（包括本集团自产煤和采购没）73.6 百万吨（2023 年 73.2 百万吨) 同比增长 0.5%，发电分部耗用本集团内部销售的煤炭量占发电分部耗煤总量 96.5 百万吨的 76.3%，消耗煤炭的绝大部分已经从内部供给。</p>\n<h2 id=\"铁路\"><a href=\"#铁路\" class=\"headerlink\" title=\"铁路\"></a>铁路</h2><p>铁路分部紧密服务一体化运营和产业链发展，进一步拓展”大一体化”优势，建立高效协同的运输生产生态系统，本集团2024 年自由铁路运输周转量达 312.1 十亿吨公里（2023 年：309.4 十亿吨公里），同比增长 0.9%。  神朔铁路 3 亿吨扩能改造工程有序推进，成功研制出氢能源动力调车机车和氢能源动力接触网作业车等核心装备。巴准铁路暖水集运站铁路专用线、三道渠铁路专用线顺利开通，设计装车能力 2000 万吨/年。</p>\n<p>2024 年，本集团完成金属矿石、化工品等非煤货物运量 24.5 百万吨（2023 年：22.3 百万吨），同比增长 9.9%，其中反向非煤货物运输 18.8 百万吨。</p>\n<p>营业情况</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>变动(%)</th>\n<th>主要变动原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>营业收入(百万)</td>\n<td>43115</td>\n<td>42961</td>\n<td>0.4</td>\n<td>自有铁路运输周转量增长</td>\n</tr>\n<tr>\n<td>营业成本(百万)</td>\n<td>26819</td>\n<td>27059</td>\n<td>(0.9)</td>\n<td>受检修计划影响，修理费同比减少</td>\n</tr>\n<tr>\n<td>毛利率(%)</td>\n<td>37.8</td>\n<td>37.0</td>\n<td>上升 0.8 个百分点</td>\n<td></td>\n</tr>\n<tr>\n<td>利润总额(百万)</td>\n<td>12562</td>\n<td>11039</td>\n<td>13.8</td>\n<td>资产减值损失同比减少</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2024 年，铁路分部单位运输成本为 0.081 元/吨公里（2023 年：0.085 元/吨公里），同比下降 4.7%，主要原因是受检修计划影响，修理费同比减少</p>\n<h2 id=\"港口\"><a href=\"#港口\" class=\"headerlink\" title=\"港口\"></a>港口</h2><p>本集团港口分部深化内外协同合作，完善港航协同联动机制，精简装卸流程，报销组织生产。2024 年，黄骅港完成装船量 214.4 百万吨（2023:209.5 百万吨），同比增长 2.3%，连续 6 年位居“北煤南运”港口首位，散杂货吞吐量完成 8.2 百万吨，创开港以来最好水平。天津煤码头完成装船量 44.0 百万吨（2023 年：45.8 百万吨），同比下降 3.9%。</p>\n<p>加快推进多功能、综合性、现代化港口建设。黄骅港（煤炭港区）五期工程（规划煤炭下水量 5,000 万吨/年）、天津港务二期工程（设计年通过能力煤炭 3,500 万吨、矿石 1,800 万吨）获得核准批复；黄骅港（煤炭港区）油品码头工程、珠海港高栏港区国能散货码头工程开工建设；珠海港务 2 号、3 号卸船泊位升级，满足 15 万吨级船舶满载通航条件</p>\n<p>黄骅港构建覆盖煤港生产全过程的长效抑尘系统、生态环境智能管控系统及“两湖三湿地”生态水循环系统，抑尘率达到 98%，年节约淡水 400 万立方米以上；</p>\n<p>经营成果</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>变动(%)</th>\n<th>主要变动原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>营业收入(百万)</td>\n<td>6842</td>\n<td>6749</td>\n<td>1.4</td>\n<td>港口装船量增长</td>\n</tr>\n<tr>\n<td>营业成本(百万)</td>\n<td>4058</td>\n<td>3754</td>\n<td>8.1</td>\n<td>航道疏浚费等增长；港口装船量增长</td>\n</tr>\n<tr>\n<td>毛利率(%)</td>\n<td>40.7</td>\n<td>44.4</td>\n<td>下降 3.7 个百分点</td>\n<td></td>\n</tr>\n<tr>\n<td>利润总额(百万)</td>\n<td>2122</td>\n<td>2301</td>\n<td>(7.8)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2024 年港口分部单位运输成本为 13.1 元/吨（2023 年：12.5 元/吨），同比增长 4.8%，主要原因是航道疏浚费等增长。</p>\n<h2 id=\"航运\"><a href=\"#航运\" class=\"headerlink\" title=\"航运\"></a>航运</h2><p>2024 年完成航运货运量 129.9 百万吨（2023年：152.9百万吨），同比下降 15%，完成航运周转量 149.4 十亿吨海里（2023年：164.7十亿吨海里），同比下降 9.3%，完成非煤运输量 4.4 百万吨（2023 年：3.7 百万吨），同比增长 18.9%</p>\n<p>经营成果</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>变动(%)</th>\n<th>主要变动原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>营业收入(百万)</td>\n<td>4996</td>\n<td>4836</td>\n<td>3.3</td>\n<td>平均海运价格增长</td>\n</tr>\n<tr>\n<td>营业成本(百万)</td>\n<td>4457</td>\n<td>4594</td>\n<td>(3.0)</td>\n<td>业务结构调整导致航运周转量下降</td>\n</tr>\n<tr>\n<td>毛利率(%)</td>\n<td>10.8</td>\n<td>5.0</td>\n<td>下降 5.8 个百分点</td>\n<td></td>\n</tr>\n<tr>\n<td>利润总额(百万)</td>\n<td>260</td>\n<td>100</td>\n<td>160.0</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2024 年航运分部单位运输成本为 0.030 元/吨海里（2023 年：0.028 元/吨海里），同比增长 7.1%，主要原因是航运周转量下降。从数字上看 运输总量少了，利润多了。</p>\n<h2 id=\"煤化工\"><a href=\"#煤化工\" class=\"headerlink\" title=\"煤化工\"></a>煤化工</h2><p>本集团煤化工分部为包头煤化工煤制烯烃项目，主要产品包括聚乙烯（生产能力约 30万吨/年），聚丙烯（生产能力约 30万吨/年）及少量副产品（包括工业硫磺、混合碳五、工业丙烷、混合碳四、工业用甲醇、精甲醇等）。2024 年，包头煤化工煤制烯烃升级示范项目（生产能力 75万吨/年）建设有序推进。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>物品</th>\n<th>2024 销售量(千吨)</th>\n<th>2024 价格(元/吨)</th>\n<th>2023 销售量(千吨)</th>\n<th>2023 价格（元/吨)</th>\n<th>销售量变动(%)</th>\n<th>价格变动(%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>聚乙烯</td>\n<td>332.2</td>\n<td>6645</td>\n<td>364.4</td>\n<td>6446</td>\n<td>(8.8)</td>\n<td>3.1</td>\n</tr>\n<tr>\n<td>聚丙烯</td>\n<td>313.6</td>\n<td>5896</td>\n<td>341.5</td>\n<td>5908</td>\n<td>(8.2)</td>\n<td>(0.2)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>经营成果</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>变动(%)</th>\n<th>主要变动原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>营业收入(百万)</td>\n<td>5633</td>\n<td>6098</td>\n<td>(7.6)</td>\n<td>煤制烯烃生产设备按计划检修，聚烯烃产品产量及销量下降</td>\n</tr>\n<tr>\n<td>营业成本(百万)</td>\n<td>5305</td>\n<td>5412</td>\n<td>(2.0)</td>\n<td>同上</td>\n</tr>\n<tr>\n<td>毛利率(%)</td>\n<td>5.8</td>\n<td>11.2</td>\n<td>下降 5.4 个百分点</td>\n<td></td>\n</tr>\n<tr>\n<td>利润总额(百万)</td>\n<td>37</td>\n<td>190</td>\n<td>(80.5)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2024 年，煤化工部共耗煤 4.6 百万吨（2023 年 4.9 百万吨），同步下降 6.1%,全部本集团内销售的煤炭（包括资产和采购）</p>\n<h2 id=\"煤电结合\"><a href=\"#煤电结合\" class=\"headerlink\" title=\"煤电结合\"></a>煤电结合</h2><p>公司本身有煤，也有火电，因此会有内部销售的情况，2024 年，发电分部共耗用本集团内部销售的煤炭（包括本集团自产煤和采购煤）73.6 百万吨（2023 年：73.2 百万吨），同比增长 0.5%。发电分部耗用本集团内部销售的煤炭量占发电分部耗煤总量 96.5 百万吨的 76.3%。  由于使用内部煤炭进行发电，在煤价波动或者电价波动的时候，可以有一定的缓冲。</p>\n<p>另外内部电厂和煤矿具体较近，因此运费成本也相对较低，自己的铁路运输自己的煤炭，整体的成本也更低。这里可能有几个原因：1）使用自有的运输路线，2）部分电厂和煤矿相对比较近。</p>\n<p>从年报中可知，煤矿和电厂的分布如下</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142515.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142515.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142704.png\" alt=\"\"></p>\n<p>运输成本如下所示</p>\n<blockquote>\n<p>其中自有成本包括铁路和港口，航运暂时没找到，这里计算的成本较实际可能偏高，由于航运整体的收入和成本不大，所以暂时不做进一步细化</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>运输成本</td>\n<td>55180(100%)</td>\n<td>52236(100%)</td>\n<td>50094(100%)</td>\n<td>58027(100%)</td>\n<td>51557(100%)</td>\n</tr>\n<tr>\n<td>自有成本*</td>\n<td>37041(67.12%)</td>\n<td>34681(66.39%)</td>\n<td>33226(66.32%)</td>\n<td>39319(67.75%)</td>\n<td>38304(74.29%)</td>\n</tr>\n<tr>\n<td>外部成本</td>\n<td>18139(32.87%)</td>\n<td>17555(33.60%)</td>\n<td>16868(33.67%)</td>\n<td>18708(32.24%)</td>\n<td>13253(25.70%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到，自有运输成本占 66% 以上，这部分在成本计算的时候会按照市价进行计算，但是实际不需要花这么多钱，仅需要花费运输路线的成本即可，因此整体的运输成本相对较低。 粗略估算整体的运输成本比其他公司要少 66% * (37% — 铁路的毛利率) ~ 24% 也就是卖同样的煤，单位运输成本可能会减少 20% 左右，这部分会成为整个公司的利润。</p>\n<p>接下来可以对比自产煤的利润率和外购煤的利润率，如下所示</p>\n<blockquote>\n<p>由于 2022 年以前，年报暂无外购煤和自产煤相关详细数据 — 2021 年报描述公司暂无法区分自产煤和外购煤相关数据，因此暂不纳入计算</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>自产煤（销售量）</td>\n<td>327</td>\n<td>325.4</td>\n<td>316.2</td>\n</tr>\n<tr>\n<td>外购煤（销售量）</td>\n<td>132</td>\n<td>124.6</td>\n<td>101.6</td>\n</tr>\n<tr>\n<td>自产煤（销售收入)</td>\n<td>172442</td>\n<td>178242</td>\n<td>188818</td>\n</tr>\n<tr>\n<td>外购煤（销售收入)</td>\n<td>86373</td>\n<td>84626</td>\n<td>80178</td>\n</tr>\n<tr>\n<td>自产煤（销售成本)</td>\n<td>95642</td>\n<td>95250</td>\n<td>93150</td>\n</tr>\n<tr>\n<td>外购煤（销售收入)</td>\n<td>86373</td>\n<td>84626</td>\n<td>80178</td>\n</tr>\n<tr>\n<td>外购煤（销售成本)</td>\n<td>84797</td>\n<td>82617</td>\n<td>77627</td>\n</tr>\n<tr>\n<td>自产煤（毛利率)</td>\n<td>44.5%</td>\n<td>46.6%</td>\n<td>50.7%</td>\n</tr>\n<tr>\n<td>外购煤（毛利率）</td>\n<td>1.8%</td>\n<td>2.4%</td>\n<td>3.2%</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到自产煤的毛利率远大于外购煤的毛利率，另外这部分既然不赚钱，为啥还要做生意呢？或许是为了维持运输线路，运输路线只要能同正常流转就能够赚钱（运输自己的煤可以减少开支，运输其他公司物品可以赚利润）</p>\n<p>从发电分部来说，现在有两个政策对火电相对较好：1）容量电价[2]；2）电价浮动[3]。第一个是说只要保证有相关的能力，就能有一定的收入（不管是否发电） — 但是需要电的时候要能保证提供，否则会扣费，甚至取消相关资格；第二个是电价会按市场需要波动，低峰更便宜，高峰更贵。</p>\n<p>由于公司内部有煤，有电，然后有容量电价，以及电价的浮动，那么在煤炭价格进行波动的时候，可以内部进行一定的缓冲，比如煤炭价格下跌的时候，可以适当的给内部发电部门供应更多的煤炭（这个有上限），然后发电分部可以通过多发电（甚至在高峰期多发电 — 这个查看调度优先级），这样可以把一部分由于煤炭降价导致收入转移到电力下游，一定程度的对冲价格的波动，整体的收入和利润会更平衡一些。后文我们会对具体的波动数值进行一个推演。</p>\n<p>这里可以分为 </p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>煤炭上涨</th>\n<th>煤价不变</th>\n<th>煤炭下跌</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>电价上涨</td>\n<td>(1)</td>\n<td>(2)</td>\n<td>(3)</td>\n</tr>\n<tr>\n<td>电价不变</td>\n<td>(4)</td>\n<td>(5)</td>\n<td>(6)</td>\n</tr>\n<tr>\n<td>电价下跌</td>\n<td>(7)</td>\n<td>(8)</td>\n<td>(9)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>这里我们需要重点关注的是 (9) 这个位置，也就是煤价和电价都下跌的情况，后续我们会对这个进行一些具体的推演</p>\n<h1 id=\"经营情况\"><a href=\"#经营情况\" class=\"headerlink\" title=\"经营情况\"></a>经营情况</h1><h2 id=\"现金流量以及分红\"><a href=\"#现金流量以及分红\" class=\"headerlink\" title=\"现金流量以及分红\"></a>现金流量以及分红</h2><p>公司业务挣的钱，可能会有一些资本开支，也可能会有分红，接下来我们看看业务收入，以及现金流量净额的流向如何</p>\n<p>2024 年经营活动产生的现金流净额 93348 百万，「购建固定资产、无形资产和其他长期资产支付的现金」是 37032 百万，两者剩余 56316 百万，预计分红 44903 百万，占净利润的 76.5%（2023 年 75.2%），可以看到现金流量是足够分红支出的。另外公司承诺 25-27 年承诺每年以现金方式分配的利润不少于本公司当年实现的归属本公司股东净利润的 65%，实际最近 3 年都高于 70%(2024 年 76.5%， 2023 年 75.2%，2022 年 72.8%)。 2022 - 2024 的三年股东回报规划，承诺以现金方式分配的利润不少于公司当年实现归母净利的 60%，</p>\n<p>公司 24 年经营现金流和 固定资产、无形资产等支持，分红的情况如下所示（单位百万）</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>经营活动产生的现金流量净额</td>\n<td>93348</td>\n<td>89687</td>\n<td>109734</td>\n<td>94575</td>\n<td>81289</td>\n</tr>\n<tr>\n<td>购建固定资产、无形资产和其他长期资产支付的现金</td>\n<td>37032(39.67%)</td>\n<td>37084(41.34%)</td>\n<td>28684(26.13%)</td>\n<td>23863(25.23%)</td>\n<td>20673(25.43%)</td>\n</tr>\n<tr>\n<td>分红</td>\n<td>44903(48.10%)</td>\n<td>44903(50.06%)</td>\n<td>50665(46.17%)</td>\n<td>50466(53.36%)</td>\n<td>35962(44.23%)</td>\n</tr>\n<tr>\n<td>剩余</td>\n<td>11413(12.22%)</td>\n<td>7700(8.58%)</td>\n<td>30385(27.68%)</td>\n<td>20246(21.40%)</td>\n<td>24654(30.32%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以从上表看出，经营活动的现金流净额减去固定资产、无形资产的投资后，是足够分红的（也就是「剩余」一栏都是正数），可见公司是有钱分红的。 从年报可以分析 2023 年「购建固定资产、无形资产和其他长期资产支付的现金」增加是因为有发电厂投产，2024 年「购建固定资产、无形资产和其他长期资产支付的现金」增加是因为在建工程的投入更多，后续可以持续观察看看，这部分看是否会有大幅度的投入。</p>\n<h2 id=\"合同负债和应收款\"><a href=\"#合同负债和应收款\" class=\"headerlink\" title=\"合同负债和应收款\"></a>合同负债和应收款</h2><p>我们来看看公司的合同负债，以及应收账款，这两部分表示公司已经收到下游的钱还未交付，或者已经交付还未收到钱。一定程度可以看出公司的议价权。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>合同负债</td>\n<td>4045</td>\n<td>7208</td>\n<td>5597</td>\n<td>6864</td>\n<td>5256</td>\n</tr>\n<tr>\n<td>应收账款</td>\n<td>12466</td>\n<td>11875</td>\n<td>10968</td>\n<td>10258</td>\n<td>7798</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到公司既有合同负债，又有应收账款，然后查看应收账款的相应情况如下</p>\n<p>按性质分</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>售电款</td>\n<td>7869</td>\n<td>7539</td>\n<td>6475</td>\n<td>4480</td>\n<td>3619</td>\n</tr>\n<tr>\n<td>售煤款</td>\n<td>2182</td>\n<td>2003</td>\n<td>1802</td>\n<td>3380</td>\n<td>1982</td>\n</tr>\n<tr>\n<td>售热款</td>\n<td>267</td>\n<td>319</td>\n<td>280</td>\n<td>217</td>\n<td>262</td>\n</tr>\n<tr>\n<td>其他</td>\n<td>3292</td>\n<td>3209</td>\n<td>3632</td>\n<td>3458</td>\n<td>3234</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>按账龄分析</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>账龄</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1 年以内</td>\n<td>12125(89%)</td>\n<td>11497(87%)</td>\n<td>10646(87%)</td>\n<td>9648(84%)</td>\n<td>7009(78%)</td>\n</tr>\n<tr>\n<td>1-2 年</td>\n<td>182(1%)</td>\n<td>253(2%)</td>\n<td>165(1%)</td>\n<td>155(1%)</td>\n<td>131(1%)</td>\n</tr>\n<tr>\n<td>2-3 年</td>\n<td>136(1%)</td>\n<td>56(1%)</td>\n<td>30(1%)</td>\n<td>87(1%)</td>\n<td>93(1%)</td>\n</tr>\n<tr>\n<td>&gt; 3年</td>\n<td>1167(9%)</td>\n<td>1264(10%)</td>\n<td>1348(11%)</td>\n<td>1645(14%)</td>\n<td>1864(20%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>应收账款金额前五的单位</p>\n<ul>\n<li>2024 <img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151023782.png\" alt=\"\"></li>\n<li>2023 <img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115102144.png\" alt=\"\"></li>\n<li>2022 <img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115102413.png\" alt=\"\"></li>\n<li>2021  <img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151018170.png\" alt=\"\"></li>\n<li>2020 <img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115101901.png\" alt=\"\"></li>\n</ul>\n<p>可以看到应收账款主要在「售电」，主要是电力公司，主要在一年以内，这个应该是和结算周期有关，可以推测煤炭分部有一定的合同负债，从这个来看，相对来说煤炭分部有一定的议价权</p>\n<p>接下来我们单独看煤炭分部的应收账款于营业收入的比值，一定程度看议价能力的变动，如果「应收账款」/「营业收入」变大，表示议价能力变弱，否则变高</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>应收账款</td>\n<td>2182</td>\n<td>2003</td>\n<td>1802</td>\n<td>3380</td>\n<td>1982</td>\n</tr>\n<tr>\n<td>营业收入</td>\n<td>268618</td>\n<td>273306</td>\n<td>277474</td>\n<td>292661</td>\n<td>292661</td>\n</tr>\n<tr>\n<td>比值</td>\n<td>0.81%</td>\n<td>0.73%</td>\n<td>0.64%</td>\n<td>1.15%</td>\n<td>0.67%</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看出来 2021 年的比值超过 1%，其他几年都低于 1%。搜了下，发现 2021 年刚好是煤炭价格下跌的一年，这个能对应上，煤炭下跌，行情不好，应收账款变的更多了。</p>\n<h2 id=\"和煤炭公司，电力公司的部分对比\"><a href=\"#和煤炭公司，电力公司的部分对比\" class=\"headerlink\" title=\"和煤炭公司，电力公司的部分对比\"></a>和煤炭公司，电力公司的部分对比</h2><p>中国神华在于煤电、运输等一体化运营，我们也来对比下和煤炭公司、电力公司在不同指标上的情况，有一个直观的对比和了解。我们选择 毛利率、ROE 以及资产负债率这三个指标，其中毛利率表示生意模式是否优秀，ROE 表示资产回报率，资产负债率则表示抗极限风险的能力。</p>\n<p>毛利率</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2016</th>\n<th>2017</th>\n<th>2018</th>\n<th>2019</th>\n<th>2020</th>\n<th>2021</th>\n<th>2022</th>\n<th>2023</th>\n<th>2024</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>陕西煤业</td>\n<td>43.39</td>\n<td>55.40</td>\n<td>48.69</td>\n<td>40.93</td>\n<td>27.46</td>\n<td>35.84</td>\n<td>44.99</td>\n<td>37.86</td>\n<td>32.69</td>\n</tr>\n<tr>\n<td>华能国际</td>\n<td>21.43</td>\n<td>11.31</td>\n<td>11.30</td>\n<td>12.5</td>\n<td>14.5</td>\n<td>17.4</td>\n<td>-0.33</td>\n<td>3.04</td>\n<td>12.11</td>\n</tr>\n<tr>\n<td>中国神华</td>\n<td>39.5</td>\n<td>42.1</td>\n<td>41.1</td>\n<td>36.7</td>\n<td>36.4</td>\n<td>32.9</td>\n<td>39.03</td>\n<td>35.89</td>\n<td>34.04</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>ROE</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2021</th>\n<th>2022</th>\n<th>2023</th>\n<th>2024</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>陕西煤业</td>\n<td>24.03</td>\n<td>33.3</td>\n<td>20.64</td>\n<td>21.32</td>\n</tr>\n<tr>\n<td>华能国际</td>\n<td>-10.29</td>\n<td>-8.92</td>\n<td>4.28</td>\n<td>5.14</td>\n</tr>\n<tr>\n<td>中国神华</td>\n<td>13.82</td>\n<td>18.77</td>\n<td>15.99</td>\n<td>14.97</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>资产负债率</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2020</th>\n<th>2021</th>\n<th>2022</th>\n<th>2023</th>\n<th>2024</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>陕西煤业</td>\n<td>39.78%</td>\n<td>60.82%</td>\n<td>60.19%</td>\n<td>62.99%</td>\n<td>63.35%</td>\n</tr>\n<tr>\n<td>华能国际</td>\n<td>67.71%</td>\n<td>74.68%</td>\n<td>74.82%</td>\n<td>68.33%</td>\n<td>65.40%</td>\n</tr>\n<tr>\n<td>中国神华</td>\n<td>23.9%</td>\n<td>26.6%</td>\n<td>26.1%</td>\n<td>24.1%</td>\n<td>23.4%</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>对于 ROE 这一项，我们可以再继续进行细分，查看「销售净利率」、「资产周转率」以及「权益系数」的相关数值，其中「销售净利率」表示赚钱多狠，资产周转率表示公司跑的多块，权益系数表示杠杆有多高</p>\n<p>销售净利率</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>神华</td>\n<td>17.3</td>\n<td>17.3</td>\n<td>20.2</td>\n<td>14.9</td>\n<td>16.7</td>\n</tr>\n<tr>\n<td>陕西煤业</td>\n<td>12.14</td>\n<td>6.2</td>\n<td>21</td>\n<td>14</td>\n<td>15.6</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>资产周转率</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>神华</td>\n<td>52.53</td>\n<td>54.80</td>\n<td>56.08</td>\n<td>57.52</td>\n<td>41.76</td>\n</tr>\n<tr>\n<td>陕西煤业</td>\n<td>79.28</td>\n<td>72.99</td>\n<td>79.91</td>\n<td>91.02</td>\n<td>68.5</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>权益乘数</p>\n<blockquote>\n<p>使用公式 = 1/ (1 - 资产负债率)</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>神华</td>\n<td>1.3</td>\n<td>1.31</td>\n<td>1.35</td>\n<td>1.36</td>\n<td>1.31</td>\n</tr>\n<tr>\n<td>陕西煤业</td>\n<td>2.7</td>\n<td>2.7</td>\n<td>2.51</td>\n<td>2.55</td>\n<td>2.51</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以从上面的图表中看到，神华和陕西煤业比较，销售净利率相对还是比较好的，资产周转率不如，，然后杠杆率比较低。其中对于杠杆率来说，虽然可能借到很便宜的钱，杠杆可以放大收益，但是在行情不好的时候，风险也会被放大，因此这个也变相的体现抗风险能力</p>\n<h1 id=\"风险\"><a href=\"#风险\" class=\"headerlink\" title=\"风险\"></a>风险</h1><p>对于神华来说，针对不同的业务，会有不同的风险，比如</p>\n<ul>\n<li>对于煤炭生意来说：1）最大的风险在于新能源的推广，这块由于现在储能上还不太能跟上，因此煤炭作为资源压舱石还一直在使用，但是未来如果储能有重大进展的话，则新能源可能会大幅替代火电；2）是否可能对煤炭企业或者火电企业收取「碳」相关的税，从而促进能源转型；3）作为国企，在煤炭涨价的时候，是否需要承受更多的社会责任，对本公司的利益是否有影响。</li>\n<li>对于电力生意来说：1）火电是否会被新能源发电去掉；2）现在的电价方式是否会发生变化</li>\n<li>对于铁路来说：如果不需要允许这么多煤，那么能否比较快速的转运其他非煤物品</li>\n</ul>\n<p>我们可以知道这些都和火电有关，那么我们通过国家能源官网[4]的装机信息来看，不同类系发电的装机情况，火电的装机情况暂时还行，斜率是往上的</p>\n<p>2025 全国不同类型装机容量新增数，可以用 (1-3) - (1-2) 获得 3 月新增</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目(万千瓦)</th>\n<th>1-2</th>\n<th>1-3月</th>\n<th>1-4 月</th>\n<th>1-5</th>\n<th>1-6</th>\n<th>1-7</th>\n<th>1-8</th>\n<th>1-9</th>\n<th>1-10</th>\n<th>1-11</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>水电</td>\n<td>191</td>\n<td>213</td>\n<td>265</td>\n<td>325</td>\n<td>393</td>\n<td>589</td>\n<td>684</td>\n<td>716</td>\n<td>835</td>\n<td>912</td>\n</tr>\n<tr>\n<td>火电</td>\n<td>388</td>\n<td>925</td>\n<td>1298</td>\n<td>1755</td>\n<td>2578</td>\n<td>4198</td>\n<td>4987</td>\n<td>5668</td>\n<td>6508</td>\n<td>7752</td>\n</tr>\n<tr>\n<td>核电</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>153</td>\n<td>153</td>\n</tr>\n<tr>\n<td>风电</td>\n<td>928</td>\n<td>1462</td>\n<td>1996</td>\n<td>4628</td>\n<td>5139</td>\n<td>5367</td>\n<td>5784</td>\n<td>6109</td>\n<td>7001</td>\n<td>8250</td>\n</tr>\n<tr>\n<td>太阳能发电</td>\n<td>3947</td>\n<td>5971</td>\n<td>10493</td>\n<td>19785</td>\n<td>21221</td>\n<td>22325</td>\n<td>23061</td>\n<td>24027</td>\n<td>25287</td>\n<td>27489</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>相关图形如下所示（可以观察斜率表示增长率）</p>\n\n<div id=\"echarts1019\" style=\"width: 85%;height:400px;margin: 0 auto\"></div>\n<script src=\"https://unpkg.com/echarts@5.6.0/dist/echarts.min.js\" ></script>\n<script >\n  if (window.eChartecharts1019ResizeHandler) {\n    window.removeEventListener(\"resize\", eChartecharts1019ResizeHandler);\n  }\n  var optionecharts1019 = option = {\n  title: {\n    text: '新增装机量'\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  legend: {\n    data: ['水电', '火电', '核电', '风电', '太阳能']\n  },\n  grid: {\n    left: '3%',\n    right: '4%',\n    bottom: '3%',\n    containLabel: true\n  },\n  toolbox: {\n    feature: {\n      saveAsImage: {}\n    }\n  },\n  xAxis: {\n    type: 'category',\n    boundaryGap: false,\n    data: ['2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n  },\n  yAxis: {\n    type: 'value'\n  },\n  series: [\n    {\n      name: '水电',\n      type: 'line',\n\n      data: [191, 213, 265, 325, 393, 589, 684, 716, 835, 912]\n    },\n    {\n      name: '火电',\n      type: 'line',\n\n      data: [388, 925, 1298, 1755, 2578, 4198, 4987, 5668, 6500, 7752]\n    },\n    {\n      name: '核电',\n      type: 'line',\n\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 153, 153]\n    },\n    {\n      name: '风电',\n      type: 'line',\n\n      data: [928, 1462, 1996, 4628, 5139, 5367, 5784, 6109, 7001, 8250]\n    },\n    {\n      name: '太阳能',\n      type: 'line',\n\n      data: [3947, 5971, 10493, 19785, 21221, 22325, 23061, 24027, 25287, 27489]\n    }\n  ]\n};;\n  if (window.echarts !== undefined) {\n    var eChartecharts1019 = echarts.init(document.getElementById('echarts1019'));\n    eChartecharts1019.setOption(optionecharts1019);\n    var eChartecharts1019ResizeHandler = function() {\n      eChartecharts1019.resize();\n    };\n    window.addEventListener(\"resize\", eChartecharts1019ResizeHandler);\n  }\n</script>\n<h1 id=\"神华自己的价值\"><a href=\"#神华自己的价值\" class=\"headerlink\" title=\"神华自己的价值\"></a>神华自己的价值</h1><p>首先我们对神华进行公司的价值估算，这样可以和现在的市值进行比较。我们根据不同业务的综合进行估值</p>\n<ul>\n<li>其中煤炭现在保有量 343.6 亿吨，按照现在均价 584 元/吨，总价在 20 万亿。如果按照 300 百万吨一年的销量，大概一年营收 1755 亿，然后按照 5% 左右的折旧率，以及计算 50 年的话，大概总价值 3万亿，按照 30% 的利润率，则总价在在 1万亿左右。</li>\n<li>现在铁路总共 2408 公里，按照修建铁路 1 公里的成本大约在 1.5 亿左右，就算不再使用，也可以进行售卖，这块的价值 3600 亿左右</li>\n<li>电厂的价值估算，现在总共有 4万兆瓦的装机容量，目前新建的成本大概在 3500 元/千瓦，则重估的价值等于 1400 亿</li>\n<li>另外还有港口和航运等这些资产</li>\n</ul>\n<p>可以发现整个神华的资产是肯定超过现在的市值 8300 亿的。因此现在的市值是相对比较便宜的。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] 华源证券 煤炭行业中期策略报告 (2025.06.27)<br>[2] <a href=\"https://www.ndrc.gov.cn/xxgk/zcfb/tz/202311/t20231110_1361897.html\">https://www.ndrc.gov.cn/xxgk/zcfb/tz/202311/t20231110_1361897.html</a><br>[3] <a href=\"https://www.ndrc.gov.cn/xxgk/zcfb/tz/202110/t20211012_1299461.html\">https://www.ndrc.gov.cn/xxgk/zcfb/tz/202110/t20211012_1299461.html</a><br>[4] <a href=\"https://www.nea.gov.cn/20251026/70d3b88f62f1401bbe47a8212e06ad8e/c.html\">https://www.nea.gov.cn/20251026/70d3b88f62f1401bbe47a8212e06ad8e/c.html</a></p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>中国神华的情况，数据主要以 2024 年年报为主</p>\n</blockquote>\n<h1 id=\"股东以及相关关系\"><a href=\"#股东以及相关关系\" class=\"headerlink\" title=\"股东以及相关关系\"></a>股东以及相关关系</h1><p>整体的控股关系如下图所示</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151952893.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151953271.png\" alt=\"\"></p>","more":"<h1 id=\"业务基本情况\"><a href=\"#业务基本情况\" class=\"headerlink\" title=\"业务基本情况\"></a>业务基本情况</h1><p>公司包括多个部门，煤炭生产→煤炭运输 （铁路、 港口、 航运） →煤炭转化 （发<br>电及煤化工）的一体化产业链，各分部之间存在业务往来，比如本公司的煤炭供给给发电部门，然后途中会使用本公司的铁路/航运等进行运行。</p>\n<p>其中按照 2024 年的情况，不同分部的营收毛利如下所示</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>分行业</th>\n<th>营业收入（百万）</th>\n<th>营业成本（百万)</th>\n<th>毛利率(%)</th>\n<th>营业收入比上年增减(%)</th>\n<th>营业成本比上年增减 (%)</th>\n<th>毛利率比上年增减(%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>煤炭</td>\n<td>268618</td>\n<td>188066</td>\n<td>30.0</td>\n<td>(1.7)</td>\n<td>1.2</td>\n<td>(2.0)</td>\n</tr>\n<tr>\n<td>发电</td>\n<td>94217</td>\n<td>78832</td>\n<td>16.3</td>\n<td>2.0</td>\n<td>2.7</td>\n<td>(0.6)</td>\n</tr>\n<tr>\n<td>铁路</td>\n<td>43115</td>\n<td>26819</td>\n<td>37.8</td>\n<td>0.4</td>\n<td>(0.9)</td>\n<td>0.8</td>\n</tr>\n<tr>\n<td>港口</td>\n<td>6842</td>\n<td>4058</td>\n<td>40.7</td>\n<td>1.4</td>\n<td>8.1</td>\n<td>(3.7)</td>\n</tr>\n<tr>\n<td>航运</td>\n<td>4996</td>\n<td>4457</td>\n<td>10.8</td>\n<td>3.3</td>\n<td>(3.0)</td>\n<td>5.8</td>\n</tr>\n<tr>\n<td>煤化工</td>\n<td>5633</td>\n<td>5305</td>\n<td>5.8</td>\n<td>(7.6)</td>\n<td>(2.0)</td>\n<td>(5.4)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到其中煤炭占比最多，营业收入占 63.4%，发电占 22.25%，铁路占 10.18% 其他的占 5% 左右。</p>\n<p>公司不同分部之间也有交易，比如煤炭分部会卖煤给发电部门，同时会使用自己铁路分部的铁路进行运输等，</p>\n<p>20204 年的分部间交易如下</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>分部业绩</th>\n<th>煤炭</th>\n<th>发电</th>\n<th>铁路</th>\n<th>港口</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>对外交易收入</td>\n<td>223753</td>\n<td>94012</td>\n<td>11120</td>\n<td>1796</td>\n</tr>\n<tr>\n<td>分部间交易收入</td>\n<td>44865</td>\n<td>205</td>\n<td>31995</td>\n<td>5046</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看出来，煤炭供给给内部 16.7%(其中电力部门 16%，煤化工分部 0.7%)，外部占比 83.3% 主要还是销往外部；发电部门供给给内部占 0.2% 基本可以忽略，铁路部分供给给内部占 74.2% 外部占 25.8%，港口内部占 73.7% 外部占比 26.3%； 可以看出，煤炭、发电主要是供给外部，运输（铁路/港口）主要还是内部使用。</p>\n<h2 id=\"煤炭\"><a href=\"#煤炭\" class=\"headerlink\" title=\"煤炭\"></a>煤炭</h2><blockquote>\n<p>煤炭行业来看，我国经济增长将持续拉动能源需求，煤炭作为全球最重要的能源来源之一， 尽管面临着可再生能源、 低碳发展和环保要求的多重挑战， 在可预见的未来市场中依旧扮演着关键角色。 预计电力和化工用煤是煤炭消费的主要增量来源。 煤炭产量预计总体保持稳定。进口煤价格优势缩小，进口煤量或小幅减少。总体来看，2025年煤炭市场供需向平衡偏宽松方向发展， 市场煤占比增加， 煤炭市场价格中枢或小幅下降，稳定在合理区间。受季节性波动、突发事件等因素影响，局部地区、部分时段可能出现供应偏紧的局面</p>\n</blockquote>\n<p>煤炭现在有两类销售：第一个是通过销售集团销售，主要是第一个，共有三种：年度长协，月度长协，以及现货；第二个就是煤矿坑口直接销售，整体占比 5% 以内。其中</p>\n<p>2024 年不同类型的销售情况如下</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>销售量(百万吨)</th>\n<th>占比 (%)</th>\n<th>价格(不含税)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>年度长协</td>\n<td>246.4</td>\n<td>53.6</td>\n<td>491</td>\n</tr>\n<tr>\n<td>月度长协</td>\n<td>154.8</td>\n<td>33.7</td>\n<td>705</td>\n</tr>\n<tr>\n<td>现货</td>\n<td>36.2</td>\n<td>7.9</td>\n<td>627</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>现在的煤炭包括自产煤，以及外购煤，成本包括：采掘成本，销售成本，运输成本，加工和管理，热值换算等成本。<br>其中 2024 年的自产煤采掘成本是 179 元/吨，然后根据 [1] 预测的完全成本，中国神华（蒙西坑口到秦皇岛）完全成本是 640 元/吨左右（其中运费估算 250元/吨，陕西动力煤的运费成本在 200 元/吨左右，陕西动力煤的运输成本在 230 元/吨左右），由于中国神华的运输会使用自己的铁路/港口等，因此运费会更低一些，按照煤炭分部的运输成本计算，则平均运输成本 = 总平均运输成本/总销量 = 55180百万/459.3百万吨 = 120.13934248 元/吨，可见神华的平均运输成本比市场要便宜大几十/吨。</p>\n<p>其中热值换算，是因为中国煤的情况：北多南少，西多东少，然后从北方运往其他地方的时候，一般会用秦皇岛港口，所以市场往往会以秦皇岛 5500 大卡的价格计算，但是如果煤的热力值和 5500 不同，就需要进行换算</p>\n<p>煤炭的采掘量以及储量如下所示，2024 年产量 327.1 百万吨，销售 459.3 百万吨，对前五大外部煤炭客户销售量为 192.4 百万吨，占煤炭销售总量的 41.9%，其中对最大客户国家能源接团的煤炭销售为 164.9 百万吨，占煤炭销售总量的 35.9%，整体储量如下所示</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>内外部客户</th>\n<th>销售量(百万吨)</th>\n<th>占销售量比例 (%)</th>\n<th>价格(不含税) 元/ 吨</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>对外部客户销售</td>\n<td>381.2</td>\n<td>83.0</td>\n<td>573</td>\n</tr>\n<tr>\n<td>对内部发电分部销售</td>\n<td>73.5</td>\n<td>16.0</td>\n<td>523</td>\n</tr>\n<tr>\n<td>对内部煤化工分部销售</td>\n<td>4.6</td>\n<td>1.0</td>\n<td>424</td>\n</tr>\n<tr>\n<td>销售量合计/平均价格（不含税)</td>\n<td>459.3</td>\n<td>100</td>\n<td>564</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>从这里看电力部分消耗内部煤炭 16%</p>\n<p>煤炭的保有量 343.6 亿吨，较上一年增加 17.8 亿吨，煤炭保有可采储量 150.9 亿吨，较上一年增加 17.1 亿吨；JORC 标准下本集团的煤炭可售储量为 105.1 亿吨，较上一年增加 10.3 亿吨，不同矿区的保有量，以及相关信息如下</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>矿区</th>\n<th>保有资源量（中国标准）</th>\n<th>保有可采储量（中国标准）</th>\n<th>证实储量（中国标准）</th>\n<th>可信储量（中国标准）</th>\n<th>煤炭可售储量（JORC标准）</th>\n<th>主要煤种</th>\n<th>主要商品煤的发热量（千克/千克)</th>\n<th>硫分(%)</th>\n<th>灰分(%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>神东矿区</td>\n<td>158.0</td>\n<td>89.7</td>\n<td>18.7</td>\n<td>36.6</td>\n<td>65.4</td>\n<td>长焰煤/不粘煤</td>\n<td>4720-5730</td>\n<td>0.2-0.6</td>\n<td>8.4-19.4</td>\n</tr>\n<tr>\n<td>新街台格庙矿区</td>\n<td>110.1</td>\n<td>14.0</td>\n<td>6.2</td>\n<td>4.5</td>\n<td>9.4</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>准格尔矿区</td>\n<td>40.3</td>\n<td>29.2</td>\n<td>8.9</td>\n<td>9.7</td>\n<td>21.3</td>\n<td>长焰煤</td>\n<td>4409 -4744</td>\n<td>0.4-0.6</td>\n<td>25.0-29.8</td>\n</tr>\n<tr>\n<td>胜利矿区</td>\n<td>22.3</td>\n<td>10.2</td>\n<td>2.2</td>\n<td>5.4</td>\n<td>1.9</td>\n<td>褐煤</td>\n<td>2980</td>\n<td>1.1</td>\n<td>23.8</td>\n</tr>\n<tr>\n<td>宝日希勒矿区</td>\n<td>12.5</td>\n<td>7.5</td>\n<td>1.4</td>\n<td>4.2</td>\n<td>7.0</td>\n<td>褐煤</td>\n<td>3551</td>\n<td>0.2</td>\n<td>13.9</td>\n</tr>\n<tr>\n<td>包头矿区</td>\n<td>0.4</td>\n<td>0.3</td>\n<td>0.1</td>\n<td>0.0</td>\n<td>0.1</td>\n<td>长焰煤/不粘煤</td>\n<td>4073-4399</td>\n<td>0.5-1.0</td>\n<td>14.1 -18.3</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"电力\"><a href=\"#电力\" class=\"headerlink\" title=\"电力\"></a>电力</h2><blockquote>\n<p>电力行业来看，综合考虑我国目前阶段经济增长潜力、“十四五”规划和国家宏观调控政策措施等因素，根据中国电力企业联合会预测结果，预计 2025 年全国全社会用电量同比增长 6%左右。新能源装机持续增长，部分地区新能源消纳压力凸显。预计2025 年底煤电占总装机比重将降至三分之一。综合考虑电力消费需求增长、电源投产等情况，预计 2025 年迎峰度夏等用电高峰期部分地区电力供需形势紧平衡</p>\n</blockquote>\n<p>全年总售电量 210.28 十亿千瓦时，占同期占社会用电量 98521 亿千瓦时的 2.1%， 其中市场交易电量达 205.20 十亿千瓦时，占总售电量的 97.6%；平均售电价格 403元/兆瓦时（2023 年 414 元/兆瓦时），本集团享有获取容量电费资格的国内煤电机组共 68 台，约占本集团国内煤电机组总数的 94%，2024 年共获取容量电费约 50 亿元（含税）。</p>\n<p>本集团火电供电标准煤耗降至 292.9 可/千瓦时（2023 年 294.9 克/千瓦时）</p>\n<p>本集团加大可再生能源项目开发和产业基金投资。本集团充分利用露天矿排土场、复垦区、铁路沿线闲置用地等土地资源投资建设光伏项目，2024 年新增对外商业运营的光伏发电装机容量合计 366 兆瓦。</p>\n<p>本集团发电机组总装机容量 46264 兆瓦，其中燃煤发电机组总装机容量 43184 兆瓦，约占全国煤电发电装机容量 11.9 亿千瓦的 3.6%。</p>\n<p>不同类型的电源情况如下所示</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>电源种类</th>\n<th>2024 年 12 月 31 日总装机容量</th>\n<th>2023 年 12 月 31 日 总装机容量</th>\n<th>新增</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>燃煤发电</td>\n<td>43184</td>\n<td>43164</td>\n<td>20</td>\n</tr>\n<tr>\n<td>燃气发电</td>\n<td>2194</td>\n<td>950</td>\n<td>1244</td>\n</tr>\n<tr>\n<td>水电</td>\n<td>125</td>\n<td>125</td>\n<td>0</td>\n</tr>\n<tr>\n<td>光伏发电</td>\n<td>761</td>\n<td>395</td>\n<td>366</td>\n</tr>\n<tr>\n<td>合计</td>\n<td>46264</td>\n<td>44634</td>\n<td>1630</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>本集团燃煤发电机组平均利用小时达 5030 小时，同比减少 191 小时，比全国 6000 千瓦及以上的电厂燃煤发电设备平均利用小时数 4628 小时高 402 小时，利用小时比平均高，表示有一定的调度优先级（后续可以持续观察利用小时数于平均利用小时数的相对情况）。另外2024 年整体的「6000 千瓦及以上电厂发电设备利用小时」 3442（全年累计），同比减少 157 小时，全国线路损失率 4.37%，同比减少 0.17%</p>\n<p>本集团具体发电利用小时如下</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>电源种类</th>\n<th>平均利用小时(2024)</th>\n<th>平均利用小时(2023)</th>\n<th>变动 (%)</th>\n<th>发电厂用电率(%)(2024)</th>\n<th>发电厂用电率(203)</th>\n<th>变动</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>燃煤发电(含矸石电厂)</td>\n<td>5030</td>\n<td>5221</td>\n<td>(3.7)</td>\n<td>5.07</td>\n<td>5.20</td>\n<td>下降 0.13 个百分点</td>\n</tr>\n<tr>\n<td>燃气发电</td>\n<td>4151</td>\n<td>4152</td>\n<td>(0.0)</td>\n<td>1.66</td>\n<td>1.56</td>\n<td>上升 0.10 个百分点</td>\n</tr>\n<tr>\n<td>水电</td>\n<td>5097</td>\n<td>5228</td>\n<td>(2.5)</td>\n<td>0.63</td>\n<td>0.28</td>\n<td>上升 0.35 个百分点</td>\n</tr>\n<tr>\n<td>光伏发电</td>\n<td>1317</td>\n<td>905</td>\n<td>45.5</td>\n<td>1.03</td>\n<td>/</td>\n<td>/</td>\n</tr>\n<tr>\n<td>加权平均</td>\n<td>4960</td>\n<td>5167</td>\n<td>(4.0)</td>\n<td>4.98</td>\n<td>5.11</td>\n<td>下降 0.13 个百分点</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>电力市场化交易 </p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>变动 (%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>市场化交易的总电量(十亿千瓦时)</td>\n<td>205.2</td>\n<td>194.56</td>\n<td>5.5</td>\n</tr>\n<tr>\n<td>总上网电量（十亿千瓦时)</td>\n<td>210.28</td>\n<td>199.75</td>\n<td>5.3</td>\n</tr>\n<tr>\n<td>市场化交易电量占比 (%)</td>\n<td>97.6</td>\n<td>97.4</td>\n<td>上升 0.2 个百分点</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2024 年 发电分部共耗本集团内部销售的煤炭（包括本集团自产煤和采购没）73.6 百万吨（2023 年 73.2 百万吨) 同比增长 0.5%，发电分部耗用本集团内部销售的煤炭量占发电分部耗煤总量 96.5 百万吨的 76.3%，消耗煤炭的绝大部分已经从内部供给。</p>\n<h2 id=\"铁路\"><a href=\"#铁路\" class=\"headerlink\" title=\"铁路\"></a>铁路</h2><p>铁路分部紧密服务一体化运营和产业链发展，进一步拓展”大一体化”优势，建立高效协同的运输生产生态系统，本集团2024 年自由铁路运输周转量达 312.1 十亿吨公里（2023 年：309.4 十亿吨公里），同比增长 0.9%。  神朔铁路 3 亿吨扩能改造工程有序推进，成功研制出氢能源动力调车机车和氢能源动力接触网作业车等核心装备。巴准铁路暖水集运站铁路专用线、三道渠铁路专用线顺利开通，设计装车能力 2000 万吨/年。</p>\n<p>2024 年，本集团完成金属矿石、化工品等非煤货物运量 24.5 百万吨（2023 年：22.3 百万吨），同比增长 9.9%，其中反向非煤货物运输 18.8 百万吨。</p>\n<p>营业情况</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>变动(%)</th>\n<th>主要变动原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>营业收入(百万)</td>\n<td>43115</td>\n<td>42961</td>\n<td>0.4</td>\n<td>自有铁路运输周转量增长</td>\n</tr>\n<tr>\n<td>营业成本(百万)</td>\n<td>26819</td>\n<td>27059</td>\n<td>(0.9)</td>\n<td>受检修计划影响，修理费同比减少</td>\n</tr>\n<tr>\n<td>毛利率(%)</td>\n<td>37.8</td>\n<td>37.0</td>\n<td>上升 0.8 个百分点</td>\n<td></td>\n</tr>\n<tr>\n<td>利润总额(百万)</td>\n<td>12562</td>\n<td>11039</td>\n<td>13.8</td>\n<td>资产减值损失同比减少</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2024 年，铁路分部单位运输成本为 0.081 元/吨公里（2023 年：0.085 元/吨公里），同比下降 4.7%，主要原因是受检修计划影响，修理费同比减少</p>\n<h2 id=\"港口\"><a href=\"#港口\" class=\"headerlink\" title=\"港口\"></a>港口</h2><p>本集团港口分部深化内外协同合作，完善港航协同联动机制，精简装卸流程，报销组织生产。2024 年，黄骅港完成装船量 214.4 百万吨（2023:209.5 百万吨），同比增长 2.3%，连续 6 年位居“北煤南运”港口首位，散杂货吞吐量完成 8.2 百万吨，创开港以来最好水平。天津煤码头完成装船量 44.0 百万吨（2023 年：45.8 百万吨），同比下降 3.9%。</p>\n<p>加快推进多功能、综合性、现代化港口建设。黄骅港（煤炭港区）五期工程（规划煤炭下水量 5,000 万吨/年）、天津港务二期工程（设计年通过能力煤炭 3,500 万吨、矿石 1,800 万吨）获得核准批复；黄骅港（煤炭港区）油品码头工程、珠海港高栏港区国能散货码头工程开工建设；珠海港务 2 号、3 号卸船泊位升级，满足 15 万吨级船舶满载通航条件</p>\n<p>黄骅港构建覆盖煤港生产全过程的长效抑尘系统、生态环境智能管控系统及“两湖三湿地”生态水循环系统，抑尘率达到 98%，年节约淡水 400 万立方米以上；</p>\n<p>经营成果</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>变动(%)</th>\n<th>主要变动原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>营业收入(百万)</td>\n<td>6842</td>\n<td>6749</td>\n<td>1.4</td>\n<td>港口装船量增长</td>\n</tr>\n<tr>\n<td>营业成本(百万)</td>\n<td>4058</td>\n<td>3754</td>\n<td>8.1</td>\n<td>航道疏浚费等增长；港口装船量增长</td>\n</tr>\n<tr>\n<td>毛利率(%)</td>\n<td>40.7</td>\n<td>44.4</td>\n<td>下降 3.7 个百分点</td>\n<td></td>\n</tr>\n<tr>\n<td>利润总额(百万)</td>\n<td>2122</td>\n<td>2301</td>\n<td>(7.8)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2024 年港口分部单位运输成本为 13.1 元/吨（2023 年：12.5 元/吨），同比增长 4.8%，主要原因是航道疏浚费等增长。</p>\n<h2 id=\"航运\"><a href=\"#航运\" class=\"headerlink\" title=\"航运\"></a>航运</h2><p>2024 年完成航运货运量 129.9 百万吨（2023年：152.9百万吨），同比下降 15%，完成航运周转量 149.4 十亿吨海里（2023年：164.7十亿吨海里），同比下降 9.3%，完成非煤运输量 4.4 百万吨（2023 年：3.7 百万吨），同比增长 18.9%</p>\n<p>经营成果</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>变动(%)</th>\n<th>主要变动原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>营业收入(百万)</td>\n<td>4996</td>\n<td>4836</td>\n<td>3.3</td>\n<td>平均海运价格增长</td>\n</tr>\n<tr>\n<td>营业成本(百万)</td>\n<td>4457</td>\n<td>4594</td>\n<td>(3.0)</td>\n<td>业务结构调整导致航运周转量下降</td>\n</tr>\n<tr>\n<td>毛利率(%)</td>\n<td>10.8</td>\n<td>5.0</td>\n<td>下降 5.8 个百分点</td>\n<td></td>\n</tr>\n<tr>\n<td>利润总额(百万)</td>\n<td>260</td>\n<td>100</td>\n<td>160.0</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2024 年航运分部单位运输成本为 0.030 元/吨海里（2023 年：0.028 元/吨海里），同比增长 7.1%，主要原因是航运周转量下降。从数字上看 运输总量少了，利润多了。</p>\n<h2 id=\"煤化工\"><a href=\"#煤化工\" class=\"headerlink\" title=\"煤化工\"></a>煤化工</h2><p>本集团煤化工分部为包头煤化工煤制烯烃项目，主要产品包括聚乙烯（生产能力约 30万吨/年），聚丙烯（生产能力约 30万吨/年）及少量副产品（包括工业硫磺、混合碳五、工业丙烷、混合碳四、工业用甲醇、精甲醇等）。2024 年，包头煤化工煤制烯烃升级示范项目（生产能力 75万吨/年）建设有序推进。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>物品</th>\n<th>2024 销售量(千吨)</th>\n<th>2024 价格(元/吨)</th>\n<th>2023 销售量(千吨)</th>\n<th>2023 价格（元/吨)</th>\n<th>销售量变动(%)</th>\n<th>价格变动(%)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>聚乙烯</td>\n<td>332.2</td>\n<td>6645</td>\n<td>364.4</td>\n<td>6446</td>\n<td>(8.8)</td>\n<td>3.1</td>\n</tr>\n<tr>\n<td>聚丙烯</td>\n<td>313.6</td>\n<td>5896</td>\n<td>341.5</td>\n<td>5908</td>\n<td>(8.2)</td>\n<td>(0.2)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>经营成果</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>变动(%)</th>\n<th>主要变动原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>营业收入(百万)</td>\n<td>5633</td>\n<td>6098</td>\n<td>(7.6)</td>\n<td>煤制烯烃生产设备按计划检修，聚烯烃产品产量及销量下降</td>\n</tr>\n<tr>\n<td>营业成本(百万)</td>\n<td>5305</td>\n<td>5412</td>\n<td>(2.0)</td>\n<td>同上</td>\n</tr>\n<tr>\n<td>毛利率(%)</td>\n<td>5.8</td>\n<td>11.2</td>\n<td>下降 5.4 个百分点</td>\n<td></td>\n</tr>\n<tr>\n<td>利润总额(百万)</td>\n<td>37</td>\n<td>190</td>\n<td>(80.5)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>2024 年，煤化工部共耗煤 4.6 百万吨（2023 年 4.9 百万吨），同步下降 6.1%,全部本集团内销售的煤炭（包括资产和采购）</p>\n<h2 id=\"煤电结合\"><a href=\"#煤电结合\" class=\"headerlink\" title=\"煤电结合\"></a>煤电结合</h2><p>公司本身有煤，也有火电，因此会有内部销售的情况，2024 年，发电分部共耗用本集团内部销售的煤炭（包括本集团自产煤和采购煤）73.6 百万吨（2023 年：73.2 百万吨），同比增长 0.5%。发电分部耗用本集团内部销售的煤炭量占发电分部耗煤总量 96.5 百万吨的 76.3%。  由于使用内部煤炭进行发电，在煤价波动或者电价波动的时候，可以有一定的缓冲。</p>\n<p>另外内部电厂和煤矿具体较近，因此运费成本也相对较低，自己的铁路运输自己的煤炭，整体的成本也更低。这里可能有几个原因：1）使用自有的运输路线，2）部分电厂和煤矿相对比较近。</p>\n<p>从年报中可知，煤矿和电厂的分布如下</p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142515.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142515.png\" alt=\"\"></p>\n<p><img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260116142704.png\" alt=\"\"></p>\n<p>运输成本如下所示</p>\n<blockquote>\n<p>其中自有成本包括铁路和港口，航运暂时没找到，这里计算的成本较实际可能偏高，由于航运整体的收入和成本不大，所以暂时不做进一步细化</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>运输成本</td>\n<td>55180(100%)</td>\n<td>52236(100%)</td>\n<td>50094(100%)</td>\n<td>58027(100%)</td>\n<td>51557(100%)</td>\n</tr>\n<tr>\n<td>自有成本*</td>\n<td>37041(67.12%)</td>\n<td>34681(66.39%)</td>\n<td>33226(66.32%)</td>\n<td>39319(67.75%)</td>\n<td>38304(74.29%)</td>\n</tr>\n<tr>\n<td>外部成本</td>\n<td>18139(32.87%)</td>\n<td>17555(33.60%)</td>\n<td>16868(33.67%)</td>\n<td>18708(32.24%)</td>\n<td>13253(25.70%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到，自有运输成本占 66% 以上，这部分在成本计算的时候会按照市价进行计算，但是实际不需要花这么多钱，仅需要花费运输路线的成本即可，因此整体的运输成本相对较低。 粗略估算整体的运输成本比其他公司要少 66% * (37% — 铁路的毛利率) ~ 24% 也就是卖同样的煤，单位运输成本可能会减少 20% 左右，这部分会成为整个公司的利润。</p>\n<p>接下来可以对比自产煤的利润率和外购煤的利润率，如下所示</p>\n<blockquote>\n<p>由于 2022 年以前，年报暂无外购煤和自产煤相关详细数据 — 2021 年报描述公司暂无法区分自产煤和外购煤相关数据，因此暂不纳入计算</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>自产煤（销售量）</td>\n<td>327</td>\n<td>325.4</td>\n<td>316.2</td>\n</tr>\n<tr>\n<td>外购煤（销售量）</td>\n<td>132</td>\n<td>124.6</td>\n<td>101.6</td>\n</tr>\n<tr>\n<td>自产煤（销售收入)</td>\n<td>172442</td>\n<td>178242</td>\n<td>188818</td>\n</tr>\n<tr>\n<td>外购煤（销售收入)</td>\n<td>86373</td>\n<td>84626</td>\n<td>80178</td>\n</tr>\n<tr>\n<td>自产煤（销售成本)</td>\n<td>95642</td>\n<td>95250</td>\n<td>93150</td>\n</tr>\n<tr>\n<td>外购煤（销售收入)</td>\n<td>86373</td>\n<td>84626</td>\n<td>80178</td>\n</tr>\n<tr>\n<td>外购煤（销售成本)</td>\n<td>84797</td>\n<td>82617</td>\n<td>77627</td>\n</tr>\n<tr>\n<td>自产煤（毛利率)</td>\n<td>44.5%</td>\n<td>46.6%</td>\n<td>50.7%</td>\n</tr>\n<tr>\n<td>外购煤（毛利率）</td>\n<td>1.8%</td>\n<td>2.4%</td>\n<td>3.2%</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到自产煤的毛利率远大于外购煤的毛利率，另外这部分既然不赚钱，为啥还要做生意呢？或许是为了维持运输线路，运输路线只要能同正常流转就能够赚钱（运输自己的煤可以减少开支，运输其他公司物品可以赚利润）</p>\n<p>从发电分部来说，现在有两个政策对火电相对较好：1）容量电价[2]；2）电价浮动[3]。第一个是说只要保证有相关的能力，就能有一定的收入（不管是否发电） — 但是需要电的时候要能保证提供，否则会扣费，甚至取消相关资格；第二个是电价会按市场需要波动，低峰更便宜，高峰更贵。</p>\n<p>由于公司内部有煤，有电，然后有容量电价，以及电价的浮动，那么在煤炭价格进行波动的时候，可以内部进行一定的缓冲，比如煤炭价格下跌的时候，可以适当的给内部发电部门供应更多的煤炭（这个有上限），然后发电分部可以通过多发电（甚至在高峰期多发电 — 这个查看调度优先级），这样可以把一部分由于煤炭降价导致收入转移到电力下游，一定程度的对冲价格的波动，整体的收入和利润会更平衡一些。后文我们会对具体的波动数值进行一个推演。</p>\n<p>这里可以分为 </p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>煤炭上涨</th>\n<th>煤价不变</th>\n<th>煤炭下跌</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>电价上涨</td>\n<td>(1)</td>\n<td>(2)</td>\n<td>(3)</td>\n</tr>\n<tr>\n<td>电价不变</td>\n<td>(4)</td>\n<td>(5)</td>\n<td>(6)</td>\n</tr>\n<tr>\n<td>电价下跌</td>\n<td>(7)</td>\n<td>(8)</td>\n<td>(9)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>这里我们需要重点关注的是 (9) 这个位置，也就是煤价和电价都下跌的情况，后续我们会对这个进行一些具体的推演</p>\n<h1 id=\"经营情况\"><a href=\"#经营情况\" class=\"headerlink\" title=\"经营情况\"></a>经营情况</h1><h2 id=\"现金流量以及分红\"><a href=\"#现金流量以及分红\" class=\"headerlink\" title=\"现金流量以及分红\"></a>现金流量以及分红</h2><p>公司业务挣的钱，可能会有一些资本开支，也可能会有分红，接下来我们看看业务收入，以及现金流量净额的流向如何</p>\n<p>2024 年经营活动产生的现金流净额 93348 百万，「购建固定资产、无形资产和其他长期资产支付的现金」是 37032 百万，两者剩余 56316 百万，预计分红 44903 百万，占净利润的 76.5%（2023 年 75.2%），可以看到现金流量是足够分红支出的。另外公司承诺 25-27 年承诺每年以现金方式分配的利润不少于本公司当年实现的归属本公司股东净利润的 65%，实际最近 3 年都高于 70%(2024 年 76.5%， 2023 年 75.2%，2022 年 72.8%)。 2022 - 2024 的三年股东回报规划，承诺以现金方式分配的利润不少于公司当年实现归母净利的 60%，</p>\n<p>公司 24 年经营现金流和 固定资产、无形资产等支持，分红的情况如下所示（单位百万）</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>经营活动产生的现金流量净额</td>\n<td>93348</td>\n<td>89687</td>\n<td>109734</td>\n<td>94575</td>\n<td>81289</td>\n</tr>\n<tr>\n<td>购建固定资产、无形资产和其他长期资产支付的现金</td>\n<td>37032(39.67%)</td>\n<td>37084(41.34%)</td>\n<td>28684(26.13%)</td>\n<td>23863(25.23%)</td>\n<td>20673(25.43%)</td>\n</tr>\n<tr>\n<td>分红</td>\n<td>44903(48.10%)</td>\n<td>44903(50.06%)</td>\n<td>50665(46.17%)</td>\n<td>50466(53.36%)</td>\n<td>35962(44.23%)</td>\n</tr>\n<tr>\n<td>剩余</td>\n<td>11413(12.22%)</td>\n<td>7700(8.58%)</td>\n<td>30385(27.68%)</td>\n<td>20246(21.40%)</td>\n<td>24654(30.32%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以从上表看出，经营活动的现金流净额减去固定资产、无形资产的投资后，是足够分红的（也就是「剩余」一栏都是正数），可见公司是有钱分红的。 从年报可以分析 2023 年「购建固定资产、无形资产和其他长期资产支付的现金」增加是因为有发电厂投产，2024 年「购建固定资产、无形资产和其他长期资产支付的现金」增加是因为在建工程的投入更多，后续可以持续观察看看，这部分看是否会有大幅度的投入。</p>\n<h2 id=\"合同负债和应收款\"><a href=\"#合同负债和应收款\" class=\"headerlink\" title=\"合同负债和应收款\"></a>合同负债和应收款</h2><p>我们来看看公司的合同负债，以及应收账款，这两部分表示公司已经收到下游的钱还未交付，或者已经交付还未收到钱。一定程度可以看出公司的议价权。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>合同负债</td>\n<td>4045</td>\n<td>7208</td>\n<td>5597</td>\n<td>6864</td>\n<td>5256</td>\n</tr>\n<tr>\n<td>应收账款</td>\n<td>12466</td>\n<td>11875</td>\n<td>10968</td>\n<td>10258</td>\n<td>7798</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到公司既有合同负债，又有应收账款，然后查看应收账款的相应情况如下</p>\n<p>按性质分</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>售电款</td>\n<td>7869</td>\n<td>7539</td>\n<td>6475</td>\n<td>4480</td>\n<td>3619</td>\n</tr>\n<tr>\n<td>售煤款</td>\n<td>2182</td>\n<td>2003</td>\n<td>1802</td>\n<td>3380</td>\n<td>1982</td>\n</tr>\n<tr>\n<td>售热款</td>\n<td>267</td>\n<td>319</td>\n<td>280</td>\n<td>217</td>\n<td>262</td>\n</tr>\n<tr>\n<td>其他</td>\n<td>3292</td>\n<td>3209</td>\n<td>3632</td>\n<td>3458</td>\n<td>3234</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>按账龄分析</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>账龄</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1 年以内</td>\n<td>12125(89%)</td>\n<td>11497(87%)</td>\n<td>10646(87%)</td>\n<td>9648(84%)</td>\n<td>7009(78%)</td>\n</tr>\n<tr>\n<td>1-2 年</td>\n<td>182(1%)</td>\n<td>253(2%)</td>\n<td>165(1%)</td>\n<td>155(1%)</td>\n<td>131(1%)</td>\n</tr>\n<tr>\n<td>2-3 年</td>\n<td>136(1%)</td>\n<td>56(1%)</td>\n<td>30(1%)</td>\n<td>87(1%)</td>\n<td>93(1%)</td>\n</tr>\n<tr>\n<td>&gt; 3年</td>\n<td>1167(9%)</td>\n<td>1264(10%)</td>\n<td>1348(11%)</td>\n<td>1645(14%)</td>\n<td>1864(20%)</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>应收账款金额前五的单位</p>\n<ul>\n<li>2024 <img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151023782.png\" alt=\"\"></li>\n<li>2023 <img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115102144.png\" alt=\"\"></li>\n<li>2022 <img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115102413.png\" alt=\"\"></li>\n<li>2021  <img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/202601151018170.png\" alt=\"\"></li>\n<li>2020 <img src=\"https://raw.githubusercontent.com/klion26/ImageRepo/master/20260115101901.png\" alt=\"\"></li>\n</ul>\n<p>可以看到应收账款主要在「售电」，主要是电力公司，主要在一年以内，这个应该是和结算周期有关，可以推测煤炭分部有一定的合同负债，从这个来看，相对来说煤炭分部有一定的议价权</p>\n<p>接下来我们单独看煤炭分部的应收账款于营业收入的比值，一定程度看议价能力的变动，如果「应收账款」/「营业收入」变大，表示议价能力变弱，否则变高</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>应收账款</td>\n<td>2182</td>\n<td>2003</td>\n<td>1802</td>\n<td>3380</td>\n<td>1982</td>\n</tr>\n<tr>\n<td>营业收入</td>\n<td>268618</td>\n<td>273306</td>\n<td>277474</td>\n<td>292661</td>\n<td>292661</td>\n</tr>\n<tr>\n<td>比值</td>\n<td>0.81%</td>\n<td>0.73%</td>\n<td>0.64%</td>\n<td>1.15%</td>\n<td>0.67%</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看出来 2021 年的比值超过 1%，其他几年都低于 1%。搜了下，发现 2021 年刚好是煤炭价格下跌的一年，这个能对应上，煤炭下跌，行情不好，应收账款变的更多了。</p>\n<h2 id=\"和煤炭公司，电力公司的部分对比\"><a href=\"#和煤炭公司，电力公司的部分对比\" class=\"headerlink\" title=\"和煤炭公司，电力公司的部分对比\"></a>和煤炭公司，电力公司的部分对比</h2><p>中国神华在于煤电、运输等一体化运营，我们也来对比下和煤炭公司、电力公司在不同指标上的情况，有一个直观的对比和了解。我们选择 毛利率、ROE 以及资产负债率这三个指标，其中毛利率表示生意模式是否优秀，ROE 表示资产回报率，资产负债率则表示抗极限风险的能力。</p>\n<p>毛利率</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2016</th>\n<th>2017</th>\n<th>2018</th>\n<th>2019</th>\n<th>2020</th>\n<th>2021</th>\n<th>2022</th>\n<th>2023</th>\n<th>2024</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>陕西煤业</td>\n<td>43.39</td>\n<td>55.40</td>\n<td>48.69</td>\n<td>40.93</td>\n<td>27.46</td>\n<td>35.84</td>\n<td>44.99</td>\n<td>37.86</td>\n<td>32.69</td>\n</tr>\n<tr>\n<td>华能国际</td>\n<td>21.43</td>\n<td>11.31</td>\n<td>11.30</td>\n<td>12.5</td>\n<td>14.5</td>\n<td>17.4</td>\n<td>-0.33</td>\n<td>3.04</td>\n<td>12.11</td>\n</tr>\n<tr>\n<td>中国神华</td>\n<td>39.5</td>\n<td>42.1</td>\n<td>41.1</td>\n<td>36.7</td>\n<td>36.4</td>\n<td>32.9</td>\n<td>39.03</td>\n<td>35.89</td>\n<td>34.04</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>ROE</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2021</th>\n<th>2022</th>\n<th>2023</th>\n<th>2024</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>陕西煤业</td>\n<td>24.03</td>\n<td>33.3</td>\n<td>20.64</td>\n<td>21.32</td>\n</tr>\n<tr>\n<td>华能国际</td>\n<td>-10.29</td>\n<td>-8.92</td>\n<td>4.28</td>\n<td>5.14</td>\n</tr>\n<tr>\n<td>中国神华</td>\n<td>13.82</td>\n<td>18.77</td>\n<td>15.99</td>\n<td>14.97</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>资产负债率</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2020</th>\n<th>2021</th>\n<th>2022</th>\n<th>2023</th>\n<th>2024</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>陕西煤业</td>\n<td>39.78%</td>\n<td>60.82%</td>\n<td>60.19%</td>\n<td>62.99%</td>\n<td>63.35%</td>\n</tr>\n<tr>\n<td>华能国际</td>\n<td>67.71%</td>\n<td>74.68%</td>\n<td>74.82%</td>\n<td>68.33%</td>\n<td>65.40%</td>\n</tr>\n<tr>\n<td>中国神华</td>\n<td>23.9%</td>\n<td>26.6%</td>\n<td>26.1%</td>\n<td>24.1%</td>\n<td>23.4%</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>对于 ROE 这一项，我们可以再继续进行细分，查看「销售净利率」、「资产周转率」以及「权益系数」的相关数值，其中「销售净利率」表示赚钱多狠，资产周转率表示公司跑的多块，权益系数表示杠杆有多高</p>\n<p>销售净利率</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>神华</td>\n<td>17.3</td>\n<td>17.3</td>\n<td>20.2</td>\n<td>14.9</td>\n<td>16.7</td>\n</tr>\n<tr>\n<td>陕西煤业</td>\n<td>12.14</td>\n<td>6.2</td>\n<td>21</td>\n<td>14</td>\n<td>15.6</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>资产周转率</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>神华</td>\n<td>52.53</td>\n<td>54.80</td>\n<td>56.08</td>\n<td>57.52</td>\n<td>41.76</td>\n</tr>\n<tr>\n<td>陕西煤业</td>\n<td>79.28</td>\n<td>72.99</td>\n<td>79.91</td>\n<td>91.02</td>\n<td>68.5</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>权益乘数</p>\n<blockquote>\n<p>使用公式 = 1/ (1 - 资产负债率)</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>公司</th>\n<th>2024</th>\n<th>2023</th>\n<th>2022</th>\n<th>2021</th>\n<th>2020</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>神华</td>\n<td>1.3</td>\n<td>1.31</td>\n<td>1.35</td>\n<td>1.36</td>\n<td>1.31</td>\n</tr>\n<tr>\n<td>陕西煤业</td>\n<td>2.7</td>\n<td>2.7</td>\n<td>2.51</td>\n<td>2.55</td>\n<td>2.51</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以从上面的图表中看到，神华和陕西煤业比较，销售净利率相对还是比较好的，资产周转率不如，，然后杠杆率比较低。其中对于杠杆率来说，虽然可能借到很便宜的钱，杠杆可以放大收益，但是在行情不好的时候，风险也会被放大，因此这个也变相的体现抗风险能力</p>\n<h1 id=\"风险\"><a href=\"#风险\" class=\"headerlink\" title=\"风险\"></a>风险</h1><p>对于神华来说，针对不同的业务，会有不同的风险，比如</p>\n<ul>\n<li>对于煤炭生意来说：1）最大的风险在于新能源的推广，这块由于现在储能上还不太能跟上，因此煤炭作为资源压舱石还一直在使用，但是未来如果储能有重大进展的话，则新能源可能会大幅替代火电；2）是否可能对煤炭企业或者火电企业收取「碳」相关的税，从而促进能源转型；3）作为国企，在煤炭涨价的时候，是否需要承受更多的社会责任，对本公司的利益是否有影响。</li>\n<li>对于电力生意来说：1）火电是否会被新能源发电去掉；2）现在的电价方式是否会发生变化</li>\n<li>对于铁路来说：如果不需要允许这么多煤，那么能否比较快速的转运其他非煤物品</li>\n</ul>\n<p>我们可以知道这些都和火电有关，那么我们通过国家能源官网[4]的装机信息来看，不同类系发电的装机情况，火电的装机情况暂时还行，斜率是往上的</p>\n<p>2025 全国不同类型装机容量新增数，可以用 (1-3) - (1-2) 获得 3 月新增</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>项目(万千瓦)</th>\n<th>1-2</th>\n<th>1-3月</th>\n<th>1-4 月</th>\n<th>1-5</th>\n<th>1-6</th>\n<th>1-7</th>\n<th>1-8</th>\n<th>1-9</th>\n<th>1-10</th>\n<th>1-11</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>水电</td>\n<td>191</td>\n<td>213</td>\n<td>265</td>\n<td>325</td>\n<td>393</td>\n<td>589</td>\n<td>684</td>\n<td>716</td>\n<td>835</td>\n<td>912</td>\n</tr>\n<tr>\n<td>火电</td>\n<td>388</td>\n<td>925</td>\n<td>1298</td>\n<td>1755</td>\n<td>2578</td>\n<td>4198</td>\n<td>4987</td>\n<td>5668</td>\n<td>6508</td>\n<td>7752</td>\n</tr>\n<tr>\n<td>核电</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>153</td>\n<td>153</td>\n</tr>\n<tr>\n<td>风电</td>\n<td>928</td>\n<td>1462</td>\n<td>1996</td>\n<td>4628</td>\n<td>5139</td>\n<td>5367</td>\n<td>5784</td>\n<td>6109</td>\n<td>7001</td>\n<td>8250</td>\n</tr>\n<tr>\n<td>太阳能发电</td>\n<td>3947</td>\n<td>5971</td>\n<td>10493</td>\n<td>19785</td>\n<td>21221</td>\n<td>22325</td>\n<td>23061</td>\n<td>24027</td>\n<td>25287</td>\n<td>27489</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>相关图形如下所示（可以观察斜率表示增长率）</p>\n\n<div id=\"echarts1019\" style=\"width: 85%;height:400px;margin: 0 auto\"></div>\n<script src=\"https://unpkg.com/echarts@5.6.0/dist/echarts.min.js\" ></script>\n<script >\n  if (window.eChartecharts1019ResizeHandler) {\n    window.removeEventListener(\"resize\", eChartecharts1019ResizeHandler);\n  }\n  var optionecharts1019 = option = {\n  title: {\n    text: '新增装机量'\n  },\n  tooltip: {\n    trigger: 'axis'\n  },\n  legend: {\n    data: ['水电', '火电', '核电', '风电', '太阳能']\n  },\n  grid: {\n    left: '3%',\n    right: '4%',\n    bottom: '3%',\n    containLabel: true\n  },\n  toolbox: {\n    feature: {\n      saveAsImage: {}\n    }\n  },\n  xAxis: {\n    type: 'category',\n    boundaryGap: false,\n    data: ['2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n  },\n  yAxis: {\n    type: 'value'\n  },\n  series: [\n    {\n      name: '水电',\n      type: 'line',\n\n      data: [191, 213, 265, 325, 393, 589, 684, 716, 835, 912]\n    },\n    {\n      name: '火电',\n      type: 'line',\n\n      data: [388, 925, 1298, 1755, 2578, 4198, 4987, 5668, 6500, 7752]\n    },\n    {\n      name: '核电',\n      type: 'line',\n\n      data: [0, 0, 0, 0, 0, 0, 0, 0, 153, 153]\n    },\n    {\n      name: '风电',\n      type: 'line',\n\n      data: [928, 1462, 1996, 4628, 5139, 5367, 5784, 6109, 7001, 8250]\n    },\n    {\n      name: '太阳能',\n      type: 'line',\n\n      data: [3947, 5971, 10493, 19785, 21221, 22325, 23061, 24027, 25287, 27489]\n    }\n  ]\n};;\n  if (window.echarts !== undefined) {\n    var eChartecharts1019 = echarts.init(document.getElementById('echarts1019'));\n    eChartecharts1019.setOption(optionecharts1019);\n    var eChartecharts1019ResizeHandler = function() {\n      eChartecharts1019.resize();\n    };\n    window.addEventListener(\"resize\", eChartecharts1019ResizeHandler);\n  }\n</script>\n<h1 id=\"神华自己的价值\"><a href=\"#神华自己的价值\" class=\"headerlink\" title=\"神华自己的价值\"></a>神华自己的价值</h1><p>首先我们对神华进行公司的价值估算，这样可以和现在的市值进行比较。我们根据不同业务的综合进行估值</p>\n<ul>\n<li>其中煤炭现在保有量 343.6 亿吨，按照现在均价 584 元/吨，总价在 20 万亿。如果按照 300 百万吨一年的销量，大概一年营收 1755 亿，然后按照 5% 左右的折旧率，以及计算 50 年的话，大概总价值 3万亿，按照 30% 的利润率，则总价在在 1万亿左右。</li>\n<li>现在铁路总共 2408 公里，按照修建铁路 1 公里的成本大约在 1.5 亿左右，就算不再使用，也可以进行售卖，这块的价值 3600 亿左右</li>\n<li>电厂的价值估算，现在总共有 4万兆瓦的装机容量，目前新建的成本大概在 3500 元/千瓦，则重估的价值等于 1400 亿</li>\n<li>另外还有港口和航运等这些资产</li>\n</ul>\n<p>可以发现整个神华的资产是肯定超过现在的市值 8300 亿的。因此现在的市值是相对比较便宜的。</p>\n<h1 id=\"Ref\"><a href=\"#Ref\" class=\"headerlink\" title=\"Ref\"></a>Ref</h1><p>[1] 华源证券 煤炭行业中期策略报告 (2025.06.27)<br>[2] <a href=\"https://www.ndrc.gov.cn/xxgk/zcfb/tz/202311/t20231110_1361897.html\">https://www.ndrc.gov.cn/xxgk/zcfb/tz/202311/t20231110_1361897.html</a><br>[3] <a href=\"https://www.ndrc.gov.cn/xxgk/zcfb/tz/202110/t20211012_1299461.html\">https://www.ndrc.gov.cn/xxgk/zcfb/tz/202110/t20211012_1299461.html</a><br>[4] <a href=\"https://www.nea.gov.cn/20251026/70d3b88f62f1401bbe47a8212e06ad8e/c.html\">https://www.nea.gov.cn/20251026/70d3b88f62f1401bbe47a8212e06ad8e/c.html</a></p>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"clhsl7avl00042uv91n8t5gkt","tag_id":"clhsl7avm00052uv9dbfaeevl","_id":"clhsl7avo00092uv9cxumdwj9"},{"post_id":"clhsl7avl00042uv91n8t5gkt","tag_id":"clhsl7avn00062uv929e1e35a","_id":"clhsl7avo000a2uv9h6pr1neq"},{"post_id":"clhsl7avl00042uv91n8t5gkt","tag_id":"clhsl7avn00072uv91lgc6b65","_id":"clhsl7avo000b2uv9b4pu3tj6"},{"post_id":"clhsl7avl00042uv91n8t5gkt","tag_id":"clhsl7avn00082uv9axbxck28","_id":"clhsl7avo000c2uv97710315w"},{"post_id":"cm5f2gbxw0000y8mk40oneky3","tag_id":"clhsl7avi00022uv94hujckvg","_id":"cm5f2gby10001y8mka5v5a99i"},{"post_id":"cm7esg5hw0000dhjo0zq785ir","tag_id":"cm7esg5i10001dhjohilg3h41","_id":"cm7esg5i20005dhjo11ye5l5r"},{"post_id":"cm7esg5hw0000dhjo0zq785ir","tag_id":"cm7esg5i20002dhjohfyx6u0m","_id":"cm7esg5i20006dhjo2dhr35rb"},{"post_id":"cm7esg5hw0000dhjo0zq785ir","tag_id":"cm7esg5i20003dhjoebqtcfox","_id":"cm7esg5i30007dhjo3iwg71b2"},{"post_id":"cm7esg5hw0000dhjo0zq785ir","tag_id":"cm7esg5i20004dhjo2zzvhqdh","_id":"cm7esg5i30008dhjoa4jibqff"},{"post_id":"cm8l8eflp0001cjjl80sl72n6","tag_id":"cm8b722sa0002jujj4n58byp7","_id":"cm8l8efls0003cjjl2uqmebzp"},{"post_id":"cm8l8eflp0001cjjl80sl72n6","tag_id":"cm8b722sb0003jujjfr340oqh","_id":"cm8l8efls0004cjjlcxeodra9"},{"post_id":"cm8zliwkd000atkmk0i722o2i","tag_id":"cm7esg5i10001dhjohilg3h41","_id":"cm8zliwkf000btkmk6fxg1wy7"},{"post_id":"cm8zliwkd000atkmk0i722o2i","tag_id":"cm7esg5i20002dhjohfyx6u0m","_id":"cm8zliwkf000ctkmkdhz9bcjb"},{"post_id":"cm8zliwkd000atkmk0i722o2i","tag_id":"cm8l8eflq0002cjjl0pen4e2p","_id":"cm8zliwkf000dtkmkfug07ivx"},{"post_id":"cm8zliwkd000atkmk0i722o2i","tag_id":"cm8l8efls0005cjjl308998jz","_id":"cm8zliwkg000etkmk41y70f7f"},{"post_id":"cm99qn2hc00001nmk2xf74mbp","tag_id":"cm7esg5i10001dhjohilg3h41","_id":"cm99qn2hg00011nmk3o9i6g5x"},{"post_id":"cm99qn2hc00001nmk2xf74mbp","tag_id":"cm997xg77000191mkbh7z2f5r","_id":"cm99qn2hg00021nmk1u52cx5l"},{"post_id":"cm99qn2hc00001nmk2xf74mbp","tag_id":"cm997xg78000291mk8a121iav","_id":"cm99qn2hg00031nmkbk6d6bsb"},{"post_id":"cm99qn2hc00001nmk2xf74mbp","tag_id":"cm997xg79000391mk7wq05sf9","_id":"cm99qn2hg00041nmkfg5d5zgo"},{"post_id":"cm9oaybst001j2umkhf4721ax","tag_id":"cm9mlemri00012umkdsl4dj8s","_id":"cm9oaybsu001k2umk6yx4exlu"},{"post_id":"cm9oaybst001j2umkhf4721ax","tag_id":"cm9mlemrk00022umk2ttq5e8n","_id":"cm9oaybsu001l2umkgh4e3c35"},{"post_id":"cm9oaybst001j2umkhf4721ax","tag_id":"cm9mlemrk00032umkbuq23qp5","_id":"cm9oaybsu001m2umkbjkrewtz"},{"post_id":"cm9y6y65v00066kjn7bo51lpf","tag_id":"cm9y6swn300026kjnazqn7kxp","_id":"cm9y6y65x00076kjn5uu229ms"},{"post_id":"cm9y6y65v00066kjn7bo51lpf","tag_id":"cm9y6swn400036kjn5u231a9f","_id":"cm9y6y65x00086kjnehru2z93"},{"post_id":"cmaw4d1hg0008k3mk2ce79l16","tag_id":"cmavx3hvc0001k3mk0i6e1xx6","_id":"cmaw4d1hj0009k3mk8mwz7jnp"},{"post_id":"cmaw4d1hg0008k3mk2ce79l16","tag_id":"cmavx3hvt0002k3mk4rpn54uo","_id":"cmaw4d1hj000ak3mkdqk389ej"},{"post_id":"cmcpjktu7000b6xfy24cedmvm","tag_id":"cm7esg5i10001dhjohilg3h41","_id":"cmcpjktu7000c6xfydxktauti"},{"post_id":"cmcpjktu7000b6xfy24cedmvm","tag_id":"cm7esg5i20002dhjohfyx6u0m","_id":"cmcpjktu7000d6xfygioe30fe"},{"post_id":"cmcpjktu7000b6xfy24cedmvm","tag_id":"cmcmxlj0k000113mkh00v9dr9","_id":"cmcpjktu7000e6xfy431cdgyg"},{"post_id":"cmcpjktu7000b6xfy24cedmvm","tag_id":"cm7esg5i20004dhjo2zzvhqdh","_id":"cmcpjktu8000f6xfy2v2fczb8"},{"post_id":"cmfqtzost0002yafy39ds1f5c","tag_id":"cmfqtzosv0003yafy9y5d6e8f","_id":"cmfqtzot00008yafyhpuohj4q"},{"post_id":"cmfqtzost0002yafy39ds1f5c","tag_id":"cmfqtzosy0004yafyfeezc0xs","_id":"cmfqtzot00009yafy7m8n3ek4"},{"post_id":"cmfqtzost0002yafy39ds1f5c","tag_id":"cmfqtzosz0005yafy6clkhrjh","_id":"cmfqtzot0000ayafyfade3u15"},{"post_id":"cmfqtzost0002yafy39ds1f5c","tag_id":"cmfqtzosz0006yafy3u3weq84","_id":"cmfqtzot0000byafydhndc2ef"},{"post_id":"cmfqtzost0002yafy39ds1f5c","tag_id":"cmfqtzosz0007yafy7bc4397a","_id":"cmfqtzot0000cyafy064b6bqn"},{"post_id":"cmfqtzot1000dyafyes954mop","tag_id":"cm997xg77000191mkbh7z2f5r","_id":"cmfqu2m6w0002mxfy5glsaf9r"},{"post_id":"cmfqtzot1000dyafyes954mop","tag_id":"cmfqu2m6t0000mxfyclc9edrb","_id":"cmfqu2m6w0003mxfy7ubkddwp"},{"post_id":"cmfqtzot1000dyafyes954mop","tag_id":"cmfqu2m6w0001mxfy3ev2dfvq","_id":"cmfqu2m6w0004mxfy0fjc9ybv"},{"post_id":"cmgfxrcd2000os1fy1axk8akx","tag_id":"cm997xg77000191mkbh7z2f5r","_id":"cmgfxrcd3000ps1fy09ni12at"},{"post_id":"cmgfxrcd2000os1fy1axk8akx","tag_id":"cmgfxbsi40002s1fy356n5a15","_id":"cmgfxrcd3000qs1fy4bkjbotv"},{"post_id":"cmgfxrcd2000os1fy1axk8akx","tag_id":"cmgfxbsi50003s1fy4vzq729l","_id":"cmgfxrcd3000rs1fy232p4a5z"},{"post_id":"cmgfxrcd2000os1fy1axk8akx","tag_id":"cmgfxcfbe0007s1fygijpamzc","_id":"cmgfxrcd3000ss1fya7n9fi23"},{"post_id":"cmi87ko2q000spwmk6zatebak","tag_id":"cmi1eosie0005mofyaenj7lb6","_id":"cmi87ko2r000tpwmkg2q6bmru"},{"post_id":"cmi87ko2q000spwmk6zatebak","tag_id":"cmi1eosif0006mofycv1ydi2c","_id":"cmi87ko2r000upwmkax2z67ei"},{"post_id":"cmi87ko2q000spwmk6zatebak","tag_id":"cmfqtzosz0005yafy6clkhrjh","_id":"cmi87ko2r000vpwmke4y9akgu"},{"post_id":"cmi87ko2q000spwmk6zatebak","tag_id":"cmi1eosif0007mofyaxxz2asz","_id":"cmi87ko2r000wpwmk02yz3ui3"},{"post_id":"cmi87ko2q000spwmk6zatebak","tag_id":"cmi5a0zr20000iqmkemdxd6gt","_id":"cmi87ko2r000xpwmkfthhfjfz"},{"post_id":"cmi87ko2q000spwmk6zatebak","tag_id":"cmi5a0zr50001iqmkfitc3vrg","_id":"cmi87ko2r000ypwmkayl26yjd"},{"post_id":"cmkgimn3a000fdgmkef45144z","tag_id":"cm997xg77000191mkbh7z2f5r","_id":"cmkgimn3a000gdgmk2lfbf2ve"},{"post_id":"cmkgimn3a000fdgmkef45144z","tag_id":"cmkggpgq20005dgmk52a8b0xc","_id":"cmkgimn3b000hdgmkcgnxbpit"},{"post_id":"cmkgimn3a000fdgmkef45144z","tag_id":"cm7esg5i20003dhjoebqtcfox","_id":"cmkgimn3b000idgmk0sddby3a"}],"Tag":[{"name":"大数据, 全局认识, 偏见, 论文, 系统","_id":"clhsl7avi00022uv94hujckvg"},{"name":"lsm","_id":"clhsl7avm00052uv9dbfaeevl"},{"name":"lsm-tree","_id":"clhsl7avn00062uv929e1e35a"},{"name":"minimum-global-awareness","_id":"clhsl7avn00072uv91lgc6b65"},{"name":"paper","_id":"clhsl7avn00082uv9axbxck28"},{"name":"stock","_id":"cm7esg5i10001dhjohilg3h41"},{"name":"maotai","_id":"cm7esg5i20002dhjohfyx6u0m"},{"name":"company-analysis","_id":"cm7esg5i20003dhjoebqtcfox"},{"name":"wine","_id":"cm7esg5i20004dhjo2zzvhqdh"},{"name":"review","_id":"cm8b722sa0002jujj4n58byp7"},{"name":"question","_id":"cm8b722sb0003jujjfr340oqh"},{"name":"profit","_id":"cm8l8eflq0002cjjl0pen4e2p"},{"name":"cost","_id":"cm8l8efls0005cjjl308998jz"},{"name":"investment","_id":"cm997xg77000191mkbh7z2f5r"},{"name":"分红","_id":"cm997xg78000291mk8a121iav"},{"name":"compond","_id":"cm997xg79000391mk7wq05sf9"},{"name":"compare","_id":"cm9mlemri00012umkdsl4dj8s"},{"name":"opportunity-cost","_id":"cm9mlemrk00022umk2ttq5e8n"},{"name":"iterative velocity","_id":"cm9mlemrk00032umkbuq23qp5"},{"name":"differentiation","_id":"cm9y6swn300026kjnazqn7kxp"},{"name":"strategy","_id":"cm9y6swn400036kjn5u231a9f"},{"name":"iceberg-summit","_id":"cmavx3hvc0001k3mk0i6e1xx6"},{"name":"notes","_id":"cmavx3hvt0002k3mk4rpn54uo"},{"name":"price","_id":"cmcmxlj0k000113mkh00v9dr9"},{"name":"arrow","_id":"cmfqtzosv0003yafy9y5d6e8f"},{"name":"variant","_id":"cmfqtzosy0004yafyfeezc0xs"},{"name":"parquet","_id":"cmfqtzosz0005yafy6clkhrjh"},{"name":"rust","_id":"cmfqtzosz0006yafy3u3weq84"},{"name":"optimization","_id":"cmfqtzosz0007yafy7bc4397a"},{"name":"startup","_id":"cmfqu2m6t0000mxfyclc9edrb"},{"name":"innovation","_id":"cmfqu2m6w0001mxfy3ev2dfvq"},{"name":"pattern","_id":"cmgfxbsi40002s1fy356n5a15"},{"name":"theory","_id":"cmgfxbsi50003s1fy4vzq729l"},{"name":"arbitrage","_id":"cmgfxcfbe0007s1fygijpamzc"},{"name":"file-format","_id":"cmi1eosie0005mofyaenj7lb6"},{"name":"column-fiel-format","_id":"cmi1eosif0006mofycv1ydi2c"},{"name":"lance","_id":"cmi1eosif0007mofyaxxz2asz"},{"name":"vortex","_id":"cmi5a0zr20000iqmkemdxd6gt"},{"name":"nimble","_id":"cmi5a0zr50001iqmkfitc3vrg"},{"name":"601088","_id":"cmkggpgq20005dgmk52a8b0xc"}]}}