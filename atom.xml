<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>klion26</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-09-20T14:07:38.941Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>klion26</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一次 InputStream#read 使用不当导致的问题</title>
    <link href="http://yoursite.com/2018/09/09/%E4%B8%80%E6%AC%A1-InputStream-read-%E4%BD%BF%E7%94%A8%E4%B8%8D%E5%BD%93%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2018/09/09/一次-InputStream-read-使用不当导致的问题/</id>
    <published>2018-09-09T05:38:19.000Z</published>
    <updated>2018-09-20T14:07:38.941Z</updated>
    
    <content type="html"><![CDATA[<p> 一句话总结：InputStream#read 对于当次能够读取多少字节不做保证，必须以该函数的返回值做为实际读取字节数的事实。<a id="more"></a></p>
<p>#1. 问题<br>由于某些功能的需要，实现如下函数，从某个 InputStream copy 特定长度的数据到 OutputStream，其中 InputStream 为打开的某个 HDFS 文件流</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">private void copySpecifiedLengthBytes(final InputStream in, final OutputStream out, final long size) &#123;</div><div class="line">    long current = 0;</div><div class="line">    byte[] bytes = new byte[BLOCKSIZE]; //BLOCKSIZE = 4096;</div><div class="line">    int bytesRead;</div><div class="line">    while (current + BLOCKSIZE &lt; size) &#123;</div><div class="line">        bytesRead = in.read(bytes);</div><div class="line">        current += bytesRead;</div><div class="line">        out.write(bytes);</div><div class="line">    &#125;</div><div class="line">    int byteLeftToRead = (int) (size - current);</div><div class="line">    bytesRead = in.read(bytes, 0, byteLeftToRead);</div><div class="line">    out.write(bytes, 0, bytesRead);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>看到上面的函数，可以先思考下会不会出现问题，如果可能出现问题，则会在哪个地方，以及问题的展现形式会是什么样的。<br>|<br>|<br>|<br>|<br>|<br>|<br>|<br>|<br>|<br>|<br>上面的代码在某些场景下会有问题，大致如下：OutputStream 的中间部分会多出来一些无关字节，导致整个 OutputStream 的内容是错误的。</p>
<h1 id="2-定位分析"><a href="#2-定位分析" class="headerlink" title="2. 定位分析"></a>2. 定位分析</h1><blockquote>
<p>当我们知道所有的来龙去脉之后，回过头来看发现其实并没有那么难，但是当我们只看到现象的时候，可能会有无数种解释，这个时候需要能够验证哪种解释才是合理的。</p>
</blockquote>
<p>看到 OutputStream 中的数据不对，怀疑如下两点 1) InputStream 中的数据是否准确; 2) 读取的起止位置是否准确;</p>
<p>通过添加相关日志重现问题，初步确定 InputStream 中的数据是可信的，从 InputStream 中读取的起止位置也是准确的，但是 OutputStream 中得到的数据是非预期的。暂时不知道对不上的数据是怎么来的，但是基本能够定位问题在于上面的 copySpecifiedLengthBytes 函数。</p>
<p>为了验证确实是这里的问题，将该函数进行了修改，改成如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">private void copySpecifiedLengthBytes(final InputStream in, final OutputStream out, final long size) &#123;</div><div class="line">    byte[] bytes = new byte[BLOCKSIZE]; //BLOCKSIZE = 4096;</div><div class="line">    int bytesRead;</div><div class="line">    long byteLeft = size;</div><div class="line">    while (byteLeft &gt; 0) &#123;</div><div class="line">        bytesRead = in.read(bytes, 0, (int) Math.min(byteLeft, bytes.length));</div><div class="line">        byteLeft -= bytesRead;</div><div class="line">        out.write(bytes, 0, bytesRead);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>然后尝试进行复现该问题，发现没有再次复现（之前基本每次都能复现），基本确定问题在这里。但是留下几个问题不能完全解释清楚：</p>
<ol>
<li><p>把 HDFS 文件 copy 到本地，尝试复现的时候，发现无法复现，且得到的 OutputStream 是预期中的（正确的数据）</p>
</li>
<li><p>为什么从同一个 HDFS 多次复现的时候，得到的 OutputStream 结果是一致的（错的一致）</p>
</li>
</ol>
<h1 id="3-原因"><a href="#3-原因" class="headerlink" title="3. 原因"></a>3. 原因</h1><p>上面遗留的第一个问题，从本地文件读取时不能复现，与实现有关，找了下源码，没有发现 read 函数有中间中断的情况，因此没有出现问题。</p>
<p>第二个问题，看到的现象是从同一台机器上读取同一个文件，得到的 OutputStream 一致（错的一致），也就是说 InputStream#read 的行为在多次复现过程中完全一致，所以导致多次复现得到的 OutputStream 也错的一致。</p>
<p>然后我们尝试在错误的 copySpecifiedLengthBytes 函数中添加日志，查看哪些地方出错，看到一个现象，在大致读取来 128K 的地方，InputStream#read 真正读取到的字节数少于 BLOCKSIZE，但是我们写出的数据量为 BLOCKSIZE，从而导致后面的 out.write(bytes) 多写出一些无关字节，至此我们基本能够解释上面的遗留问题来，但是又引发了另一个问题</p>
<blockquote>
<p>为什么每次都在 128K 左右的地方出错呢？而且每次执行 copySpecifiedLengthBytes 仅仅在第一个 128K 附近出错，后面的地方都没有出错呢？</p>
</blockquote>
<p>然后我们打开 hadoop-hdfs-client 的代码，从 DFSInputStream 开始跟踪，发现在 BlockReaderRemote.java 中有一段这样的代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">// First packet will include some data prior to the first byte</div><div class="line">// the user requested. Skip it.</div><div class="line">if (curHeader.getOffsetInBlock() &lt; startOffset) &#123;</div><div class="line">    int newPos = (int) (startOffset - curHeader.getOffsetInBlock());</div><div class="line">    curDataSlice.position(newPos);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这段代码表示读取的第一个 packet（HDFS 读写的最小单元） 头部会包含一些非法数据，需要跳过，但是后续的 packet 则不需要跳过，这个和我们看到的现象基本吻合。那到底是不是这里呢？</p>
<p>通过准备环境，然后在 curDataSlice.position(newPos) 处添加断点，发现如预期的停在了断点处，也就是说问题的根源来自这里。至此所有的遗留问题都解决了。</p>
<p>接下来梳理一下整个流程：</p>
<ol>
<li><p>使用 InputStream#read 进行读取</p>
</li>
<li><p>DFSInputStream 会读取 packet</p>
</li>
<li><p>DFSInputStream 读取 packet 的时候会对第一个 packet 进行部分字节的跳过, 这里是因为 HDFS 的读写最小单元是 packet，seek 的 offset 可能不是 packet 的开头，那么就会从 packet 的开头进行读取，然后实际读取的时候需要把前面一部分进行跳过。</p>
</li>
<li><p>导致第一步中的 read 读取不充分（实际读取的字节数比预期的少），导致 out.write(bytes) 的行为不符合预期</p>
</li>
</ol>
<p>最后附上可以进行直观查看效果的 UT<br>当使用错误的 copySpecifiedLengthBytes 的时候，下面的测试会挂掉，注意挂掉的原因，当使用正确的测试的使用，则会通过<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">@Test</div><div class="line">public void testCopySpecifiedLengthBytes() throws IOException &#123;</div><div class="line">   int length = 4 * 1024 * 1024;</div><div class="line">   byte[] from = new byte[length];</div><div class="line"></div><div class="line">   Random rnd = new Random();</div><div class="line">   rnd.nextBytes(from);</div><div class="line"></div><div class="line">   InputStream fromStream = spy(new ByteArrayInputStream(from));</div><div class="line"></div><div class="line">   doAnswer(new Answer() &#123;</div><div class="line">       private int idx = 0;</div><div class="line">       @Override</div><div class="line">       public Object answer(InvocationOnMock invocation) throws Throwable &#123;</div><div class="line">           byte[] first = invocation.getArgumentAt(0, byte[].class);</div><div class="line">           int off = invocation.getArgumentAt(1, Integer.class);</div><div class="line">           int len = invocation.getArgumentAt(2, Integer.class);</div><div class="line"></div><div class="line">           int bytesReadThisTime = Math.min(100, len);</div><div class="line">           System.arraycopy(from, idx, first, off, bytesReadThisTime);</div><div class="line">           idx += bytesReadThisTime;</div><div class="line"></div><div class="line">           return bytesReadThisTime;</div><div class="line">       &#125;</div><div class="line">    &#125;).when(fromStream).read(any(byte[].class), anyInt(), anyInt());</div><div class="line"></div><div class="line">    ByteArrayOutputStream toStream = new ByteArrayOutputStream(length);</div><div class="line">    copySpecifiedLengthBytes(fromStream, toStream, length);</div><div class="line">    assertArrayEquals(from toStream.toByteArray());</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt; 一句话总结：InputStream#read 对于当次能够读取多少字节不做保证，必须以该函数的返回值做为实际读取字节数的事实。
    
    </summary>
    
    
      <category term="read" scheme="http://yoursite.com/tags/read/"/>
    
      <category term="I/O" scheme="http://yoursite.com/tags/I-O/"/>
    
      <category term="HDFS" scheme="http://yoursite.com/tags/HDFS/"/>
    
      <category term="InputStream" scheme="http://yoursite.com/tags/InputStream/"/>
    
      <category term="problem_solving" scheme="http://yoursite.com/tags/problem-solving/"/>
    
  </entry>
  
  <entry>
    <title>Flink-State</title>
    <link href="http://yoursite.com/2018/04/06/Flink-State/"/>
    <id>http://yoursite.com/2018/04/06/Flink-State/</id>
    <published>2018-04-06T09:33:30.000Z</published>
    <updated>2018-04-06T13:52:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 中 State 用于保存 Task 的状态，Checkpoint 的时候，会将 State 保存到外存中。</p>
<p>State 有两种，Keyed State 和 Operator State，每一种则可以有两种形式存在：Managed 和 Raw。其中 Keyed State 只能引用在 Keyed Stream 上，在 Flink 中使用 keyBy() 创建一个 keyed Stream. Flink 保证同一个 key 的 Tuple 会被发送到同一个 task 进行处理，Operator State 使用 ListState（用于 rescale），上层是一个 HashMap<string, partitionableliststate=""> Key 是 name，value 是一个封装了 list 的 class。</string,></p>
<a id="more"></a>
<p>State 的入口在 AbstractStateBackend，AbstractStateBackend 的子类有 </p>
<ul>
<li>MemoryStateBackend</li>
<li>RocksDBStateBackend </li>
<li>FsStateBackend</li>
</ul>
<p>本文主要分析 MemoryStateBackend 和 RocksDBStateBackend。如无特殊说明，本文所有代码均使用附[1]</p>
<img src="/2018/04/06/Flink-State/state-hierarchy.png" alt="state-hierarchy.png" title="">
<h2 id="MemoryStateBackend"><a href="#MemoryStateBackend" class="headerlink" title="MemoryStateBackend"></a>MemoryStateBackend</h2><p>MemoryStateBackend 使用内存作为存储主要包括一些配置项（内存大小 等）以及创建 operator/keyed state 的接口，本文会创建一个 HeapKeyedStateBackend</p>
<p>HeapKeyedStateBackend 会提供创建各种 State 的接口（ValueState，ListState，MapState，SortedMapState，ReducingState，FoldingState，AggregatingState，RawQueueState，RawSecodaryState，RawStortedSecondaryState 等），返回当前 state 的 snapshot（checkpoint 会用到） 以及从指定的 KeyedStateHandles 恢复的接口。</p>
<p>其中 createValueState 则创建一个 HeapValueState</p>
<p>一些重要的变量和方法如下所示：</p>
<ul>
<li>变量<ul>
<li>entries – 记录具体的值，类型为 Map<integer, map<k,="" map<n,="" sv="">&gt;&gt; 每个 value 由<keygroup, key,="" namespace=""> 唯一确定</keygroup,></integer,></li>
<li>defaultValue – 表示 StateValue 的初始值，没有则为 null</li>
<li>backend – 当前 state 所属的 stateBackend</li>
<li>stateDescriptor – 当前 state 的描述信息，主要包括当前 state 的 namespace、value 已经面向用户的 descriptors 等</li>
</ul>
</li>
<li>方法<ul>
<li>createNewMap() – 创建一个 map，跟进是否为 Queryable 的 state，选择是否创建 ConcurrentHashMap</li>
<li>snapshot(int, keyGroup, DataOutputView outputView) – 将指定 keyGroup 的 key 进行一次 snapshot，写入到指定的 outputView 中</li>
<li>restore(int keyGroup, DataInputView intputView)  – 从 inputView 中恢复</li>
<li>get(int keyGroup, K key, N namespace)  – 获取特定的 value</li>
<li>clear(int keyGroup, K key, N namespace) – 清空特定的 value</li>
<li>clear(Set<statekey<k, n="">&gt; stateKeys) – 清空特定的 value</statekey<k,></li>
<li>value() – 返回特定的 value</li>
<li>update(V value) – 更新特定的 value</li>
</ul>
</li>
<li>update(int keyGroup, K key, N namespace, V value) </li>
</ul>
<h3 id="程序流程解释"><a href="#程序流程解释" class="headerlink" title="程序流程解释"></a>程序流程解释</h3><p>程序和 State 相关的流程如下：</p>
<ol>
<li>50 行创建一个 MemoryState，且设置 DefaultValue 为 (0, 0)</li>
<li>每次处理一个 Tuple 的时候，会首先读取当前 key 对应的 value（第 25 行）</li>
<li>然后进行处理后，更新 state 值（28 - 34 行）</li>
<li>最后跟进 state 的值判断是否进行相应处理 – 往下有发送平均值，以及清空 state （37 - 40 行）</li>
</ol>
<p>state 的值变化如下所示(红色的 0 为调用 clear 后生成)</p>
<table>
<thead>
<tr>
<th>f0</th>
<th>f1</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>8</td>
</tr>
<tr>
<td><span data-type="color" style="color:#F5222D;">0</span></td>
<td><span data-type="color" style="color:#F5222D;">0</span></td>
</tr>
<tr>
<td>1</td>
<td>7</td>
</tr>
<tr>
<td>2</td>
<td>11</td>
</tr>
<tr>
<td><span data-type="color" style="color:#F5222D;">0</span></td>
<td><span data-type="color" style="color:#F5222D;">0</span></td>
</tr>
<tr>
<td>1</td>
<td>2</td>
</tr>
</tbody>
</table>
<h2 id="RocksDBStateBackend"><a href="#RocksDBStateBackend" class="headerlink" title="RocksDBStateBackend"></a>RocksDBStateBackend</h2><p>RocksDBStateBackend 和 MemoryStateBackend 的区别主要在于，使用 RocksDB 替代 Memory 来存储 State。</p>
<p>由于 RocksDB 是一个 Key-Value Store，因此存储数据结构，和 MemoryStateBackend 稍微不一样。其中 key 为 serialized(keyGroup, key, namespace), value 为 serialized(value)</p>
<h2 id="自问自答"><a href="#自问自答" class="headerlink" title="自问自答"></a>自问自答</h2><ul>
<li>有哪些 StateBackend 实现，区别都是什么，每一种的优劣是什么<ul>
<li>StateBackend 的实现在文首给出来，其中 MemoryStateBackend 会很快，但是不仅行持久化，RocksDBStateBackend 使用 RocksDB 进行 State 存储，速度快，且会存储到持久化介质上</li>
<li>MemoryStateBackend 的局限：<ul>
<li>每个 state 的大小有上限限制，默认 5M，可配置</li>
<li>state 大小不能超过 akka frame size（其他的 statebackend 是否可以呢？）</li>
<li>JobManager 的内存需要能够存放所有的 state</li>
<li>建议使用场景：开发和调试阶段；state 不大的场景</li>
</ul>
</li>
<li>RocksDBStateBackend<ul>
<li>RocksDBStateBackend 将 in-flight 数据存在 RocksDB 中，会存放在 TaskManager 的 data 目录下</li>
<li>经常使用异步 Snapshot</li>
<li>局限如下：<ul>
<li>每个 key value 的大小不能超过 2^31（因为RocksDB 的 JNI bridge API 使用 byte[] 格式）</li>
</ul>
</li>
<li>建议使用场景：<ul>
<li>state 量很大，window 窗口很长的 job</li>
<li>其他需要 high-available 的场景</li>
</ul>
</li>
<li>支持增量 checkpoint</li>
</ul>
</li>
<li>FsStateBackend<ul>
<li>将 in-flight 数据存储在 TaskManager 的内存中，checkpoint 的时候将数据存储到外存</li>
<li>默认使用异步 snapshot </li>
<li>建议使用场景：<ul>
<li>大 state，window 窗口很长的 job</li>
<li>其他需要 high-available 的场景</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>作业选择不同 StateBackend 的标准是什么<ul>
<li>跟进速度和是否需要持久化到外存选择？</li>
</ul>
</li>
<li>不同 StateBackend 保存的数据结构是什么样的<ul>
<li>MemoryStateBackend 包括多种 State，其中 HeapValueState 的数据结构为 Map<integer, map<n,="" sv="">&gt;&gt; </integer,></li>
<li>RocksDBStateBackend 则存储的是 serialized(keyGroup, key, namespace) &lt;-&gt; serialized(value) 的形式</li>
</ul>
</li>
<li>不同 StateBackend 中内存占用怎么估计/计算<ul>
<li>暂时还不知道</li>
</ul>
</li>
<li>如果需要迁移 State 数据，怎么完成的（作业的并发进行调整）</li>
<li>哪些节点/角色会有 StateBackend，都用来做什么<ul>
<li>所有需要保存 State 的节点（？）JobManager、Task 等</li>
</ul>
</li>
<li>Keyed Stream 中不同的 key 会被发送到同一个 task 吗？key 往下发送的逻辑是什么<ul>
<li>根据 hash(key) 往下游发送</li>
</ul>
</li>
<li>keyGroup 和什么有关，生成规则是什么，在查问题的时候会用到吗（某个 value 属于哪个 keyGroup）<ul>
<li>keyGroup 的存在主要用于 rescale task，能够避免 random io 等</li>
<li>现在 keyGroup 在 Job 启动的时候确定，后面不会进行变更</li>
<li>key 属于哪个 keyGroup 由 hash 函数确定</li>
</ul>
</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="https://flink.apache.org/features/2017/07/04/flink-rescalable-state.html" target="_blank" rel="external">https://flink.apache.org/features/2017/07/04/flink-rescalable-state.html</a><br>[2] <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/state_backends.html" target="_blank" rel="external">https://ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/state_backends.html</a></p>
<h2 id="附"><a href="#附" class="headerlink" title="附"></a>附</h2><p>[1] 本文使用代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StreamingState</span> </span>&#123;</div><div class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">      <span class="comment">// get the execution environment</span></div><div class="line">      <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</div><div class="line"><span class="comment">// this can be used in a streaming program like this (assuming we have a StreamExecutionEnvironment env)</span></div><div class="line">      env.fromElements(Tuple2.of(<span class="number">1L</span>, <span class="number">3L</span>), Tuple2.of(<span class="number">1L</span>, <span class="number">5L</span>), Tuple2.of(<span class="number">1L</span>, <span class="number">7L</span>), Tuple2.of(<span class="number">1L</span>, <span class="number">4L</span>), Tuple2.of(<span class="number">1L</span>, <span class="number">2L</span>))</div><div class="line">         .keyBy(<span class="number">0</span>)</div><div class="line">         .flatMap(<span class="keyword">new</span> CountWindowAverage())</div><div class="line">         .print();</div><div class="line"></div><div class="line">      env.execute(<span class="string">"Streaming WordCount"</span>);</div><div class="line">   &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">CountWindowAverage</span> <span class="keyword">extends</span> <span class="title">RichFlatMapFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">Long</span>, <span class="title">Long</span>&gt;, <span class="title">Tuple2</span>&lt;<span class="title">Long</span>, <span class="title">Long</span>&gt;&gt; </span>&#123;</div><div class="line">   <span class="comment">/**</span></div><div class="line">    * The ValueState handle. The first field is the count, the second field a running sum.</div><div class="line">    */</div><div class="line">   <span class="keyword">private</span> <span class="keyword">transient</span> ValueState&lt;Tuple2&lt;Long, Long&gt;&gt; sum;</div><div class="line">  <span class="meta">@Overridelus</span></div><div class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(Tuple2&lt;Long, Long&gt; input, Collector&lt;Tuple2&lt;Long, Long&gt;&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">      <span class="comment">// access the state value</span></div><div class="line">      Tuple2&lt;Long, Long&gt; currentSum = sum.value();</div><div class="line"></div><div class="line">      <span class="comment">// update the count</span></div><div class="line">      currentSum.f0 += <span class="number">1</span>;</div><div class="line"></div><div class="line">      <span class="comment">// add the second field of the input value</span></div><div class="line">      currentSum.f1 += input.f1;</div><div class="line"></div><div class="line">      <span class="comment">// update the state</span></div><div class="line">      sum.update(currentSum);</div><div class="line"></div><div class="line">      <span class="comment">// if the count reaches 2, emit the average and clear the state</span></div><div class="line">      <span class="keyword">if</span> (currentSum.f0 &gt;= <span class="number">2</span>) &#123;</div><div class="line">         out.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(input.f0, currentSum.f1 / currentSum.f0));</div><div class="line">         sum.clear();</div><div class="line">    &#125;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="meta">@Override</span></div><div class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration config)</span> </span>&#123;</div><div class="line">      ValueStateDescriptor&lt;Tuple2&lt;Long, Long&gt;&gt; descriptor =</div><div class="line">         <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(</div><div class="line">            <span class="string">"average"</span>, <span class="comment">// the state name</span></div><div class="line">            TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;Long, Long&gt;&gt;() &#123;&#125;), <span class="comment">// type information</span></div><div class="line">            Tuple2.of(<span class="number">0L</span>, <span class="number">0L</span>)); <span class="comment">// default value of the state, if nothing was set</span></div><div class="line">      sum = getRuntimeContext().getState(descriptor);</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>[2] keyGroup 的好处</p>
<img src="/2018/04/06/Flink-State/state-rescale.png" alt="state-rescale.png" title="">
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 中 State 用于保存 Task 的状态，Checkpoint 的时候，会将 State 保存到外存中。&lt;/p&gt;
&lt;p&gt;State 有两种，Keyed State 和 Operator State，每一种则可以有两种形式存在：Managed 和 Raw。其中 Keyed State 只能引用在 Keyed Stream 上，在 Flink 中使用 keyBy() 创建一个 keyed Stream. Flink 保证同一个 key 的 Tuple 会被发送到同一个 task 进行处理，Operator State 使用 ListState（用于 rescale），上层是一个 HashMap&lt;string, partitionableliststate=&quot;&quot;&gt; Key 是 name，value 是一个封装了 list 的 class。&lt;/string,&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://yoursite.com/tags/Flink/"/>
    
      <category term="State" scheme="http://yoursite.com/tags/State/"/>
    
      <category term="MemoryStateBackend" scheme="http://yoursite.com/tags/MemoryStateBackend/"/>
    
      <category term="RocksDBStateBackend" scheme="http://yoursite.com/tags/RocksDBStateBackend/"/>
    
  </entry>
  
  <entry>
    <title>Java 内存泄漏分析和对内存设置</title>
    <link href="http://yoursite.com/2018/03/14/Java-%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E5%88%86%E6%9E%90%E5%92%8C%E5%AF%B9%E5%86%85%E5%AD%98%E8%AE%BE%E7%BD%AE/"/>
    <id>http://yoursite.com/2018/03/14/Java-内存泄漏分析和对内存设置/</id>
    <published>2018-03-14T04:15:45.000Z</published>
    <updated>2018-03-14T04:28:15.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-内存泄漏的背景知识"><a href="#1-内存泄漏的背景知识" class="headerlink" title="1 内存泄漏的背景知识"></a>1 内存泄漏的背景知识</h1><p>为了判断 Java 中是否有内存泄漏，我们首先必须了解 Java 是如何管理内存的。下面我们先给出一个简单的内存泄漏的例子，在这个例子中我们循环申请 Object 对象，并将所申请的对象放入一个 HashMap 中，如果我们仅仅释放引用本身，那么 HashMap 仍然引用该对象，所以这个对象对 GC 来说是不可回收的。</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">HashMap mapObj = new HashMap()</div><div class="line">	  </div><div class="line">	public void myfun() &#123;</div><div class="line">		String obj1 = new String(&quot;abcd&quot;);</div><div class="line">		mapObj.put(obj1, obj1);</div><div class="line">		...</div><div class="line">		obj1 = null;   //此时 obj1 指向的物理内存没有释放，因为 hashmap 引用该地址</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p>JVM 可以自动回收垃圾，但它只能回收满足条件的垃圾，有时需要们确保条件的满足。如果程序中，存在越来越多不在影响程序未来执行的对象（也就是不再需要的对象），而且这些对象和根对象之间存在引用路径，那么就发生了内存泄漏。</p>
<p>内存泄漏常发生在如下场景：</p>
<ul>
<li>全局容器类，对象不再需要时，忘记从容器中 remove</li>
<li>像 Runnable 对象等被 Java 虚拟机自身管理的对象，没有正确的释放渠道。Runnable 对象必须交给一个 Thread 去 run，否则该对象就永远不会消亡</li>
</ul>
<h2 id="1-1-Java-对象的-Size"><a href="#1-1-Java-对象的-Size" class="headerlink" title="1.1 Java 对象的 Size"></a>1.1 Java 对象的 Size</h2><p>在 64 位的平台上，Java 对象的占用内存如下</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>大小</th>
</tr>
</thead>
<tbody>
<tr>
<td>Object</td>
<td>16</td>
</tr>
<tr>
<td>Float</td>
<td>16</td>
</tr>
<tr>
<td>Double</td>
<td>24</td>
</tr>
<tr>
<td>Integer</td>
<td>16</td>
</tr>
<tr>
<td>Long</td>
<td>24</td>
</tr>
</tbody>
</table>
<h2 id="1-2-对象及其引用"><a href="#1-2-对象及其引用" class="headerlink" title="1.2 对象及其引用"></a>1.2 对象及其引用</h2><p>为了说明对象和引用，我们先定义一个简单的类</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">class Person &#123;</div><div class="line">	String name;</div><div class="line">	int age;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Person p1 = new Person() 包含如下几个动作</p>
<ol>
<li>右边的 new Person 在堆空间分配一块内存，创建一个 Person 类对象</li>
<li>末尾的 () 意味着创建对象之后，立即调用构造函数，进行初始化</li>
<li>左边的 Person p1 创建了一个引用变量，所谓引用变量，就是后来用于指向 Person 类示例的引用</li>
<li>= 符号使刚刚创建的对象引用指向刚刚创建的对象<br>上面的代码如下所示：</li>
</ol>
<img src="/2018/03/14/Java-内存泄漏分析和对内存设置/image1.png" alt="image1.png" title="">
<p>如果再将对象赋值给 p2 的话，变成下面这样的</p>
<img src="/2018/03/14/Java-内存泄漏分析和对内存设置/image2.png" alt="image2.png" title="">
<p>执行 p2 = new Person() 之后变成</p>
<img src="/2018/03/14/Java-内存泄漏分析和对内存设置/image3.png" alt="image3.png" title="">
<h2 id="1-3-虚拟机垃圾自动回收机制"><a href="#1-3-虚拟机垃圾自动回收机制" class="headerlink" title="1.3 虚拟机垃圾自动回收机制"></a>1.3 虚拟机垃圾自动回收机制</h2><p>垃圾自动回收做两件事情：</p>
<ol>
<li>标记垃圾</li>
<li>清除垃圾</li>
</ol>
<p>标记过程现在主要使用 根可达性 分析（还有引用计数法等），清除之后可能会有一些小的内存快，所有还有压缩的过程。</p>
<p>下图中的灰色对象表示可以被回收的对象（根不可达）</p>
<img src="/2018/03/14/Java-内存泄漏分析和对内存设置/image4.png" alt="image4.png" title="">
<p>哪些对象可以成为 根 呢？ <a href="http://help.eclipse.org/luna/index.jsp?topic=%2Forg.eclipse.mat.ui.help%2Fconcepts%2Fgcroots.html&amp;cp=37_2_3" target="_blank" rel="external">http://help.eclipse.org/luna/index.jsp?topic=%2Forg.eclipse.mat.ui.help%2Fconcepts%2Fgcroots.html&amp;cp=37_2_3</a></p>
<ul>
<li>没有被任何外部对象引用的栈上的对象</li>
<li>静态变量</li>
<li>JNI handler 包括全局和局部</li>
<li>系统 Class</li>
<li>存活着的监视器</li>
</ul>
<h1 id="2-内存泄漏的症状"><a href="#2-内存泄漏的症状" class="headerlink" title="2 内存泄漏的症状"></a>2 内存泄漏的症状</h1><h2 id="2-1-为什么会发生-OOM-问题？"><a href="#2-1-为什么会发生-OOM-问题？" class="headerlink" title="2.1 为什么会发生 OOM 问题？"></a>2.1 为什么会发生 OOM 问题？</h2><p>内存不足会有三种情况：</p>
<ul>
<li>对内存不足</li>
<li>本地内存不足</li>
<li>Perm 内存不足</li>
</ul>
<p>发生 OOM 的时候，可以检查如下几个方面：</p>
<ul>
<li>应用程序的缓存功能</li>
<li>大量长期活动对象</li>
<li>对内存泄漏</li>
<li>本地内存泄漏</li>
</ul>
<h2 id="2-2-内存泄漏的症状"><a href="#2-2-内存泄漏的症状" class="headerlink" title="2.2 内存泄漏的症状"></a>2.2 内存泄漏的症状</h2><p>内存泄漏一般会有如下几个症状：</p>
<ul>
<li>系统越来越慢，并且有 CPU 使用率过高</li>
<li>运行一段时间后，OOM</li>
<li>虚拟机 core dump</li>
</ul>
<h1 id="3-内存泄漏的定位和分析"><a href="#3-内存泄漏的定位和分析" class="headerlink" title="3 内存泄漏的定位和分析"></a>3 内存泄漏的定位和分析</h1><p>内存泄漏的分析并不复杂，但需要耐心，一般内存泄漏只能事后分析，而重现问题需要耐心。</p>
<h2 id="3-1-对内存泄漏定位"><a href="#3-1-对内存泄漏定位" class="headerlink" title="3.1 对内存泄漏定位"></a>3.1 对内存泄漏定位</h2><p>当出现 java.lang.OutOfMemoryError: Java Heap Space 异常，就表示堆内存不足了。堆内存不足的原因有如下几种：</p>
<ul>
<li>堆内存设置太小</li>
<li>内存泄漏</li>
<li>设计不足，缓存了多余的数据</li>
<li>如果怀疑有内存泄漏，可以添加 -verbose:gc 参数后重现启动 Java 进程，输出大致如下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">8190.813: [GC 164675K-&gt;251016K(1277056K), 0.0117749 secs] #8190.813 表示垃圾回收的时间点，秒为单位。GC/Full GC 表示垃圾回收的类型</div><div class="line">8190.825: [Full GC 251016K-&gt;164654K(1277056K), 0.8142190 secs]   # 251016K表示回收前占用的内存大小，164654K 表示回收后占用的内存大小，1277056K 表示当前对内存总大小，0.8142190 表示回收耗时</div><div class="line">8191.644: [GC 164678K-&gt;251214K(1277248K), 0.0123627 secs]</div><div class="line">8191.657: [Full GC 251214K-&gt;164661K(1277248K), 0.8135393 secs]</div><div class="line">8192.478: [GC 164700K-&gt;251285K(1277376K), 0.0130357 secs]</div><div class="line">8192.491: [Full GC 251285K-&gt;164670K(1277376K), 0.8118171 secs]</div><div class="line">8193.311: [GC 164726K-&gt;251182K(1277568K), 0.0121369 secs]</div><div class="line">8193.323 : [Full GC 251182K-&gt;164644K(1277568K), 0.8186925 secs]</div><div class="line">8194.156: [GC 164766K-&gt;251028K(1277760K), 0.0123415 secs]</div><div class="line">8194.169: [Full GC 251028K-&gt;164660K(1277760K), 0.8144430 secs]</div></pre></td></tr></table></figure>
<p>怀疑内存泄漏后，我们通过 Full GC 日志进一步确认，检查 Full GC  后的可用内存是否持续增大。步骤如下：</p>
<ul>
<li>获取系统稳定后的 GC 日志（不稳定的日志不可靠）</li>
<li>过滤 FullGC 日志，可能会有如下两种情况<ul>
<li>FullGC 后内存使用量持续增长，一直到设置的堆内存最大值，基本可以确定内存泄漏</li>
<li>内存使用量增长后又回落，出于一个动态平衡区间，基本排除内存泄漏</li>
</ul>
</li>
</ul>
<p>GC 日志只能帮忙找到是否有泄漏，找出内存泄漏的地方，需要依赖一些其他的工具</p>
<ul>
<li>JProfile</li>
<li>OptimizedIt</li>
<li>JProbe</li>
<li>JConsole</li>
<li>-Xrunhprof </li>
</ul>
<h2 id="3-2-本地内存泄漏的定位"><a href="#3-2-本地内存泄漏的定位" class="headerlink" title="3.2 本地内存泄漏的定位"></a>3.2 本地内存泄漏的定位</h2><p>GC 日志无异常，但 Java 进程使用内存逐渐增大，并且无停止上涨的趋势。本地内存泄漏的原因有如下几个：</p>
<ul>
<li>JNI 调用中出现内存泄漏(JNI 调用出现内存泄漏，可以使用 C/C++ 内存泄漏分析方法定位)</li>
<li>JDK bug</li>
<li>操作系统问题</li>
</ul>
<p>本地内存泄漏可能伴有如下异常<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">java.lang.OutOfMemoryError: unable to create new native thread , Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: unable to create new native thread</div><div class="line">      at java.lang.Thread.start0(Native Method)</div><div class="line">      at java.lang.Thread.start(Thread.java:574)</div><div class="line">      at TestThread.main(TestThread.java:34)</div></pre></td></tr></table></figure></p>
<p>上面这个异常可能的原因有：</p>
<ul>
<li>创建的线程过多，可打印总线程数查看</li>
<li>swap 分区不足</li>
<li>堆内存过大，本地内存不足</li>
</ul>
<h2 id="3-3-Perm-区内存不足定位"><a href="#3-3-Perm-区内存不足定位" class="headerlink" title="3.3 Perm 区内存不足定位"></a>3.3 Perm 区内存不足定位</h2><p>出现 java.lang.OutOfMemoryError: PermGen space Perm ，说明 Perm 区内存不足</p>
<ul>
<li>依赖注入，没有卸载</li>
<li>Perm 区太小</li>
</ul>
<h2 id="3-4-分析方法"><a href="#3-4-分析方法" class="headerlink" title="3.4 分析方法"></a>3.4 分析方法</h2><ol>
<li>jmap -histo <java pid=""> &gt; objhist.log,  </java></li>
<li>如果系统已经 OutOfMemory，可以使用  jmap-heap:format=b<javapid> 获取内存信息</javapid></li>
<li>添加参数 -XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=”$PATH” 当发生 OOM 时会收集相应信息</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-内存泄漏的背景知识&quot;&gt;&lt;a href=&quot;#1-内存泄漏的背景知识&quot; class=&quot;headerlink&quot; title=&quot;1 内存泄漏的背景知识&quot;&gt;&lt;/a&gt;1 内存泄漏的背景知识&lt;/h1&gt;&lt;p&gt;为了判断 Java 中是否有内存泄漏，我们首先必须了解 Java 是如何管理内存的。下面我们先给出一个简单的内存泄漏的例子，在这个例子中我们循环申请 Object 对象，并将所申请的对象放入一个 HashMap 中，如果我们仅仅释放引用本身，那么 HashMap 仍然引用该对象，所以这个对象对 GC 来说是不可回收的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
      <category term="内存" scheme="http://yoursite.com/tags/%E5%86%85%E5%AD%98/"/>
    
      <category term="内存泄漏" scheme="http://yoursite.com/tags/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>通过 Java 线程堆栈进行性能瓶颈分析</title>
    <link href="http://yoursite.com/2018/02/28/%E9%80%9A%E8%BF%87-Java-%E7%BA%BF%E7%A8%8B%E5%A0%86%E6%A0%88%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/</id>
    <published>2018-02-28T09:32:05.000Z</published>
    <updated>2018-02-28T09:47:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>改善性能意味着用更少的资源做更多的事情。为了利用并发来提高系统性能，我们需要更有效的利用现有的处理器资源，这意味着我们期望使 CPU 尽可能出于忙碌状态（当然，并不是让 CPU 周期出于应付无用计算，而是让 CPU 做有用的事情而忙）。如果程序受限于当前的 CPU 计算能力，那么我们通过增加更多的处理器或者通过集群就能提高总的性能。总的来说，性能提高，需要且仅需要解决当前的受限资源，当前受限资源可能是：</p>
<ul>
<li>CPU： 如果当前 CPU 已经能够接近 100% 的利用率，并且代码业务逻辑无法再简化，那么说明该系统的性能以及达到上线，只有通过增加处理器来提高性能</li>
<li>其他资源：比如连接数等。可以修改代码，尽量利用 CPU，可以获得极大的性能提升</li>
</ul>
<a id="more"></a>
<p>如果你的系统有如下的特点，说明系统存在性能瓶颈：</p>
<ul>
<li><p>随着系统逐步增加压力，CPU 使用率无法趋近 100%（如下图）</p>
<img src="/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image1.png" alt="image1.png" title="">
</li>
<li><p>持续运行缓慢。时常发现应用程序运行缓慢。通过改变环境因子（负载，连接数等）也无法有效提升整体响应时间</p>
</li>
<li>系统性能随时间的增加逐渐下降。在负载稳定的情况下，系统运行时间越长速度越慢。可能是由于超出某个阈值范围，系统运行频繁出错从而导致系统死锁或崩溃</li>
<li>系统性能随负载的增加而逐渐下降。</li>
</ul>
<p>一个好的程序，应该是能够充分利用 CPU 的。如果一个程序在单 CPU 的机器上无论多大压力都不能使 CPU 使用率接近 100%，说明这个程序设计有问题。一个系统的性能瓶颈分析过程大致如下：</p>
<ol>
<li>先进性单流程的性能瓶颈分析，受限让单流程的性能达到最优。</li>
<li>进行整体性能瓶颈分析。因为单流程性能最优，不一定整个系统性能最优。在多线程场合下，锁争用㩐给也会导致性能下降。</li>
</ol>
<p>高性能在不同的应用场合下，有不同的含义：</p>
<ol>
<li>有的场合高性能意味着用户速度的体验，如界面操作等</li>
<li>有的场合，高吞吐量意味着高性能，如短信或者彩信，系统更看重吞吐量，而对每一个消息的处理时间不敏感</li>
<li>有的场合，是二者的结合</li>
</ol>
<p>性能调优的终极目标是：系统的 CPU 利用率接近 100%，如果 CPU 没有被充分利用，那么有如下几个可能：</p>
<ol>
<li>施加的压力不足</li>
<li>系统存在瓶颈</li>
</ol>
<h1 id="1-常见的性能瓶颈"><a href="#1-常见的性能瓶颈" class="headerlink" title="1 常见的性能瓶颈"></a>1 常见的性能瓶颈</h1><h2 id="1-1-由于不恰当的同步导致的资源争用"><a href="#1-1-由于不恰当的同步导致的资源争用" class="headerlink" title="1.1 由于不恰当的同步导致的资源争用"></a>1.1 由于不恰当的同步导致的资源争用</h2><h3 id="1-1-1-不相关的两个函数，公用了一个锁，或者不同的共享变量共用了同一个锁，无谓地制造出了资源争用"><a href="#1-1-1-不相关的两个函数，公用了一个锁，或者不同的共享变量共用了同一个锁，无谓地制造出了资源争用" class="headerlink" title="1.1.1 不相关的两个函数，公用了一个锁，或者不同的共享变量共用了同一个锁，无谓地制造出了资源争用"></a>1.1.1 不相关的两个函数，公用了一个锁，或者不同的共享变量共用了同一个锁，无谓地制造出了资源争用</h3><p>下面是一种常见的错误</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">class MyClass &#123;</div><div class="line">    Object sharedObj;</div><div class="line">	synchronized fun1() &#123;...&#125; //     访问共享变量 sharedObj</div><div class="line">	synchronized fun2() &#123;...&#125; //     访问共享变量 sharedObj</div><div class="line">	synchronized fun3() &#123;...&#125; //     不访问共享变量  sharedObj</div><div class="line">	synchronized fun4() &#123;...&#125; //     不访问共享变量  sharedObj</div><div class="line">	synchronized fun5() &#123;...&#125; //     不访问共享变量  sharedObj</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面的代码将 synchronized 加在类的每一个方法上面，违背了保护什么锁什么的原则。对于无共享资源的方法，使用了同一个锁，人为造成了不必要的等待。Java 缺省提供了 this 锁，这样很多人喜欢直接在方法上使用 synchronized 加锁，很多情况下这样做是不恰当的，如果不考虑清楚就这样做，很容易造成锁粒度过大：</p>
<ul>
<li>两个不相干的方法（没有使用同一个共享变量），共用了 this 锁，导致人为的资源竞争</li>
<li>即使一个方法中的代码也不是处处需要锁保护的。如果整个方法使用了 synchronized，那么很可能就把 synchronized 的作用域给人为扩大了。在方法级别上加锁，是一种粗犷的锁使用习惯。</li>
</ul>
<p>上面的代码应该变成下面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">class MyClass &#123;</div><div class="line">	Object sharedObj;</div><div class="line">	synchronized fun1() &#123;...&#125; //     访问共享变量 sharedObj</div><div class="line">	synchronized fun2() &#123;...&#125; //     访问共享变量 sharedObj</div><div class="line">	fun3() &#123;...&#125; //     不访问共享变量  sharedObj</div><div class="line">	fun4() &#123;...&#125; //     不访问共享变量  sharedObj</div><div class="line">	fun5() &#123;...&#125; //     不访问共享变量  sharedObj</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="1-1-2-锁的粒度过大，对共享资源访问完成后，没有将后续的代码放在synchronized-同步代码块之外"><a href="#1-1-2-锁的粒度过大，对共享资源访问完成后，没有将后续的代码放在synchronized-同步代码块之外" class="headerlink" title="1.1.2 锁的粒度过大，对共享资源访问完成后，没有将后续的代码放在synchronized 同步代码块之外"></a>1.1.2 锁的粒度过大，对共享资源访问完成后，没有将后续的代码放在synchronized 同步代码块之外</h3><p>这样会导致当前线程占用锁的时间过长，其他需要锁的线程只能等待，最终导致性能受到极大影响</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">void fun1()</div><div class="line">&#123;</div><div class="line">    synchronized(lock) &#123;</div><div class="line">    ...... //正在访问共享资源</div><div class="line">    ...... //做其他耗时操作，但这些耗时操作与共享资源无关</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面的代码，会导致一个线程长时间占有锁，而在这么长的时间里其他线程只能等待，这种写法在不同的场合下有不同的提升余地：</p>
<ul>
<li>单 CPU 场合  将耗时操作拿到同步块之外，有的情况下可以提升性能，有的场合则不能：<ul>
<li>同步块的耗时代码是 CPU 密集型代码（纯 CPU 运算等），不存在磁盘 IO/网络 IO 等低 CPU 消耗的代码，这种情况下，由于 CPU 执行这段代码是 100% 的使用率，因此缩小同步块也不会带来任何性能上的提升。但是，同时缩小同步块也不会带来性能上的下降</li>
<li>同步块中的耗时代码属于磁盘/网络 IO等低 CPU 消耗的代码，当当前线程正在执行不消耗 CPU 的代码时，这时候 CPU 是空闲的，如果此时让 CPU 忙起来，可以带来整体性能上的提升，所以在这种场景下，将耗时操作的代码放在同步之外，肯定是可以提高整个性能的（？）</li>
</ul>
</li>
<li>多 CPU 场合  将耗时的操作拿到同步块之外，总是可以提升性能<ul>
<li>同步块的耗时代码是 CPU 密集型代码（纯 CPU 运算等），不存在磁盘 IO/网络 IO 等低 CPU 消耗的代码，这种情况下，由于是多 CPU，其他 CPU也许是空闲的，因此缩小同步块可以让其他线程马上得到执行这段代码，可以带来性能的提升</li>
<li>同步块中的耗时代码属于磁盘/网络 IO等低 CPU 消耗的代码，当当前线程正在执行不消耗 CPU 的代码时，这时候总有 CPU 是空闲的，如果此时让 CPU 忙起来，可以带来整体性能上的提升，所以在这种场景下，将耗时操作的代码放在同步块之外，肯定是可以提高整个性能的</li>
</ul>
</li>
</ul>
<p>不管如何，缩小同步范围，对系统没有任何不好的影响，大多数情况下，会带来性能的提升，所以一定要缩小同步范围，因此上面的代码应该改为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">void fun1()</div><div class="line">&#123;</div><div class="line">     synchronized(lock) &#123;</div><div class="line">		...... //正在访问共享资源</div><div class="line">	&#125;</div><div class="line">	...... //做其他耗时操作，但这些耗时操作与共享资源无关</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="1-1-3-其他问题"><a href="#1-1-3-其他问题" class="headerlink" title="1.1.3 其他问题"></a>1.1.3 其他问题</h3><ul>
<li>Sleep 的滥用，尤其是轮询中使用 sleep，会让用户明显感觉到延迟，可以修改为 notify 和 wait</li>
<li>String + 的滥用，每次 + 都会产生一个临时对象，并有数据的拷贝</li>
<li>不恰当的线程模型</li>
<li>效率地下的 SQL 语句或者不恰当的数据库设计</li>
<li>不恰当的 GC 参数设置导致的性能低下</li>
<li>线程数量不足</li>
<li>内存泄漏导致的频繁 GC</li>
</ul>
<h2 id="2-2-性能瓶颈分析的手段和工具"><a href="#2-2-性能瓶颈分析的手段和工具" class="headerlink" title="2.2 性能瓶颈分析的手段和工具"></a>2.2 性能瓶颈分析的手段和工具</h2><p>上面提到的这些原因形成的性能瓶颈，都可以通过线程堆栈分析，找到根本原因。</p>
<h3 id="2-2-1-如何去模拟，发现性能瓶颈"><a href="#2-2-1-如何去模拟，发现性能瓶颈" class="headerlink" title="2.2.1 如何去模拟，发现性能瓶颈"></a>2.2.1 如何去模拟，发现性能瓶颈</h3><p>性能瓶颈的几个特征：</p>
<ul>
<li>当前的性能瓶颈只有一处，只有当解决了这一处，才知道下一处。没有解决当前性能瓶颈，下一处性能瓶颈是不会出现的。如下图所示，第二段是瓶颈，解决第二段的瓶颈后，第一段就变成了瓶颈，如此反复找到所有的性能瓶颈</li>
</ul>
<img src="/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image2.png" alt="image2.png" title="">
<ul>
<li>性能瓶颈是动态的，低负载下不是瓶颈的地方，高负载下可能成为瓶颈。由于 JProfile 等性能剖析工具依附在 JVM 上带来的开销，使系统根本就无法达到该瓶颈出现时需要的性能，因此在这种场景下线程堆栈分析才是一个真正有效的方法</li>
</ul>
<p>鉴于性能瓶颈的以上特点，进行性能模拟的时候，一定要使用比系统当前稍高的压力下进行模拟，否则性能瓶颈不会出现。具体步骤如下：</p>
<img src="/2018/02/28/通过-Java-线程堆栈进行性能瓶颈分析/image3.png" alt="image3.png" title="">
<h3 id="2-2-2-如何通过线程堆栈识别性能瓶颈"><a href="#2-2-2-如何通过线程堆栈识别性能瓶颈" class="headerlink" title="2.2.2 如何通过线程堆栈识别性能瓶颈"></a>2.2.2 如何通过线程堆栈识别性能瓶颈</h3><p>通过线程堆栈，可以很容易的识别多线程场合下高负载的时候才会出现的性能瓶颈。一旦一个系统出现性能瓶颈，最重要的就是识别性能瓶颈，然后根据识别的性能瓶颈进行修改。一般多线程系统，先按照线程的功能进行归类（组），把执行相同功能代码的线程作为一组进行分析。当使用堆栈进行分析的时候，以这一组线程进行统计学分析。如果一个线程池为不同的功能代码服务，那么将整个线程池的线程作为一组进行分析即可。</p>
<p>一般一个系统一旦出现性能瓶颈，从堆栈上分析，有如下三种最为典型的堆栈特征：</p>
<ol>
<li>绝大多数线程的堆栈都表现为在同一个调用上下文，且只剩下非常少的空闲线程。可能的原因如下：<ul>
<li>线程的数量过少</li>
<li>锁的粒度过大导致的锁竞争</li>
<li>资源竞争</li>
<li>锁范围中有大量耗时操作</li>
<li>远程通信的对方处理缓慢</li>
</ul>
</li>
<li>绝大多数线程出于等待状态，只有几个工作的线程，总体性能上不去。可能的原因是，系统存在关键路径，关键路径已经达到瓶颈</li>
<li>线程总的数量很少（有些线程池的实现是按需创建线程，可能程序中创建线程</li>
</ol>
<p>一个例子</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div></pre></td><td class="code"><pre><div class="line">&quot;Thread-243&quot; prio=1 tid=0xa58f2048 nid=0x7ac2 runnable</div><div class="line">   [0xaeedb000..0xaeedc480]</div><div class="line">          at java.net.SocketInputStream.socketRead0(Native Method)</div><div class="line">	       at java.net.SocketInputStream.read(SocketInputStream.java:129)</div><div class="line">	       at oracle.net.ns.Packet.receive(Unknown Source)</div><div class="line">	       ... ...</div><div class="line">		          at oracle.jdbc.driver.LongRawAccessor.getBytes()</div><div class="line">	       at oracle.jdbc.driver.OracleResultSetImpl.getBytes()</div><div class="line">	       - locked &lt;0x9350b0d8&gt; (a oracle.jdbc.driver.OracleResultSetImpl)</div><div class="line">	       at oracle.jdbc.driver.OracleResultSet.getBytes(O)</div><div class="line">	       ... ...</div><div class="line">		          at org.hibernate.loader.hql.QueryLoader.list()</div><div class="line">	       at org.hibernate.hql.ast.QueryTranslatorImpl.list()</div><div class="line">	       ... ...</div><div class="line">		          at com.wes.NodeTimerOut.execute(NodeTimerOut.java:175)</div><div class="line">	       at com.wes.timer.TimerTaskImpl.executeAll(TimerTaskImpl.java:707)</div><div class="line">	       at com.wes.timer.TimerTaskImpl.execute(TimerTaskImpl.java:627)</div><div class="line">	       - locked &lt;0x80df8ce8&gt; (a com.wes.timer.TimerTaskImpl)</div><div class="line">	       at com.wes.threadpool.RunnableWrapper.run(RunnableWrapper.java:209)</div><div class="line">	       at com.wes.threadpool.PooledExecutorEx$Worker.run()</div><div class="line">	       at java.lang.Thread.run(Thread.java:595)</div><div class="line">	&quot;Thread-248&quot; prio=1 tid=0xa58f2048 nid=0x7ac2 runnable</div><div class="line">	   [0xaeedb000..0xaeedc480]</div><div class="line">	          at java.net.SocketInputStream.socketRead0(Native Method)</div><div class="line">	       at java.net.SocketInputStream.read(SocketInputStream.java:129)</div><div class="line">	       at oracle.net.ns.Packet.receive(Unknown Source)</div><div class="line">	       ... ...</div><div class="line">		          at oracle.jdbc.driver.LongRawAccessor.getBytes()</div><div class="line">	       at oracle.jdbc.driver.OracleResultSetImpl.getBytes()</div><div class="line">	       - locked &lt;0x9350b0d8&gt; (a oracle.jdbc.driver.OracleResultSetImpl)</div><div class="line">	       at oracle.jdbc.driver.OracleResultSet.getBytes(O)</div><div class="line">	       ... ...</div><div class="line">		          at org.hibernate.loader.hql.QueryLoader.list()</div><div class="line">	       at org.hibernate.hql.ast.QueryTranslatorImpl.list()</div><div class="line">	       ... ...</div><div class="line">		           at com.wes.NodeTimerOut.execute(NodeTimerOut.java:175)</div><div class="line">	        at com.wes.timer.TimerTaskImpl.executeAll(TimerTaskImpl.java:707)</div><div class="line">	        at com.wes.timer.TimerTaskImpl.execute(TimerTaskImpl.java:627)</div><div class="line">	        - locked &lt;0x80df8ce8&gt; (a com.wes.timer.TimerTaskImpl)</div><div class="line">	        at com.wes.threadpool.RunnableWrapper.run(RunnableWrapper.java:209)</div><div class="line">	        at com.wes.threadpool.PooledExecutorEx$Worker.run()</div><div class="line">	        at java.lang.Thread.run(Thread.java:595)</div><div class="line">	        ... ...</div><div class="line">			&quot;Thread-238&quot; prio=1 tid=0xa4a84a58 nid=0x7abd in Object.wait()</div><div class="line">			[0xaec56000..0xaec57700]</div><div class="line">			    at java.lang.Object.wait(Native Method)</div><div class="line">	    at com.wes.collection.SimpleLinkedList.poll(SimpleLinkedList.java:104)</div><div class="line">	    - locked &lt;0x6ae67be0&gt; (a com.wes.collection.SimpleLinkedList)</div><div class="line">	    at com.wes.XADataSourceImpl.getConnection_internal(XADataSourceImpl.java:1642)</div><div class="line">	    ... ...</div><div class="line">		    at org.hibernate.impl.SessionImpl.list()</div><div class="line">	    at org.hibernate.impl.SessionImpl.find()</div><div class="line">	    at com.wes.DBSessionMediatorImpl.find()</div><div class="line">	    at com.wes.ResourceDBInteractorImpl.getCallBackObj()</div><div class="line">	    at com.wes.NodeTimerOut.execute(NodeTimerOut.java:152)</div><div class="line">	    at com.wes.timer.TimerTaskImpl.executeAll()</div><div class="line">	    at com.wes.timer.TimerTaskImpl.execute(TimerTaskImpl.java:627)</div><div class="line">	    - locked &lt;0x80e08c00&gt; (a com.facilities.timer.TimerTaskImpl)</div><div class="line">	    at com.wes.threadpool.RunnableWrapper.run(RunnableWrapper.java:209)</div><div class="line">	    at com.wes.threadpool.PooledExecutorEx$Worker.run()</div><div class="line">	    at java.lang.Thread.run(Thread.java:595)</div><div class="line">	 </div><div class="line">	 </div><div class="line">	&quot;Thread-233&quot; prio=1 tid=0xa4a84a58 nid=0x7abd in Object.wait()</div><div class="line">	[0xaec56000..0xaec57700]</div><div class="line">	 </div><div class="line">	    at java.lang.Object.wait(Native Method)</div><div class="line">	    at com.wes.collection.SimpleLinkedList.poll(SimpleLinkedList.java:104)</div><div class="line">	    - locked &lt;0x6ae67be0&gt; (a com.wes.collection.SimpleLinkedList)</div><div class="line">	    at com.wes.XADataSourceImpl.getConnection_internal(XADataSourceImpl.java:1642)</div><div class="line">	    ... ...</div><div class="line">		    at org.hibernate.impl.SessionImpl.list()</div><div class="line">	    at org.hibernate.impl.SessionImpl.find()</div><div class="line">	    at com.wes.DBSessionMediatorImpl.find()</div><div class="line">	    at com.wes.ResourceDBInteractorImpl.getCallBackObj()</div><div class="line">	    at com.wes.NodeTimerOut.execute(NodeTimerOut.java:152)</div><div class="line">	    at com.wes.timer.TimerTaskImpl.executeAll()</div><div class="line">	    at com.wes.timer.TimerTaskImpl.execute(TimerTaskImpl.java:627)</div><div class="line">	    - locked &lt;0x80e08c00&gt; (a com.facilities.timer.TimerTaskImpl)</div><div class="line">	    at com.wes.threadpool.RunnableWrapper.run(RunnableWrapper.java:209)</div><div class="line">	    at com.wes.threadpool.PooledExecutorEx$Worker.run()</div><div class="line">	    at java.lang.Thread.run(Thread.java:595)</div><div class="line">	    ... ...</div></pre></td></tr></table></figure>
<p>从堆栈看，有 51 个（socket）访问，其中有 50 个是 JDBC 数据库访问。其他方法被阻塞在 java.lang.Object.wait() 方法上。</p>
<h3 id="2-2-3-其他提高性能的方法"><a href="#2-2-3-其他提高性能的方法" class="headerlink" title="2.2.3 其他提高性能的方法"></a>2.2.3 其他提高性能的方法</h3><p>减少锁的粒度，比如 ConcurrentHashMap 的实现默认使用 16 个锁的 Array（有一个副作用：锁整个容器会很费力，可以添加一个全局锁）</p>
<h3 id="2-2-4-性能调优的终结条件"><a href="#2-2-4-性能调优的终结条件" class="headerlink" title="2.2.4 性能调优的终结条件"></a>2.2.4 性能调优的终结条件</h3><p>性能调优总有一个终止条件，如果系统满足如下两个条件，即可终止：</p>
<ol>
<li>算法足够优化</li>
<li>没有线程/资源的使用不当而导致的 CPU 利用不足</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;改善性能意味着用更少的资源做更多的事情。为了利用并发来提高系统性能，我们需要更有效的利用现有的处理器资源，这意味着我们期望使 CPU 尽可能出于忙碌状态（当然，并不是让 CPU 周期出于应付无用计算，而是让 CPU 做有用的事情而忙）。如果程序受限于当前的 CPU 计算能力，那么我们通过增加更多的处理器或者通过集群就能提高总的性能。总的来说，性能提高，需要且仅需要解决当前的受限资源，当前受限资源可能是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU： 如果当前 CPU 已经能够接近 100% 的利用率，并且代码业务逻辑无法再简化，那么说明该系统的性能以及达到上线，只有通过增加处理器来提高性能&lt;/li&gt;
&lt;li&gt;其他资源：比如连接数等。可以修改代码，尽量利用 CPU，可以获得极大的性能提升&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
      <category term="线程堆栈" scheme="http://yoursite.com/tags/%E7%BA%BF%E7%A8%8B%E5%A0%86%E6%A0%88/"/>
    
      <category term="性能分析" scheme="http://yoursite.com/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    
      <category term="瓶颈" scheme="http://yoursite.com/tags/%E7%93%B6%E9%A2%88/"/>
    
  </entry>
  
  <entry>
    <title>线程堆栈分析</title>
    <link href="http://yoursite.com/2018/01/06/%E7%BA%BF%E7%A8%8B%E5%A0%86%E6%A0%88%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2018/01/06/线程堆栈分析/</id>
    <published>2018-01-06T13:52:24.000Z</published>
    <updated>2018-01-07T11:34:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文为读书笔记，关于 Java 线程堆栈分析，在阅读并进行实验的基础上进行整理，如果有问题欢迎反馈<br><a id="more"></a></p>
<p>Java 虚拟机提供了线程转储（Thread dump）的后门，通过这个后门，可以将线程堆栈打印出来。这个后门就是通过向 Java 进程发送一个 QUIT 信号，Java 虚拟机收到该信号之后，将系统当前的 Java 线程调用堆栈打印出来。</p>
<p><code>kill -3 &lt;java_pid&gt;  /jstack &lt;java_pid&gt;</code></p>
<h1 id="1-Demo"><a href="#1-Demo" class="headerlink" title="1. Demo"></a>1. Demo</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">public class MyTest &#123;</div><div class="line">	    Object obj1 = new Object();</div><div class="line">		Object obj2 = new Object();</div><div class="line">		public void fun1() &#123;</div><div class="line">			synchronized(obj1) &#123;</div><div class="line">				fun2();</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		public void fun2() &#123;</div><div class="line">			synchronized(obj2) &#123;</div><div class="line">				while(true) &#123;</div><div class="line">					System.out.print(&quot;&quot;);</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		public static void main(String[] args) &#123;</div><div class="line">			MyTest aa = new MyTest();</div><div class="line">			aa.fun1();</div><div class="line">		&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="1-1-使用-kill-3-得到的结果"><a href="#1-1-使用-kill-3-得到的结果" class="headerlink" title="1.1 使用 kill -3 得到的结果"></a>1.1 使用 kill -3 得到的结果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">2017-12-26 10:59:58</div><div class="line">Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.76-b04 mixed mode):</div><div class="line">	&quot;Attach Listener&quot; daemon prio=10 tid=0x00007fd9d4001000 nid=0x6993 runnable [0x0000000000000000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">	&quot;Service Thread&quot; daemon prio=10 tid=0x00007fda3c0a8800 nid=0x695f runnable [0x0000000000000000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">	&quot;C2 CompilerThread1&quot; daemon prio=10 tid=0x00007fda3c0a6000 nid=0x695e waiting on condition [0x0000000000000000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">	&quot;C2 CompilerThread0&quot; daemon prio=10 tid=0x00007fda3c0a3000 nid=0x695d waiting on condition [0x0000000000000000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">	&quot;Signal Dispatcher&quot; daemon prio=10 tid=0x00007fda3c0a0800 nid=0x695c waiting on condition [0x0000000000000000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">	&quot;Finalizer&quot; daemon prio=10 tid=0x00007fda3c078000 nid=0x695b in Object.wait() [0x00007fda32e06000]</div><div class="line">		java.lang.Thread.State: WAITING (on object monitor)</div><div class="line">		at java.lang.Object.wait(Native Method)</div><div class="line">		- waiting on &lt;0x0000000758c04858&gt; (a java.lang.ref.ReferenceQueue$Lock)</div><div class="line">		at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)</div><div class="line">		- locked &lt;0x0000000758c04858&gt; (a java.lang.ref.ReferenceQueue$Lock)</div><div class="line">		at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)</div><div class="line">		at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)</div><div class="line">	&quot;Reference Handler&quot; daemon prio=10 tid=0x00007fda3c076000 nid=0x695a in Object.wait() [0x00007fd9ec28e000]</div><div class="line">		java.lang.Thread.State: WAITING (on object monitor)</div><div class="line">		at java.lang.Object.wait(Native Method)</div><div class="line">		- waiting on &lt;0x0000000758c04470&gt; (a java.lang.ref.Reference$Lock)</div><div class="line">		at java.lang.Object.wait(Object.java:503)</div><div class="line">		at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)</div><div class="line">		- locked &lt;0x0000000758c04470&gt; (a java.lang.ref.Reference$Lock)</div><div class="line">		&quot;main&quot; prio=10 tid=0x00007fda3c008800 nid=0x6950 runnable [0x00007fda4588a000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">		at MyTest.fun2(MyTest.java:12)</div><div class="line">		- locked &lt;0x0000000758c4a7f8&gt; (a java.lang.Object)</div><div class="line">		at MyTest.fun1(MyTest.java:6)</div><div class="line">		- locked &lt;0x0000000758c4a7e8&gt; (a java.lang.Object)</div><div class="line">		at MyTest.main(MyTest.java:18)</div><div class="line">	&quot;VM Thread&quot; prio=10 tid=0x00007fda3c071800 nid=0x6959 runnable</div><div class="line">	&quot;GC task thread#0 (ParallelGC)&quot; prio=10 tid=0x00007fda3c01e000 nid=0x6951 runnable</div><div class="line">	&quot;GC task thread#1 (ParallelGC)&quot; prio=10 tid=0x00007fda3c020000 nid=0x6952 runnable</div><div class="line">	&quot;GC task thread#2 (ParallelGC)&quot; prio=10 tid=0x00007fda3c022000 nid=0x6953 runnable</div><div class="line">	&quot;GC task thread#3 (ParallelGC)&quot; prio=10 tid=0x00007fda3c024000 nid=0x6954 runnable</div><div class="line">	&quot;GC task thread#4 (ParallelGC)&quot; prio=10 tid=0x00007fda3c026000 nid=0x6955 runnable</div><div class="line">	&quot;GC task thread#5 (ParallelGC)&quot; prio=10 tid=0x00007fda3c027800 nid=0x6956 runnable</div><div class="line">	&quot;GC task thread#6 (ParallelGC)&quot; prio=10 tid=0x00007fda3c029800 nid=0x6957 runnable</div><div class="line">	&quot;GC task thread#7 (ParallelGC)&quot; prio=10 tid=0x00007fda3c02b800 nid=0x6958 runnable</div><div class="line">	&quot;VM Periodic Task Thread&quot; prio=10 tid=0x00007fda3c0b3000 nid=0x6960 waiting on condition</div><div class="line">	JNI global references: 123</div><div class="line">	Heap</div><div class="line">		PSYoungGen total 150528K, used 7772K [0x0000000758c00000, 0x0000000763380000, 0x0000000800000000)</div><div class="line">		eden space 129536K, 6% used [0x0000000758c00000,0x0000000759397200,0x0000000760a80000)</div><div class="line">		from space 20992K, 0% used [0x0000000761f00000,0x0000000761f00000,0x0000000763380000)</div><div class="line">		to space 20992K, 0% used [0x0000000760a80000,0x0000000760a80000,0x0000000761f00000)</div><div class="line">		ParOldGen total 342528K, used 0K [0x000000060a400000, 0x000000061f280000, 0x0000000758c00000)</div><div class="line">		object space 342528K, 0% used [0x000000060a400000,0x000000060a400000,0x000000061f280000)</div><div class="line">		PSPermGen total 21504K, used 2429K [0x0000000605200000, 0x0000000606700000, 0x000000060a400000)</div><div class="line">		object space 21504K, 11% used [0x0000000605200000,0x000000060545f738,0x0000000606700000)</div></pre></td></tr></table></figure>
<h2 id="1-2-jstack-的结果"><a href="#1-2-jstack-的结果" class="headerlink" title="1.2 jstack 的结果"></a>1.2 jstack 的结果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">2017-12-26 11:04:54</div><div class="line">Full thread dump Java HotSpot(TM) 64-Bit Server VM (24.76-b04 mixed mode):</div><div class="line">	&quot;Attach Listener&quot; daemon prio=10 tid=0x00007fd9d4001000 nid=0x6993 waiting on condition [0x0000000000000000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">	&quot;Service Thread&quot; daemon prio=10 tid=0x00007fda3c0a8800 nid=0x695f runnable [0x0000000000000000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">	&quot;C2 CompilerThread1&quot; daemon prio=10 tid=0x00007fda3c0a6000 nid=0x695e waiting on condition [0x0000000000000000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">	&quot;C2 CompilerThread0&quot; daemon prio=10 tid=0x00007fda3c0a3000 nid=0x695d waiting on condition [0x0000000000000000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">	&quot;Signal Dispatcher&quot; daemon prio=10 tid=0x00007fda3c0a0800 nid=0x695c runnable [0x0000000000000000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">	&quot;Finalizer&quot; daemon prio=10 tid=0x00007fda3c078000 nid=0x695b in Object.wait() [0x00007fda32e06000]</div><div class="line">		java.lang.Thread.State: WAITING (on object monitor)</div><div class="line">		at java.lang.Object.wait(Native Method)</div><div class="line">		- waiting on &lt;0x0000000758c04858&gt; (a java.lang.ref.ReferenceQueue$Lock)</div><div class="line">		at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)</div><div class="line">		- locked &lt;0x0000000758c04858&gt; (a java.lang.ref.ReferenceQueue$Lock)</div><div class="line">		at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)</div><div class="line">		at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)</div><div class="line">	&quot;Reference Handler&quot; daemon prio=10 tid=0x00007fda3c076000 nid=0x695a in Object.wait() [0x00007fd9ec28e000]</div><div class="line">		java.lang.Thread.State: WAITING (on object monitor)</div><div class="line">		at java.lang.Object.wait(Native Method)</div><div class="line">		- waiting on &lt;0x0000000758c04470&gt; (a java.lang.ref.Reference$Lock)</div><div class="line">		at java.lang.Object.wait(Object.java:503)</div><div class="line">		at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)</div><div class="line">		- locked &lt;0x0000000758c04470&gt; (a java.lang.ref.Reference$Lock)</div><div class="line">	&quot;main&quot; prio=10 tid=0x00007fda3c008800 nid=0x6950 runnable [0x00007fda4588a000]</div><div class="line">		java.lang.Thread.State: RUNNABLE</div><div class="line">		at MyTest.fun2(MyTest.java:12)</div><div class="line">		- locked &lt;0x0000000758c4a7f8&gt; (a java.lang.Object)</div><div class="line">		at MyTest.fun1(MyTest.java:6)</div><div class="line">		- locked &lt;0x0000000758c4a7e8&gt; (a java.lang.Object)</div><div class="line">		at MyTest.main(MyTest.java:18)</div><div class="line">	&quot;VM Thread&quot; prio=10 tid=0x00007fda3c071800 nid=0x6959 runnable</div><div class="line">	&quot;GC task thread#0 (ParallelGC)&quot; prio=10 tid=0x00007fda3c01e000 nid=0x6951 runnable</div><div class="line">	&quot;GC task thread#1 (ParallelGC)&quot; prio=10 tid=0x00007fda3c020000 nid=0x6952 runnable</div><div class="line">	&quot;GC task thread#2 (ParallelGC)&quot; prio=10 tid=0x00007fda3c022000 nid=0x6953 runnable</div><div class="line">	&quot;GC task thread#3 (ParallelGC)&quot; prio=10 tid=0x00007fda3c024000 nid=0x6954 runnable</div><div class="line">	&quot;GC task thread#4 (ParallelGC)&quot; prio=10 tid=0x00007fda3c026000 nid=0x6955 runnable</div><div class="line">	&quot;GC task thread#5 (ParallelGC)&quot; prio=10 tid=0x00007fda3c027800 nid=0x6956 runnable</div><div class="line">	&quot;GC task thread#6 (ParallelGC)&quot; prio=10 tid=0x00007fda3c029800 nid=0x6957 runnable</div><div class="line">	&quot;GC task thread#7 (ParallelGC)&quot; prio=10 tid=0x00007fda3c02b800 nid=0x6958 runnable</div><div class="line">	&quot;VM Periodic Task Thread&quot; prio=10 tid=0x00007fda3c0b3000 nid=0x6960 waiting on condition</div><div class="line">	JNI global references: 123</div></pre></td></tr></table></figure>
<h2 id="1-3-分析"><a href="#1-3-分析" class="headerlink" title="1.3 分析"></a>1.3 分析</h2><p>用户线程为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&quot;main&quot; prio=10 tid=0x00007fda3c008800 nid=0x6950 runnable [0x00007fda4588a000] //main 表示线程名称，proi=1 表示线程优先级，tid=0x00007fda3c008800 表示线程 id，nid=0x6950 表示本地线程 id（这个查问题的时候会用到），runnable 表示线程状态，0x00007fda4588a000 表示内存地址</div><div class="line"> java.lang.Thread.State: RUNNABLE</div><div class="line">  at MyTest.fun2(MyTest.java:12) //第一个MyTest 表示类名，fun2 表示方法名，第二个 MyTest.java 表示正在调用的函数所在的源代码文件，12 表示行号</div><div class="line">	 - locked &lt;0x0000000758c4a7f8&gt; (a java.lang.Object) //locked 表示持有锁，后面的 0x0000000758c4a7f8 表示锁的 ID</div><div class="line">	 at MyTest.fun1(MyTest.java:6)</div><div class="line">	 - locked &lt;0x0000000758c4a7e8&gt; (a java.lang.Object)</div><div class="line">	 at MyTest.main(MyTest.java:18)</div></pre></td></tr></table></figure>
<p>如何获得 Java 虚拟机对应的本地线程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">1. jps //获取 Java 进程 ID</div><div class="line">2. pstack &lt;java_pid&gt; 获得 Java 虚拟机的本地线程的堆栈</div></pre></td></tr></table></figure>
<p>获得的本地线程栈如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div></pre></td><td class="code"><pre><div class="line">Thread 19 (Thread 0x7fda4588b700 (LWP 26960)): // Thread 19 表示线程名称，0x7fda4588b700 表示本地线程 id，LWP 26960 本地线程的另一种表示，LWP-light weight process（和上面的 nid 会一一对应，这里是十进制，上面的是十六进制）</div><div class="line">#0 0x00007fda401b2c47 in ?? ()</div><div class="line">#1 0x00007fda401ab8fc in ?? ()</div><div class="line">#2 0x0000000758c4a7f8 in ?? ()</div><div class="line">#3 0x00007fda4588a8a0 in ?? ()</div><div class="line">#4 0x0000000000000001 in ?? ()</div><div class="line">#5 0x00007fda4014f058 in ?? ()</div><div class="line">#6 0x00007fda4588a8f8 in ?? ()</div><div class="line">#7 0x00007fda4014f058 in ?? ()</div><div class="line">#8 0x0000000758c4a7d0 in ?? ()</div><div class="line">#9 0x0000000000000001 in ?? ()</div><div class="line">#10 0x0000000758c4a7e8 in ?? ()</div><div class="line">#11 0x00007fda4588a8a8 in ?? ()</div><div class="line">#12 0x000000060545d7b0 in ?? ()</div><div class="line">#13 0x00007fda4588a918 in ?? ()</div><div class="line">#14 0x000000060545dc80 in ?? ()</div><div class="line">#15 0x0000000000000000 in ?? ()</div><div class="line">	Thread 18 (Thread 0x7fda40148700 (LWP 26961)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4438dad3 in GCTaskManager::get_task(unsigned int) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4438f198 in GCTaskThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">		Thread 17 (Thread 0x7fda3a5b3700 (LWP 26962)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4438dad3 in GCTaskManager::get_task(unsigned int) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4438f198 in GCTaskThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">			Thread 16 (Thread 0x7fda3a4b2700 (LWP 26963)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4438dad3 in GCTaskManager::get_task(unsigned int) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4438f198 in GCTaskThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">				Thread 15 (Thread 0x7fda3a3b1700 (LWP 26964)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4438dad3 in GCTaskManager::get_task(unsigned int) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4438f198 in GCTaskThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">					Thread 14 (Thread 0x7fda3a2b0700 (LWP 26965)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4438dad3 in GCTaskManager::get_task(unsigned int) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4438f198 in GCTaskThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">						Thread 13 (Thread 0x7fda3a1af700 (LWP 26966)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4438dad3 in GCTaskManager::get_task(unsigned int) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4438f198 in GCTaskThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">							Thread 12 (Thread 0x7fda3a0ae700 (LWP 26967)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4438dad3 in GCTaskManager::get_task(unsigned int) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4438f198 in GCTaskThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">								Thread 11 (Thread 0x7fda39fad700 (LWP 26968)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4438dad3 in GCTaskManager::get_task(unsigned int) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4438f198 in GCTaskThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">									Thread 10 (Thread 0x7fda32f08700 (LWP 26969)):</div><div class="line">#0 0x00007fda4546ba5e in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44657c0f in os::PlatformEvent::park(long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda44619b2e in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda447e1899 in VMThread::loop() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda447e1ba0 in VMThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">										Thread 9 (Thread 0x7fd9ec28f700 (LWP 26970)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda44646ddd in ObjectMonitor::wait(long, bool, Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda444b6298 in JVM_MonitorWait () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4015bd98 in ?? ()</div><div class="line">#5 0x00007fda3c0768d8 in ?? ()</div><div class="line">#6 0x00007fd900000000 in ?? ()</div><div class="line">#7 0x00007fda3c076000 in ?? ()</div><div class="line">#8 0x00007fd9ec28e5d8 in ?? ()</div><div class="line">#9 0x0000000605202798 in ?? ()</div><div class="line">#10 0x00007fd9ec28e648 in ?? ()</div><div class="line">#11 0x00000006052a9e68 in ?? ()</div><div class="line">#12 0x0000000000000000 in ?? ()</div><div class="line">											Thread 8 (Thread 0x7fda32e07700 (LWP 26971)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda44646ddd in ObjectMonitor::wait(long, bool, Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda444b6298 in JVM_MonitorWait () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4015bd98 in ?? ()</div><div class="line">#5 0x00007fda3c078a08 in ?? ()</div><div class="line">#6 0x00007fda00000000 in ?? ()</div><div class="line">#7 0x00007fda3c078000 in ?? ()</div><div class="line">#8 0x00007fda32e065e8 in ?? ()</div><div class="line">#9 0x0000000000000000 in ?? ()</div><div class="line">												Thread 7 (Thread 0x7fda32d06700 (LWP 26972)):</div><div class="line">#0 0x00007fda4546da00 in sem_wait () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda446578ea in check_pending_signals(bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda44650b35 in signal_thread_entry(JavaThread*, Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda447930ff in JavaThread::thread_main_inner() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda44793205 in JavaThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#7 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">													Thread 6 (Thread 0x7fda32c05700 (LWP 26973)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a086 in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda44282648 in CompileQueue::get() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4428674a in CompileBroker::compiler_thread_loop() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda447930ff in JavaThread::thread_main_inner() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda44793205 in JavaThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#8 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#9 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#10 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">														Thread 5 (Thread 0x7fda32b04700 (LWP 26974)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a086 in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda44282648 in CompileQueue::get() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4428674a in CompileBroker::compiler_thread_loop() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda447930ff in JavaThread::thread_main_inner() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda44793205 in JavaThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#8 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#9 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#10 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">															Thread 4 (Thread 0x7fda32a03700 (LWP 26975)):</div><div class="line">#0 0x00007fda4546b68c in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44652543 in os::PlatformEvent::park() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda4461987f in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda446e95a8 in ServiceThread::service_thread_entry(JavaThread*, Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda447930ff in JavaThread::thread_main_inner() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44793205 in JavaThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#8 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#9 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">																Thread 3 (Thread 0x7fda32902700 (LWP 26976)):</div><div class="line">#0 0x00007fda4546ba5e in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44657c0f in os::PlatformEvent::park(long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda44619b2e in Monitor::IWait(Thread*, long) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda4461a00e in Monitor::wait(bool, long, bool) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda4478f121 in WatcherThread::sleep() const () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda4478f63e in WatcherThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">																	Thread 2 (Thread 0x7fda32801700 (LWP 27027)):</div><div class="line">#0 0x00007fda4546eb2d in accept () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda44136af1 in LinuxAttachListener::dequeue() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#2 0x00007fda44136c8b in AttachListener::dequeue() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#3 0x00007fda441357da in attach_listener_thread_entry(JavaThread*, Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#4 0x00007fda447930ff in JavaThread::thread_main_inner() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#5 0x00007fda44793205 in JavaThread::run() () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#6 0x00007fda44658ca8 in java_start(Thread*) () from /usr/local/jdk1.7.0_76/jre/lib/amd64/server/libjvm.so</div><div class="line">#7 0x00007fda45467aa1 in start_thread () from /lib64/libpthread.so.0</div><div class="line">#8 0x00007fda44d99aad in clone () from /lib64/libc.so.6</div><div class="line">																		Thread 1 (Thread 0x7fda4588d700 (LWP 26959)):</div><div class="line">#0 0x00007fda454682fd in pthread_join () from /lib64/libpthread.so.0</div><div class="line">#1 0x00007fda45256505 in ContinueInNewThread0 () from /usr/local/jdk1.7.0_76/bin/../lib/amd64/jli/libjli.so</div><div class="line">#2 0x00007fda4524b58a in ContinueInNewThread () from /usr/local/jdk1.7.0_76/bin/../lib/amd64/jli/libjli.so</div><div class="line">#3 0x00007fda4524e0e0 in JLI_Launch () from /usr/local/jdk1.7.0_76/bin/../lib/amd64/jli/libjli.so</div><div class="line">#4 0x0000000000400686 in main ()</div></pre></td></tr></table></figure>
<p>线程状态中的 runnable 从虚拟机的角度来看，表示这个线程正在运行。但是出于 runnable 的线程不一定真正消耗 CPU。出于 runnable 的线程只能说明该线程没有阻塞在 java 的 wait 或者 sleep 方法上，同时也没有等待在锁上面。但是如果该线程调用了本地方法（比如 java.net.SocketInputStream.socketRead0) ，而本地方法出于等待状态，这个时候虚拟机是不知道本地代码中发生了什么，此时尽管当前线程实际上也是阻塞状态，但实际上显示出来的还是 runnable 状态，这种情况下是不消耗 CPU 的。如下线程堆栈所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">&quot;Thread-243&quot; prio=1 tid=0xa58f2048 nid=0x7ac2 runnable [0xaeedb000..0xaeedc480]</div><div class="line">        at java.net.SocketInputStream.socketRead0(Native Method)</div><div class="line">	        at java.net.SocketInputStream.read(SocketInputStream.java:129)</div><div class="line">	        at oracle.net.ns.Packet.receive(Unknown Source)</div><div class="line">	        at oracle.net.ns.DataPacket.receive(Unknown Source)</div><div class="line">	        at oracle.net.ns.NetInputStream.getNextPacket(Unknown Source)</div><div class="line">	        at oracle.net.ns.NetInputStream.read(Unknown Source)</div><div class="line">	        at oracle.jdbc.driver.T4CMAREngine.getNBytes(T4CMAREngine.java:1520)</div><div class="line">	        at oracle.jdbc.driver.T4CMAREngine.unmarshalNBytes()</div><div class="line">	        at oracle.jdbc.driver.T4CLongRawAccessor.readStreamFromWire()</div><div class="line">	        at oracle.jdbc.driver.T4CLongRawAccessor.readStream()</div><div class="line">	        at oracle.jdbc.driver.T4CInputStream.getBytes(T4CInputStream.java:70)</div><div class="line">	        - locked &lt;0x934f4258&gt; (a oracle.jdbc.driver.T4CInputStream)</div><div class="line">	        - locked &lt;0x6b0dd600&gt; (a oracle.jdbc.driver.T4CConnection)</div><div class="line">	        at oracle.jdbc.driver.OracleInputStream.needBytes()</div><div class="line">	        ... ...</div><div class="line">			        at org.hibernate.loader.Loader.list(Loader.java:1577)</div><div class="line">	        at org.hibernate.loader.hql.QueryLoader.list()</div><div class="line">	        at com.wes.timer.TimerTaskImpl.execute(TimerTaskImpl.java:627)</div><div class="line">	        - locked &lt;0x80df8ce8&gt; (a com.wes.timer.TimerTaskImpl)</div><div class="line">	        at com.wes.threadpool.RunnableWrapper.run(RunnableWrapper.java:209)</div><div class="line">	        at com.wes.threadpool.PooledExecutorEx$Worker.run()</div><div class="line">	        at java.lang.Thread.run(Thread.java:595)</div></pre></td></tr></table></figure>
<p>那么 “.<clinit>“ 和 “.<init>“ 各表示什么含义呢？ “.<clinit>“ 表示当前正在执行类的初始化，”.<init>“ 正在执行对象的构造函数。</init></clinit></init></clinit></p>
<p>除接口外，初始化一个类之前必须保证其直接父类已被初始化，并且该初始化过程是由 JVM 保证线程安全的。并非所有的类都拥有一个 <clinit> 方法，在以下条件中该类不会拥有 <clinit> 方法</clinit></clinit></p>
<ul>
<li>该类既没有声明任何类变量，也没有静态初始化语句</li>
<li>该类声明了类变量，但没有明确使用类变量初始化语句或静态初始化语句初始化</li>
<li>该类仅包含静态 final 变量的类变量初始化语句，并且类变量初始化语句是编译时常量表达式</li>
</ul>
<h1 id="2-锁的解读"><a href="#2-锁的解读" class="headerlink" title="2 锁的解读"></a>2 锁的解读</h1><p>多线程中，wait() 和 sleep() 的区别。wait() 和 sleep() 有一个共同点，就是二者都会把当前的线程阻塞住，我们称之为睡眠或者等待。但二者实际上是完全不同的两个函数，有着本质的区别：</p>
<ul>
<li>当线程执行到 wait() 方法上，当前线程会释放监视锁，此时其他线程可以占有该锁，一旦 wait() 方法执行完成，当前线程又继续持有该锁，直到执行完该锁的作用域。<br>wait() 方法退出的原因：<ul>
<li>达到了等待时间，自动退出。如 wati(5000), 5秒后 wait 方法退出</li>
<li>其他的线程调用了该锁的 notify() 方法。当如果多个线程在等待同一个锁，只有一个线程会被通知到</li>
</ul>
</li>
<li>sleep() 与锁操作无关，如果该方法恰好在一个锁的保护范围之内，当前线程及时在执行 sleep() 的时候，仍然继续保持监视锁。该方法实际上仅仅完成等待或者睡眠的语义</li>
</ul>
<img src="/2018/01/06/线程堆栈分析/wait_sleep.png" alt="wait_sleep.png" title="">
<p>与锁相关的三个重要信息如下：</p>
<ul>
<li>当一个线程占有一个锁的时候，线程堆栈中会打印 – locked <0x22bffb60></0x22bffb60></li>
<li>当一个线程正在等待其他线程释放该锁，线程堆栈中会打印 – waiting to lock <0x22bffb60></0x22bffb60></li>
<li>当一个线程占有一个锁，但有执行到该锁的 wait() 上，线程堆栈中首先打印 locked, 然后又会打印 – waiting on <0x22c03c60></0x22c03c60></li>
</ul>
<h1 id="3-线程状态的解读"><a href="#3-线程状态的解读" class="headerlink" title="3 线程状态的解读"></a>3 线程状态的解读</h1><h2 id="3-1-RUNNABLE"><a href="#3-1-RUNNABLE" class="headerlink" title="3.1 RUNNABLE"></a>3.1 RUNNABLE</h2><p>RUNNABLE 从虚拟机的角度看，线程处于正在运行的状态，正在运行不一定消耗 CPU，比如下面的线程栈，在等待 IO</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Thread-39&quot; daemon prio=1 tid=0x08646590 nid=0x666d runnable [5beb7000..5beb88b8]</div><div class="line">  java.lang.Thread.State: RUNNABLE</div><div class="line">      at java.net.SocketInputStream.socketRead0(Native Method)</div><div class="line">	    at java.net.SocketInputStream.read(SocketInputStream.java:129)</div><div class="line">	    at java.io.BufferedInputStream.fill(BufferedInputStream.java:183)</div><div class="line">	    at java.io.BufferedInputStream.read(BufferedInputStream.java:201)</div><div class="line">	    - locked &lt;0x47bfb940&gt; (a java.io.BufferedInputStream)</div><div class="line">	    at org.postgresql.PG_Stream.ReceiveChar(PG_Stream.java:141)</div><div class="line">	    at org.postgresql.core.QueryExecutor.execute(QueryExecutor.java:68)</div><div class="line">	    - locked &lt;0x47bfb758&gt; (a org.postgresql.PG_Stream)</div><div class="line">	    at org.postgresql.Connection.ExecSQL(Connection.java:398)</div></pre></td></tr></table></figure>
<p>下面的线程栈则消耗 CPU</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">&quot;Thread-444&quot; prio=1 tid=0xa4853568 nid=0x7ade runnable [0xafcf7000..0xafcf8680]</div><div class="line">  java.lang.Thread.State: RUNNABLE</div><div class="line">      //实实在在对应 CPU 指令</div><div class="line">     at org.apache.commons.collections.ReferenceMap.getEntry(Unknown Source)</div><div class="line">	   at org.apache.commons.collections.ReferenceMap.get(Unknown Source)</div><div class="line">	   at org.hibernate.util.SoftLimitMRUCache.get(SoftLimitMRUCache.java:51)</div><div class="line">	   at org.hibernate.engine.query.QueryPlanCache.getNativeSQLQueryPlan()</div><div class="line">	   at org.hibernate.impl.AbstractSessionImpl.getNativeSQLQueryPlan()</div><div class="line">	   at org.hibernate.impl.AbstractSessionImpl.list()</div><div class="line">	   at org.hibernate.impl.SQLQueryImpl.list(SQLQueryImpl.java:164)</div><div class="line">	   at com.mogoko.struts.logic.user.LeaveMesManager.getCommentByShopId()</div><div class="line">	   at com.mogoko.struts.action.shop.ShopIndexBaseInfoAction.execute()</div><div class="line">	   ......</div></pre></td></tr></table></figure>
<p>下面的代码正在进行 JNI 本地方法调用，具体是否消耗 CPU，要看 TcpRecvExt 的实现，如果 TcpRecvExt 是纯运算代码，那么实实在在的消耗 CPU，如果 TcpRecvExt() 中存在挂起的代码，那么该线程尽管显示 RUNNABLE，实际也不消耗 CPU 的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&quot;ClientReceiveThread&quot; daemon prio=1 tid=0x99dbacf8 nid=0x7988 runnable [...]</div><div class="line">  java.lang.Thread.State: RUNNABLE</div><div class="line">      at com.pangu.network.icdcomm.htcpapijni.TcpRecvExt(Native Method)</div><div class="line">	    at com.pangu.network.icdcomm.IcdComm.receive(IcdComm.java:60)</div><div class="line">	    at com.msp.client.MspFactory$ClientReceiveThread.task(MspFactory.java:333)</div><div class="line">	    at com.msp.system.TaskThread.run(TaskThread.java:94)</div></pre></td></tr></table></figure>
<h2 id="3-2-TIMED-WAITING-on-object-monitor"><a href="#3-2-TIMED-WAITING-on-object-monitor" class="headerlink" title="3.2 TIMED_WAITING(on object monitor)"></a>3.2 TIMED_WAITING(on object monitor)</h2><p>TIMED_WAITING(on object monitor) 表示当前线程被挂起一段时间，说明该线程正在执行 object.wait(int time) 方法，不消耗 CPU</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&quot;JMX server&quot; daemon prio=6 tid=0x0ad2c800 nid=0xdec in Object.wait() [...]</div><div class="line">  java.lang.Thread.State: TIMED_WAITING (on  object  monitor)</div><div class="line">	   at java.lang.Object.wait(Native Method)</div><div class="line">	   - waiting on &lt;0x03129da0&gt; (a [I)</div><div class="line">	   at com.sun.jmx.remote.internal.ServerComm$Timeout.run(ServerComm.java:150)</div><div class="line">	   - locked &lt;0x03129da0&gt; (a [I)</div><div class="line">	   at java.lang.Thread.run(Thread.java:620)</div></pre></td></tr></table></figure>
<h2 id="3-3-TIME-WAITING-sleeping"><a href="#3-3-TIME-WAITING-sleeping" class="headerlink" title="3.3 TIME_WAITING(sleeping)"></a>3.3 TIME_WAITING(sleeping)</h2><p>TIME_WAITING(sleeping) 表示当前线程被挂起一段时间，正在执行 Thread.sleep(int time) 方法，不消耗 CPU</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&quot;Comm thread&quot; daemon prio=10 tid=0x00002aaad4107400 nid=0x649f waiting on condition</div><div class="line">    [0x000000004133b000..0x000000004133ba00]</div><div class="line">	        java.lang.Thread.State: TIMED_WAITING (sleeping)</div><div class="line">	            at java.lang.Thread.sleep(Native Method)</div><div class="line">	            at org.apache.hadoop.mapred.Task$1.run(Task.java:282)</div><div class="line">	            at java.lang.Thread.run(Thread.java:619)</div></pre></td></tr></table></figure>
<h2 id="3-4-TIME-WAITING-parking"><a href="#3-4-TIME-WAITING-parking" class="headerlink" title="3.4 TIME_WAITING(parking)"></a>3.4 TIME_WAITING(parking)</h2><p>TIME_WAITING(parking) 表示线程被挂起，正在执行 Thread.sleep(int time) 方法，不消耗 CPU</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&quot;RMI TCP&quot; daemon prio=6 tid=0x0ae3b800 nid=0x958 waiting on condition [0x17eff000..0x17effa94]</div><div class="line">    java.lang.Thread.State: TIMED_WAITING (parking)</div><div class="line">	       at sun.misc.Unsafe.park(Native Method)</div><div class="line">	       - parking to wait for  &lt;0x02f49f58&gt; (a java.util.concurrent.SynchronousQueue$TransferStack)</div><div class="line">	       at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:179)</div><div class="line">	       at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)</div><div class="line">	       at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)</div><div class="line">	       at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:871)</div><div class="line">	       at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:495)</div><div class="line">	       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:693)</div><div class="line">	       at java.lang.Thread.run(Thread.java:620)</div></pre></td></tr></table></figure>
<p>3.5 WAITING(on object monitor)<br>WAITING(on object monitor) 表示当前线程被挂起，正在执行 obj.wait() 只能通过 notify() 唤醒，不消耗 CPU</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&quot;IPC Client&quot; daemon prio=10 tid=0x00002aaad4129800 nid=0x649d in Object.wait() [0x039000..0x039d00]</div><div class="line">       java.lang.Thread.State: WAITING (on object monitor)</div><div class="line">	            at java.lang.Object.wait(Native Method)</div><div class="line">	            - waiting on &lt;0x00002aaab3acad18&gt;; (aorg.apache.hadoop.ipc.Client$Connection)</div><div class="line">	            at java.lang.Object.wait(Object.java:485)</div><div class="line">	            at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:234)</div><div class="line">	            - locked &lt;0x00002aaab3acad18&gt; (aorg.apache.hadoop.ipc.Client$Connection)</div><div class="line">	            at org.apache.hadoop.ipc.Client$Connection.run(Client.java:273)</div></pre></td></tr></table></figure>
<h2 id="3-6-小结"><a href="#3-6-小结" class="headerlink" title="3.6 小结"></a>3.6 小结</h2><p>处于 TIME_WAITING、WAITING 状态的线程不消耗 CPU，处于 RUNNABLE 状态的线程要结合线程代码性质判断，是否消耗 CPU</p>
<ul>
<li>如果是纯 Java 运算代码，消耗 CPU</li>
<li>如果是网络 IO，很少消耗 CPU</li>
<li>如果是本地代码，结合本地代码性质进行判断（通过 pstack/gstack 获取本地线程栈），如果是纯运算代码，消耗 CPU，如果被挂起，不消耗 CPU，如果是 IO，则不怎么消耗 CPU</li>
</ul>
<h1 id="4-接触线程堆栈进行问题分析"><a href="#4-接触线程堆栈进行问题分析" class="headerlink" title="4 接触线程堆栈进行问题分析"></a>4 接触线程堆栈进行问题分析</h1><p>线程堆栈翻译系统当前时间正在执行什么代码。根据这些信息就可以知道系统当前到底在做什么。看堆栈一般从三个视角来分析：堆栈的局部信息、一次堆栈的统计信息（全局信息）、多个堆栈的对比信息</p>
<ol>
<li>视角一  从一次的堆栈信息中，我们能直接获取以下直接的信息：<br> a. 当前每一个线程的调用层次关系（调用上下文），即每个线程当前正在调用哪些函数<br> b. 当前每个线程当前的状态：持有了哪些锁？在等待哪些锁？</li>
<li>视角二  从一次的堆栈信息中，我们还可以获取下面的统计方面信息：<br> a. 当前锁的争用情况：<pre><code>i. 是不是很多线程在等待同一个锁，如果很多线程等待同一个锁，说明这个系统已经出现了性能瓶颈，并导致了锁竞争。还可能是某个线程长时间持有一个锁不释放（比如这个线程正陷入了死循环的代码或者正在请求一个资源，很长时间得不到唤醒）
ii. 是否有死锁，哪些线程形成了死锁
</code></pre> b. 当前大多数线程在干什么，即正在执行什么代码<br> c. 当前线程总数量</li>
<li>视角三 从多次（即前后打印多次堆栈进行对比）的堆栈信息中，我们还可以获得下面的统计对比方面的信息：<br> a. 一个线程是否在长期执行。如果每次打印的堆栈，某一个线程一直处于同样的调用上下文中，那么说明这个线程一直在执行这段代码，此时就要根据代码逻辑检查，这种长期执行是否合理？<br> b. 某个线程是否存在长期获取不到锁的情况？线程是不是永远得不到唤醒？如果每次打印的堆栈，某一个线程一直在等待一个锁，那么就需要检查占有这个锁的线程为什么不释放锁？</li>
</ol>
<p>通过多个视角进行观察，线程堆栈在定位如下类型的问题上非常有帮助：</p>
<ul>
<li>线程死锁分析（视角一）</li>
<li>Java 代码导致的 CPU 过高分析（视角三）</li>
<li>死循环分析（视角三）</li>
<li>资源不足分析（视角二）</li>
<li>性能瓶颈分析（视角二和视角三）</li>
</ul>
<h2 id="4-1-线程死锁分析"><a href="#4-1-线程死锁分析" class="headerlink" title="4.1 线程死锁分析"></a>4.1 线程死锁分析</h2><p>死锁的原因：当两个或多个线程正在等待被对方占有的锁，死锁就会发生。死锁会导致两个线程无法继续运行，被永远挂起。下图中在时间点0，线程 0 占有了 lock0，线程1占有了 lock1，然后时间点 2 线程0 企图获取 lock 1，线程 1 企图获取 lock 0.由于这两个线程互相要等待被对方占有的锁，自己才能继续，因此造成死锁，二者永远没有机会继续运行下去。</p>
<img src="/2018/01/06/线程堆栈分析/dead_lock.png" alt="dead_lock.png" title="">
<p>一个简单的例子</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line">package MyPackage;</div><div class="line">public class Main &#123;</div><div class="line">	public static void main(String[] args) &#123;</div><div class="line">		Object lockobj1 = new Object();</div><div class="line">		Object lockobj2 = new Object();</div><div class="line">		TestThread1 thread1 = new TestThread1(lockobj1,lockobj2);</div><div class="line">		thread1.start();</div><div class="line">		TestThread2 thread2 = new TestThread2(lockobj1,lockobj2);</div><div class="line">		thread2.start();</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">                 </div><div class="line">package MyPackage;</div><div class="line">public class TestThread1  extends Thread&#123;</div><div class="line">	Object lock1 = null;</div><div class="line">	Object lock2 = null;</div><div class="line">	public TestThread1(Object lock1_,Object lock2_)</div><div class="line">	&#123;</div><div class="line">		lock1 = lock1_;</div><div class="line">		lock2 = lock2_;</div><div class="line">		this.setName(this.getClass().getName());</div><div class="line">	&#125;</div><div class="line">	public void run()</div><div class="line">	&#123;</div><div class="line">		fun();</div><div class="line">	&#125;</div><div class="line">	public void fun()&#123;</div><div class="line">		synchronized(lock1)&#123;</div><div class="line">			try&#123;</div><div class="line">				Thread.sleep(2);</div><div class="line">			&#125;</div><div class="line">			catch(Exception e)&#123;</div><div class="line">				e.printStackTrace();</div><div class="line">			&#125;</div><div class="line">			synchronized(lock2)&#123;</div><div class="line">			&#125;</div><div class="line">   		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">                 </div><div class="line">package MyPackage;</div><div class="line">public class TestThread2  extends Thread&#123;</div><div class="line">	Object lock1 = null;</div><div class="line">	Object lock2 = null;</div><div class="line">	public TestThread2(Object lock1_,Object lock2_)</div><div class="line">	&#123;</div><div class="line">		lock1 = lock1_;</div><div class="line">		lock2 = lock2_;</div><div class="line">		this.setName(this.getClass().getName());</div><div class="line">	&#125;</div><div class="line">	public void run()</div><div class="line">	&#123;</div><div class="line">		fun();</div><div class="line">	&#125;</div><div class="line">	public void fun()&#123;</div><div class="line">		synchronized(lock2)&#123;</div><div class="line">			try&#123;</div><div class="line">				Thread.sleep(2);</div><div class="line">			&#125;</div><div class="line">			catch(Exception e)&#123;</div><div class="line">				e.printStackTrace();</div><div class="line">			&#125;</div><div class="line">			synchronized(lock1)&#123;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>jstack 得到结果如下（截取后的堆栈信息）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">Found one Java-level deadlock:</div><div class="line">=============================</div><div class="line">&quot;MyPackage.TestThread2&quot;:</div><div class="line">  waiting to lock monitor 0x00007fa1b00062c8 (object 0x0000000758c4aa78, a java.lang.Object),</div><div class="line">  which is held by &quot;MyPackage.TestThread1&quot;</div><div class="line">&quot;MyPackage.TestThread1&quot;:</div><div class="line">  waiting to lock monitor 0x00007fa1b0004ed8 (object 0x0000000758c4aa88, a java.lang.Object),</div><div class="line">  which is held by &quot;MyPackage.TestThread2&quot;</div><div class="line">		 </div><div class="line">Java stack information for the threads listed above:</div><div class="line">===================================================</div><div class="line">&quot;MyPackage.TestThread2&quot;:</div><div class="line">  at MyPackage.TestThread2.fun(TestThread2.java:24)</div><div class="line">	- waiting to lock &lt;0x0000000758c4aa78&gt; (a java.lang.Object)</div><div class="line">	- locked &lt;0x0000000758c4aa88&gt; (a java.lang.Object)</div><div class="line">	at MyPackage.TestThread2.run(TestThread2.java:13)</div><div class="line">&quot;MyPackage.TestThread1&quot;:</div><div class="line">   at MyPackage.TestThread1.fun(TestThread1.java:24)</div><div class="line">	- waiting to lock &lt;0x0000000758c4aa88&gt; (a java.lang.Object)</div><div class="line">	- locked &lt;0x0000000758c4aa78&gt; (a java.lang.Object)</div><div class="line">   at MyPackage.TestThread1.run(TestThread1.java:13)</div><div class="line">	 </div><div class="line">Found 1 deadlock.</div></pre></td></tr></table></figure>
<p>要避免死锁的问题，唯一的办法就是修改代码。一个可靠的并发系统可以说是设计出来的，而不是通过改 Bug 改出来的，这一点与其他类型的 Bug 有很大的不同。另外，死锁的两个或多个线程是不消耗 CPU 的，有的人认为 CPU 100% 的使用率是线程死锁造成的，这个说法是不对的。无限循环（死循环），并且循环中代码都是 CPU 密集型，才有可能导致 CPU 的 100% 使用率，像 socket 或者数据库等 IO 操作是不怎么消耗 CPU 的。</p>
<h2 id="4-2-Java-代码死循环等导致的-CPU-过高分析"><a href="#4-2-Java-代码死循环等导致的-CPU-过高分析" class="headerlink" title="4.2 Java 代码死循环等导致的 CPU 过高分析"></a>4.2 Java 代码死循环等导致的 CPU 过高分析</h2><p>当系统负载大的时候，CPU 的使用率会较高，但是不正确的代码也会导致 CPU 过高，比如死循环。当发生 CPU 过高的问题，我们需要能够分析 CPU 高的真正原因。通过多次打印堆栈，前后堆栈对比找到一直在运行的线程，这些线程都是可疑的线程，具体的步骤如下：</p>
<ul>
<li>通过 jstack 等获取第一次的堆栈信息</li>
<li>等待一段时间，再获取第二次堆栈信息</li>
<li>预处理两次堆栈信息，首先去掉处于 sleeping 或者 waiting 状态的线程，因为这种线程是不消耗 CPU 的</li>
<li>比较第一次堆栈和第二次堆栈预处理后的线程，找出这段时间一直活跃的线程，如果两次堆栈中同一个线程处于同样的调用上下文，那么就应该列为重点怀疑对象。结合代码进行检查</li>
</ul>
<p>如果通过堆栈定位，没有发现热点代码段，那么 CPU 过高可能是不恰当的内存设置导致的频繁 GC，而从导致 CPU 过高</p>
<p>第一次 jstack 的输出如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&quot;Thread-444&quot; prio=1 tid=0xa4853568 nid=0x7ade runnable [0xafcf7000..0xafcf8680]</div><div class="line">        at org.apache.commons.collections.ReferenceMap.getEntry(Unknown Source)</div><div class="line">	        at org.apache.commons.collections.ReferenceMap.get(Unknown Source)</div><div class="line">	        at org.hibernate.util.SoftLimitMRUCache.get(SoftLimitMRUCache.java:51)</div><div class="line">	        at org.hibernate.engine.query.QueryPlanCache.getNativeSQLQueryPlan()</div><div class="line">	        at org.hibernate.impl.AbstractSessionImpl.getNativeSQLQueryPlan()</div><div class="line">	        at org.hibernate.impl.AbstractSessionImpl.list()</div><div class="line">	        at org.hibernate.impl.SQLQueryImpl.list(SQLQueryImpl.java:164)</div><div class="line">	        at com.mogoko.struts.logic.user.LeaveMesManager.getCommentByShopId()</div><div class="line">	        at com.mogoko.struts.action.shop.ShopIndexBaseInfoAction.execute()</div><div class="line">	        ......</div></pre></td></tr></table></figure>
<p>第二次 jstack 的输出如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&quot;Thread-444&quot; prio=1 tid=0xa4853568 nid=0x7ade runnable [0xafcf7000..0xafcf8680]</div><div class="line">        at org.apache.commons.collections.ReferenceMap.getEntry(Unknown Source)</div><div class="line">	        at org.apache.commons.collections.ReferenceMap.get(Unknown Source)</div><div class="line">	        at org.hibernate.util.SoftLimitMRUCache.get(SoftLimitMRUCache.java:51)</div><div class="line">	        at org.hibernate.engine.query.QueryPlanCache.getNativeSQLQueryPlan()</div><div class="line">	        at org.hibernate.impl.AbstractSessionImpl.getNativeSQLQueryPlan()</div><div class="line">	        at org.hibernate.impl.AbstractSessionImpl.list()</div><div class="line">	        at org.hibernate.impl.SQLQueryImpl.list(SQLQueryImpl.java:164)</div><div class="line">	        at com.mogoko.struts.logic.user.LeaveMesManager.getCommentByShopId()</div><div class="line">	        at com.mogoko.struts.action.shop.ShopIndexBaseInfoAction.execute()</div><div class="line">	        ... ...</div></pre></td></tr></table></figure>
<p>在长达 5 分钟的时间里，一直在执行 org.apache.commons.collections.ReferenceMap.getEntry() 方法，说明这个方法一直没有结束。具体属于正常还是 Bug，需要结合源码进行判断。</p>
<p>导致死循环的代码属于代码的 Bug，这种类型的问题，重现比较难，但一旦重现，就比较容易解决。一般通过分析代码可以发现问题。导致死循环的原因大致有如下几个：</p>
<ul>
<li>HashMap 等线程不安全的容器，用在多线程读/写的场合，导致 HashMap 的方法调用形成死循环（可以参考2015-08-19 Hadoop升级过程出现异常问题casestudy）</li>
<li>多线程场合，对共享变量没有进行保护，导致数据混乱，从而使循环退出条件永远不满足，导致死循环的发生，比如：<ul>
<li>for, while 循环中的退出条件永远不满足导致的死循环</li>
<li>链表等数据结构首尾相连，导致遍历永远无法停止</li>
</ul>
</li>
<li>其他编码错误</li>
</ul>
<h2 id="4-3-高消耗-CPU-代码的常用分析方法"><a href="#4-3-高消耗-CPU-代码的常用分析方法" class="headerlink" title="4.3 高消耗 CPU 代码的常用分析方法"></a>4.3 高消耗 CPU 代码的常用分析方法</h2><p>借助操作系统提供的性能分析工具进行 CPU 消耗分析。上面介绍了针对死循环导致 CPU 遍告的分析方法，但是有些场景没有死循环也会导致 CPU 变高，我们需要借助系统提供的一些性能分析工具进行分析。在 Linux 中使用 top -p $pid 进行，步骤如下</p>
<ol>
<li>top -p $pid</li>
<li>输入 “H” 查看该进程所有线程的统计情况（CPU 等）如下所示（对于某些操作系统版本不支持 top 命令进行线程统计的</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">下面 PID 表示线程 ID，即 LWPID</div><div class="line">  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND</div><div class="line">  25059 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25060 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.04 java</div><div class="line">  25061 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25062 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25063 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25064 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25065 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25066 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25067 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25068 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25069 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:01.19 java</div><div class="line">  25070 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25071 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25072 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25073 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25074 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25075 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div><div class="line">  25076 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:24.31 java</div><div class="line">  25077 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:01.00 java</div><div class="line">  25078 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:01.05 java</div><div class="line">  25141 sankuai   20   0 9918m  55m 8264 S  0.0  0.2   0:00.00 java</div></pre></td></tr></table></figure>
<p>具体导致问题的代码可能是：</p>
<ol>
<li>纯 Java 代码导致的 CPU 过高</li>
<li>Java 代码中调用的 JNI 代码导致的 CPU 过高</li>
<li>虚拟机自身的代码导致的 CPU 过高，比如 GC 的 bug 等</li>
</ol>
<p>可以如下进行分析：</p>
<ol>
<li>top -p $pid 获取最消耗 CPU 的本地线程 ID</li>
<li>jstack 打印出 Java 堆栈</li>
<li>pstack 打印本地线程堆栈</li>
<li>在 Java 线程堆栈中查找 nid=&lt;第一步中最消耗 CPU 时间的线程 id&gt;<br> a. 如果找到的线程是纯 Java 代码，则该 Java 代码导致 CPU 过高<br> b. 如果找到的是 Native code，说明导致 CPU 过高的问题在 JNI 调用中<br> c. 如果找不到对于的线程，则有如下两种可能：<pre><code>i. JNI 调用中重新创建的线程来执行，在 Java 线程堆栈中不存在该线程的信息
ii. 虚拟机自身的代码导致的 CPU 过高，如堆内存不够导致的频繁 fullgc，或虚拟机的 bug 等
</code></pre></li>
</ol>
<h2 id="4-4-资源不足等导致的性能下降分析"><a href="#4-4-资源不足等导致的性能下降分析" class="headerlink" title="4.4 资源不足等导致的性能下降分析"></a>4.4 资源不足等导致的性能下降分析</h2><p>大多数时候资源不足和性能瓶颈是统一类问题。</p>
<ul>
<li>大量的线程停在同样的调用上下文上</li>
<li>资源数量配置太少，系统当前压力比较大，资源不足导致某些线程不能及时获得资源而等待</li>
<li>获得资源的线程把持资源时间太久（比如获取数据库连接），导致资源不足</li>
<li>设计不合理导致资源占用时间过久，如 SQL 语句设计不恰当，或者没有索引导致的数据库访问太慢等</li>
<li>资源用完后，某些异常情况下，没有关闭或回收，导致可用资源泄漏或减少</li>
</ul>
<h2 id="4-5-线程不退出导致的系统挂死分析"><a href="#4-5-线程不退出导致的系统挂死分析" class="headerlink" title="4.5 线程不退出导致的系统挂死分析"></a>4.5 线程不退出导致的系统挂死分析</h2><p>线程挂死，表现为每次打印线程堆栈，该线程都在同一个调用上下文，该类问题可以通过多次打印堆栈进行分析，导致线程挂死的原因有很多，如：</p>
<ul>
<li>线程正在执行死循环代码</li>
<li>资源不足或资源泄漏，造成当前线程阻塞在锁对象上，长期得不到唤醒</li>
<li>如果当前程序和外部通信，当外部程序挂起无返回时，也会导致当前线程挂起</li>
</ul>
<h2 id="4-6-其他问题分析"><a href="#4-6-其他问题分析" class="headerlink" title="4.6 其他问题分析"></a>4.6 其他问题分析</h2><ul>
<li>多个锁导致的锁链分析 – 多个线程等待同一个锁</li>
<li>进行性能瓶颈分析</li>
</ul>
<h2 id="4-7-线程堆栈不能分析什么问题"><a href="#4-7-线程堆栈不能分析什么问题" class="headerlink" title="4.7 线程堆栈不能分析什么问题"></a>4.7 线程堆栈不能分析什么问题</h2><p>线程堆栈定位问题，只能定位在当前线程上留下痕迹的问题，如线程死锁，线程挂死等，另外，定位由于锁的设计不恰当导致的性能问题，线程堆栈也是最有效的工具，因为性能问题时时刻刻反映在当前的线程统计状况上。但线程堆栈对于不留痕迹的问题，就无能为力了。例如：</p>
<ul>
<li>线程为什么跑飞</li>
<li>并发的 Bug 导致的数据混乱</li>
<li>数据库梭镖的问题</li>
<li>在实际的系统中，系统的问题分为几种类型：</li>
</ul>
<p>堆栈中能够表现出问题的，使用线程堆栈进行定位</p>
<ul>
<li>无法在线程中留下痕迹的问题定位，需要依赖一个好的日志设计</li>
<li>非常隐蔽的问题，只能依赖于丰富的代码经验，如多线程导致的数据混乱以及幽灵代码等</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>《Java 问题定位技术》</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文为读书笔记，关于 Java 线程堆栈分析，在阅读并进行实验的基础上进行整理，如果有问题欢迎反馈&lt;br&gt;
    
    </summary>
    
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
      <category term="线程堆栈" scheme="http://yoursite.com/tags/%E7%BA%BF%E7%A8%8B%E5%A0%86%E6%A0%88/"/>
    
      <category term="JVM" scheme="http://yoursite.com/tags/JVM/"/>
    
      <category term="分析" scheme="http://yoursite.com/tags/%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>millwheel</title>
    <link href="http://yoursite.com/2017/12/22/millwheel/"/>
    <id>http://yoursite.com/2017/12/22/millwheel/</id>
    <published>2017-12-22T13:27:22.000Z</published>
    <updated>2017-12-24T03:11:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文属于 MillWheel 论文的阅读与翻译稿，部分地方使用自己的语言进行描述，部分地方进行翻译（附带原文）<br>讲述 MillWhell 的编程模型以及具体实现。MillWhell 的逻辑时间（logical time）使得开发基于时间的聚合应用更方便，从设计之初，MillWhell 就考虑了容错性以及扩展性。</p>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>在 Google，流处理系统需要做到 fault tolerance，persistent state 以及 scalability。</p>
<p>MillWhell 是为了流处理，低延迟而量身定做的（tailored specifically to streaming, low-latency systems). </p>
<p>MillWhell 的 API 保证幂等性，从用户角度来看就是保证了恰好一次的语义。<br>Furthermore， the API that MillWheel provides for record processing handles each record in an idempotent fashion, making record delivery occur exactly once from the user’s perspective.</p>
<h2 id="Motivation-and-Requirements"><a href="#Motivation-and-Requirements" class="headerlink" title="Motivation and Requirements"></a>Motivation and Requirements</h2><p>需要实时的分析搜索的高峰和波谷（spike and dip）<br>现在的做法，缓存 1 秒的 batch，然后使用模型预测与真实数据进行比较，如果相差很大，就有大概率出现了高峰/波谷。</p>
<p>存储：高峰/波谷 的持续时间不固定，因此需要保存一定的时间</p>
<p>Low Watermarks：需要区分「数据延迟」 和 「没有数据」，这样也能容忍数据的晚到（真实世界的数据是乱序的）</p>
<p>恰好一次：至少一次（at least once）可能导致波峰的出现</p>
<p>requirements of MillWhell：</p>
<ul>
<li>低延迟（Data should be available to consumers as soon as it is published i.e. there are no system-intrinsic barriers to ingesting inputs and providing output data).</li>
<li>提供易用的状态保存抽象接口（Persistent state abstractions should be available to user code, and should be integrated into the system’s overall consistency model.)</li>
<li>处理乱序（Out-of-order data should be handled gracefully by the system.)</li>
<li>系统提供单调递增的 low watermark（A monotonically increasing low watermark of data timestamps should be computed by the system.)</li>
<li>可扩展性好（Latency should stay constant as the system scales to more than machines.)</li>
<li>恰好一次的语义（The system should provide exactly-once delivery of records)</li>
</ul>
<h2 id="System-Overview"><a href="#System-Overview" class="headerlink" title="System Overview"></a>System Overview</h2><p>MillWheel 是一个基于用户定义逻辑以及输入输出数据的图（MillWheel is a graph of user-defined transformations on input data that produces output data.)<br>这些转换被称为计算，计算需要能够在框架层面做好负载均衡的分布式处理（用户不需要关系）</p>
<p>MillWheel 的输入输出组有 (key, value, timestamp) 三元组组成，其中 <code>key</code> 是系统内部有意义的元数据结构，<code>value</code> 表示真实数据的字节数组，可以是任何的值，<code>timestamp</code> 可以是用户设定的任何值（一般和墙上时间近似）MillWheel 会根据三元组进行 low watermark 的具体计算</p>
<p>用户的计算会形成一套具体的数据流图（a pipeline of user computations will form a data flow graph, as outputs from one computation become inputs for another, and so on.)</p>
<p>用户可以在不重启系统的情况下，动态的添加计算逻辑（Users can add and remove computations from a topology dynamically, without needing to restart the entire system.)</p>
<p>MillWhell 对每条数据提供幂等的处理（MillWheel makes record processing idempotent with regard to the framework API. <strong>As long as applications use the state and communication abstractions provided by the system, failures and retries are hidden from user code.</strong>)</p>
<p>在计算过程中，用户代码可以放到到每个 key 以及每个 computation 对应的存储内容</p>
<h2 id="Core-Concepts"><a href="#Core-Concepts" class="headerlink" title="Core Concepts"></a>Core Concepts</h2><p>MillWheel 提供了流计算的基本元素，同时提供了清晰的抽象（MillWheel surfaces the essential elements of a streaming system, while providing clean abstractions.）</p>
<h3 id="Computations"><a href="#Computations" class="headerlink" title="Computations"></a>Computations</h3><p>用户逻辑定义在 computation 中，提供了用户代码的封装（Application logic lives in computations, which encapsulate arbitrary user code.)</p>
<p>MillWhell 会在接受到数据的时候触发用户逻辑，包括连接外部系统，操作其他的 MillWheel 计算以及进行输出（Computation code is invoked upon receipt of input data, at which point user-defined actions are triggered, including contacting external systems, manipulating other MillWheel primitives, or outputting data.)</p>
<p>需要用户保证外部系统的幂等性（If external systems are contacted, it is up to the user to ensure that the effects of their code on these systems is idempotent.)</p>
<p>Computation 应该针对单个 <code>key</code> 进行，而且不能对 <code>key</code> 在不同机器上的分布有预期（Computation code is written to operate in the context of a single key, and is agnostic to the distribution of keys among different machines.)</p>
<p>保证同一个 key 之间是顺序执行的，不同的 key 可以并行执行。</p>
<h3 id="Keys"><a href="#Keys" class="headerlink" title="Keys"></a>Keys</h3><p>在 MillWheel 中 <code>key</code> 是用于聚合和比较的核心抽象（Keys are the primary abstraction for aggregation and comparison between different records in MillWheel)<br>每条记录会根据用户的规则分配一个具体的 <code>key</code>，computation 的逻辑运行在特定的 <code>key</code> 的空间内，同时也只能访问对应 <code>key</code> 的状态数据</p>
<h3 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h3><p>Stream 是 MillWheel 系统中任意两个 computation 中间的转换机制（Streams are the delivery mechanism between different computations in MillWheel.) </p>
<p>每个 computation 会订阅 0 个或多个 stream，同时会输出到至少 1 个 stream，不同 computation 间的数据流转由系统进行保证（A computation subscribes to zero or more input streams and publishes one or more output streams, and the system guarantees delivery along theses channels)</p>
<h3 id="Persistent-State"><a href="#Persistent-State" class="headerlink" title="Persistent State"></a>Persistent State</h3><p>在 MillWheel 系统中，状态是一个不透明的字节数组，由用户提供序列化和反序列化的逻辑。状态数据的存储系统有 BigTable/Spanner 提供。</p>
<h3 id="Low-Watermarks"><a href="#Low-Watermarks" class="headerlink" title="Low Watermarks"></a>Low Watermarks</h3><p>low watermark 提供了未来数据最小时间戳的界限（The low watermark for a computation provides a bound on the timestamp of future records arriving at that computation)</p>
<p><strong>定义</strong>: low watermark 的定义通过数据流水线递归进行给出（We provide a recursive definition of low watermarks based on a pipeline’s data flow)，给定一个 computation，A，它最老的工作由正在做的工作中，timestamp 最小的工作给出（Given a computation, A, let the oldest work of A be a timestamp corresponding to the oldest unfinished (in-flight, stored, or pending-delivery) record in A.). 在这个定义下 A 的 low watermark 可以写成 <code>min(oldest work of A, low watermark of C: C outputs to A)</code>，也就是所有上游的 low watermark 以及自己的最老（不一定是最早开始的）工作的时间</p>
<p>low watermark 由外部系统进行打点（Low watermark values are seeded by injector, which send data into MillWheel from external systems)</p>
<p>在真实世界中，对外部系统的延迟往往是一个估计值，因此需要能够容忍一小部分落后与 low watermark 的数据</p>
<p>用户可以假定自己获取的数据是全量的（这个假定对 low watermark 很重要）（By waiting for the low watermark of a computation to advance past a certain value, the user can determine that they have a complete picture of their data up to that time)</p>
<p>用户可以给每条记录赋予一个不小于输入源数据时间戳的任意值（When assigning timestamps to new or aggregate records, it is up to the user to pick a timestamp no smaller than any of the source records.)</p>
<h3 id="Timers"><a href="#Timers" class="headerlink" title="Timers"></a>Timers</h3><p>Timers 是一段针对每个 <code>key</code> 的定时触发（基于墙上时间或者 low watermark）的回调逻辑（Timers are per-key programmatic hooks that trigger at a specific wall time or low watermark value.)</p>
<p>Timer 一旦设定，将由框架保证按时间戳递增的触发（Once set, timers are guaranteed to fire in increasing timestamp order)</p>
<p>Timer 会有记录日志以及相应状态保存，同样提供恰好一次的语义（They – Timers – are journaled in persistent state and can survive process restarts and machine failures. When a timer fires, it runs the specified user function and has the same exactly-once guarantee as input records)</p>
<h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">class Computation &#123;</div><div class="line">	//Hooks called by the system</div><div class="line">	void ProcessRecord(Record data);</div><div class="line">	void ProcessTimer(Timer timer);</div><div class="line"></div><div class="line">	//Accessors for other abstractions.</div><div class="line">	void SetTimer(String tag, int64 time);</div><div class="line">	void ProduceRecord(Record data, String stream);</div><div class="line">	StateType MutablePersistentState();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>用户通过重载 <code>ProcessRecord</code> 和 <code>ProcessTimer</code> 来做具体的工作</p>
<h3 id="Computation-API"><a href="#Computation-API" class="headerlink" title="Computation API"></a>Computation API</h3><p>两个用户逻辑的入口是 <code>ProcessRecord</code> 和 <code>ProcessTimer</code>（The two main entry point into user code are provided by the ProcessRecord and ProcessTimer hooks) </p>
<p>系统接受到外部 RPC 之后（输入）会调用用户逻辑，用户逻辑可以访问状态数据，然后系统将输出传给下游（The MillWheel system invokes user-defined processing hooks in response to incoming RPCs. User code accesses state, timers, and productions through the framework API. The framework performs any actual RPCs and state modifications)</p>
<h3 id="Injector-and-Low-Watermark-API"><a href="#Injector-and-Low-Watermark-API" class="headerlink" title="Injector and Low Watermark API"></a>Injector and Low Watermark API</h3><p>系统会为每个 Computation 中待处理的任务计算一个 low watermark（At the system layer, each computation calculates a low watermark value for all of its pending work(in-progress and queued deliveries).</p>
<p>所有的状态也都可以被赋予一个时间戳（Persistent state can also be assigned a timestamp value(e.g. the trailing edge of an aggregation window.) 这都由系统自动建立，从而为用户提供透明的 timer 语义 – 用户一般不需要和底层的 low watermark 进行交互，而是通过时间戳进行操作 low watermark（This is rolled up automatically by the system in order to provide API semantics for timers in a transparent way – users rarely interact with low watermarks in computation code, but rather manipulate them indirectly through timestam assignation to records.)</p>
<p><strong>Injectors</strong>: Injectors 从外部系统读入数据到 MillWheel（Injectors bring external data into MillWheel)<br>Injector 负责最初的 low watermark 生成，因此可以间隙性的往下游发送传递的 low watermark 表示当前传递的情况（Since injectors seed low watermark values for the rest of the pipeline, they are able to publish an <em>injector low watermark</em> that propagates to any subscribers among their output streams, reflecting their potential deliveries along those stream.</p>
<p>一个 Injector 可能会由多个进程处理，因此 injector 的 low watermark 由所有这些进程共同决定（这些进程中最小的 low watermark）（An injector can be distributed across multiple processes, such that the aggregate low watermark of these processes is used as the injector low watermark.)</p>
<p>用户可以自定义一组预期的输出进程，用于度量系统的健壮性以及网络的延迟情况（The user can specify an expected set of injector processes, making this metric robust against process failures and network outages.)</p>
<h2 id="Fault-tolerance"><a href="#Fault-tolerance" class="headerlink" title="Fault tolerance"></a>Fault tolerance</h2><h3 id="Delivery-Guarantees"><a href="#Delivery-Guarantees" class="headerlink" title="Delivery Guarantees"></a>Delivery Guarantees</h3><p>MillWheel 编程模型的简洁性通过由框架提供幂等操作，而不需要用户自己实现幂等操作来完成。这可以大大减少用户的编程复负担。（Much of the conceptual simplicity of MillWheel’s programming model hinges upon its ability to take non-idempotent user code and run it as if it were idempotent. By removing this requirement from computation authors, we relieve them of a significant implementation burden.)</p>
<h4 id="恰好一次（Exactly-Once-Delivery）"><a href="#恰好一次（Exactly-Once-Delivery）" class="headerlink" title="恰好一次（Exactly-Once Delivery）"></a>恰好一次（Exactly-Once Delivery）</h4><p>每个 computation 接受到数据后的处理步骤如下：</p>
<ul>
<li>数据会和上次的去重数据进行比较，如果有重复则跳过（The record is checked against deduplication data from previous deliveries; duplicates are discarded.)</li>
<li>执行用户代码，生成针对 timer，state，production 的变化（User code is run for the input record, possibly resulting in pending changes to timers state, and productions.)</li>
<li>将上一步的变化保存到后端存储（pending changes are committed to the backing store)</li>
<li>ACK 上游(Senders are ACKed）</li>
<li>发送给下游（Pending downstream productions are sent）</li>
</ul>
<p>作为优化，可能某个 checkpoint 点会针对多条记录进行（As an optimization, the above operations may be coalesced into a single checkpoint for multiple records.)</p>
<p>MillWheel 中的数据在被 ACK 之前会一直重发，从而保证 At-Least-Once，这是 Exactly-Once 的前提（Deliveries in MillWheel are retried until they are ACKed in order to meet our at-least-once requirement, which is a prerequisite for exactly-once.)</p>
<p>这就引入了如下一个问题，如果下游在正常更新状态后，ACK 前退出了，就会接受到两条同样的数据，因此需要对数据进行去重（However, this introduces the case where a receiver may crash before it has a chance to ACK the input record, even if it has persisted the state corresponding to successful processing of that record. In this case, we must prevent duplicate processing when the sender retries its delivery.)</p>
<p>MillWheel 给每条产生的数据赋予一个全局唯一的 ID，利用原子操作的状态更新包含该 ID 来进行去重操作（The system assigns unique ID to all records at production time. We identify duplicate records by including this unique ID for the record in the same atomic write as the state modification.) </p>
<p>如果接受到已经成功处理的消息，系统比较后直接丢弃并 ACK（防止无休止的重试）（If the same record is later retried, we can compare it to the journaled ID, and discard and ACK the duplicate (lest it continue to retry indefinitely)</p>
<p>由于内存有限，不会将所有处理过的数据保存在内存，因此保存一个 Bloomfilter 保存我们见过的数据，如果 Bloomfiler 返回结果为空，则需要读取后端存储检查是否为重复数据。Record ID 会在确保所有发送方都已经重试完成后进行回收（Since we cannot necessarily store all duplication data in-memory, we maintain a Bloom filter of known record fingerprints, to provide a fast path for records that we must read the backing store to determine whether a record is a duplicate. Record IDs for past deliveries are garbage collected after MillWheel can guarantee that all internal senders have finished retrying.) 对于 Injector，系统会延迟回收 ID（For injectors that frequently deliver late data, we delay this garbage collection by a corresponding slack value (typically on the order of a few hours).</p>
<h4 id="Strong-productions"><a href="#Strong-productions" class="headerlink" title="Strong productions"></a>Strong productions</h4><p>由于 MillWheel 处理的数据可能是乱序以及不确定性的，因此会在数据产生后，发往下游以及更新状态数据前进行 checkpoint（Since MillWheel handles inputs that are not necessarily ordered or deterministic, we checkpoint produced records before delivery in the same atomic write as state modification.)</p>
<p>这种在记录产生之前进行 checkpoint 的模式被称为 strong production(We call this pattern of checkpointing before record production strong productions.)</p>
<p>如果没有 checkpoint 的话，可能导致同一个逻辑窗口的数据不一致（Without a checkpoint, it would be possible for that computation to produce a window count downstream, but crash before saving its state. Once the computation came back up, it might receive another record (and add it to the count) before producing the same aggregate, creating a record that was bit-wise distinct from its predecessor but corresponded to the same logical window.)</p>
<p>MillWheel 使用 Bigtable 作为存储系统，Bigtable 对用户屏蔽了内部细节（相对于 读-修改-写 的操作），使得 checkpoint 就像 log 的行为一样。当一个进程启动的时候，checkpoint 会被重新读入内存并重放，当处理完成后 checkpoint 会被删除。（We use a storage system such as Bigtable, which efficiently implements blind writes (as opposed to read-modify-write operations), making checkpoints mimic the behavior of a log. When a process restarts, the checkpoints are scanned into memory and replayed. Checkpoint data is deleted once these productions are successful.)</p>
<h4 id="6-1-3-Weak-Productions-and-Idempotency"><a href="#6-1-3-Weak-Productions-and-Idempotency" class="headerlink" title="6.1.3 Weak Productions and Idempotency"></a>6.1.3 Weak Productions and Idempotency</h4><p>结合 Strong productions 以及 exactly-once 的消息传递性可以保证很多计算都是幂等的，包括系统层面的重试（Taken together, the combination of strong productions and exactly-once delivery makes many computations idempotent with regard to system-level retries.)</p>
<p>有些计算就算没有这些保证就已经是幂等的了（However, some computations may already be idempotent, regardless of the presence of these guarantees (which come with a resource and latency cost).) </p>
<p>因此 Strong productions 以及/或者 exactly-once 可以从用户层面取消（Depending on the semantic needs of an application, strong productions and/or exactly-once can be disabled by the user at their discretion.)</p>
<p>对于 <em>weak productions</em>, 我们不会在发送数据前进行 checkpoint，而是在保存状态前乐观的向下游广播数据，（For <em>weak production</em>, rather than checkpointing record productions before delivery, we broadcast downstream deliveries optimistically, prior to persisting state). 从经验得到，这会引入一个新的问题：整个流水线的完成时间会严重耦合，且依赖下游的 ACK（Empirically, this introduces a new problem, in that the completion times of consecutive stages of the pipeline are now strictly coupled as they wait for downstream ACKs of records.) 结合机器的故障率，端到端的延迟会随着流水线的深度增加而增加（Combined with the possibility of machine failure, this can greatly increase end-to-end latency for straggler productions as pipeline depth increases.) 例如，我们假设每台机器发生故障的概率为 1%，那么我们遇到故障的概率会随着流水线的深度递增而递增 – 对于深度为 5 的流水线，我们有 5% 的概率遇到至少一次机器故障（For example, if we assume (rather pessimistically) that there is a 1% chance that any machine will fail during a given minute, then the probability that we will be waiting on at least one failure increases disastrously with pipeline depth – for a pipeline of depth 5, a given production could have nearly a 5% chance of experiencing a failure every minute!）我们通过对部分延迟的数据流进行 checkpoint 来解决这一问题，允许这些接受者对他们的上游进行 ACK。通过这种选择性的 checkpoint 方式，我们既可以降低端到端的延迟，也可以减少所有资源的使用（We ameliorate this by checkpointing a small percentage of straggler pending productions, allowing those stages to ACK their senders. By selectively checkpoint in this way, we can both improve end-to-end latency and reduce overall resource consumption.)在 Figure 11 中，我们描述了这种 checkpoint 的具体实现。（In Figure 11, we show this checkpointing mechanism in action.) Computation A 的下游是 Computation B，而 Computation B 则马上将数据发送给下游 Computation C（Computation A produces to Computation B, which immediately produces to Computation C.) 然而 Computation C 的 ACK 则很慢，所以 Computation B 会在 1 秒的延迟之后进行 checkpointing。这样之后，Computation B 能够对上游 Computation A 进行 ACK，允许 Computation A 释放所占用的资源（However, Computation C is slow to ACK, so Computation B checkpoints the production after 1-second delay. Thus, Computation B can ACK the delivery from Computation A, allowing A to free any resources associated with the production.) 就算 Computation B 在后续阶段重启了，也能够从之前 checkpoint 的地方进行恢复，然后重新发送数据给下游 Computation C，而且没有数据丢失。（Even when Computation B subsequently restarts, it is able to recover the record from the checkpoint and retry delivery to Computation C, with no data loss.)</p>
<img src="/2017/12/22/millwheel/figure11_checkpoint.jpg" alt="figure11_checkpoint.jpg" title="">
<p>上面这种松散模式更适合具有幂等性的流水线，因为这样重试不会影响正确性，下游也是可以进行重试的。现实世界中一个幂等的例子就是无状态的过滤，任何时候输入相同的数据，会产生同样的输出。（The above relaxations would be appropriate in the case of a pipeline with idempotent computations, since retries would not affect correctness, and downstream production would also be retry-agnostic. A real-world example of an idempotent computation is a stateless filter, where repeated deliveries along input streams will not change the result.)</p>
<h3 id="6-2-State-Manipulation-状态操作"><a href="#6-2-State-Manipulation-状态操作" class="headerlink" title="6.2 State Manipulation/状态操作"></a>6.2 State Manipulation/状态操作</h3><p>关于 MillWheel 的实现机制中如何操作状态，我们讨论了保存到后端存储的“hard” 状态，也讨论了保存在内存的“软”状态。我们需要满足如下几条对用户的保证：（In implementing mechanism to manipulate user state in MillWheel, we discuss both the “hard” state and that is persisted to our backing store and the “soft” state which includes any in-memory caches or aggregates. We must satisfy the following user-visible guarantess:)</p>
<ul>
<li>系统不会丢失数据（The system does not loss data)</li>
<li>更新状态保证恰好一次的语义（Updates to state must obey exactly-once semantics)</li>
<li>系统保存的数据在任何时候都应该是一致的（All persisted data throughout the system must be consistent at any given point in time)</li>
<li>Low watermarks 必须能够反应系统中排队的请求（Low watermarks must reflect all pending state in the system.)</li>
<li>对于特定的 key，它相关的定时器必须按序触发（Timers must fire in-order for a given key.)</li>
</ul>
<p>为了避免保存的状态数据不一致（比如触发器，用户状态，以及生产 checkpoints 之间），我们将每个 key 对应的状态数据更新封转为一个原子操作。（To avoid inconsistencies in persisted state (e.g. between timers, user state, and production checkpoints), we wrap all per-key updates in a single atomic operation.)这样可以适应系统任何时候的失败和中断（This results in resiliency against process failures and other unpredictable events that may interrupt the process at any given time.) 正如前面所说的，同一个操作中保证恰好一次的数据更新，并且对每个 key 的一致性状态数据提供保证（As mentioned previously, exactly-once data is updated in this same operation, adding it to the per-key consistency envelope)</p>
<p>由于计算会在机器之间迁移（负载均衡，故障或者其他原因），影响数据一致性的最大原因变为僵尸写入进程以及残留网络写入后端存储的概率（As work may shift between machines (due to load balancing, failures, or other reasons) a major threat to our data consistency is the possibility of zombie writers and network remnants issuing stale writes to our backing store.)。 为了解决这个问题，我们给每个 writer 附上一个序列化 token，后端存储会跟进这个 token 来验证写入是否合理。（To address this possibility, we attach a sequencer token to each write, which the mediator of the backing store checks for validity before allowing the write to commit.) 每个新工作进程首先将之前的工作进程设置为失效，这样就不会受之前进程的影响了。（New workers invalidate any extant sequencers before starting work, so that no remnant writes can succeed thereafter.) 这个序列号作为一个租约执行机制，就像 Centrifuge 系统一样。（The sequencer is functioning as a lease enforcement mechanism, in a similar manner to the Centrifuge system.) 因此，我们能够保证同一时刻点，对于特定的 key 只会有一个进程在进行写入。（Thus, we can guarantee that, for a given key, only a single worker can write to that key at a particular point in time.)</p>
<p>这种单写入进程的保证对软状态的维护同样重要，而且它不能通过事务进行处理（This single-writer guarantee is also critical to the maintenance of soft state, and it cannot be guaranteed by depending on transactions.) 以缓存写入缓慢为例：如果在构建缓存之后，来自另外一个进程的僵尸进程还在写入，则会导致缓存的不一致。（Take the case of a cache of pending timers: if a remnant write from another process could alter the persisted timer state after said cache was built, the cache would be inconsistent.)图 12 描述了这种情况，图中僵尸进程 B 由于外部因素，写入后端存储的事务没有按时到达后端。在事务实际开始前，B 的后继者，B-prime，执行定时器的扫描。在扫描完成之后，事务完成且 A 被 ACK，这样 B-prime 就拥有一个不完整的计时器状态。（This situation is illustrated by Figure 12, where a zombie process (B) issues a transaction that is delayed on the wire, in response to a production from A. Before the transaction begins, B’s successor, B-prime, performs its initial scan of pending timers. After this scan completes, the transaction is applied and A is ACKed, leaving B-prime with incomplete timer state.) 丢失的定时器可能被无限期的孤立，造成相应的输出延迟，这对于延迟敏感的系统是不能接受的（The lost timer could be orphaned indefinitely, delaying any of its output actions by an arbitrary amount of time, Clearly, this is unacceptable for a latency-sensitive system.)<br><img src="/2017/12/22/millwheel/figure12_transaction.jpg" alt="figure12_transaction.jpg" title=""></p>
<p>此外，检测点也会遇到同样的情况，通过避免对后端存储的初始化扫描，系统的状态仍然是不可知的。（Furthermore, this same situation could occur with a checkpointed production, where it would remain unknown to the system by eluding an initial scan of the backing store.) 这种生产值直到产生 watermark 的时候才会被考虑到，而且这段时间内，我们可能向消费者报告一个错误的 watermark 值。另外，watermark 是单调递增的，所以我们无法对错误的 watermark 值进行纠正。违反 low watermark 的保证，则可能导致结果出错，其中包括提前触发定时器和产生不完整的窗口等。（This production would then note be accounted for in the low watermark until it was discovered, and in the intervening time, we might be reporting  an erroneous low watermark value to consumers. Furthermore, since our low watermarks are monotonically increasing, we are unable to correct an erroneous advancement in the value. By violating our low watermark guarantees, a variety of correctness violations could occur, including premature timer firings and incomplete window productions.)</p>
<p>为了能够快速的从故障中进行恢复，MillWheel 中的每个算子可以在任何时刻进行任何粒度状态的 checkpoint（实践中，跟进数据量的不同，一般会有亚秒级别的，或者记录级别的 checkpoint）（In order to quickly recover from unplanned process failures, each computation worker in MillWheel can checkpoint its state at an arbitrarily fine granularity (in practice, sub-second or per-record granularity is standard, depending on input volume). 我们使用始终一致的软状态运行我们在特定的情况 – 机器宕机或者负载不均衡 – 进行最少的 checkpoint 数据扫描。在扫描 checkpoint 数据的时候，通常是异步的，这样运行在扫描 checkpoint 的时候同事也提供计算。（Our use of always-consistent soft state allows us to minimize the number of occasions when we must scan these checkpoints to specific cases – machine failures or load-balancing events. When we do perform scans, these can often be asynchronous, allowing the computation to continue processing input records while the scan progresses.)</p>
<h2 id="7-System-implementation"><a href="#7-System-implementation" class="headerlink" title="7 System implementation"></a>7 System implementation</h2><h3 id="7-1-Architecture"><a href="#7-1-Architecture" class="headerlink" title="7.1 Architecture"></a>7.1 Architecture</h3><p>MillWheel 部署在一组动态主机服务器上作为分布式系统提供服务。流水线中的每个计算会运行在一台或多态机器上，不同机器上的流通过 RPC 进行传递。在每台机器上，MillWheel 会管理输入以及进程级别的元数据，并且根据需要委托给相应的用户计算。（MillWheel deployments run as distributed systems on a dynamic set of host servers. Each computation in a pipeline runs on one or more machines, and streams are delivered via RPC. On each machine, the MillWheel system marshals incoming work and manages process-level metadata, delegating to the appropriate user computation as necessary.)</p>
<p>负载分配和均衡由一个复制的主机进行处理，它将每个计算分成一组有用不同密钥的单元（这些密钥会涵盖所有的可能性），然后将它们分发到一批机器上。（Load distribution and balancing is handled by a replicated master, which divides each computation into a set of owned lexicographic key intervals (collectively covering all key possibilities) and assigns these intervals to a set of machines.) 对于 CPU 压力过大或内存压力过大的情况（通过标准的进程监控得到），可以将这些单元进行移动，分割或者合并它们。每个单元被分配了一个唯一的序列号，当这个单元被移动，分割或者合并之后，这个序列号就失效了。这个序列号的重要性已经在 6.2 中进行了讨论。（In response to increased CPU load or memory pressure (reported by a standard perprocess monitor), it can move these intervals around, split them, or merge them. Each interval is assigned a unique sequencer, which is invalidated whenever the interval is moved, split, or merged. The importance of this sequencer was discussed in Section 6.2)</p>
<p>对于状态的存储，MillWheel 使用类似 Bigtable 或者 Spanner 类似的系统，提供原子性的，行级更新。同一个 key 的定时器，延迟的生产，以及保存的状态保存在同一行（For persistent state, MillWheel uses a database like Bigtable or Spanner, which provides atomic, single-row updates. Timers, pending productions, and persistent state for a given key are all stored in the same row in the data store.)</p>
<p>当一个 key 的一个最小单元由于机器故障导致被重新分配到其他机器上上，MillWheel 能投通过从后端存储中读取元数据快速的进行恢复。最初会在内存建立相应的堆式数据结构，用于保存堆积的定时器以及 checkpoint 过的输出，这些数据在整个 key 的生命周期中和后端存储中保持一致。为了保证这个特性，我们保证了单实例写入的语义 – 6.2 节中有详细描述。（MillWheel recovers from machine failures efficiently by scanning metadata from this backing store whenever a a key interval is assigned to a new owner. This initial scan populates in-memory structures like the heap of pending timers and the queue of checkpointed productions, which are then assumed to be consistent with the backing store for the lifetime of the interval assignment. To support this assumption, we enforce single-writer semantics(per-computation worker) that are detailed in Section 6.2)</p>
<h3 id="7-2-Low-Watermarks"><a href="#7-2-Low-Watermarks" class="headerlink" title="7.2 Low Watermarks"></a>7.2 Low Watermarks</h3><p>为了保证数据的一致性，low watermark 必须被实现为一个子系统，而且能够全局能够访问且持续是正确的。我们将这实现为一个 central authority（类似 OOP），这个系统跟踪系统的所有 low watermark 且将他们记录到状态存储系统中，用以防止由于系统失败导致得到错误的 low watermark。（In order to ensure data consistency, low watermark must be implemented as a sub-system that is globally available and correct. We h have implemented this as a central authority (similar to OOP), which tracks all low watermark values in the system and journals them to persistent state, preventing the reporting of erroneous values in cases of process failure.)</p>
<p>当向 central authority 汇报数据的时候，每个进程会报自己工作的时间戳信息也带上。这包括已经 checkpoint 或者堆积的 production，堆积的定时器或者需要保存的状态信息。每个进程的效率依赖与我们内存中的保持一致性的数据结构，不需要去查询耗时更严重的后端存储。因为每个进程被分配给了每个 key 的一个最小单元，因此 low watermark 的更新也是以 key 的最小单元为单位而向 central authority 进行汇报。（When reporting to the central authority, each process aggregates timestamp information for all of its owned work. This includes any checkpointed or pending productions, as well as any pending timers or persisted state. Each process is able to do this efficiently by depending on the consistency of our in-memory data structures, eliminating the need to perform any expensive queries over the backing data store. Since processes are assigned work based on key intervals, low watermark updates are also bucketed into key intervals, and sent to the central authority.)</p>
<p>为了计算整个系统的 low watermark，这个 authority 必须能否访问所有堆积后以及处理过的工作的 low watermark 信息。当聚合每个进程的更新操作时，同时跟踪每个进程中的计算对应的区间所对应的 low watermark 值。如果某些 key 的最小单元丢失了，则丢失的单元的 low watermark 会被标记为上次得到的值，知道该单元的计算重新恢复为止。然后 authority 会在整个系统中对 low watermark 进行广播。（To accurately compute system low watermarks, this authority must have access to low watermark information for all pending and persisted work in the system. When aggregating per-process updates, it tracks the completeness of its information for each computation by building an interval map of low watermark values for the computation. If any interval is missing, then the low watermark corresponds to the last known value for the missing interval until it reports a new value. The authority then broadcasts low watermark values for all computations in the system.)</p>
<p>下游通过订阅它感兴趣的上游计算的 low watermark 值，从而计算它的整个输入的 low watermark 值。这个值由工作进程进行计算，而不是 authority 进行计算，与下面这个理由是一致的：central authority 的 low watermark 值应该不大于工作进程的 low watermark。通过有工作进行进行计算，central authority 的 low watermark 值就不会大于工作进程的 low watermark 值了，从而保证了这个属性。（Interested consumer computations subscribe to low watermark values for each of their sender computations, and thus compute the low watermark of their input as the minimum over these values. The reason that these minima are computed by the workers, rather than the central authority, is one of consistency: the central authority’s low watermark values should always be at least as conservative as those of the workers. Accordingly, by having workers compute the minima of their respective inputs, the authority’s low watermark never leads the workers’, and this property is preserved.)</p>
<p>为了能够在 central authority 保证一致性，我们给每个 low watermark 的更新附带上一个序列号。类似之前提到的单进程写入模式下更新本地 key 最小单元的状态，这个序列号保证只有最后的属主能够成功更新该 key 最小单元的 low watermark。为了扩展能力，authority 能够分布在多态机器上，每台 worker 机器上有一个或多个计算。经验上，这个能够在不损失性能的前提下扩展到 500000 个 key 最小单元。（To maintain consistency at the central authority, we attach sequencers to all low watermark updates. In a similar manner to our single-writer scheme for local updates to key interval state, these sequences ensure that only the latest owner of a given key interval can update its low watermark value. For scalability, the authority can be sharded across multiple machines, with one or more computations on each worker. Empirically, this can scale to 500000 key intervals with no loss in performance.)</p>
<p>在该系统中，我们还可以选择去除异常值，并为对速度特别要求的流水线提供启发式的 low watermark。比如，我们可以通过 99% 的记录时间戳得到一个 99% 的 low watermark。只对近似结果感兴趣的窗口消费者，可以利用这些 low watermark，从而避免等待那些晚到的数据。（Given a global summary of work in the system, we are able to optionally strip away outliers and offer heuristic low watermark values for pipelines that are more interested in speed than accuracy. For example, we can compute a 99% low watermark that corresponds to the progress of 99% of the record timestamps in the system. A windowing consumer that is only interested in approximate results could then use these low watermark values to operate with lower latency, having eliminated its need to wait on stragglers.)</p>
<p>总之，在我们的实现中，low watermark 对系统中的流没有时间顺序上的要求。low watermark 会反应正在进行的和已经保存的状态，通过建立一个全局的 low watermark 值来源，我们从逻辑上防止了不一致性，类似 low watermark 的回退。（In summary, our implementation of low watermarks does not require any sort of strict time ordering on streams in the system. Low watermarks reflect both in-flight and persisted state. By establishing a global source of truth for low watermark values, we prevent logical inconsistencies, like low watermarks moving backwards.)</p>
<h2 id="8-Evaluation"><a href="#8-Evaluation" class="headerlink" title="8 Evaluation"></a>8 Evaluation</h2><p>为了说明 MillWheel 的性能，我们提供了针对流处理系统关键指标的试验结果</p>
<h3 id="8-1-output-latency"><a href="#8-1-output-latency" class="headerlink" title="8.1 output latency"></a>8.1 output latency</h3><p>流处理系统中，延迟是对于性能的一个关键指标。MillWheel 系统支持低延迟的结果，并且随着系统的扩展而不增加延迟。我们使用了一个单 Stage 的消息传递，计算内容为排序的列子来进行说明 MillWheel 的性能。这类似于在连续计算中发生的多对多的 shuffle，是 MillWheel 中排序的会遇到的一个最差场景。Figure 13 展示了运行在 200 CPU 上的结果。消息传递的中位数延迟为 3.6 毫秒，95% 的延迟为 30 毫秒，这能够很好的满足 Google 内部对流系统的需求（95 线甚至在人类可能反应的时间内）（This resembles the many-to-many shuffle that occurs between successive computations that are keyed differently, and thus is a worst case of sorts for record delivery in MillWheel. Figure 13 shows the latency distribution for records when running over 200 CPUs. Median record delay is 3.6 milliseconds and 95th-percentile latency is 30 milliseconds, which easily fulfills the requirements for many streaming systems at Google (even 95th percentile is within human reaction time).<br><img src="/2017/12/22/millwheel/figure13_latency.jpg" alt="figure13_latency.jpg" title=""></p>
<p>这个测试是在关闭了 strong production 以及恰好一次的情况下进行的。当开启这两个特性的时候，延迟中位数变为 33.7 毫秒，95 线变为 93.8 毫秒。这个对比可以说明，计算本身的幂等性可以通过关闭这两个特性而大大降低延迟。（This test was performed with strong productions and exactly-once disabled. With both of these features enabled, median latency jumps up to 33.7 milliseconds and 95th-percentile latency to 93.8 milliseconds. This is a succinct demonstration of how idempotent computations can decrease their latency by disabling these two features.)</p>
<p>为了能够验证 MillWheel 的延迟不会随着系统的扩展而增加，我们将之前的单 Stage 实验跑在不同的 CPU 配置上，从 20 到 2000. Figure 14 展示了延迟的中位数基本保持不变。延迟的 99 线却会变糟（虽然都还在 100 毫秒以内）。然而，最差的延迟情况预计会随着规模的增加而增加 – 更多的资源意味着更多的出错可能。（To verify that MillWheel’s latency profile scales well with the system’s resource footprint, we ran the single-stage latency experiment with setups ranging in size from 20 CPUs to 2000 CPUs, scaling input proportionally. Figure 14 shows that median latency stays roughly constant, regardless of system size. 99th-percentile latency does get significantly worse (though still on the order of 100ms). However, tail latency is expected to degrade with scale – more machines mean that there are more opportunities for things to go wrong.)<br><img src="/2017/12/22/millwheel/figure14_latency_scalability.jpg" alt="figure14_latency_scalability.jpg" title=""></p>
<h3 id="8-2-Watermark-Lag"><a href="#8-2-Watermark-Lag" class="headerlink" title="8.2 Watermark Lag"></a>8.2 Watermark Lag</h3><p>虽然某些计算（比如 Zeitgeist 中的波峰波谷检测）不需要定时器，但是其他许多计算（比如 dip detection）使用 low watermark 来触发定时器进行输出。对于这些计算，low watermark 的延迟将会导致结果的不新鲜。由于 low watermark 从计算图的源头开始进行产生，我们期望 low watermark 的延迟与流水线上计算与输入端的距离成正比。我们使用 200 CPU 运行了一个 3 级 MillWheel 流水线，并且每秒钟计算一次每个计算的 low watermark 值。图 15 中，我们可以看到，第一阶段的 low watermark 延迟了 1.8 秒，但是，对于后续的阶段，每阶段的延迟增加了不到 200 毫秒。怎么减少 watermark 的延迟现在还是一个正在发展中的领域。（While some computations (like spike detection in Zeitgeist) do not need times, many computations (like dip detection) use timers to wait for the low watermark to advance before outputting aggregates. For these computations, the low watermark’s lag behind real time bounds the freshness of these aggregates. Since the low watermark propagates from injectors through the computation graph, we expect the lag of a computation’s low watermark to be proportional to its maximum pipeline distance from an injector. We ran a simple three-stage MillWheel pipeline on 200 CPUs, and polled each computation’s low watermark value once per second. In Figure 15, we can see that the first stage’s watermark lagged real time by 1.8 seconds, however, for subsequent stages, the lag increased per stage by less than 200ms. Reducing watermark lag is an active area of development.<br><img src="/2017/12/22/millwheel/figure15_lowwatermark.jpg" alt="figure15_lowwatermark.jpg" title=""></p>
<h3 id="Framework-Level-Caching"><a href="#Framework-Level-Caching" class="headerlink" title="Framework-Level Caching"></a>Framework-Level Caching</h3><p>由于 checkpoint 的频率很好，MillWheel 会产生非常多和存储层交互的流量。当使用 Bigtable 类似的系统时，读取的成本要高于写入，而 MillWheel 通过框架层面的缓存来解决这一问题。MillWheel 的一个常见用例是将数据缓存到存储引擎中，直到 low watermark 通过了窗口边界然后再获取这些数据进行聚合。这种使用模式对于存储系统中常见的 LRU 缓存是非常不利的，刚修改过的数据很可能并不是马上就需要读取的数据。MillWheel 知道它的数据怎么被使用，并且能够提供更好的缓存策略。在图 16 中，我们给出了工作进程和存储进程使用的 CPU 数与缓存大小的关系（出于商业机密考虑，CPU 使用率进行了标准化），增加缓存大小可以线性的增加 CPU 使用率（超过 550MB 的缓存，由于大部分数据已经被缓存，所有基本没有更大的作用）。在这个实验中，MillWheel 的缓存可以将 CPU 的使用率降低为原来的二分之一。<br><img src="/2017/12/22/millwheel/figure16_cache.jpg" alt="figure16_cache.jpg" title=""></p>
<h3 id="8-4-Real-world-Deployments"><a href="#8-4-Real-world-Deployments" class="headerlink" title="8.4 Real-world Deployments"></a>8.4 Real-world Deployments</h3><p>MillWheel 支持了 Google 内部的各种系统。为各种广告客户执行流连接，其中许多需要给客户展示低延迟的数据大盘。计费系统依赖于 MillWheel 的恰好一次保证。除了 Zeitgeist 之外，MillWheel 还提供一个广泛的异常检测服务，该服务被很多不同的团队看作开箱即用的服务使用。其他部署还包括了网络交换机以及集群运行状态监控。MillWheel 还支持了面向用户的工具，比如 Google 街景中的全景图像生成和处理。（MillWheel powers a diverse set of internal Google systems. It performs streaming joins for a variety of Ads customers, many of whom require low latency updates to customer-visible dashboards. Billing pipelines depend on MillWheel’s exactly-once guarantees. Beyond Zeitgeist, MillWheel powers a generalized anomaly-detection service that is used as a turnkey solution by many different teams. Other deployments include network switch and cluster health monitoring. MillWheel also powers user-facing tools like image panorama generation and image processing for Google Street View.)</p>
<p>同样还有 MillWheel 不适用的常见。单个操作太大导致在计算过程中对 checkpoint 不友好的情况不适合，因为系统的稳定依赖于动态负载均衡。如果负载均衡器遇到这样的算子，要么只能强制结束，然后调度到其他机器，或者等待它完成。前者浪费资源，后者则使机器过载。作为一个分布式系统，MillWheel 对于不同 key 之间不能够并行的场景也处理不好。如果整个流水线上 90% 的流量都和某个特定的 key 绑定在一起，那么某台机器必须能够处理该流水线的 90% 流量，这显然是不可取的。建议作业的开发人员避免会造成单台机器会处理很高流量的  key（比如使用用户使用的语言或者用于代理等），或者通过构建两级聚合来处理相应的事情。（There are problems that MillWheel is poorly suited for. Monolithic operations that are inherently resistant to checkpointing are poor candidates for inclusion in computation code, since the system’s stability depends on dynamic load balancing. If the load balancer encounters a host spot that coincides with such an operation, it must choose to either interrupt the operation, forcing it to restart, or wait until finishes. The former wastes resources, and the latter risks overloading a machines. As a distributed system, MillWheel does not perform well on problems that are not easily parallelized between different keys. If 90% of a pipeline’s traffic is assigned a single key, then one machine must handle 90% of the overall system load for that stream, which is clearly inadvisable. Computation authors are advised to avoid keys that are high-traffic enough to bottleneck on a single machine (such as a customer’s language or user-agent string), or build a two-phase aggregator.)</p>
<p>如果计算基于 low watermark 进行聚合，数据的延迟导致 low watermark 一直不能正常更新，MillWheel 的性能就会下降。这可能会导致系统中缓冲的数据产生数小时的偏差。通常情况下，内存使用量和数据倾斜成正比，因为作业依赖 low watermark 来熟悉缓冲区的数据。为了防止内存使用量不受限制的增长，有效的补救措施是通过等待注入较新的记录，直到 low watermark 继续前进，来限制系统中的总偏差。（If a computation is performing an aggregation based on low watermark timers, MillWheel’s performance degrades if data delays hold back low watermarks for large amounts of time. This can result in hours of skew over buffered records in the system. Oftentimes memory usage is proportional to skew, because an application depends on low watermark to flush this buffered data. To prevent memory usage from growing without bound, an effective remedy is to limit total skew in the system, by waiting to inject newer records until the low watermarks have advanced.)</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文属于 MillWheel 论文的阅读与翻译稿，部分地方使用自己的语言进行描述，部分地方进行翻译（附带原文）&lt;br&gt;讲述 MillWhell 的编程模型以及具体实现。MillWhell 的逻辑时间（logical time）使得开发基于时间的聚合应用更方便，从设计之初，MillWhell 就考虑了容错性以及扩展性。&lt;/p&gt;
    
    </summary>
    
    
      <category term="computing" scheme="http://yoursite.com/tags/computing/"/>
    
      <category term="streaming" scheme="http://yoursite.com/tags/streaming/"/>
    
      <category term="millwheel" scheme="http://yoursite.com/tags/millwheel/"/>
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>tasksetmanager</title>
    <link href="http://yoursite.com/2017/12/03/tasksetmanager/"/>
    <id>http://yoursite.com/2017/12/03/tasksetmanager/</id>
    <published>2017-12-03T07:58:53.000Z</published>
    <updated>2017-12-03T09:49:01.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">/**</div><div class="line">* Schedules the tasks within a single TaskSet in the TaskSchedulerImpl. This class keeps track of</div><div class="line">* each task, retries tasks if they fail (up to a limited number of times), and</div><div class="line">* handles locality-aware scheduling for this TaskSet via delay scheduling. The main interfaces</div><div class="line">* to it are resourceOffer, which asks the TaskSet whether it wants to run a task on one node,</div><div class="line">* and statusUpdate, which tells it that one of its tasks changed state (e.g. finished).</div><div class="line">*</div><div class="line">* THREADING: This class is designed to only be called from code with a lock on the</div><div class="line">* TaskScheduler (e.g. its event handlers). It should not be called from other threads.</div><div class="line">*</div><div class="line">* @param sched           the TaskSchedulerImpl associated with the TaskSetManager</div><div class="line">* @param taskSet         the TaskSet to manage scheduling for</div><div class="line">* @param maxTaskFailures if any particular task fails this number of times, the entire</div><div class="line">*                        task set will be aborted</div><div class="line">*/</div></pre></td></tr></table></figure>
<p><code>TaskSetManager</code> 负责某个 TaskSet 的调度，对该 TaskSet 的所有 task 进行跟踪，如果有失败的 task，会负责重试（重试有上限），并且通过 delay scheduling（可以想想这个怎么实现的？） 实现 locality  locality-aware scheduling. 主要的接口有 <code>resourceOffer</code> – 用于判断一个 TaskSet 中的 task 是否需要运行到某个 node 上，<code>statusUpdate</code> – 用于跟踪 task 的状态变化。不是线程安全的。</p>
<a id="more"></a>
<p><code>dequeeTaskFromList(execId: String, list: ArrayBuffer[Int]): Option[Int]</code> 负责从对应的 list 中删除返回一个 pending Task，如果没有合适的 Task 就返回 None，该 function 中会将那些已经运行的 task 进行删除，会跳过所有的不能在对应 execId 上运行的 task（通过 executorIsBlacklisted(execId, index) 进行判断）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">while (indexOffset &gt; 0) &#123;</div><div class="line">	indexOffset -= 1</div><div class="line">	val index = list(indexOffset)</div><div class="line">	if (!executorIsBlacklisted(execId, index)) &#123;</div><div class="line">		// This should almost always be list.trimEnd(1) to remove tail</div><div class="line">		list.remove(indexOffset)</div><div class="line">		if (copiesRunning(index) == 0 &amp;&amp; !successful(index)) &#123;</div><div class="line">			return Some(index)</div><div class="line">	    &#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>dequeueTask(execId: String, host: String, maxLocality: TaskLocality.Value): Option[(Int, TaskLocality.Value, Boolean)])</code> 删除并返回一个可执行的 task，只返回符合 locality 约束的 task。首先逐个 locality 进行查找，如果有符合的 task 直接返回，否则返回一个合适的 推测执行的 task</p>
<p><code>executorIsBlacklisted(execId: String, taskId: Int): Boolean</code> 进行判断某个 execId 上能否运行对应的 task（如果之前这个 taskId 在这个 execId 上运行失败了，而且当前时间和之间失败的时间差小于阈值 <code>EXECUTOR_TASK_BLACKLIST_TIMEOUT</code>）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">def executorIsBlacklisted(execId: String, taskId: Int): Boolean = &#123;</div><div class="line">	if (failedExecutors.contains(taskId)) &#123;</div><div class="line">		val failed = failedExecutors.get(taskId).get</div><div class="line"></div><div class="line">		return failed.contains(execId) &amp;&amp;</div><div class="line">		clock.getTimeMillis() - failed.get(execId).get &lt; EXECUTOR_TASK_BLACKLIST_TIMEOUT</div><div class="line">	&#125;</div><div class="line"></div><div class="line">    false</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>dequeueSpeculativeTask(execId: String, host: String, locality: TaskLocality.Value): Option[(Int, TaskLocality.Value)]</code> 负责删除并返回一个 推测执行的 task，如果没有合适的就返回 None。逻辑就是遍历所有 task，然后看 task 是否能运行在特定的 TaskLocality 上，如果可以就返回，并且将该 task 从推测执行的 task list 中删除。TaskLocality 的顺序为 <code>{PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY}</code></p>
<p>如何实施推测执行，逻辑在 <code>checkSpeculatableTasks</code> 函数中，</p>
<ol>
<li>如果该 TaskSetManager 变为 zoombie 了，或者只包含一个 task，就不推测执行（为什么一个 task 就不推测执行）</li>
<li>如果完成的 task 数大于等于 <code>minFinishedForSpeculation = (SPECULATION_QUANTILE * numTasks).floor.toInt</code>（其中 <code>SPECULATION_QUANTILE</code> 默认 0.75，可以通过 <code>spark.speculation.quantile</code> 设置）且有 task 成功执行过，则执行下面的步骤</li>
<li>将所有执行成功的 task 的执行时间进行排序，取第 <code>val medianDuration = durations(min((0.5 * tasksSuccessful).round.toInt, durations.size - 1))
val threshold = max(SPECULATION_MULTIPLIER * medianDuration, 100)</code>  threshold 作为临界值，对每个 task 进行检测。</li>
<li>如果该 task 还没有运行成功，运行时间超过 <code>threshold</code>，只有一个实例在跑，而且没有推测执行过，就进行推测执行</li>
<li>推测执行保证同一个 task 的不同实例不会调度到同一台主机上，且不会调度到以及被加进黑名单的主机中</li>
</ol>
<p><code>resourceOffer（execId: String,host: String,maxLocality:TaskLocality.TaskLocality): Option[TaskDescription]</code> 负责资源的实际分配，如果当前 taskSetManager 不是 zoombie 状态才进行处理。首先找出当前时间可以被调度到的最高 Locality，然后使用 <code>dequeuTask</code> 删除并找到一个符合条件的 task，如果找到就更新相关的状态数据（包括，更新现在正在运行的 task 有哪些，更新当前的 locality，然后将 task 所需要的文件等序列化，附加到一个 TaskDescription 结构中并且返回），并且通知 DAGScheduler 该 task 已经开始运行。如果序列化有问题，则直接抛异常。</p>
<p><code>getAllowedLocalityLevel(curTime: Long): TaskLocality.TaskLocality</code> 获取当前时间对应的一个 TaskLocality, 这里面会有时间等待（等待的时间就是每个 TaskLocality 的等待时间，默认 3s，可以配置）</p>
<p><code>handleTaskGettingResult</code> 主要进行状态标记，然后通知 DAGScheduler<br><code>canFetchMoreResults(size: Long): Boolean</code> 检测是否还能 fetch size 字节大小已经序列化后的数据，如果不能，就将该 taskSetManger 标记为 zoombie，并且通知 DAGScheduler 该 TaskSet 为失败</p>
<p><code>handleSuccessfulTask(tid: Long, result: DirectTaskResult[_]): Unit</code> 负责将一个 task 标记为成功，并且如果当前 TaskSet 所有 task 都运行完成，就标记为 zoombie 状态，并且通知 DAGScheduler。</p>
<p><code>handleFailedTask(tid: Long, state: TaskState, reason: TaskEndReason)</code> 将task 标记为失败，并且重新添加到 pendingTask 队列中，然后通知 DAGScheduler。根据失败的信息不同，做不同的处理：</p>
<ol>
<li>FetchFailure：直接想当前的 <code>tasksetManager</code> 标记为 zoombie，然后做一定的清理工作，就把当前的 <code>tasksetManager</code> 标记为成功</li>
<li>ExceptionFailure：如果是 <code>NotSerializableException</code> 就直接退出，否则会打印相应异常，然后进行重试</li>
<li>其他的异常，打印日志</li>
</ol>
<p><code>executorLost(execId: String, host: String, reason: ExecutorLossReason)</code> 负责处理 executorLost 的情况，由 taskSchedulerImp 调用。逻辑如下</p>
<ul>
<li>如果是 <code>ShufflleMapTask</code> 且没有开启 <code>externalShuffleServiceEnabled</code> 就进行如下操作：如果 task 以及成功了，就将这些 task 标记为失败，且进行重试（因为后续的 task 需要从这些 task 中获取数据）</li>
<li>如果是其他的，就直接调用 <code>handleFailedTask</code> 进行处理，然后重新计算 <code>locality</code></li>
</ul>
<p><code>getLocalityWait(level: TaskLocality.TaskLocality): Long =</code> 用于获取 locality, 代码如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">val defaultWait = conf.get(&quot;spark.locality.wait&quot;, &quot;3s&quot;)</div><div class="line">val localityWaitKey = level match &#123;</div><div class="line">	case TaskLocality.PROCESS_LOCAL =&gt; &quot;spark.locality.wait.process&quot;</div><div class="line">	case TaskLocality.NODE_LOCAL =&gt; &quot;spark.locality.wait.node&quot;</div><div class="line">	case TaskLocality.RACK_LOCAL =&gt; &quot;spark.locality.wait.rack&quot;</div><div class="line">	case _ =&gt; null</div><div class="line">&#125;</div><div class="line"></div><div class="line">if (localityWaitKey != null) &#123;</div><div class="line">	conf.getTimeAsMs(localityWaitKey, defaultWait)</div><div class="line">&#125; else &#123;</div><div class="line">	0L</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="疑问："><a href="#疑问：" class="headerlink" title="疑问："></a>疑问：</h3><ol>
<li>推测执行的时候，为什么 TaskSet 只有 1 个 task 的话就不推测执行</li>
<li>推测执行对每个 task 只会进行一次？<br> a. 可以被 推测执行多次，只执行一次的逻辑是使用 <code>speculatableTasks</code> 做检测的，当运行一个 推测执行的 task 后，该 task 就会从 <code>speculatableTasks</code> 进行删除，然后就可以进行推测执行了。严格的说法是，只运行同一个 task 的一个实例在“排队等待被推测执行”</li>
<li>每个 task 的 <code>preferredLocations</code> 怎么得到的？根据什么规则？每一个的含义又是什么，总共有 <code>{PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY}</code> 这些可选项</li>
<li>每个 TaskSet 的所有 task 都是一样的 locality？</li>
<li>推测执行的时候，如果最后执行成功多个 task，会对结果有影响吗？怎么规避这种影响的</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;/**&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;* Schedules the tasks within a single TaskSet in the TaskSchedulerImpl. This class keeps track of&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;* each task, retries tasks if they fail (up to a limited number of times), and&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;* handles locality-aware scheduling for this TaskSet via delay scheduling. The main interfaces&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;* to it are resourceOffer, which asks the TaskSet whether it wants to run a task on one node,&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;* and statusUpdate, which tells it that one of its tasks changed state (e.g. finished).&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;*&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;* THREADING: This class is designed to only be called from code with a lock on the&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;* TaskScheduler (e.g. its event handlers). It should not be called from other threads.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;*&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;* @param sched           the TaskSchedulerImpl associated with the TaskSetManager&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;* @param taskSet         the TaskSet to manage scheduling for&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;* @param maxTaskFailures if any particular task fails this number of times, the entire&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;*                        task set will be aborted&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;*/&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;TaskSetManager&lt;/code&gt; 负责某个 TaskSet 的调度，对该 TaskSet 的所有 task 进行跟踪，如果有失败的 task，会负责重试（重试有上限），并且通过 delay scheduling（可以想想这个怎么实现的？） 实现 locality  locality-aware scheduling. 主要的接口有 &lt;code&gt;resourceOffer&lt;/code&gt; – 用于判断一个 TaskSet 中的 task 是否需要运行到某个 node 上，&lt;code&gt;statusUpdate&lt;/code&gt; – 用于跟踪 task 的状态变化。不是线程安全的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="source_code" scheme="http://yoursite.com/tags/source-code/"/>
    
      <category term="tasksetmanager" scheme="http://yoursite.com/tags/tasksetmanager/"/>
    
      <category term="task" scheme="http://yoursite.com/tags/task/"/>
    
      <category term="stage" scheme="http://yoursite.com/tags/stage/"/>
    
  </entry>
  
  <entry>
    <title>TaskScheduler</title>
    <link href="http://yoursite.com/2017/11/27/TaskScheduler/"/>
    <id>http://yoursite.com/2017/11/27/TaskScheduler/</id>
    <published>2017-11-27T13:02:24.000Z</published>
    <updated>2017-11-27T13:12:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文属于自己看源码后的记录</p>
</blockquote>
<p>与不同的后端调度器一起，进行 task 的调度（task 是 DAGScheduler 中划分的 Stage 中的具体任务），后端调度器包括 <code>LocalBackend</code>， <code>SparkDeploySchedulerBackend</code>，<code>MesosSchedulerBackend</code>，<code>YarnClientSchedulerBackend</code>， <code>YarnClusterSchedulerBackend</code>，<code>SimrSchedulerBackend</code>等</p>
<p>整个 TaskSchedulerImpl 比较简单，复杂的地方在于和各种 后端调度器联合，以及具体 <code>TasksetManager</code> 进行联合</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">TaskSchedulerImpl(</div><div class="line">	val sc: SparkContext, // SparkContext</div><div class="line">	val maxTaskFailures: Int, //每个 task 允许失败的最大次数</div><div class="line">	isLocal: Boolean = false) //是否本地运行</div></pre></td></tr></table></figure>
<p>对于没有传入 <code>maxTaskFailures</code> 参数的，使用 <code>sc.conf.getInt(&quot;spark.task.maxFailures&quot;, 4)</code>，可以使用配置参数，默认为 4 次。</p>
<p><code>TaskSchedulerImple</code> 的入口是 <code>submitTasks()</code> ，由 <code>DAGScheduler</code> 划分好 Stage 之后进行调用</p>
<p>在 <code>submitTasks</code> 中会进行资源的检测（是否申请到资源，标志位 <code>hasLaunchedTask</code> 由后面的 <code>resourceOffers</code> 进行设置），每 <code>STARVATION_TIMEOUT_MS</code> 检测一次，直到 <code>hasLaunchedTask</code> 为 True 为止，<code>STARVATION_TIMEOUT_MS</code> 默认 15s，可以通过 <code>spark.starvation.timeout</code> 进行配置，该函数会将当前的 taskSetManger 添加到整个 <code>ScheduleablePool</code> 中，然后通过 <code>backend.reviveOffer</code> 将 task 分配到 executor 上去</p>
<p>另外在 <code>TaskSchedulerImpl</code> 中会启动 推测执行的后台线程，默认 100ms 检测一次，可以通过 <code>spark.speculation.interval</code> 进行配置</p>
<p>每个 Task 默认使用的 CPU 数由 <code>CPUS_PER_TASK</code> 进行控制，默认为 1，可以通过 <code>spark.task.cpus</code> 进行设置</p>
<p><code>private val taskSetsByStageIdAndAttempt = new HashMap[Int, HashMap[Int, TaskSetManager]]</code> 根据 StageId 和 Attempt 来确定 taskSets</p>
<p><code>private val schedulingModeConf = conf.get(&quot;spark.scheduler.mode&quot;, &quot;FIFO&quot;)</code> task 调度的模式，默认为 FIFO</p>
<p><code>private[spark] var taskResultGetter = new TaskResultGetter(sc.env, this) --- Runs a thread pool that deserializes and remotely fetches (if necessary) task results</code> </p>
<p><code>executorsByHost = new HashMap[String, HashSet[String]]</code> 保存每个 Host 中运行的所有 executor</p>
<p><code>hostsByRack = new HashMap[String, HashSet[String]]</code> 不同 Rack 对于的 host</p>
<p><code>executorIdToHost = new HashMap[String, String]</code> 保存 executorId 到 host 的对于关系</p>
<p>另外还有 <code>backend: SchedulerBackend</code>， <code>dagScheduler: DAGScheduler</code>，<code>mapOutputTracker = SparkEnv.get.mapOutputTracker</code>，</p>
<p><code>initialize（）</code> 主要设置 backend 以及 schedulerPool，<br><code>start()</code> 启动 backend, 然后按需启动 推测执行的线程</p>
<p>Yarn-cluster 模式下的 backend 为 <code>org.apache.spark.scheduler.cluster.YarnClusterSchedulerBackend</code>，其中 backend 在 <code>SparkContext</code> 中初始化（根据运行的模式不同，初始化不同的 backend）</p>
<p><code>resourceOffers(offers: Seq[WorkerOffer]): Seq[Seq[TaskDescription]]</code> 用于分配资源，将 task 分配到指定的 executor 上，传入的参数是所有可以分配 task 的 executor，流程如下：</p>
<ol>
<li>首先更新 executorIdToHost，executorIdToRunningTaskIds 以及 hostsByRack，这些信息在分配 task 的时候会用到</li>
<li>将所有的 executor 进行打乱，防止全部 task 都分配到一个 executor 上（这里和下面的策略关联，下面使用 round-robin 进行分配），那么分配策略还有其他的吗？不同策略之间的对比是怎样的</li>
<li>根据具体的策略（FIFO 或者 FAIR 等）将所有 task 进行排序（如果本次有新加的 executor，那么所有的 taskset 都需要重新计算 locality）根据什么规则进行 locality 的重新计算？具体在 TaskSetManager 实现</li>
<li>通过 resourceOfferSingleTaskSet 进行分配</li>
</ol>
<p><code>resourceOfferSingleTaskSet(taskSet: TaskSetManager, maxLocality: TaskLocality, shuffledOffers: Seq[WorkerOffer], availableCpus: Array[Int],tasks: Seq[ArrayBuffer[TaskDescription]]) : Boolean = {}</code> 给一个 TaskSet 分配资源，具体逻辑如下：</p>
<p>枚举每个 executor，如果当前 executor 的可用 cpu 大于单个 task 需要的 cpu<br>则调用 tasksetManager.resourceOffer() 进行具体的 task 分配，并且更新相应的信息<br>包括 taskIdToTaskSetManager，taskIdToExecutorId, executorIdToRunningTaskIds，executorsByHost 等。然后直接返回</p>
<p><code>cancelTasks(stageId: Int, interruptThread: Boolean): Unit</code> 取消某个 stage 的所有 task。分两种情况：</p>
<ul>
<li>task set manager 已经创建，并且有部分 task 已经被调度，这种情况下，给对于的 executor 发送 kill 指令，然后终止整个 stage</li>
<li>task set manager 已经创建，但是还没有 task 被调度，直接终止整个 stage 即可</li>
</ul>
<p><code>taskSetFinished(manager: TaskSetManager): Unit</code><br>整个 task set manager 的 task 都执行完成了，主要做一些清理公族藕，然后将 task set manager 删除</p>
<p><code>statusUpdate(tid: Long, state: TaskState, serializedData: ByteBuffer)</code> 进行 task 的状态更新</p>
<ul>
<li>如果 task 的状态为 LOST</li>
<li>这个状态仅仅在 Mesos 中使用，每个 executor 对于一个 task，所以将这个 executor 标记为 Failure</li>
<li>如果 task 的状态为 {FINISHED, FAILED, KILLED, LOST} 中的任何一种</li>
<li>首先清理 taskset scheduler 的一些状态信息（比如需要跟踪的 task 等），并根据状态信息（FINISHED 是一类，其他三种为一类）更新相应的状态信息<br>如果检测到有失败的 executor（只在 mesos 模式下会产生），会给 dagscheduler 发送 executorLost 信号，并且调用 backend 的 makeOffer 重新调度 task</li>
</ul>
<p><code>executorHeartbeatReceived(execId: String, taskMetrics: Array[(Long, TaskMetrics)], blockManagerId: BlockManagerId): Boolean) = {}</code><br>更新正在运行的 task 的状态， 并且充当 master 和 BlockManager 的心跳，如果 master 认识当前 blockManager，则返回 true，否则返回 false – 表示 blockManager 需要重新注册</p>
<ul>
<li>taskMetrics: Array[(Long, TaskMetrics)]  //taskId -&gt; TaskMetrics</li>
<li>根据每个 taskId 获取对于的信息（taskId, taskSetMgr.stageId, taskSetMgr.taskSet.stageAttemptId, metrics) 发送给 dagScheduler, 其中 metric 为 taskMetrics 的第二维信息</li>
</ul>
<p><code>handleTaskGettingResult() &amp; handleSuccessfulTask()</code> 直接调用对应的 taskSetManager 对应方法</p>
<p><code>handleFailedTask(taskSetManager: TaskSetManager, tid: Long, taskState: TaskState, reason: TaskEndReason): Unit = synchronized {}</code><br>如果对应的 taskSetManger 不是僵尸状态，而且 taskState 不为 KILLED，就重新申请资源</p>
<p><code>executorLost(executorId: String, reason: ExecutorLossReason): Unit = {}</code></p>
<ul>
<li>如果 <code>executorIdToRunningTasksIds</code> 包含当前上报的 executor（失败的 executor 有 task 正在运行）, 则将当前 executor 从所有的数据结构中进行删除，然后通知 <code>DAGScheduler</code> 并且重新申请资源</li>
<li>否则只进行一些数据结构的处理（包括从所有的数据结构中进行删除，然后打印 logger 等）</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文属于自己看源码后的记录&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;与不同的后端调度器一起，进行 task 的调度（task 是 DAGScheduler 中划分的 Stage 中的具体任务），后端调度器包括 &lt;code&gt;LocalBackend&lt;/code&gt;， &lt;code&gt;SparkDeploySchedulerBackend&lt;/code&gt;，&lt;code&gt;MesosSchedulerBackend&lt;/code&gt;，&lt;code&gt;YarnClientSchedulerBackend&lt;/code&gt;， &lt;code&gt;YarnClusterSchedulerBackend&lt;/code&gt;，&lt;code&gt;SimrSchedulerBackend&lt;/code&gt;等&lt;/p&gt;
&lt;p&gt;整个 TaskSchedulerImpl 比较简单，复杂的地方在于和各种 后端调度器联合，以及具体 &lt;code&gt;TasksetManager&lt;/code&gt; 进行联合&lt;/p&gt;
    
    </summary>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
      <category term="Task" scheme="http://yoursite.com/tags/Task/"/>
    
      <category term="Scheduler" scheme="http://yoursite.com/tags/Scheduler/"/>
    
      <category term="TaskScheduler" scheme="http://yoursite.com/tags/TaskScheduler/"/>
    
      <category term="Source_Code" scheme="http://yoursite.com/tags/Source-Code/"/>
    
      <category term="Code" scheme="http://yoursite.com/tags/Code/"/>
    
  </entry>
  
  <entry>
    <title>git inside</title>
    <link href="http://yoursite.com/2017/11/20/git-inside/"/>
    <id>http://yoursite.com/2017/11/20/git-inside/</id>
    <published>2017-11-20T13:17:59.000Z</published>
    <updated>2017-11-20T14:04:38.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p><a href="https://git-scm.com/" target="_blank" rel="external">Git</a>是一个分布式的版本控制系统，能够完成你能想到的关于版本相关的所有事情，但是 Git 却不是那么好上手，也就是所谓的入门门槛有点高。</p>
</blockquote>
<h1 id="本文会讲什么"><a href="#本文会讲什么" class="headerlink" title="本文会讲什么"></a>本文会讲什么</h1><p>本文会换一个角度讲述 Git 怎么做的，给大家提供一个另外的视角，这个视角主要设计 Git 的存储，这样给大家一个更深的认识，在平时想了解的时候，也能有合适的渠道进行。</p>
<a id="more"></a>
<h1 id="Git-是什么"><a href="#Git-是什么" class="headerlink" title="Git 是什么"></a>Git 是什么</h1><p>这个问题看上去想一句废话，因为文章开始就说了，Git 是一个分布式的版本控制系统。那么底层又是如何实现的呢？以及其他人是怎么看待 Git 的呢？</p>
<blockquote>
<p>In many ways you can just see git as a filesystem. –Linus </p>
</blockquote>
<p>从上面一句话来看，Linus 把 Git 当做一个文件系统来做的，而不是一个传统意义上的版本控制系统，恰好 Git 能够做版本控制的事情。</p>
<h1 id="Git-文件结构"><a href="#Git-文件结构" class="headerlink" title="Git 文件结构"></a>Git 文件结构</h1><p>每一个 Git 仓库中都有一个隐藏的文件夹，名字叫做 <code>.git</code> 这个文件夹包含了所有的文件内容，以及版本控制相关的信息，大致结构如下：</p>
<img src="/2017/11/20/git-inside/file_tree.png" alt="file_tree.png" title="">
<p>说几个大家关注的，有兴趣的可以自己打开文件看看</p>
<ol>
<li>HEAD 指向当前分支的最后一个 commit</li>
<li>config 表示一些本项目的配置（如果没有会使用全局的配置），最明显的是 user.name 和 user.email</li>
<li>hooks 表示一些钩子函数</li>
<li>objects, 这里面保存的是所有的数据（也就是实实在在的内容），会是主要的内容</li>
<li>refs 表示一些引用，包括分支的，远程分支的，tag 的，每一个都具体指向一个 commit</li>
</ol>
<h1 id="几个概念"><a href="#几个概念" class="headerlink" title="几个概念"></a>几个概念</h1><ol>
<li>blob :上面的 objects 中的具体文件内容（保存的是文件内容，如果多个文件的内容一样，则只保存一份）</li>
<li>tree : tree 包含 tree 或者 blob</li>
<li>commit : commit 指向 tree 的根节点</li>
<li>tag : 指向一个具体的 commit</li>
<li>parent : 表示该 commit 从哪个 commit 演变而来</li>
<li>branch : 一条 commit 的链</li>
<li>HEAD : branc 的最新 commit</li>
</ol>
<h1 id="一个例子"><a href="#一个例子" class="headerlink" title="一个例子"></a>一个例子</h1><p>假设我们有一个项目，如下图所示：</p>
<img src="/2017/11/20/git-inside/project.png" alt="project.png" title="">
<p>那么我们初始化后的 git 示意图应该是这样的</p>
<img src="/2017/11/20/git-inside/first_version.png" alt="first_version.png" title="">
<p>接着我们修改 c.txt，那么我们会得到下面的示意图</p>
<img src="/2017/11/20/git-inside/second_version.png" alt="second_version.png" title="">
<p>再接着我们修改 a.txt，我们就会得到下面的示意图</p>
<img src="/2017/11/20/git-inside/third_version.png" alt="third_version.png" title="">
<p>上面的图中灰色表示非当前版本，亮色表示当前版本，三角形代表 commit，树形表示 tree，六边形表示 blob。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文介绍了 Git 的一些基本概念，以及一个简单的示例，当然这些还远远不够了解 Git 本身的，但是我认为这些是 Git 中最基本，也是最核心的一些东西了，其他的命令大概都能够从这几个命令中得到。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://git-scm.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Git&lt;/a&gt;是一个分布式的版本控制系统，能够完成你能想到的关于版本相关的所有事情，但是 Git 却不是那么好上手，也就是所谓的入门门槛有点高。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;本文会讲什么&quot;&gt;&lt;a href=&quot;#本文会讲什么&quot; class=&quot;headerlink&quot; title=&quot;本文会讲什么&quot;&gt;&lt;/a&gt;本文会讲什么&lt;/h1&gt;&lt;p&gt;本文会换一个角度讲述 Git 怎么做的，给大家提供一个另外的视角，这个视角主要设计 Git 的存储，这样给大家一个更深的认识，在平时想了解的时候，也能有合适的渠道进行。&lt;/p&gt;
    
    </summary>
    
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
      <category term="file-system" scheme="http://yoursite.com/tags/file-system/"/>
    
      <category term="inside" scheme="http://yoursite.com/tags/inside/"/>
    
  </entry>
  
  <entry>
    <title>django-configuration in action</title>
    <link href="http://yoursite.com/2017/11/09/django-configuration-in-action/"/>
    <id>http://yoursite.com/2017/11/09/django-configuration-in-action/</id>
    <published>2017-11-09T14:34:22.000Z</published>
    <updated>2017-11-10T06:36:03.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Django-中统一配置的做法"><a href="#Django-中统一配置的做法" class="headerlink" title="Django 中统一配置的做法"></a>Django 中统一配置的做法</h1><blockquote>
<p>本文主要描述如何在 django 中统一 settings 文件</p>
</blockquote>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>django 服务会有多个环境，比如 开发环境、测试环境以及线上环境等。现在大部分使用的方案是针对每一种环境使用一个 settings 文件，然后在不同的环境中使用不同的 settings 文件。这样的设计我认为有至少两个问题:</p>
<ol>
<li>很多公用的配置不太好公用</li>
<li>文件数会很多，项目中管理会比较麻烦</li>
</ol>
<a id="more"></a>
<h1 id="新方案"><a href="#新方案" class="headerlink" title="新方案"></a>新方案</h1><p>针对 settings 文件，在 django 项目中可以使用 django-configuration module 进行管理，从而解决上面的两个问题。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><ol>
<li>使用 <code>pip install django-configurations</code> 安装 django-configuration module </li>
<li>修改 settings.py manager.py 以及 wsgi.py 三个文件即可</li>
<li>建立一个配置统一的文件，用于管理不同的配置项</li>
</ol>
<h3 id="具体-Demo"><a href="#具体-Demo" class="headerlink" title="具体 Demo"></a>具体 Demo</h3><p>settings.py</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div></pre></td><td class="code"><pre><div class="line">from configurations import Configuration</div><div class="line"># Build paths inside the project like this: os.path.join(BASE_DIR, ...)</div><div class="line">import os</div><div class="line"></div><div class="line"></div><div class="line">class Common(Configuration):</div><div class="line">    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))</div><div class="line"></div><div class="line">   # Quick-start development settings - unsuitable for production</div><div class="line">    # See https://docs.djangoproject.com/en/1.8/howto/deployment/checklist/</div><div class="line"></div><div class="line">    # SECURITY WARNING: keep the secret key used in production secret!</div><div class="line">    SECRET_KEY = &apos;secret_key&apos;</div><div class="line"></div><div class="line">    # SECURITY WARNING: don&apos;t run with debug turned on in production!</div><div class="line">    DEBUG = True</div><div class="line"></div><div class="line">    ALLOWED_HOSTS = []</div><div class="line"></div><div class="line">   # Application definition</div><div class="line"></div><div class="line">    INSTALLED_APPS = (</div><div class="line">		&apos;django.contrib.admin&apos;,</div><div class="line">		&apos;django.contrib.auth&apos;,</div><div class="line">		&apos;django.contrib.contenttypes&apos;,</div><div class="line">		&apos;django.contrib.sessions&apos;,</div><div class="line">		&apos;django.contrib.messages&apos;,</div><div class="line">		&apos;django.contrib.staticfiles&apos;,</div><div class="line">																				    )</div><div class="line"></div><div class="line">		MIDDLEWARE_CLASSES = (</div><div class="line">			&apos;django.contrib.sessions.middleware.SessionMiddleware&apos;,</div><div class="line">			&apos;django.middleware.common.CommonMiddleware&apos;,</div><div class="line">			&apos;django.middleware.csrf.CsrfViewMiddleware&apos;,</div><div class="line">			&apos;django.contrib.auth.middleware.AuthenticationMiddleware&apos;,</div><div class="line">			&apos;django.contrib.auth.middleware.SessionAuthenticationMiddleware&apos;,</div><div class="line">			&apos;django.contrib.messages.middleware.MessageMiddleware&apos;,</div><div class="line">			&apos;django.middleware.clickjacking.XFrameOptionsMiddleware&apos;,</div><div class="line">			&apos;django.middleware.security.SecurityMiddleware&apos;,</div><div class="line">			)</div><div class="line"></div><div class="line">		ROOT_URLCONF = &apos;leopard.urls&apos;</div><div class="line"></div><div class="line">		TEMPLATES = [</div><div class="line">			&#123;</div><div class="line">				&apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;,</div><div class="line">				&apos;DIRS&apos;: [],</div><div class="line">				&apos;APP_DIRS&apos;: True,</div><div class="line">				&apos;OPTIONS&apos;: &#123;</div><div class="line">					&apos;context_processors&apos;: [</div><div class="line">					&apos;django.template.context_processors.debug&apos;,</div><div class="line">					&apos;django.template.context_processors.request&apos;,</div><div class="line">					&apos;django.contrib.auth.context_processors.auth&apos;,</div><div class="line">					&apos;django.contrib.messages.context_processors.messages&apos;,</div><div class="line">					],</div><div class="line">				&#125;,</div><div class="line">			&#125;,</div><div class="line">		]</div><div class="line"></div><div class="line">		WSGI_APPLICATION = &apos;leopard.wsgi.application&apos;</div><div class="line"></div><div class="line">		# Internationalization</div><div class="line">		# https://docs.djangoproject.com/en/1.8/topics/i18n/</div><div class="line"></div><div class="line">		LANGUAGE_CODE = &apos;en-us&apos;</div><div class="line"></div><div class="line">		TIME_ZONE = &apos;UTC&apos;</div><div class="line"></div><div class="line">		USE_I18N = True</div><div class="line"></div><div class="line">		USE_L10N = True</div><div class="line"></div><div class="line">		USE_TZ = True</div><div class="line"></div><div class="line">		# Static files (CSS, JavaScript, Images)</div><div class="line">		# https://docs.djangoproject.com/en/1.8/howto/static-files/</div><div class="line"></div><div class="line">		STATIC_URL = &apos;/static/&apos;</div><div class="line"></div><div class="line">		STATE_REDIS_DB = 6</div><div class="line"></div><div class="line">		LOGGING = &#123;</div><div class="line">			&apos;version&apos;: 1,</div><div class="line">			&apos;disable_existing_loggers&apos;: False,</div><div class="line">			&apos;formatters&apos;: &#123;</div><div class="line">				&apos;verbose&apos;: &#123;</div><div class="line">					&apos;format&apos;: &apos;%(levelname)s %(asctime)s %(module)s %(funcName)s %(message)s&apos;</div><div class="line">				&#125;,</div><div class="line">			&#125;,</div><div class="line">			&apos;handlers&apos;: &#123;</div><div class="line">				&apos;mail_admins&apos;: &#123;</div><div class="line">					&apos;level&apos;: &apos;ERROR&apos;,</div><div class="line">					&apos;class&apos;: &apos;django.utils.log.AdminEmailHandler&apos;</div><div class="line">				&#125;,</div><div class="line">				&apos;console&apos;: &#123;</div><div class="line">					&apos;level&apos;: &apos;DEBUG&apos;,</div><div class="line">					&apos;class&apos;: &apos;logging.StreamHandler&apos;</div><div class="line">					&#125;,</div><div class="line">				&apos;realtimejob_file&apos;: &#123;</div><div class="line">					&apos;level&apos;: &apos;INFO&apos;,</div><div class="line">					&apos;class&apos;: &apos;logging.handlers.RotatingFileHandler&apos;,</div><div class="line">					&apos;filename&apos;: &apos;filename&apos;,</div><div class="line">					&apos;formatter&apos;: &apos;verbose&apos;</div><div class="line">					&#125;,</div><div class="line">				&#125;,</div><div class="line">			&apos;loggers&apos;: &#123;</div><div class="line">				&apos;django.request&apos;: &#123;</div><div class="line">					&apos;handlers&apos;: [&apos;mail_admins&apos;],</div><div class="line">					&apos;level&apos;: &apos;ERROR&apos;,</div><div class="line">					&apos;propagate&apos;: True,</div><div class="line">				&#125;,</div><div class="line">				&apos;django_crontab.crontab&apos;: &#123;</div><div class="line">					&apos;handlers&apos;: [&apos;console&apos;],</div><div class="line">						&apos;level&apos;: &apos;DEBUG&apos;,</div><div class="line">						&apos;propagate&apos;: True,</div><div class="line">						&#125;,</div><div class="line">					&apos;realtimejob&apos;: &#123;</div><div class="line">						&apos;handlers&apos;: [&apos;realtimejob_file&apos;],</div><div class="line">						&apos;level&apos;: &apos;INFO&apos;,</div><div class="line">						&apos;propagate&apos;: False</div><div class="line">						&#125;,</div><div class="line">			&#125;,</div><div class="line">		&#125;</div><div class="line"></div><div class="line"></div><div class="line">class Dev(Common):</div><div class="line">	  DEBUG = True</div><div class="line">	  DATABASES = &#123;</div><div class="line">		&apos;default&apos;: &#123;</div><div class="line">			&apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;,</div><div class="line">			&apos;NAME&apos;: &apos;name&apos;,</div><div class="line">			&apos;USER&apos;: &apos;user&apos;,</div><div class="line">			&apos;PASSWORD&apos;: &apos;password&apos;,</div><div class="line">			&apos;HOST&apos;: &apos;host&apos;,</div><div class="line">			&apos;PORT&apos;: &apos;port&apos;,</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">    STATE_REDIS_HOST = &apos;127.0.0.1&apos;</div><div class="line">	STATE_REDIS_PORT = 6379</div><div class="line">	STATE_REDIS_SOCKET_TIMEOUT = 1000</div><div class="line"></div><div class="line"></div><div class="line">class Prod(Common):</div><div class="line">	# Database</div><div class="line">	# https://docs.djangoproject.com/en/1.8/ref/settings/#databases</div><div class="line">	DATABASES = &#123;</div><div class="line">		&apos;default&apos;: &#123;</div><div class="line">			&apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;,</div><div class="line">			&apos;NAME&apos;: &apos;name&apos;,</div><div class="line">			&apos;USER&apos;: &apos;user&apos;,</div><div class="line">			&apos;PASSWORD&apos;: &apos;password&apos;,</div><div class="line">			&apos;HOST&apos;: &apos;host&apos;,</div><div class="line">			&apos;PORT&apos;: &apos;port&apos;,</div><div class="line">		&#125;</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p>manager.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">if __name__ == &quot;__main__&quot;:</div><div class="line">    os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;settings&quot;)</div><div class="line">	os.environ.setdefault(&apos;DJANGO_CONFIGURATION&apos;, &apos;Dev&apos;)  #设置默认的环境</div><div class="line"></div><div class="line">	from configurations.management import execute_from_command_line # 引入需要的包</div><div class="line"></div><div class="line">	execute_from_command_line(sys.argv) # 使用 django-configurations 来启动</div></pre></td></tr></table></figure></p>
<p>wsgi.py 修改同上所示<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">import os</div><div class="line">from configurations.wsgi import get_wsgi_application # 引入相关的包</div><div class="line"></div><div class="line">os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;settings&quot;)</div><div class="line">os.environ.setdefault(&apos;DJANGO_CONFIGURATION&apos;, &apos;Dev&apos;)</div><div class="line"></div><div class="line">application = get_wsgi_application() # 使用 django-configurations 中的如括进行启动</div></pre></td></tr></table></figure></p>
<p>对于希望针对不同的环境引入不同的变量值（变量名字一样），可以新建一个 commonsettings.py 文件。demo 如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">import settings</div><div class="line">import os</div><div class="line"></div><div class="line">DJANGO_CONFIGURATION_KEY = &apos;DJANGO_CONFIGURATION&apos;</div><div class="line">STATE_REDIS_HOST = getattr(settings, os.environ.get(DJANGO_CONFIGURATION_KEY, &apos;Dev&apos;)).STATE_REDIS_HOST</div><div class="line">STATE_REDIS_PORT = getattr(settings, os.environ.get(DJANGO_CONFIGURATION_KEY, &apos;Dev&apos;)).STATE_REDIS_PORT</div><div class="line">STATE_REDIS_DB = getattr(settings, os.environ.get(DJANGO_CONFIGURATION_KEY, &apos;Dev&apos;)).STATE_REDIS_DB</div><div class="line">STATE_REDIS_SOCKET_TIMEOUT = getattr(settings, os.environ.get(DJANGO_CONFIGURATION_KEY, &apos;Dev&apos;)).STATE_REDIS_SOCKET_TIMEOUT</div></pre></td></tr></table></figure>
<p>这样，所有的人从 commonsettings.py 进行引入即可，不需要关心使用的那个环境（commonsettings.py 中没有处理异常，希望对于异常情况提前抛出来）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Django-中统一配置的做法&quot;&gt;&lt;a href=&quot;#Django-中统一配置的做法&quot; class=&quot;headerlink&quot; title=&quot;Django 中统一配置的做法&quot;&gt;&lt;/a&gt;Django 中统一配置的做法&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;本文主要描述如何在 django 中统一 settings 文件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;django 服务会有多个环境，比如 开发环境、测试环境以及线上环境等。现在大部分使用的方案是针对每一种环境使用一个 settings 文件，然后在不同的环境中使用不同的 settings 文件。这样的设计我认为有至少两个问题:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;很多公用的配置不太好公用&lt;/li&gt;
&lt;li&gt;文件数会很多，项目中管理会比较麻烦&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="django" scheme="http://yoursite.com/tags/django/"/>
    
      <category term="settings" scheme="http://yoursite.com/tags/settings/"/>
    
      <category term="code-style" scheme="http://yoursite.com/tags/code-style/"/>
    
  </entry>
  
  <entry>
    <title>spark_dagscheduler</title>
    <link href="http://yoursite.com/2017/10/16/spark-dagscheduler/"/>
    <id>http://yoursite.com/2017/10/16/spark-dagscheduler/</id>
    <published>2017-10-16T12:01:20.000Z</published>
    <updated>2017-10-18T03:39:10.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>基于 spark 1.6</p>
</blockquote>
<p>面向 Stage 的调度器，负责计算每个 job 的 DAG，并将 DAG 图划分为不同的 stage，对哪些 RDD 以及相应输出进行记录，寻找一个运行相应 job 所需要的最小 stage。然后将 <code>stage</code> 以 <code>TaskSet</code> 的形式提交到下层的 <code>TaskScheduler</code> 进行具体的 task 调度。每个 <code>TaskSet</code> 包含整个可以独立运行的 task，这些 task 能够利用集群上已有的数据立即运行起来，如果集群上已有的数据已经不存在了，那么当前 task 就会失败。</p>
<p>Spark 的 stage 以 RDD 的 shuffle 为界进行划分。窄依赖的 RDD 操作会被穿起来放到一个 task 中，比如 <code>map()</code>, <code>filter()</code> 这样的操作。但是需要使用到 shuffle 依赖的操作，需要多个 stage（至少一个将中间文件写到特定的地方，另外一个从特定的地方进行读取）。每个 Stage，只会对其他 Stage 有 shuffle 依赖，在同一个 stage 中会进行很多计算。实际的将计算串起来的操作在 RDD.compute 中完成。</p>
<p><code>DAGScheduler</code> 同样会基于缓存状态决定 task 希望运行在那（preferred location），如果 shuffle 输出文件丢失造成的 Stage 失败，会重新被提交。在 <strong>Stage 内部</strong> 的不是由 shuffle 文件丢失造成的失败，由 <code>TaskScheduler</code> 来完成，<code>TaskScheduler</code> 会在取消整个 stage 前进行小部分重试。<br><a id="more"></a><br>下面的几个核心概念：</p>
<ul>
<li>Jobs (通过 <code>ActiveJob</code> 来表示）是提交给调度器中最上次工作单元。比如，用户触发一次 action，比如 <code>count()</code>，的时候，就会提交一个 Job。每个 Job 可能会包含多个 stage</li>
<li>Stages 是 Job 中产生中间结果的一系列 Task 的集合，同一个 Stage 的每个 Task 运行着同样的逻辑，只是处理同一个 RDD 的不同分区。Stage 以 Shuffle 为界（后面的 Stage 必须等前面的 Stage 运行完才能继续往下进行）。现在有两种 Stage：<code>ResultStage</code>，Job 的最终执行 action 的 Stage，<code>ShuffleMapState</code> 产生中间文件的 shuffle。如果多 Job 公用同一个 RDD 的话，Stage 可能会在多个 Job 间共享。</li>
<li>Tasks 是组小的独立工作单元，每个 Task 会被独立的分发到具体的机器上运行</li>
<li>Cache tracking: <code>DAGScheduler</code> 会记录哪些 RDD 以及被缓存过，从而避免重复计算，也会记录哪些 Stage 已经生成过输出文件从而避免重复操作</li>
<li>Preferred locations: <code>DAGScheduler</code> 会根据计算所依赖的 RDD 数据、缓存的地址以及 shuffle 输出结果对 Task 进行调度</li>
<li>Cleanup: 如果上游依赖的 Job 处理完成后，下游的数据会被清理掉，防止长驻服务的内存泄漏</li>
</ul>
<p>为了能够从错误中进行恢复，同一个 Stage 可能会被运行多次，每一次就是一个 “attempts”。如果 <code>TaskScheduler</code> 汇报某个 task 失败的原因是因为依赖的前一个 Stage 的输出文件已经不见了，那么 <code>DAGScheduler</code> 会对前一个 Stage 重新进行提交。这通过 <code>CompletionEveent</code> 以及 <code>FetchFailed</code> 或者 <code>ExecutorLost</code> 事件来完成。<code>DAGScheduler</code> 会等待一小段时间来判断是否还有其他 task 需要重试，然后将所有失败的 task 进行重试。在这一过程中，我们需要重新对之前清理过的 Stage 进行计算。由于之前的 “attempt” 可能还在运行，所以需要特别注意</p>
<img src="/2017/10/16/spark-dagscheduler/procesure.jpg" alt="procesure.jpg" title="">
<p>上面的图是 DAGScheduler.scala 的主题脉络，当然还包括其他诸如 <code>taskStarted</code>, <code>taskGettingResult</code>, <code>taskEnded</code>, <code>executorZHeatbeatReceived</code>, <code>executorLost</code>, <code>executorAdded</code>, <code>taskSetFailed</code>, 等函数</p>
<blockquote>
<p>其中带箭头的虚线为消息调用；带箭头的实线为直接调用，无箭头的实线表示方法申明和内部的主要实现（比如 <code>getShuffleMapStage</code> 中包括了 <code>getAncestorShuffleDependencies</code> 和 <code>newOrUsedShuffleStage</code>)</p>
</blockquote>
<h4 id="上面是注释，下面是代码解释"><a href="#上面是注释，下面是代码解释" class="headerlink" title="上面是注释，下面是代码解释"></a>上面是注释，下面是代码解释</h4><p>入口在 <code>runJob</code>，<code>runJob</code> 会调用 <code>submitJob(rdd, func, partitions, callSite, resultHandler, properties)</code> 返回一个 waiter，等待处理完成</p>
<p><code>submitJob</code> 核心代码如下，主要生成一个 waiter 对象，然后发送一个 <code>JobSubmitted</code> 信号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">val func2 = func.asInstanceOf[(TaskContext, Iterator[_]) =&gt; _]</div><div class="line">val waiter = new JobWaiter(this, jobId, partitions.size, resultHandler)</div><div class="line">eventProcessLoop.post(JobSubmitted(jobId, rdd, func2, partitions.toArray, callSite, waiter, SerializationUtils.clone(properties)))</div></pre></td></tr></table></figure>
<p><code>JobSubmitted</code> 方法会将整个 DAG 图进行 Stage 的划分，然后提交 finalStage（也就是 action 所在的 Stage），其中 <code>newResultStage</code> 会进行具体的 Stage 划分，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">try &#123;</div><div class="line">	// New stage creation may throw an exception if, for example, jobs are run on a</div><div class="line">	// HadoopRDD whose underlying HDFS files have been deleted.</div><div class="line">	finalStage = newResultStage(finalRDD, func, partitions, jobId, callSite)</div><div class="line">&#125; catch &#123;</div><div class="line">	case e: Exception =&gt;</div><div class="line">		logWarning(&quot;Creating new stage failed due to exception - job: &quot; + jobId, e)</div><div class="line">		listener.jobFailed(e)</div><div class="line">		return</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>submitJob</code> 返回的 <code>JobWaiter</code>，JobWaiter 用于控制 Job，以及 Job 结束后进行相应的状态更新</p>
<p><code>newResultStage</code> 会将所有的 Stage 划分出来（通过 <code>getParentStagesAndId</code> 函数，<code>getParentStages</code> 进行具体的 Stage 划分），其中 <code>getParentStages</code> 进行 BFS 进行查找（这个地方 BFS 和 DFS 有什么区别？）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">private def getParentStages(rdd: RDD[_], firstJobId: Int): List[Stage] = &#123;</div><div class="line">	val parents = new HashSet[Stage]</div><div class="line">	val visited = new HashSet[RDD[_]]</div><div class="line">	// We are manually maintaining a stack here to prevent StackOverflowError</div><div class="line">	// caused by recursively visiting</div><div class="line">	val waitingForVisit = new Stack[RDD[_]]</div><div class="line">	def visit(r: RDD[_]) &#123;</div><div class="line">		if (!visited(r)) &#123;</div><div class="line">			visited += r</div><div class="line">			// Kind of ugly: need to register RDDs with the cache here since</div><div class="line">			// we can&apos;t do it in its constructor because # of partitions is unknown</div><div class="line">			for (dep &lt;- r.dependencies) &#123;</div><div class="line">				dep match &#123;</div><div class="line">					case shufDep: ShuffleDependency[_, _, _] =&gt;</div><div class="line">						parents += getShuffleMapStage(shufDep, firstJobId)</div><div class="line">					case _ =&gt;</div><div class="line">						waitingForVisit.push(dep.rdd)</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	waitingForVisit.push(rdd)</div><div class="line">	while (waitingForVisit.nonEmpty) &#123;</div><div class="line">		visit(waitingForVisit.pop())</div><div class="line">	&#125;</div><div class="line">	parents.toList</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>getParentStages 返回某个 RDD 的所有依赖的 stage（直接和间接的），stage 以 getShuffleMapStage() 返回为准</p>
<p><code>getShuffleMapStage</code> 首先从 shuffleToMapStage(shuffleid 到 stage 的 map 结构）中查找，没有找到就以 shuffleDep.rdd 为起始点建立一个依赖关系，并且将整条依赖链上的东西都建立起来</p>
<p><code>getAncestorShuffleDependencies</code> 会以一个 RDD 为起点，找到 RDD 直接&amp;间接 依赖的所有 shuffleDependency</p>
<p><code>getAncestorShuffleDependencies</code> 和  <code>getParentStages</code> 类似但又不一样，前者在搜索的时候，每次都需要把 rdd.dep 入队，而后者只需要将 narrowdependency 的入队。还有为什么两个函数一个结果保存为 Set，一个是 Stack？</p>
<p><code>newShuffleMapStage</code> 中会更新 job 和 stage，以及 stage 和 job 的关系，每个 stage 属于哪些 job，每个 job 包含哪些 stage</p>
<p>整个类中有一个变量 <code>mapOutputTracker :MapOutputTracker</code> 用于记录 shuffle 的结果以及位置</p>
<p><code>MapOutputTracker</code> 记录 shuffleMapStage 的 output location  ，为啥要两个 status map（一个 MapStatus，一个 CachedSerializedStatus，后者是前者的序列化之后的结果）,这些 Map 都是带 ttl 的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">/* org.apache.spark.MapOutputTracker.scala</div><div class="line">* Class that keeps track of the location of the map output of</div><div class="line">* a stage. This is abstract because different versions of MapOutputTracker</div><div class="line">* (driver and executor) use different HashMap to store its metadata.</div></pre></td></tr></table></figure>
<p>Driver 使用 MapOutputTrackerMaster 跟踪 output location，只有所有 partition 的 output location 都就绪了，整个被依赖的 RDD 才是就绪的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">* MapOutputTracker for the driver. This uses TimeStampedHashMap to keep track of map</div><div class="line">* output information, which allows old output information based on a TTL.</div></pre></td></tr></table></figure>
<p>Executor 则使用 <code>MapOutputTrackerWorker</code> 从 Driver 获取 map output 的相应信息</p>
<p><code>newOrUsedShuffleStage</code> 函数中首先查找该 shuffleMapStage 是否注册过 MapOutputTracker，如果注册过就直接获取，如果没有注册过就进行注册。<br>MapOutputTracker 有两个 Map 结构，一个是原始的 partition location，一个是序列化之后的（用于加速？），这两个 map 包含过期清理策略，用于节省空间</p>
<p>定期清理的 Meta 信息包括如下几种：</p>
<ul>
<li>MAP_OUTPUT_TRACKER, </li>
<li>SPARK_CONTEXT, </li>
<li>HTTP_BROADCAST, </li>
<li>BLOCK_MANAGER,</li>
<li>SHUFFLE_BLOCK_MANAGER, </li>
<li>BROADCAST_VARS</li>
</ul>
<h3 id="上面是一条链路上的相关函数，下面包括一些其他的处理"><a href="#上面是一条链路上的相关函数，下面包括一些其他的处理" class="headerlink" title="上面是一条链路上的相关函数，下面包括一些其他的处理"></a>上面是一条链路上的相关函数，下面包括一些其他的处理</h3><h4 id="handleTaskCompletion-处理-Task-comple-的信息（不分成功和失败）"><a href="#handleTaskCompletion-处理-Task-comple-的信息（不分成功和失败）" class="headerlink" title="handleTaskCompletion 处理 Task comple 的信息（不分成功和失败）"></a><code>handleTaskCompletion</code> 处理 Task comple 的信息（不分成功和失败）</h4><p>task complete 会分几种信息：</p>
<ul>
<li><p>Success：<br>首先将 task 从 pendingTask 中去掉<br>  task 分为两种：</p>
<ul>
<li>ResultTask：<br>将 job 对应的当前 task 标记为 true（如果没有标记过的话），如果整个 job 都处理完成，就将 stage 标记为完成</li>
<li><p>ShuffleMapTask：<br>更新 outputLocation （当前 shuffleMapTask 的输出）<br>如果 ShuffleMapTask 的所有 partition 都处理完成，就将当前的 stage 标记为完成<br>这里为了防止是重复进行计算（之前失败过），需要重新进行 outputLocation 的注册（主要是增加 epoch）<br>如果当前当前的 Stage.isAvailable 为 true 就通知所有依赖该 stage 的 stage 可以继续工作了。否则重新提交失败的 task（注意这里available 和上面的 finish 不一样，available 是以 output 是否能够获取到为准）</p>
</li>
<li><p>Resubmitted：<br>将 task 加到 pendingTask 中即可，等待后续的调度</p>
</li>
<li><p>FetchFailed：<br>首先判断失败 task 的 attemp 是否是当前的 attemp，不是就忽略，然后判断当前 stage 是否正在运行，如果不是，忽略。<br>否则将当前的 stage 标记为 finish，然后将进行 mapStage.removeOutputLoc 以及 mapOutputTracker.unregisterMapOutput。<br>如果同一个 executor 上的 fetchFailed 很多（这个有调用方判断），则将所在的 executor 标记为 Failed</p>
</li>
<li><p>其他信息，直接忽略</p>
</li>
</ul>
</li>
</ul>
<h4 id="ExecutorLost"><a href="#ExecutorLost" class="headerlink" title="ExecutorLost"></a>ExecutorLost</h4><p>如果上报的 executor 之前没有上报过（会有一个 Map 记录所有上报过的 executor），或者之前上报的该 executor 对应的 epoch 小于 currentepoch， 则需要进行处理</p>
<p>首先从 blockManagerMaster 中将当前 executor 删除</p>
<p>如果没有启动 externalShuffleService（开启 <code>DynamicAllocation</code> 后需要开启，不然会出问题），或者 fetchFailed（由调用方设置），则进行下面的操作：</p>
<p><code>if (!env.blockManager.externalShuffleServiceEnabled || fetchFailed)</code></p>
<p>所该 executor 上所有的输出都进行标记删除，并且增加 <code>mapOutputTracker</code> 的 epoch</p>
<h4 id="ExecutorAdded"><a href="#ExecutorAdded" class="headerlink" title="ExecutorAdded"></a>ExecutorAdded</h4><p>  如果当前添加的 executor 是马上需要回收的，那么就从即将回收的 map 中删除，防止回收，否则不需要操作</p>
<h4 id="StageCancellation"><a href="#StageCancellation" class="headerlink" title="StageCancellation"></a>StageCancellation</h4><p>  如果有正在运行的 job 依赖当前 stage，则将所有的 job 标记为 cancel</p>
<h4 id="JobCancellation"><a href="#JobCancellation" class="headerlink" title="JobCancellation"></a>JobCancellation</h4><p>  将该 job 以及只由该 job 依赖的 stage 都标记为 failed</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>  <code>spark.stage.maxConsecutiveAttempts</code> 表示一个 stage 尝试多少次之后会被标记为失败</p>
<p>  SparkContext 中会根据模式生成和注册相应的 backend 以及 taskscheduler</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ol>
<li>如果一个 Stage 有多个 RDD，那么这些 RDD 是在同一个 TaskSet 中吗</li>
<li>如何模拟 <code>r2 = r0.reduceByKey; r3 = r1.reduceByKey; r4 = r2.map(xx); r5 = r4.union(r3); r6 = r5.map; r7 = r6.reduceByKey</code> 的 Stage 划分和生成（会有多少个 Stage，每个 Stage 分别包含哪些 RDD，以及整个 DAG 怎么整合起来的）</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;基于 spark 1.6&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;面向 Stage 的调度器，负责计算每个 job 的 DAG，并将 DAG 图划分为不同的 stage，对哪些 RDD 以及相应输出进行记录，寻找一个运行相应 job 所需要的最小 stage。然后将 &lt;code&gt;stage&lt;/code&gt; 以 &lt;code&gt;TaskSet&lt;/code&gt; 的形式提交到下层的 &lt;code&gt;TaskScheduler&lt;/code&gt; 进行具体的 task 调度。每个 &lt;code&gt;TaskSet&lt;/code&gt; 包含整个可以独立运行的 task，这些 task 能够利用集群上已有的数据立即运行起来，如果集群上已有的数据已经不存在了，那么当前 task 就会失败。&lt;/p&gt;
&lt;p&gt;Spark 的 stage 以 RDD 的 shuffle 为界进行划分。窄依赖的 RDD 操作会被穿起来放到一个 task 中，比如 &lt;code&gt;map()&lt;/code&gt;, &lt;code&gt;filter()&lt;/code&gt; 这样的操作。但是需要使用到 shuffle 依赖的操作，需要多个 stage（至少一个将中间文件写到特定的地方，另外一个从特定的地方进行读取）。每个 Stage，只会对其他 Stage 有 shuffle 依赖，在同一个 stage 中会进行很多计算。实际的将计算串起来的操作在 RDD.compute 中完成。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DAGScheduler&lt;/code&gt; 同样会基于缓存状态决定 task 希望运行在那（preferred location），如果 shuffle 输出文件丢失造成的 Stage 失败，会重新被提交。在 &lt;strong&gt;Stage 内部&lt;/strong&gt; 的不是由 shuffle 文件丢失造成的失败，由 &lt;code&gt;TaskScheduler&lt;/code&gt; 来完成，&lt;code&gt;TaskScheduler&lt;/code&gt; 会在取消整个 stage 前进行小部分重试。&lt;br&gt;
    
    </summary>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="source_code" scheme="http://yoursite.com/tags/source-code/"/>
    
      <category term="dagscheduler" scheme="http://yoursite.com/tags/dagscheduler/"/>
    
  </entry>
  
  <entry>
    <title>GC 标记-清除算法</title>
    <link href="http://yoursite.com/2017/09/17/GC-%E6%A0%87%E8%AE%B0-%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2017/09/17/GC-标记-清除算法/</id>
    <published>2017-09-17T00:51:40.000Z</published>
    <updated>2017-09-17T12:36:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>GC 的世界中有三种基本的算法，分别是：</p>
<ul>
<li>标记清除</li>
<li>引用计数</li>
<li>GC 复制</li>
</ul>
<p>其他的 GC 算法都是在这三种算法上进行修改，优化得来。本文将要介绍的是 标记-清除 算法。</p>
<a id="more"></a>
<h1 id="标记清除算法介绍"><a href="#标记清除算法介绍" class="headerlink" title="标记清除算法介绍"></a>标记清除算法介绍</h1><p>像字面意思一样，标记-清除算法分为两步：标记和清除。其中标记和清除使用伪代码分别可以写出来如下：</p>
<p>标记</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">mark_phase() &#123;</div><div class="line">    for (r: $roots)</div><div class="line">       mark(*r)</div><div class="line">&#125;</div><div class="line"></div><div class="line">mark(obj)&#123;</div><div class="line">    if(obj.mark == FALSE)</div><div class="line">        obj.mark == TRUE</div><div class="line">        for(child: children(obj))</div><div class="line">            mark(*child)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>清除</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">sweep_phase() &#123;</div><div class="line">    sweeping = $head_start    //从堆头开始清除</div><div class="line">    while (sweeping &lt; $head_end)</div><div class="line">        if (sweeping.mark == TRUE) //如果当前对象是活跃对象</div><div class="line">            sweeping.mark = FALSE</div><div class="line">        else  //如果当前对象是可清除对象，则将其加入到 free_list 中</div><div class="line">            sweeping.next = $free_list   </div><div class="line">            $free_list = sweep</div><div class="line">        sweeping += sweeping.size</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>对于标记清除算法，最基本的，将某个对象是否已经被标记，以及对象的大小等等这些信息都保存在头部，从上面的代码中，我们可以知道头部至少有三个域：标记位(名为 mark)、对象大小（名为 size）以及下一个对象的头部地址（名为 next）– 有 size 和 next 两个域，是因为下一个对象不一定在物理上是连续的。如下图所示</p>
<img src="/2017/09/17/GC-标记-清除算法/heap.png" alt="heap.png" title="">
<p>其中淡蓝色的表示还在使用的空间，白色的表示空闲空间。</p>
<h2 id="标记算法的选取"><a href="#标记算法的选取" class="headerlink" title="标记算法的选取"></a>标记算法的选取</h2><p>在标记部分，我们从 root 节点触发，然后逐一标记哪个节点不再使用，哪些节点还需要在继续存活。在上述代码中，我们给出的是 DFS 搜素算法，那么对于这一块我们可以比较 DFS 和 BFS 的区别，大致可以用下图表示：</p>
<img src="/2017/09/17/GC-标记-清除算法/BFS_DFS.jpeg" alt="BFS_DFS.jpeg" title=""> 
<p>主要区别在于：<strong>DFS 需要保存的内存使用量更低</strong></p>
<h2 id="分配内存"><a href="#分配内存" class="headerlink" title="分配内存"></a>分配内存</h2><p>所有的标记、清除等都是为了分配内存服务的，如果我们不需要再分配内存的话，那么就可以不进行前面哪些活动了。下面说说如何分配内存的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">new_obj(size) &#123;</div><div class="line">    chunk = pickup_chunk(size, $free_list) // 从上面的空闲列表中找一个合适的内存块</div><div class="line">    if (chunk != NULL)</div><div class="line">        return chunk</div><div class="line">    else</div><div class="line">        allocation_fail() //内存不够</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上面的代码表示整个分配内存的过程，其中 <code>pickup_chunk</code> 表示从空闲列表中找出一个合适的内存块，返回给申请者。</p>
<p>对于找出一个 <strong>合适</strong> 的内存块，我们已知的至少有三种方法：</p>
<ul>
<li>First-fit 返回最先找到的一个内存块</li>
<li>Best-fit  找到一个大于需要内存的最小内存块</li>
<li>Worst-fit 找到一个大于需要内存的最大内存块</li>
</ul>
<p>上面三种每一种都有不同的应用场景，也各有优劣。</p>
<h2 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h2><p>对于清除阶段，我们会遍历堆中所有的内存区域，将不需要的加入到 <code>free_list</code> 中，对于连续出现的两个内存块，我们并没有进行任何操作，那么下一次我们申请内存的时候，可能会由于没有足够大的内存块而失败。比如我们有两个大小分别为 3，4 的内存块，然后，我们需要申请一个内存大小为 5 的内存块，在之前的算法中是会失败的。这就牵涉到清除阶段的合并了，将连续的内存块进行合并形成大的内存块。上面的清除阶段算法改成如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">sweep_phase() &#123;</div><div class="line">    sweeping = $head_start    //从堆头开始清除</div><div class="line">    while (sweeping &lt; $head_end)</div><div class="line">        if (sweeping.mark == TRUE) //如果当前对象是活跃对象</div><div class="line">            sweeping.mark = FALSE</div><div class="line">        else  //如果当前对象是可清除对象，则将其加入到 free_list 中</div><div class="line">            if(sweeping == $free_list + $free_list.size) //邻接块的合并</div><div class="line">                $free_list.size + sweeping.size</div><div class="line">            else</div><div class="line">                sweeping.next = $free_list</div><div class="line">                $free_list = sweep</div><div class="line">        sweeping += sweeping.size</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h1><p>基本算法基本描述完成，接下来可以看看这种算法的优缺点分别是什么，以及是否有办法进行优化</p>
<p>优点：</p>
<ol>
<li>实现简单。算法简单，能够明显知道是否有问题，而且更容易和其他算法进行结合</li>
<li>与保守式 GC 算法兼容。在 保守式 GC 算法中，对象是不能被移动的，刚好 GC 标记-清除算法不需要移动对象。</li>
</ol>
<p>缺点：</p>
<ol>
<li>碎片化。在标记-清除的过程中，会不断的产生碎片，虽然在清除阶段有合并过程，但还是不够。</li>
<li>分配速度。由于在 标记-清除 算法 中分块不是连续的，因此每次分配都需要遍历空闲列表，找到足够大的分块，最坏的情况需要每次都遍历整个空闲列表。</li>
<li>与写时复制技术不兼容。标记-清除算法中的标记阶段，会修改对象的头部，因此和写时复制技术不兼容，可能导致很多不必要的复制。</li>
</ol>
<h1 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h1><p>既然我们了解到了该算法的优缺点，那么在此基础上如何进行改进呢？</p>
<p>针对上面的缺点分别有如下几点改进</p>
<h2 id="多个空闲链表"><a href="#多个空闲链表" class="headerlink" title="多个空闲链表"></a>多个空闲链表</h2><p>简单的说，就是将原来一个空闲链表变成现在的多个空闲链表，加快分配的速度。<br>我们之前分配内存的时候，需要查询整个空闲链表来寻找一个合适的内存块，现在我们将不同大小的内存块挂在不同的链表下面，这样我们就能够直接去合适的链表中查找了。如下图所示</p>
<img src="/2017/09/17/GC-标记-清除算法/multilink.jpeg" alt="multilink.jpeg" title="">
<p>我们有用于 2 个字的空闲链表，有用于 3 个字的空闲链表。这样当需要分配 3 个字的空间时，我们直接去对应的链表查找即可。</p>
<p>这里有一个注意的点，需要保持多少个链表呢？一般来说，根据经验，一般会将小于某个阈值的分别生成一个链表，大于该阈值的所有内存块放到一个链表中。比如所有小于 100 字的都有一个单独的链表，而所有大于等于 100 字的内存块都挂在 100 字这个链表下。</p>
<h2 id="BiBOP-法"><a href="#BiBOP-法" class="headerlink" title="BiBOP 法"></a>BiBOP 法</h2><p>另外一种优化方法，就是将大小相近的内存块放到一起，如下图所示</p>
<img src="/2017/09/17/GC-标记-清除算法/bibop.jpeg" alt="bibop.jpeg" title="">
<p>这样的形式，我们也知道去哪个地方查找需要的内存块，但是这个方法有一点不好，就是会形成很多内存碎片，比如我们分配的很多大小为 2 个字的空间，但是所有的申请中最小的都是 3 个字，这个时候这些 2 个字的空间都是浪费的</p>
<h2 id="位图标记"><a href="#位图标记" class="headerlink" title="位图标记"></a>位图标记</h2><p>位图标记法主要改善的是“和 copy-on-write 技术不兼容”，将标记位从头部抽离出来了。如下图所示</p>
<img src="/2017/09/17/GC-标记-清除算法/bitmap.jpeg" alt="bitmap.jpeg" title="">
<p>这样标记的时候就不会修改头部位置了。伪代码大致如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">mark(obj) &#123;</div><div class="line">    obj_num = (obj - $heap_start) / WORD_LENGTH</div><div class="line">    index = obj_num / WORD_LENGTH</div><div class="line">    offset = obj_num % WORD_LENGTH</div><div class="line">    </div><div class="line">    if (($bitmap_tbl[index] &amp; (1 &lt;&lt; offset)) == 0) // 未被标记</div><div class="line">        $bitmap_tbl[index] |= (1 &lt;&lt; offset)</div><div class="line">        for (child: children(obj))</div><div class="line">            mark(*child)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<blockquote>
<p>在参考条目[1] 中有描述这个算法的第二个优势：清除操作更高效。描述如下：以往的清除操作都必须遍历整个堆，把非活动对象连接到空闲链表，同时取消活动对象的标志位。</p>
</blockquote>
<p>我的理解现在还是需要遍历整个堆，而且需要取消标志位，只是现在标志位变成了连续的，这样处理起来会高效一点。</p>
<p>另外，如果有多个堆的情况下，就需要多个 bitmap 了</p>
<h2 id="延迟清除法"><a href="#延迟清除法" class="headerlink" title="延迟清除法"></a>延迟清除法</h2><p>在清除操作中，我们需要遍历整个堆，也就是处理时间和堆的大小成正比。在清除阶段，内存空间不能访问，这就牵涉到最大暂停时间。而延迟清除法（lazy sweep）则可以缩短清除操作导致的最大暂停时间。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">new_obj(size) &#123;</div><div class="line">    chunk = lazy_sweep(size) //先通过延迟清除法，查找是否以满足条件的内存块</div><div class="line">    if (chunk != NULL)</div><div class="line">        return chunk</div><div class="line"></div><div class="line">    mark_phase() //标记阶段</div><div class="line">    </div><div class="line">    chunk = lazy_sweep(size) //再次通过延迟清除法，寻找一个满足条件的内存块</div><div class="line">    if (chunk != NULL)</div><div class="line">        return chunk</div><div class="line">    </div><div class="line">    allocation_fail()</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>至于 <code>lazy_sweep</code> 函数如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">lazy_sweep(size) &#123;</div><div class="line">    while($sweeping &lt; $headp_end)</div><div class="line">        if ($sweeping.mark == TRUE) //TRUE 表示活动对象</div><div class="line">            $sweeping.mark = FALSE</div><div class="line">        else if ($sweeping.size &gt;= size)</div><div class="line">            chunk = $sweeping</div><div class="line">            $sweeping += $sweeping.size</div><div class="line">            return chunk</div><div class="line">        $sweeping += $sweeping.size</div><div class="line">    $sweeping = $head_start</div><div class="line">    return NULL</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>注意，其中的 <code>sweeping</code> 时候全局变量，因此遍历的起始位置是上次结束的地方。</p>
<p>延迟清除法有一个缺点就是。如果空闲内存块和活动对象块基本分成两个大的部分的话（如下图所示），那么对于某次清除活动对象周围的空间时，就会增加暂停时间。</p>
<img src="/2017/09/17/GC-标记-清除算法/lazy-sweep.png" alt="lazy-sweep.png" title="">
<p>上图中淡蓝色的表示活动对象，白色的表示空闲对象，当清除到活动对象附近的时候，就会增加本次的最大暂停时间。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li>《垃圾回收的算法与实现》第二章</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;GC 的世界中有三种基本的算法，分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;标记清除&lt;/li&gt;
&lt;li&gt;引用计数&lt;/li&gt;
&lt;li&gt;GC 复制&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其他的 GC 算法都是在这三种算法上进行修改，优化得来。本文将要介绍的是 标记-清除 算法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="GC" scheme="http://yoursite.com/tags/GC/"/>
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="标记-清除" scheme="http://yoursite.com/tags/%E6%A0%87%E8%AE%B0-%E6%B8%85%E9%99%A4/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="总结" scheme="http://yoursite.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>tmux 简单使用指南</title>
    <link href="http://yoursite.com/2017/07/14/tmux-%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
    <id>http://yoursite.com/2017/07/14/tmux-简单使用指南/</id>
    <published>2017-07-14T06:21:37.000Z</published>
    <updated>2017-07-14T09:37:38.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Tmux-的简单使用说明"><a href="#Tmux-的简单使用说明" class="headerlink" title="Tmux 的简单使用说明"></a>Tmux 的简单使用说明</h1><blockquote>
<p>工欲善其事，必先利其器</p>
</blockquote>
<p>Tmux 是一个多窗口管理程序。可以让用户在一个地方管理多个终端。而不需要在不同的终端间来回切换。</p>
<h2 id="在-Mac-下如何安装"><a href="#在-Mac-下如何安装" class="headerlink" title="在 Mac 下如何安装"></a>在 Mac 下如何安装</h2><p>直接使用 <code>brew install tmux</code> 就可以了，如果没有 brew，则需要先安装 brew，然后再执行上述命令。</p>
<h2 id="简单使用流程"><a href="#简单使用流程" class="headerlink" title="简单使用流程"></a>简单使用流程</h2><p>首先，需要了解 tmux 中的几个概念。session，window 以及 pane。这几者的关系如下，tmux 中可以起多个 session，每个 session 可以启动多个 window，然后每个 window 可以启动多个 pane。</p>
<p>这里给一个基本的流程</p>
<ol>
<li><p>启动 tmux（默认会启动一个 session）<br>使用 <code>tmux</code> 启动 tmux，使用 <code>exit</code> 退出 tmux，session 的命名默认是从 0 开始，一直往上加</p>
</li>
<li><p>在 session 中启动一个 window<br><code>PREFIX c</code> 会在当前 session 中创建一个 window, 其中 <code>PREFIX</code> 表示 tmux 中的命令前缀符（该条命令表示，先按下 PREFIX，然后按下 c)，</p>
</li>
<li><p>在启动的 window 中创建一个 pane<br><code>PREFIX %</code> 竖直方向切分一个 window，<code>PREFIX &quot;</code> 横向切分一个 window。这样就能够在 window 中创建 pane 了。基本的这些就够了。</p>
</li>
<li><p>如何在 session，window，pane 中进行移动<br>能够创建 session，window，pane 了，接下来就是如何在 session，window，pane 间进行移动了。<br><code>PREFIX s</code> 会列出所有 session，然后进行具体的选择（可以上下移动光标，然后按 ENTRER 确定）<br><code>PREFIX w</code> 可以列出所有的 window，然后进行具体的筛选<br><code>PREFIX n</code> 可以切换到下一个 window<br><code>PREFIX p</code> 可以切换到上一个 window<br><code>PREFIX &amp;</code> 可以关闭当前 window<br><code>PREFIX o</code> 可以在 pane 之间进行跳转<br><code>tmux ls</code> 会列出当前所有的 session（在非 tmux 环境下）</p>
</li>
</ol>
<h2 id="自定义-tmux"><a href="#自定义-tmux" class="headerlink" title="自定义 tmux"></a>自定义 tmux</h2><p>tmux 的配置文件可以保存在两个地方</p>
<ol>
<li>/etc/tmux.conf</li>
<li>~/.tmux.conf</li>
</ol>
<p>其中 2 的优先级会更高，1 的影响面更广</p>
<h2 id="接下来做什么"><a href="#接下来做什么" class="headerlink" title="接下来做什么"></a>接下来做什么</h2><p>上面的仅仅是一个入门文档，也就是最少基本知识，接下来就是多实践。推荐一本小书《tmux productive mouse-free development》</p>
<img src="/2017/07/14/tmux-简单使用指南/tmux_pic.png" alt="tmux_pic.png" title="">
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Tmux-的简单使用说明&quot;&gt;&lt;a href=&quot;#Tmux-的简单使用说明&quot; class=&quot;headerlink&quot; title=&quot;Tmux 的简单使用说明&quot;&gt;&lt;/a&gt;Tmux 的简单使用说明&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;工欲善其事，必先利其器&lt;/p&gt;
&lt;
    
    </summary>
    
    
      <category term="tmux, tools" scheme="http://yoursite.com/tags/tmux-tools/"/>
    
  </entry>
  
  <entry>
    <title>风险不仅仅是事件发生的概率</title>
    <link href="http://yoursite.com/2017/06/20/%E9%A3%8E%E9%99%A9%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AF%E4%BA%8B%E4%BB%B6%E5%8F%91%E7%94%9F%E7%9A%84%E6%A6%82%E7%8E%87/"/>
    <id>http://yoursite.com/2017/06/20/风险不仅仅是事件发生的概率/</id>
    <published>2017-06-20T14:05:59.000Z</published>
    <updated>2017-06-20T14:57:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="风险不仅仅是事件发生的概率"><a href="#风险不仅仅是事件发生的概率" class="headerlink" title="风险不仅仅是事件发生的概率"></a>风险不仅仅是事件发生的概率</h1><blockquote>
<p>风险可以定义为 = 事件结果对你的影响 * 事件发生的概率</p>
</blockquote>
<p>风险在生活中处处存在，可能我们会想冒个险没啥关系，反正发生的概率小，而且在某些时候会有高收益/回报伴随这风险，这个时候就更有诱惑力了，总有人希望通过冒险得到高回报，但这恰恰是不可取的，是非常危险的。</p>
<a id="more"></a>
<h2 id="到底能不能闯红灯"><a href="#到底能不能闯红灯" class="headerlink" title="到底能不能闯红灯"></a>到底能不能闯红灯</h2><blockquote>
<p>如果 遇到/见到过一次严重的交通事故，产生过后怕的感觉，那么就再也不会在这件事上冒险了</p>
</blockquote>
<pre><code>当你你急着过马路，但是现在是红灯，你会选择等待吗？如果这个时候旁边有人正在闯红灯，你还会等待吗？
</code></pre><p>上面的问题只能自己回答自己，回答很容易，但是实践起来就不那么容易了。</p>
<p>闯红灯是生活中很常见的事情，但是却隐藏了非常大的安全隐患。因为一旦发生交通事故，对自己来说将是不能承担的后果。</p>
<p>有人会问：那绿灯的时候就不会发生交通事故了吗？绿灯照样可能发生交通事故啊。</p>
<p>是的，这句话没问题，绿灯同样可能发生交通事故，但是有两点：</p>
<ol>
<li>闯红灯发生交通事故的责任怎么算</li>
<li>闯红灯和不闯红灯发生交通事故的概率比</li>
</ol>
<p>不闯红灯，并不能完全避免交通事故的发生 – 意外并不能完全避免，只能尽量降低其发生的可能性 – 只是将可能性降低而已，因为这事的后果是不能承担的。</p>
<h2 id="投资要不要冒险"><a href="#投资要不要冒险" class="headerlink" title="投资要不要冒险"></a>投资要不要冒险</h2><p>不同的投资标的，风险和回报率是不一样的。每个人能承受的风险能力也是不一样的。</p>
<pre><code>投资一百万，到底算不算冒险？
</code></pre><p>这是一个因人而异的问题，只有自己能回答，因为每个人的资金大小不一样，所以一百万对每个人的意义是不一样的。</p>
<p>大家都想挣钱，甚至挣快钱，这都没有问题，不过要考虑了解两点：</p>
<ol>
<li>高回报率可能伴随这高风险，这个风险是自己能承受的吗？</li>
<li>快速的挣到一大笔钱后，自己有足够的心里能力可以承受吗？ – 这一点是很重要，很重要，很重要，但是很难用语言描述清楚。短时间内得到或者失去一大笔钱对一个人的心里都会造成很大的影响。</li>
</ol>
<p>还有就是，投资基本做不到百分之一百的有把握，所以不要 all in。all in 只要失败一次就全跪了。</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ol>
<li>风险真的是风险吗？是自己真正思考过后的风险，还是听别人说的风险？</li>
<li>知道有风险的存在，可以怎么利用风险吗？</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;风险不仅仅是事件发生的概率&quot;&gt;&lt;a href=&quot;#风险不仅仅是事件发生的概率&quot; class=&quot;headerlink&quot; title=&quot;风险不仅仅是事件发生的概率&quot;&gt;&lt;/a&gt;风险不仅仅是事件发生的概率&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;风险可以定义为 = 事件结果对你的影响 * 事件发生的概率&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;风险在生活中处处存在，可能我们会想冒个险没啥关系，反正发生的概率小，而且在某些时候会有高收益/回报伴随这风险，这个时候就更有诱惑力了，总有人希望通过冒险得到高回报，但这恰恰是不可取的，是非常危险的。&lt;/p&gt;
    
    </summary>
    
      <category term="想清楚" scheme="http://yoursite.com/categories/%E6%83%B3%E6%B8%85%E6%A5%9A/"/>
    
    
      <category term="风险" scheme="http://yoursite.com/tags/%E9%A3%8E%E9%99%A9/"/>
    
      <category term="概率" scheme="http://yoursite.com/tags/%E6%A6%82%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>Streaming 程序调用 Producer.close hang 住问题追查复盘</title>
    <link href="http://yoursite.com/2017/06/03/Streaming-%E7%A8%8B%E5%BA%8F%E8%B0%83%E7%94%A8-Producer-close-hang-%E4%BD%8F%E9%97%AE%E9%A2%98%E8%BF%BD%E6%9F%A5%E5%A4%8D%E7%9B%98/"/>
    <id>http://yoursite.com/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/</id>
    <published>2017-06-03T02:44:55.000Z</published>
    <updated>2017-06-03T03:43:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文作为一个问题追查过程的复盘记录，主要希望找出自己在解决问题中可以优化改进的地方。以后遇到问题，能够快速的进行定位，解决。</p>
<a id="more"></a>
<h2 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h2><p>一个 Spark Streaming 作业从 Kafka 消费数据，写往 ES，在 Spark Streaming 作业中会采集一些 metric 指标发往一个特定的 topic A。每次往 A 发送完数据后会调用 <code>producer.close()</code> 方法，看到的现象为：作业启动一段时间之后 hang 住，类似下图</p>
<img src="/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/hang_job.jpg" alt="hang_job.jpg" title="">
<h2 id="排查问题的过程"><a href="#排查问题的过程" class="headerlink" title="排查问题的过程"></a>排查问题的过程</h2><ol>
<li>看到现象后，知道作业 hang 住了，希望能找到为什么 hang 住。找到该作业的 executor 地址（如下图所示）</li>
</ol>
<img src="/2017/06/03/Streaming-程序调用-Producer-close-hang-住问题追查复盘/executor.jpg" alt="executor.jpg" title="">
<p>然后登录到机器上，通过 lsof 查看对应的进程，再通过 jstack dump 出具体的线程栈信息。由于第一次解决线程 hang 住的问题，得到栈信息后，暂时无从下手，然后 google <code>jvm 线程 hang 住</code> 等关键词，检查死锁 – 发现没有。</p>
<p>发现线程有 <code>RUNNABLE</code>，<code>WAITING</code>，<code>TIMED_WAITING</code> 等状态，然后一个个查看这些状态分别代表啥意思。到这就不知道怎么继续了 – 中间在 Spark Streaming 微信群里请教各路大神，有人说遇到链接关不掉的情况 – 多次重复查看 jstack 出来的信息，发现有一个 WAITING 线程在等待锁，具体如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">java.lang.Thread.State: WAITING (on object monitor)</div><div class="line">        at java.lang.Object.wait(Native Method)</div><div class="line">        - waiting on &lt;0x00000000c52cfba0&gt; (a org.apache.kafka.common.utils.KafkaThread)</div><div class="line">        at java.lang.Thread.join(Thread.java:1281)</div><div class="line">        - locked &lt;0x00000000c52cfba0&gt; (a org.apache.kafka.common.utils.KafkaThread)</div><div class="line">        at java.lang.Thread.join(Thread.java:1355)</div><div class="line">        at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:422)</div><div class="line">        at org.elasticsearch.hadoop.rest.KafkaProducer.close(DSLKafkaProducer.java:60)</div></pre></td></tr></table></figure>
<p>然后对照到代码，在 Producer.close() 中有一句代码如下 <code>ioThread.join()</code>，猜测是 ioThread 一直没有执行完毕导致的。</p>
<ol>
<li><p>注释掉 producer.close() 这一句代码之后，重新上线运行 Spark Streaming 作业，发现没有再次出现问题。大致确定问题出在 <code>producer.close()</code> 这里。但是不确定更深层次的问题是啥。期间猜测是由于 producer 发送数据的时候需要有 leader 确认（配置有关），然后将这个配置修改为无需 leader 确认立即返回，但是依然会导致作业 hang 住。然后阅读源码，发现 <code>producer.close()</code> 方法做了两件事：1）将还未发送出去的数据发送出去，2）等待正在发送的数据完成。暂时没有找到造成 <code>ioThread</code> 线程 hang 住的原因。暂时不知道具体 hang 住的地方在哪，至此暂时告一段落。</p>
</li>
<li><p>再次跟进该问题，尝试找出造成线程 hang 住的原因，尝试 jdb attach 到具体的线程。得到如下信息：</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">&gt; thread 0x1</div><div class="line">kafka-producer-network-thread | producer-12[1] where</div><div class="line">	  [1] sun.nio.ch.EPollArrayWrapper.epollWait (native method)</div><div class="line">	  [2] sun.nio.ch.EPollArrayWrapper.poll (EPollArrayWrapper.java:269)</div><div class="line">	  [3] sun.nio.ch.EPollSelectorImpl.doSelect (EPollSelectorImpl.java:79)</div><div class="line">	  [4] sun.nio.ch.SelectorImpl.lockAndDoSelect (SelectorImpl.java:87)</div><div class="line">	  [5] sun.nio.ch.SelectorImpl.select (SelectorImpl.java:98)</div><div class="line">	  [6] org.apache.kafka.common.network.Selector.select (Selector.java:328)</div><div class="line">	  [7] org.apache.kafka.common.network.Selector.poll (Selector.java:218)</div><div class="line">	  [8] org.apache.kafka.clients.NetworkClient.poll (NetworkClient.java:192)</div><div class="line">	  [9] org.apache.kafka.clients.producer.internals.Sender.run (Sender.java:191)</div><div class="line">	  [10] org.apache.kafka.clients.producer.internals.Sender.run (Sender.java:135)</div><div class="line">	  [11] java.lang.Thread.run (Thread.java:745)</div></pre></td></tr></table></figure>
<p>到这里暂时不知道该怎么继续往下查了，知道在这里 hang 住了，但是暂时不知道怎么继续往下查，看着屏幕发呆，然后想着这个问题或许别人也遇到过，就从上面的 栈信息 中抽取一部分关键词进行 google，得到信息在 kafka 0.8.2.1 中 producer.close() 在某些情况下会 hang 住，详情参考 <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-19+-+Add+a+request+timeout+to+NetworkClient" target="_blank" rel="external">KIP-19</a>，在 kafka 0.9.0.0 中提供一个带超时的 close 方法进行修复。</p>
<h2 id="问题复盘"><a href="#问题复盘" class="headerlink" title="问题复盘"></a>问题复盘</h2><ol>
<li><p>在知道作业 hang 住的情况，又不了解相应调试的情况下，能否快速了解定位问题的方法，能否询问其他人快速的定位问题，或者如何通过搜索引擎快速的获取自己需要的知识。这里自己有个小私心 – 觉得这是测试的作业，想保留现场，通过自己的努力完全把问题解决，好提升自己的能力。另外自己如何在平时积累一些查问题的经验（这次发现官方文档真是个好东西）</p>
</li>
<li><p>通过微信群询问是一个方法，但是提问需要有技巧，要能够提炼出自己的问题，以及自己进行了哪些尝试，有什么思考，而不是做伸手党。</p>
</li>
<li>为什么到最后才想着 Google 相关信息，而不是在知道 producer.close() 导致作业 hang 住的时候就 Google 相关信息。</li>
<li>对 Java 排查问题的工具非常不熟练，在平时需要自己模拟各种 case 进行练手。jstack, jvisualvm, jdb 等都是第一次使用，这些工具需要在平时进行熟练。</li>
<li>对常见的库或通用的写法要有一定的了解，比如看到 <code>org.apache.kafka.common.network.Selector.poll</code> 是否能想到没有超时而导致一直 hang 住，这些平时需要积累（思考这个怎么积累？）</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文作为一个问题追查过程的复盘记录，主要希望找出自己在解决问题中可以优化改进的地方。以后遇到问题，能够快速的进行定位，解决。&lt;/p&gt;
    
    </summary>
    
      <category term="实时计算" scheme="http://yoursite.com/categories/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
      <category term="复盘" scheme="http://yoursite.com/categories/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/%E5%A4%8D%E7%9B%98/"/>
    
      <category term="problem_solve" scheme="http://yoursite.com/categories/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/%E5%A4%8D%E7%9B%98/problem-solve/"/>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="spark_streaming" scheme="http://yoursite.com/tags/spark-streaming/"/>
    
      <category term="kafka" scheme="http://yoursite.com/tags/kafka/"/>
    
      <category term="thinking" scheme="http://yoursite.com/tags/thinking/"/>
    
      <category term="problem_solve" scheme="http://yoursite.com/tags/problem-solve/"/>
    
  </entry>
  
  <entry>
    <title>如何在不重启 Spark Streaming 作业的情况下，增加消费的 topic</title>
    <link href="http://yoursite.com/2017/06/01/%E5%A6%82%E4%BD%95%E5%9C%A8%E4%B8%8D%E9%87%8D%E5%90%AF-Spark-Streaming-%E4%BD%9C%E4%B8%9A%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8C%E5%A2%9E%E5%8A%A0%E6%B6%88%E8%B4%B9%E7%9A%84-topic/"/>
    <id>http://yoursite.com/2017/06/01/如何在不重启-Spark-Streaming-作业的情况下，增加消费的-topic/</id>
    <published>2017-06-01T15:22:51.000Z</published>
    <updated>2017-06-03T03:37:01.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文所有和 kafka 相关操作都基于 Direct 消费模式</p>
</blockquote>
<p>在 Spark Streaming 作业中，每个作业会消费一个或多个 topic，但是这些 topic 需要在作业启动之前确定好，在作业运行中不能进行调整，之前<a href="https://klion26.github.io/2016/11/01/spark-streaming-topic-partition-change-auto-adaptive/" target="_blank" rel="external">修改了源码</a>做到了自适应 topic partition 扩容的情况，但是无法动态调整消费的 topic。现在需要在不重启作业的情况下，动态调整消费的 topic。</p>
<a id="more"></a>
<h2 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h2><p>回顾之前自适应 partition 调整的方案，落到源码层面最终以 partition 为最小消费单元，而不是 topic。因此动态的调整消费的 topic 在理论上就是可行的 – 假设作业已经消费的 topic 为 A，在自适应 partition 扩容的时候，我们是增加了 A 的某些 partition，那么我们同样可以增加 B topic 的 partition，其中 B topic 是作业之前没有消费的。</p>
<p>动态调整 partition 的方案中，只需要将现在消费的 parition 数不断的对齐现在 kafka 上相应 topic 的 partition 数目即可。动态调整作业消费的 topic 则需要有一个地方存储作业消费的 topic 数目，然后将这个信息周期性的同步给作业即可 – 可以理解前者使用 kafka 作为存储介质，保存了 topic 的 partition 数目。</p>
<p>本方案中，选择 zookeeper 作业作为存储 topic 的介质。希望动态调整 topic 的时候，修改 zookeeper 中对应路径下的节点即可。然后作业定时的访问 zookeeper 的特定路径同步需要消费的 topic 数目即可。示意图如下</p>
<p><img src="https://c1.staticflickr.com/5/4275/34202432474_eb409ae6a5.jpg" alt=""></p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>方案确定了，直接修改下上次自适应 partition 扩容的代码即可 – 本方案只实现了增加 topic 的功能，当前消费的 topic 不会被删除，如果需要的话可以自行修改源码满足这一点。</p>
<p>在 <code>DirectKafkaInputStream</code> 的 <code>compute</code> 函数开始处添加如下逻辑</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">val topic = currentOffsets.head._1.topic</div><div class="line">var addedTopic : Set[String] = Set()</div><div class="line">val topics = getTopicsForJob()</div><div class="line">for (i &lt;- topics) &#123;</div><div class="line">      if (!i.equals(topic)) &#123;</div><div class="line">            addedTopic = addedTopic + i</div><div class="line">       &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">if (addedTopic.nonEmpty) &#123;</div><div class="line">     val topicLeaders = MTKafkaUtils.getPartitions(kafkaParams, addedTopic)</div><div class="line">     val largestOffset = MTKafkaUtils.getLeaderOffsets(kafkaParams, topicLeaders, OffsetRequest.LatestTime)</div><div class="line"></div><div class="line">     currentOffsets = currentOffsets ++ largestOffset</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>然后增加一个获取所有 topic 的函数，下面 Constants 包中使用了一些常量，自行替换即可</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">private def getTopicsForJob() : List[String] = &#123;</div><div class="line">        val jobName = SparkEnv.get.conf.get(Constants.JOB_PREFIXED_NAME_KEY)  //这个是提交 job 时添加的一个参数，用于区分每个作业，会当作 zk 中路径的一级</div><div class="line">        val zkHostPort: String =  &quot;xxxxxxxxx&quot;</div><div class="line">        val zkClient = new ZkClient(zkHostPort, Constants.DEFAULT_SESSION_TIMEOUT, Constants.DEFAULT_CONNECTION_TIMEOUT, new ZkOffsetSerializer) //ZkOffsetSerializer 自己实现了一个简单的序列化，反序列化类，就用了 String.getBytes 和 new String()</div><div class="line"></div><div class="line">        if (!zkClient.exists(s&quot;$&#123;Constants.ROOT_PATH_OF_MULTI_TOPIC_PER_JOB&#125;/$&#123;jobName&#125;&quot;)) &#123;</div><div class="line">									            ZkUtils.updatePersistentPath(zkClient, s&quot;$&#123;Constants.ROOT_PATH_OF_MULTI_TOPIC_PER_JOB&#125;/$&#123;jobName&#125;&quot;, s&quot;$&#123;jobName&#125;&quot;);</div><div class="line">														        &#125;</div><div class="line"></div><div class="line">        zkClient.getChildren(s&quot;$&#123;Constants.ROOT_PATH_OF_MULTI_TOPIC_PER_JOB&#125;/$&#123;jobName&#125;&quot;).asScala.toList</div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文所有和 kafka 相关操作都基于 Direct 消费模式&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在 Spark Streaming 作业中，每个作业会消费一个或多个 topic，但是这些 topic 需要在作业启动之前确定好，在作业运行中不能进行调整，之前&lt;a href=&quot;https://klion26.github.io/2016/11/01/spark-streaming-topic-partition-change-auto-adaptive/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;修改了源码&lt;/a&gt;做到了自适应 topic partition 扩容的情况，但是无法动态调整消费的 topic。现在需要在不重启作业的情况下，动态调整消费的 topic。&lt;/p&gt;
    
    </summary>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="spark_streaming" scheme="http://yoursite.com/tags/spark-streaming/"/>
    
      <category term="kafka" scheme="http://yoursite.com/tags/kafka/"/>
    
      <category term="zookeeper" scheme="http://yoursite.com/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>从源码级别分析 metric-core 的抽样算法</title>
    <link href="http://yoursite.com/2017/05/29/%E4%BB%8E%E6%BA%90%E7%A0%81%E7%BA%A7%E5%88%AB%E5%88%86%E6%9E%90-metric-core-%E7%9A%84%E6%8A%BD%E6%A0%B7%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2017/05/29/从源码级别分析-metric-core-的抽样算法/</id>
    <published>2017-05-29T09:45:22.000Z</published>
    <updated>2017-06-03T03:37:50.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://metrics.dropwizard.io" target="_blank" rel="external">metric-core</a> 是一个 java metric 库，用于统计 JVM 层面以及 服务级别 的各种 metric 信息。其中 metric-core 是其核心模块，代码量不多，总共 44 个文件，5700 行左右代码（包括注释）。算是一个很小的开源项目了。由于 metric 在所有项目中都非常重要，因此选择通读该项目，本文分析 metrci-core 中的抽样算法。</p>
<a id="more"></a>
<h2 id="metric-core-中的抽样算法"><a href="#metric-core-中的抽样算法" class="headerlink" title="metric-core 中的抽样算法"></a>metric-core 中的抽样算法</h2><p>在 metric-core 中总共有四种抽样算法，分别是 <code>ExponentiallyDecayingReservoir</code>, <code>SlidingTimeWindowReservoir</code>, <code>SlidingWindowReservoir</code>, <code>UniformReservoir</code>，其中后面三个抽样算法比较常规，也通常能见到，第一个则出于一篇论文<code>Forward Decay: A Practical Time Decay Model for Streaming Systems</code>，本文会通过源码分析自己对于这种抽样算法的理解。本文暂时只分析后面三种抽样算法，对于第一种，我会单独用一篇文章进行分析。</p>
<h3 id="UniformReservoir-算法"><a href="#UniformReservoir-算法" class="headerlink" title="UniformReservoir 算法"></a>UniformReservoir 算法</h3><p>该算法来自于论文<code>Random Sampling with a Reservoir</code>，讲述了一种随机抽样的方法，主要思想是使用一个固定的“蓄水池”装满需要数量的样本，如果当前“蓄水池”未满，将接下来的样本直接放入“蓄水池”，如果“蓄水池”已满，则随机从”蓄水池“中挑选一个样本进行替换（也可能不进行替换），这样在理论上能够保证所有的样本以同样的概率被选中。代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">public void update(long value) &#123;</div><div class="line">	final long c = count.incrementAndGet();//获得当前”蓄水池“的大小</div><div class="line">	if (c &lt;= values.length()) &#123; //如果”蓄水池“未满，直接将当前样本放入</div><div class="line">		values.set((int) c - 1, value);</div><div class="line">	&#125; else &#123;</div><div class="line">		final long r = nextLong(c);//随机挑选一个数据（这个随机挑选的数可能在&quot;蓄水池”中，也可能不在“蓄水池”中</div><div class="line">		if (r &lt; values.length()) &#123;//如果随机挑选的样本，在”蓄水池“中，则进行替换</div><div class="line">			values.set((int) r, value);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>为了能够更好的理解，先使用样例如下。假设现在总共来了 10 个数 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]，而“蓄水池“大小为 3. 那么”蓄水池”的 <strong>一种可能</strong> 变化如下（说是一种可能的变化，因为这里面牵涉到概率）</p>
<ul>
<li>[1]</li>
<li>[1, 2]</li>
<li>[1, 2, 3]</li>
<li>[1, 2, 4]  # 当 4 来的时候，发现“蓄水池”已满，然后从中筛选一个进行替换掉，假设我们替换掉 3</li>
<li>[1, 5, 4] # 当 5 来的时候，发现“蓄水池”已满，然后从中筛选一个进行替换掉，假设这次我们替换掉 2</li>
<li>[1, 5, 4] # 当 6 来的时候，发现“蓄水池”已满，我们打算从之前的数字中筛选一个进行替换，这个时候假设我们得到的下标是 3 或者 4，发现下标为 3 和 4 的数字不在“蓄水池”中（“蓄水池”的最大下标为 2 – 从 0 开始），因此不进行替换，所以本次“蓄水池”不变</li>
<li>[7, 5, 4] # 当 7 来的时候，发现“蓄水池”已满，随机一个下标，我们得到 0,那么将 7 放置到下标为 0 的位置</li>
<li>[8, 5, 4] # 同上</li>
<li>[8, 5, 9] # 同上</li>
<li>[10, 5, 9] # 同上<h3 id="SlidingWindowReservoir-抽样算法"><a href="#SlidingWindowReservoir-抽样算法" class="headerlink" title="SlidingWindowReservoir 抽样算法"></a>SlidingWindowReservoir 抽样算法</h3><code>SlidingWindowReservoir</code> 抽样算法则以最近的 N 个样本作为整个数据集的子集，这样简单直接，对于数据波动不大，或者窗口大小 N 足够大的情况下，该算法会有较好的效果。代码如下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">public synchronized void update(long value) &#123;//加锁保证线程安全</div><div class="line">	        //每次替换掉最旧的数据，保证”蓄水池“中的数据是最近的 N 个样本</div><div class="line">	        measurements[(int) (count++ % measurements.length)] = value;</div><div class="line">			    &#125;</div></pre></td></tr></table></figure>
<h3 id="SlidingTimeWindowReservoir-抽样算法"><a href="#SlidingTimeWindowReservoir-抽样算法" class="headerlink" title="SlidingTimeWindowReservoir 抽样算法"></a>SlidingTimeWindowReservoir 抽样算法</h3><p>该算法是上面移动窗口算法的变种，保留的是最近 N 时间单位（支持 TimeUnit 的所有时间单位）内的数据，而不是最近的 N 个数据。代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">public void update(long value) &#123;</div><div class="line">//每 TRIM_THRESHOLD 次操作之后会进行一次 trim() 操作</div><div class="line">	if (count.incrementAndGet() % TRIM_THRESHOLD == 0) &#123;</div><div class="line">		trim();</div><div class="line">	&#125;</div><div class="line">			        //直接将该值加入到 ”蓄水池“ 中</div><div class="line">	measurements.put(getTick(), value);</div><div class="line">	&#125;</div><div class="line">//获得当前的时间</div><div class="line">private long getTick() &#123;</div><div class="line">	for (; ; ) &#123;</div><div class="line">		final long oldTick = lastTick.get();</div><div class="line">		final long tick = clock.getTick() * COLLISION_BUFFER;</div><div class="line">		// ensure the tick is strictly incrementing even if there are duplicate ticks</div><div class="line">		final long newTick = tick - oldTick &gt; 0 ? tick : oldTick + 1;</div><div class="line">		if (lastTick.compareAndSet(oldTick, newTick)) &#123;</div><div class="line">			return newTick;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">private void trim() &#123;</div><div class="line">	measurements.headMap(getTick() - window).clear();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这三种算法中，第二种和第三种是大家都很容易想到的，实现起来也很简单，第一种进行简单推导也不难，也算是一种现成的算法“蓄水池抽样”。</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>如果某个系统每天会有 N 个人请求（N 不确定），需要从这些人中等概率的抽出 K 个中奖者，那么应该怎么做呢？是否可以使用上面抽样算法中的一种呢？</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://metrics.dropwizard.io&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;metric-core&lt;/a&gt; 是一个 java metric 库，用于统计 JVM 层面以及 服务级别 的各种 metric 信息。其中 metric-core 是其核心模块，代码量不多，总共 44 个文件，5700 行左右代码（包括注释）。算是一个很小的开源项目了。由于 metric 在所有项目中都非常重要，因此选择通读该项目，本文分析 metrci-core 中的抽样算法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="code" scheme="http://yoursite.com/tags/code/"/>
    
      <category term="metric" scheme="http://yoursite.com/tags/metric/"/>
    
      <category term="reservior" scheme="http://yoursite.com/tags/reservior/"/>
    
      <category term="metric-core" scheme="http://yoursite.com/tags/metric-core/"/>
    
  </entry>
  
  <entry>
    <title>Streaming 中 Receiver 相关源码分析</title>
    <link href="http://yoursite.com/2017/05/19/Streaming-%E4%B8%AD-Receiver-%E7%9B%B8%E5%85%B3%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2017/05/19/Streaming-中-Receiver-相关源码分析/</id>
    <published>2017-05-19T03:52:54.000Z</published>
    <updated>2017-06-03T03:58:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文基于 spark 1.6.2<br>本次的源码全来自 <code>org.apache.spark.streaming.receiver</code> 这个 package 下，包括 <code>BlockGenerator.scala</code>, <code>RateLimiter</code>, <code>ReceiverdBlock.scala</code>, <code>ReceivedBlockHandler.scala</code>, <code>Receiver.scala</code>, <code>ReceiverSupervisor.scala</code>, <code>ReceiverSupervisorImpl.scala</code></p>
<a id="more"></a>
<p>其中 <code>Receiver</code> 是所有接受数据的父类，主要定义一些接口，用户只需要继承 <code>Receiver</code>，然后实现其中的接口就行。</p>
<p><code>ReceiverSupervisor</code> 则是负责和协调 <code>Receiver</code> 和其他组件，定义了一些接口，然后 <code>ReceiverSupervisorImpl</code> 是 <code>ReceiverSupervisor</code> 的具体实现，主要实现了协调其他组件（包括 <code>ReceivedBlockHandler</code> 和 <code>BlockGenerator</code> <code>BlockGeneratorListener</code> 以及远端 RPC 服务等）和 <code>Receiver</code> 的逻辑。</p>
<p><code>BlockGenerator</code> 则主要负责接受 <code>Receiver</code> 接受到的数据，然后存储成 block（具体的有 <code>ReceivedBlockHandler</code> 负责），会起两个线程来做相应的事情，一个是定时的将接受到的数据生成 block，一个是将 block push 给 <code>ReceivedBlockHandler</code> 进行存储，具体的 block 管理则通过 Spark core 的 block 模块来进行管理。</p>
<p><code>ReceivedBlockHandler</code> 则负责将 block 保存到具体的地方，包括指定的 storageLevel 以及 write ahead log。</p>
<p>整个 Receiver 端的代码结构简化版如下所示，其中 Receiver 包含一个 ReceiverSupervisor 对象，ReceiverSupervisor 负责和 BlockGenerator 以及 ReceivedBlockHandler 交互。用户继承 Receiver，实现具体的接受数据的逻辑即可，对于数据接受之后，怎么处理，都通过 ReceiverSupervisor 中转给 BlockGenerator 来处理（BlockGenerator 会有一个定时器用于生成 block，还有一个单独的线程用于将生成的 block push 给 BlockManager）</p>
<img src="/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver_sample.png" alt="Receiver_sample.png" title="">
<p>整个 Receiver 端的详细代码结构图如下所示<br><img src="/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver.png" alt="Receiver.png" title=""></p>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><ol>
<li>为什么需要将 <code>Receiver</code> 和 <code>ReceiverSupervisor</code> 进行分开呢，下面提供这两个类的函数对比图（其中第一列表示 <code>Receiver</code> 的所有函数；后面几列表示 <code>ReceiverSupervisor</code> 的所有函数，同一行的函数表示有相<img src="/2017/05/19/Streaming-中-Receiver-相关源码分析/Receiver_ReceiverSupervisor.png" alt="Receiver_ReceiverSupervisor.png" title="">
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文基于 spark 1.6.2&lt;br&gt;本次的源码全来自 &lt;code&gt;org.apache.spark.streaming.receiver&lt;/code&gt; 这个 package 下，包括 &lt;code&gt;BlockGenerator.scala&lt;/code&gt;, &lt;code&gt;RateLimiter&lt;/code&gt;, &lt;code&gt;ReceiverdBlock.scala&lt;/code&gt;, &lt;code&gt;ReceivedBlockHandler.scala&lt;/code&gt;, &lt;code&gt;Receiver.scala&lt;/code&gt;, &lt;code&gt;ReceiverSupervisor.scala&lt;/code&gt;, &lt;code&gt;ReceiverSupervisorImpl.scala&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="分布式系统" scheme="http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="实时计算" scheme="http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
      <category term="源码阅读" scheme="http://yoursite.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="spark_streaming" scheme="http://yoursite.com/tags/spark-streaming/"/>
    
      <category term="receiver" scheme="http://yoursite.com/tags/receiver/"/>
    
      <category term="source_code" scheme="http://yoursite.com/tags/source-code/"/>
    
  </entry>
  
  <entry>
    <title>Python 代码实践小结</title>
    <link href="http://yoursite.com/2017/05/10/Python-%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5%E5%B0%8F%E7%BB%93/"/>
    <id>http://yoursite.com/2017/05/10/Python-代码实践小结/</id>
    <published>2017-05-10T03:59:21.000Z</published>
    <updated>2017-06-03T04:07:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近写了较多的 Python 脚本，将最近自己写的脚本进行一个总结，其中有些是 Python 独有的，有些是所有程序设计中共有的：</p>
<ol>
<li>考虑使用 Logger（logger 怎么配置，需要输出哪些信息 – 可以反向考虑，自己看到这个 logger 的时候想了解什么信息）</li>
<li>传递的数据结构如何考虑（是否对调用方有先验知识的要求，比如返回一个 Tuple，则需要用户了解 tuple 中元素的顺序，这样情况是否应该进行封装；），数据结构定义清楚了，很多东西也就清楚了。</li>
<li>如何操作数据库（可以学习 sqlalchemy，包括 core 和 orm 两种 api）</li>
<li>异常如何处理（异常应该分开捕获 – 可以清楚的知道什么情况下导致的，异常之后应该打印日志说明出现什么问题，如果情况恶劣需要进行异常再次抛出或者报警）</li>
<li>所有获取资源的地方都应该做 check（a. 没有获取到会怎么办；b.获取到异常的怎么办）</li>
<li>所有操作资源的地方都应该检查是否操作成功</li>
<li>每个函数都应该简短，如果函数过长应该进行拆分（有个建议值，函数包含的行数应该在 20-30 行之间，具体按照这个规范做过一次之后就会发现这样真好）</li>
<li>使用 class 之后，考虑重构 <code>__str__</code> 函数，用户打印输出，如果对象放到 collection 中之后，需要实现 <code>__repr__</code> 函数，用于打印整个 collection 的时候，直观显示（如果不实现 <code>__str__</code>，会调用 <code>__repr__</code>)</li>
<li>如果有些资源会发生变化，可以单独抽取出来，做成函数，这样后续调用就可以不用改变了</li>
</ol>
<p>上述总结肯定有片面的地方，也有不全的地方，欢迎指出</p>
<a id="more"></a>
<p>附上一份 Python2.7 代码（将一些私有的东西进行了修改）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div></pre></td><td class="code"><pre><div class="line"># -*- coding:utf-8 -*-</div><div class="line"></div><div class="line">from sqlalchemy import create_engine</div><div class="line">import logging</div><div class="line">from logging.config import fileConfig</div><div class="line">import requests</div><div class="line">import Clinet # 私有的模块</div><div class="line"></div><div class="line">fileConfig(&quot;logging_config.ini&quot;)</div><div class="line">logger = logging.getLogger(&quot;killduplicatedjob&quot;)</div><div class="line"></div><div class="line">#配置可以单独放到一个模块中</div><div class="line">DB_USER = &quot;xxxxxxx&quot;</div><div class="line">DB_PASSWORD = &quot;xxxxxxxx&quot;</div><div class="line">DB_PORT = 111111</div><div class="line">DB_HOST_PORT = &quot;xxxxxxxxxx&quot;</div><div class="line">DB_DATA_BASE = &quot;xxxxxxxxxxx&quot;</div><div class="line"></div><div class="line">REST_API_URL = &quot;http://sample.com&quot;</div><div class="line"></div><div class="line">engine = create_engine(&quot;mysql://%s:%s@%s:%s/%s&quot; % (DB_USER, DB_PASSWORD, DB_HOST_PORT, DB_PORT, DB_DATA_BASE))</div><div class="line"></div><div class="line"></div><div class="line"># 这个 class 是为了在函数间传递时，不需要使用方了解属性的具体顺序而写的，也可以放到一个单独的模块中</div><div class="line">class DuplicatedJobs(object):</div><div class="line">    def __init__(self, app_id, app_name, user):</div><div class="line">        self.app_id = app_id</div><div class="line">        self.app_name = app_name</div><div class="line">        self.user = user</div><div class="line"></div><div class="line">     def __repr__(self):</div><div class="line">        return &apos;[appid:%s, app_name:%s, user:%s]&apos; % (self.app_id, self.app_name, self.user)</div><div class="line"></div><div class="line"></div><div class="line">	def find_duplicated_jobs():</div><div class="line">		logger.info(&quot;starting find duplicated jobs&quot;)</div><div class="line">		(running_apps, app_name_to_user) = get_all_running_jobs()</div><div class="line">		all_apps_on_yarn = get_apps_from_yarn_with_queue(get_resource_queue())</div><div class="line"></div><div class="line">		duplicated_jobs = []</div><div class="line">		for app in all_apps_on_yarn:</div><div class="line">			(app_id, app_name) = app</div><div class="line"></div><div class="line">			if app_id not in running_apps:</div><div class="line">				if not app_name.startswith(&quot;test&quot;):</div><div class="line">					logger.info(&quot;find a duplicated job, prefixed_name[%s] with appid[%s]&quot; % (app_name, app_id))</div><div class="line">					user = app_name_to_user[app_name]</div><div class="line">					duplicated_jobs.append(DuplicatedJobs(app_id, app_name, user))</div><div class="line">	            else:</div><div class="line">				    logger.info(&quot;Job[%s] is a test job, would not kill it&quot; % app_name)</div><div class="line"></div><div class="line">	logger.info(&quot;Find duplicated jobs [%s]&quot; % duplicated_jobs)</div><div class="line"></div><div class="line">    return duplicated_jobs</div><div class="line"></div><div class="line"></div><div class="line">def get_apps_from_yarn_with_queue(queue):</div><div class="line">	param = &#123;&quot;queue&quot;: queue&#125;</div><div class="line">	r = requests.get(REST_API_URL, params=param)</div><div class="line">	apps_on_yarn = []</div><div class="line">	try:</div><div class="line">		jobs = r.json().get(&quot;apps&quot;)</div><div class="line">		app_list = jobs.get(&quot;app&quot;, [])</div><div class="line">		for app in app_list:</div><div class="line">			app_id = app.get(&quot;id&quot;)</div><div class="line">			name = app.get(&quot;name&quot;)</div><div class="line">			apps_on_yarn.append((app_id, name))</div><div class="line"></div><div class="line">	 except Exception as e: #Exception 最好进行单独的分开，针对每一种 Exception 进行不同的处理</div><div class="line">		logger.error(&quot;Get apps from Yarn Error, message[%s]&quot; % e.message)</div><div class="line"></div><div class="line">	logger.info(&quot;Fetch all apps from Yarn [%s]&quot; % apps_on_yarn)</div><div class="line"></div><div class="line">	return apps_on_yarn</div><div class="line"></div><div class="line"></div><div class="line">def get_all_running_jobs():</div><div class="line">	job_infos = get_result_from_mysql(&quot;select * from xxxx where xx=yy&quot;)</div><div class="line"></div><div class="line">	app_ids = []</div><div class="line">	app_name_to_user = &#123;&#125;</div><div class="line">	for (topology_id, topology_name) in job_infos:</div><div class="line">		status_set = get_result_from_mysql(&quot;select * from xxxx where xx=yy&quot;)</div><div class="line">		application_id = status_set[0][0]</div><div class="line">		if &quot;&quot; != application_id:</div><div class="line">			configed_resource_queue = get_result_from_mysql(&quot;select * from xxxx where xx=yy&quot;)</div><div class="line">			app_ids.append(application_id)</div><div class="line">	        app_name_to_user[topology_name] = configed_resource_queue[0][0].split(&quot;.&quot;)[1]</div><div class="line"></div><div class="line">	logger.info(&quot;All running jobs appids[%s] topology_name2user[%s]&quot; % (app_ids, app_name_to_user))</div><div class="line">	return app_ids, app_name_to_user</div><div class="line"></div><div class="line"></div><div class="line">def kill_duplicated_jobs(duplicated_jobs):</div><div class="line">	for job in duplicated_jobs:</div><div class="line">	app_id = job.app_id</div><div class="line">	app_name = job.app_name</div><div class="line">	user = job.user</div><div class="line">	logger.info(&quot;try to kill job[%s] with appid[%s] for user[%s]&quot; % (app_name, app_id, user))</div><div class="line">	try:</div><div class="line">		Client.kill_job(app_id, user)</div><div class="line">		logger.info(&quot;Job[%s] with appid[%s] for user[%s] has been killed&quot; % (app_name, app_id, user))</div><div class="line">	except Exception as e:</div><div class="line">		logger.error(&quot;Can&apos;t kill job[%s] with appid[%s] for user[%s]&quot; % (app_name, app_id, user))</div><div class="line"></div><div class="line"></div><div class="line">def get_result_from_mysql(sql):</div><div class="line">	a = engine.execute(sql)</div><div class="line">	return a.fetchall() </div><div class="line"></div><div class="line"></div><div class="line"># 因为下面的资源可能发生变化，而且可能包含一些具体的逻辑，因此单独抽取出来，独立成一个函数</div><div class="line">def get_resource_queue():</div><div class="line">	return &quot;xxxxxxxxxxxxx&quot;</div><div class="line"></div><div class="line">if __name__ == &quot;__main__&quot;:</div><div class="line">	kill_duplicated_jobs(find_duplicated_jobs())</div></pre></td></tr></table></figure>
<p>其中 logger 配置文件如下（对于 Python 的 logger，官方文档写的非常好，建议读一次，并且实践一次）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">[loggers]</div><div class="line">keys=root, simpleLogger</div><div class="line"></div><div class="line">[handlers]</div><div class="line">keys=consoleHandler, logger_handler</div><div class="line"></div><div class="line">[formatters]</div><div class="line">keys=formatter</div><div class="line"></div><div class="line">[logger_root]</div><div class="line">level=WARN</div><div class="line">handlers=consoleHandler</div><div class="line"></div><div class="line">[logger_simpleLogger]</div><div class="line">level=INFO</div><div class="line">handlers=logger_handler</div><div class="line">propagate=0</div><div class="line">qualname=killduplicatedjob</div><div class="line"></div><div class="line">[handler_consoleHandler]</div><div class="line">class=StreamHandler</div><div class="line">level=WARN</div><div class="line">formatter=formatter</div><div class="line">args=(sys.stdout,)</div><div class="line"></div><div class="line">[handler_logger_handler]</div><div class="line">class=logging.handlers.RotatingFileHandler</div><div class="line">level=INFO</div><div class="line">formatter=formatter</div><div class="line">args=(&quot;kill_duplicated_streaming.log&quot;, &quot;a&quot;, 52428800, 3,)</div><div class="line"></div><div class="line">[formatter_formatter]</div><div class="line">format=%(asctime)s %(name)-12s %(levelname)-5s %(message)s</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近写了较多的 Python 脚本，将最近自己写的脚本进行一个总结，其中有些是 Python 独有的，有些是所有程序设计中共有的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;考虑使用 Logger（logger 怎么配置，需要输出哪些信息 – 可以反向考虑，自己看到这个 logger 的时候想了解什么信息）&lt;/li&gt;
&lt;li&gt;传递的数据结构如何考虑（是否对调用方有先验知识的要求，比如返回一个 Tuple，则需要用户了解 tuple 中元素的顺序，这样情况是否应该进行封装；），数据结构定义清楚了，很多东西也就清楚了。&lt;/li&gt;
&lt;li&gt;如何操作数据库（可以学习 sqlalchemy，包括 core 和 orm 两种 api）&lt;/li&gt;
&lt;li&gt;异常如何处理（异常应该分开捕获 – 可以清楚的知道什么情况下导致的，异常之后应该打印日志说明出现什么问题，如果情况恶劣需要进行异常再次抛出或者报警）&lt;/li&gt;
&lt;li&gt;所有获取资源的地方都应该做 check（a. 没有获取到会怎么办；b.获取到异常的怎么办）&lt;/li&gt;
&lt;li&gt;所有操作资源的地方都应该检查是否操作成功&lt;/li&gt;
&lt;li&gt;每个函数都应该简短，如果函数过长应该进行拆分（有个建议值，函数包含的行数应该在 20-30 行之间，具体按照这个规范做过一次之后就会发现这样真好）&lt;/li&gt;
&lt;li&gt;使用 class 之后，考虑重构 &lt;code&gt;__str__&lt;/code&gt; 函数，用户打印输出，如果对象放到 collection 中之后，需要实现 &lt;code&gt;__repr__&lt;/code&gt; 函数，用于打印整个 collection 的时候，直观显示（如果不实现 &lt;code&gt;__str__&lt;/code&gt;，会调用 &lt;code&gt;__repr__&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;如果有些资源会发生变化，可以单独抽取出来，做成函数，这样后续调用就可以不用改变了&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上述总结肯定有片面的地方，也有不全的地方，欢迎指出&lt;/p&gt;
    
    </summary>
    
      <category term="语言学习" scheme="http://yoursite.com/categories/%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="计算机基础" scheme="http://yoursite.com/categories/%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="code" scheme="http://yoursite.com/tags/code/"/>
    
      <category term="logger" scheme="http://yoursite.com/tags/logger/"/>
    
  </entry>
  
  <entry>
    <title>从现在开始写作</title>
    <link href="http://yoursite.com/2017/04/15/%E4%BB%8E%E7%8E%B0%E5%9C%A8%E5%BC%80%E5%A7%8B%E5%86%99%E4%BD%9C/"/>
    <id>http://yoursite.com/2017/04/15/从现在开始写作/</id>
    <published>2017-04-15T04:07:32.000Z</published>
    <updated>2017-06-03T04:11:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>这里的写作不特指写长篇大论的文章</p>
<h2 id="为什么要写作"><a href="#为什么要写作" class="headerlink" title="为什么要写作"></a>为什么要写作</h2><blockquote>
<p>写作是了帮助自己更好的思考，提高自己的效率。</p>
</blockquote>
<p>首先，每个人同一时刻能记住的东西有限，而做一件事情可能需要考虑的条件往往会比较多，将所有的情况写到一张纸上，就能在需要的时候看到自己需要的条件。相信每个人都有这样的体验：做数学题的时候，将所有的已知条件，或者自己推导出来的结论写到草稿纸上，往往能更快的解出这道题目。这也是写作帮助自己思考的一个直接。</p>
<p>其次，我遇到过这种情况，自己想着是这么回事，可是写下来的时候，发现无从下笔，根本写不出来，写出来之后，也很难向别人清楚、准确的表达自己的意思。这归根结底还是没有思考清楚导致的，而写作可以帮助我整理自己的思路。</p>
<p>然后，当过客服的人肯定有一个体会，客服非常耗时间，而这些客服的问题大部分是差不多的，一对一的客服是非常低效的，就算在群组里面进行客服，其实很多后来遇到同样问题的人也是不看群历史记录（或者不知道以前有人遇到过类似的问题）的。这种情况下，虽然文档不是最优解，但能够省出自己足够多的时间，实际上这是一件杠杆率非常高（产出投入比高）的事件。</p>
<a id="more"></a>
<h2 id="写什么"><a href="#写什么" class="headerlink" title="写什么"></a>写什么</h2><p>既然明确了写作的目的，那么写什么也就清楚了。</p>
<ol>
<li><p>写对自己有用的东西</p>
<ul>
<li>读书笔记。看完一本书之后，可以写一个读书笔记，或者用思维导图整理书中内容，整理的过程是帮助自己加深书中思想印象的过程，可以帮助自己将整本书串起来，有一个全局的了解，也知道自己哪些地方暂时不太清楚。</li>
<li>自己解决问题的总结。总结可以帮助自己复盘 – 有复盘才有改进的方向；备忘。我曾经在公司内网上记录了自己解决某个问题的过程与解决方案，后来有不少遇到同样问题的同事联系我，每个人的问题相似，但每个人的问题又都不一样，解决别人的问题，实际上也能扩大自己的知识储备。</li>
<li>写教程 – 教是最好的学。在自己写教程的过程中，实际上也是自己再教自己一次相应的知识，对掌握的知识了解更深，对掌握不够的知识，去学习了解。</li>
<li>自己对某件事的思考过程。将自己的思考过程写下来，能够更好的了解自己是怎么考虑问题的，在哪些地方可以进行改善，哪些地方是自己没有考虑到的，能够帮助自己更好的提高思考质量。</li>
</ul>
</li>
<li><p>写对别人有用的东西</p>
</li>
</ol>
<blockquote>
<p>解决问题的思路和方案，以及教程对别人也是有用的。其他对别人有用的东西，暂时还在思考中。</p>
</blockquote>
<h2 id="怎么写"><a href="#怎么写" class="headerlink" title="怎么写"></a>怎么写</h2><blockquote>
<p>用笔写</p>
</blockquote>
<p>为什么写，以及写什么都考虑清楚之后，怎么写就不再是个问题了。如果你习惯写在纸质的本子上，那么买一个自己喜欢的本子，一只自己喜欢的笔，直接写就好了；如果你习惯使用电脑或者手机写，那么新建一个文件夹，在里面写就好了。</p>
<p>写的东西并不一定要公开，对于暂时不成熟的东西，或者私密的东西，保存在一个只有自己能看的地方就好了；对于成熟的东西，或者可以公开的东西，公开发表就好了。公开发表有一个好处，得到更多的反馈，这些反馈是非常利于自己进步的。</p>
<p>另外，有一个很简单的小技巧。自己维护一个素材记录本（可以是纸质的本子，可以是电子产品 – 建议购买正版），里面记录自己觉得不错的句子，例子，表达方式等等，偶尔翻一翻，或者打算写作的时候进行一下搜索。</p>
<h2 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h2><ol>
<li>写的不好怎么办  <blockquote>
<p>没有人一生下来就会吃饭吗？也没有人长大之后不会吃饭</p>
</blockquote>
</li>
<li>不知道怎么写开头怎么办<blockquote>
<p>如果不写开头的话，知道怎么写吗？知道的话，那就不要写开头了，为什么一定要写开头呢</p>
</blockquote>
</li>
<li>要写多少才合适呢<blockquote>
<p>没有一个统一的结论写多少才合适，只要能将自己想表达的东西讲清楚就行。写作最终受益的是自己，这不是在考试，不要为了凑字数而写。</p>
</blockquote>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里的写作不特指写长篇大论的文章&lt;/p&gt;
&lt;h2 id=&quot;为什么要写作&quot;&gt;&lt;a href=&quot;#为什么要写作&quot; class=&quot;headerlink&quot; title=&quot;为什么要写作&quot;&gt;&lt;/a&gt;为什么要写作&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;写作是了帮助自己更好的思考，提高自己的效率。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先，每个人同一时刻能记住的东西有限，而做一件事情可能需要考虑的条件往往会比较多，将所有的情况写到一张纸上，就能在需要的时候看到自己需要的条件。相信每个人都有这样的体验：做数学题的时候，将所有的已知条件，或者自己推导出来的结论写到草稿纸上，往往能更快的解出这道题目。这也是写作帮助自己思考的一个直接。&lt;/p&gt;
&lt;p&gt;其次，我遇到过这种情况，自己想着是这么回事，可是写下来的时候，发现无从下笔，根本写不出来，写出来之后，也很难向别人清楚、准确的表达自己的意思。这归根结底还是没有思考清楚导致的，而写作可以帮助我整理自己的思路。&lt;/p&gt;
&lt;p&gt;然后，当过客服的人肯定有一个体会，客服非常耗时间，而这些客服的问题大部分是差不多的，一对一的客服是非常低效的，就算在群组里面进行客服，其实很多后来遇到同样问题的人也是不看群历史记录（或者不知道以前有人遇到过类似的问题）的。这种情况下，虽然文档不是最优解，但能够省出自己足够多的时间，实际上这是一件杠杆率非常高（产出投入比高）的事件。&lt;/p&gt;
    
    </summary>
    
      <category term="我的生活" scheme="http://yoursite.com/categories/%E6%88%91%E7%9A%84%E7%94%9F%E6%B4%BB/"/>
    
      <category term="想清楚" scheme="http://yoursite.com/categories/%E6%88%91%E7%9A%84%E7%94%9F%E6%B4%BB/%E6%83%B3%E6%B8%85%E6%A5%9A/"/>
    
    
      <category term="写作" scheme="http://yoursite.com/tags/%E5%86%99%E4%BD%9C/"/>
    
      <category term="成长" scheme="http://yoursite.com/tags/%E6%88%90%E9%95%BF/"/>
    
  </entry>
  
</feed>
