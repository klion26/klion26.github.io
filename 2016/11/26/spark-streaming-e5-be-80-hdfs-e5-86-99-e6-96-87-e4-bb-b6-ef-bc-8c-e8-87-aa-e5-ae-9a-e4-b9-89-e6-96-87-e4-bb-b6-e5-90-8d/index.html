<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Spark Streaming 往 HDFS 写文件，自定义文件名 | Hexo</title>
  <meta name="author" content="John Doe">
  
  <meta name="description" content="需求将 kafka 上的数据实时同步到 HDFS，不能有太多小文件
实现过程Spark Streaming 支持 RDD#saveAsTextFile，将数据以 纯文本 方式写到 HDFS，我们查看 RDD#saveAsTextFile 可以看到
RDD.rddToPairRDDFunctions(">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Spark Streaming 往 HDFS 写文件，自定义文件名"/>
  <meta property="og:site_name" content="Hexo"/>

  
    <meta property="og:image" content="undefined"/>
  

  
  
    <link href="/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/css/themes/bootstrap.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  



</head>

 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/">Hexo</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header page-header-inverse ">		
			<h1 class="title title-inverse "> Spark Streaming 往 HDFS 写文件，自定义文件名</h1>
		</div>		
	






<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  		

	  <div class="markdown-body">

<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>将 kafka 上的数据实时同步到 HDFS，不能有太多小文件</p>
<h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><p>Spark Streaming 支持 RDD#saveAsTextFile，将数据以 <strong>纯文本</strong> 方式写到 HDFS，我们查看 RDD#saveAsTextFile 可以看到</p>
<pre><code>RDD.rddToPairRDDFunctions(r)(nullWritableClassTag, textClassTag, null)
      .saveAsHadoopFile[TextOutputFormat[NullWritable, Text]](path)
`&lt;/pre&gt;
从上面这句话我们可以知道，首先将 RDD 转化为 PariRDD（PariRDD 的数据是 (K,V) 类型的），然后再调用 saveAsHadoopFile 函数进行实际的操作。上面的语句中 `r` 是原始 RDD，`nullWritableClassTag` 和 `textClassTag` 表示所写数据的类型（分别代表 PariRDD 的 K 和 V 的类型），使用 `nullWritableClassTag` 是因为 HDFS 不会将 PairRDD 的 key 进行实际写入，从效果上看就只写入了 PariRDD 的 V 字段。`TextOutputFormat` 是一个格式化函数，后面我们再来看这个函数，`NullWritable` 则表示一个占位符，同样是这个字段不需要实际写入 HDFS，`Text` 表示我们将写入文本类型的数据。

我们看到 `TextOutputFormat` 这个类中有一个函数是 `RecordWriter` 用于操作没一条记录的写入，代码如下
&lt;pre&gt;`public RecordWriter&lt;K, V&gt; getRecordWriter(FileSystem ignored, JobConf job, String name, Progressable progress) throws IOException {
        boolean isCompressed = getCompressOutput(job);
        String keyValueSeparator = job.get(&quot;mapreduce.output.textoutputformat.separator&quot;, &quot;\t&quot;);
        if(!isCompressed) {
            Path codecClass1 = FileOutputFormat.getTaskOutputPath(job, name);
            FileSystem codec1 = codecClass1.getFileSystem(job);
            FSDataOutputStream file1 = codec1.create(codecClass1, progress);
            return new TextOutputFormat.LineRecordWriter(file1, keyValueSeparator);
        } else {
            Class codecClass = getOutputCompressorClass(job, GzipCodec.class);
            CompressionCodec codec = (CompressionCodec)ReflectionUtils.newInstance(codecClass, job);
            Path file = FileOutputFormat.getTaskOutputPath(job, name + codec.getDefaultExtension());
            FileSystem fs = file.getFileSystem(job);
            FSDataOutputStream fileOut = fs.create(file, progress);
            return new TextOutputFormat.LineRecordWriter(new DataOutputStream(codec.createOutputStream(fileOut)), keyValueSeparator);
        }
    }
</code></pre><p></p></div><br>从上面的代码中我们可以的知道，首先打开需要的文件，获得对应的 Stream，然后直接往里面写数据就行了。接下来我们需要做还有：1）自定义文件名；2）往文件追加数据<p></p>
<p>而这两个需求都可以在 RecordWriter 中进行实现。</p>
<p>对于自定义文件名，重写下面这句话就行了</p>
<p><pre class="lang:default decode:true">Path codecClass1 = FileOutputFormat.getTaskOutputPath(job, name);</pre><br>其中 name 就是文件名，我们自定义 name 就 OK 了</p>
<p>如果希望往文件追加数据的话（不然会有很多小文件）：</p>
<p>我们可以在获取文件流的时候，传入已经存在的文件，然后往里面追加就行了。而且将 creat 函数换成 append 即可，具体参考下面的代码：</p>
<p><pre class="lang:default decode:true  ">override def getRecordWriter(ignored: FileSystem, job: JobConf, name: String, progress: Progressable): RecordWriter[K, V] = {<br>        val isCompressed: Boolean = FileOutputFormat.getCompressOutput(job)<br>        val keyValueSeparator: String = job.get(“mapreduce.output.textoutputformat.separator”, “\t”)<br>        val iname = name + System.currentTimeMillis() / HDFSService.getBatchInteral<br>        if (!isCompressed) {<br>            val file: Path = FileOutputFormat.getTaskOutputPath(job, iname)<br>            val fs: FileSystem = file.getFileSystem(job)<br>            val newFile : Path = new Path(FileOutputFormat.getOutputPath(job), iname)<br>            val fileOut : FSDataOutputStream = if (fs.exists(newFile)) {<br>                fs.append(newFile)<br>            } else {<br>                fs.create(file, progress)<br>            }<br>            new TextOutputFormat.LineRecordWriter<a href="fileOut, keyValueSeparator">K, V</a><br>        } else {<br>            val codecClass: Class[_ &lt;: CompressionCodec] = FileOutputFormat.getOutputCompressorClass(job, classOf[GzipCodec])<br>            // create the named codec<br>            val codec: CompressionCodec = ReflectionUtils.newInstance(codecClass, job)<br>            // build the filename including the extension<br>            val file: Path = FileOutputFormat.getTaskOutputPath(job, iname + codec.getDefaultExtension)<br>            val fs: FileSystem = file.getFileSystem(job)<br>            val newFile : Path = new Path(FileOutputFormat.getOutputPath(job), iname + codec.getDefaultExtension)</pre></p>
<pre><code>        val fileOut: FSDataOutputStream = if (fs.exists(newFile)) {
            fs.append(newFile)
        } else {
            fs.create(file, progress)
        }
        new TextOutputFormat.LineRecordWriter[K, V](new DataOutputStream(codec.createOutputStream(fileOut)), keyValueSeparator)
    }
}&lt;/pre&gt;
</code></pre><p>&nbsp;</p>
	  
	</div>

	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
				
    	<li class="prev"><a href="/2016/12/02/spark-streaming-consume-kafka-message-from-specify-timestamp/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i>Prev</a></li>
  		

        <li><a href="/archives"><i class="fa fa-archive"></i>Archive</a></li>

		
		   <li class="next"><a href="/2016/11/01/spark-streaming-topic-partition-change-auto-adaptive/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a></li>         
        
	
</ul>
</div>

    </center>
	</div>

    <!-- share -->
    
        
    <div class="bdsharebuttonbox">
        <a href="#" class="bds_more" data-cmd="more"></a>
        <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
        <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
        <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
        <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
        <a href="#" class="bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
        <a href="#" class="bds_evernotecn" data-cmd="evernotecn" title="分享到印象笔记"></a>
        <a href="#" class="bds_youdao" data-cmd="youdao" title="分享到有道云笔记"></a>
        <a href="#" class="bds_copy" data-cmd="copy" title="分享到复制网址"></a>
    </div>
    <script>
        window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{}};
        with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
    </script>


        

    
	
	<!-- comment -->
	
<section id="comment">
  <h2 class="title">Comments</h2>

  
</section>

	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2016-11-26 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/分布式系统/">分布式系统<span>8</span></a></li> <li><a href="/categories/分布式系统/实时计算/">实时计算<span>4</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/spark/">spark<span>3</span></a></li> <li><a href="/tags/spark-streaming/">spark-streaming<span>7</span></a></li> <li><a href="/tags/append/">append<span>2</span></a></li> <li><a href="/tags/hdfs/">hdfs<span>2</span></a></li>
    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->



	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2017 John Doe
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>

</body>
   </html>
